docstring_tokens
this is a special variant of the send message that will halt a tutor until a response is received . it will time out after a set amount of time .
starts the tutor in event - driven mode .
constructor . creates an empty accelerator lattice .
method . initializes the lattice and child node structures .
method . returns the initialization status ( true or false ) .
method . adds a child node into the lattice . if the user specifies the index > = 0 the element will be inserted in the specified position into the children array
method . returns a list of all children of the first level in the lattice .
method . set up a new list of all children of the first level in the lattice .
method . returns the node with certain name .
method . returns nodes with a certain name .
method . returns nodes off a certain class .
method . returns nodes with names each of them has the certain substring . it is also possible to specify the unwanted substring as no_sub parameter .
method . returns the index of the node in the upper level of the lattice children - nodes .
"method . returns a dictionary of { node:(start position , stop position ) } tuples for all children of the first level in the lattice ."
method . returns the physical length of the lattice .
this method is used for a lattice reversal and a bunch backtracking . this method will reverse the order of the children nodes . it will apply the reverse recursively to the all children nodes .
returns the text with the lattice structure .
"it returns the sub - accelerator lattice with children with indexes between index_start and index_stop , inclusive . the subclasses of acclattice should not override this method ."
it returns the sub - accelerator lattice with children with indexes between index_start and index_stop inclusive . the subclasses of acclattice should override this method to replace acclattice ( ) constructor by the sub - class type constructor
method . tracks the actions through all nodes in the lattice . the indexes are inclusive .
constructor . creates the statlats teapot element .
the statlats - teapot class implementation of the accnodebunchtracker class track(probe ) method .
constructor . creates the statlats teapot element .
the statlats - teapot class implementation of the accnodebunchtracker class track(probe ) method .
constructor . creates the statlats teapot element .
the moments - teapot class implementation of the accnodebunchtracker class track(probe ) method .
constructor . creates the moments teapot element .
the moments - teapot class implementation of the accnodebunchtracker class track(probe ) method .
constructor . creates the statlats teapot element .
the bunchtuneanalysis - teapot class implementation of the accnodebunchtracker class track(probe ) method .
constructor . creates the statlats teapot element .
the bunchtuneanalysis - teapot class implementation of the accnodebunchtracker class track(probe ) method .
start consuming the stream
add a new rule
remove a rule by tag
factory method to get a stream object
get settings object with monthly limit info
getter for the custom named ' continuation ' object .
"iterator interface , self is an iterator"
"iterator interface , returns the next ' page '"
alias for _ _ next _ _
returns an iterator for each item in each page
creates a new section in a project .
returns the compact records for all sections in the specified project .
returns the complete record for a single section .
"a specific , existing section can be updated by making a put request on the url for that project . only the fields provided in the ` data ` block will be updated ; any unspecified fields will remain unchanged . ( note that at this time , the only field that can be updated is the ` name ` field . )"
"a specific , existing section can be deleted by making a delete request on the url for that section ."
move sections relative to each other in a board view . one of ` before_section ` or ` after_section ` is required .
returns the full record for a single team .
returns the compact records for all teams in the organization visible to the authorized user .
returns the compact records for all teams to which user is assigned .
returns the compact records for all users that are members of the team .
the user making this call must be a member of the team in order to add others . the user to add must exist in the same organization as the team in order to be added . the user to add can be referenced by their globally unique user id or their email address . returns the full user record for the added user .
the user to remove can be referenced by their globally unique user id or their email address . removes the user from the specified team . returns an empty data record .
"returns string representations of two polynomials : 1 ) a circle with radius r centered at ( a , b ) ; 2 ) a line through the origin with slope s."
"given in pols the polynomials for the line intersecting a circle for a general slope s , solves the problem for a special numerical value for s , given in the slope . the value of the slope is added as last coordinate to each solution ."
we have two equations in three variables in pols and therefore we expect a one dimensional set .
"given a witness sets in the tuple witset , runs a membership test on a solution ."
"generates the system and its witness set . as a sanity check , a membership test is done . returns the witness set for a fixed circle intersect with a one parameter family of lines as a tuple of polynomials and solutions"
returns a random complex number on the unit circle .
"returns a linear equation in the variables in the list vars , with random complex coefficients ."
"returns the equations which define the points where the jacobian matrix is singular , as a random linear combination of the columns . random complex coefficients are generated to scale the multiplier variables ."
"to each solution in sols , adds l1 and l2 with values 1 , and zz2 and zz3 with values zero ."
"extends the witness set with two free variables l1 and l2 , addition two linear equations , and two slack variables zz2 and zz3 ."
"we have three equations in pols in five variables : x , y , s , l1 , and l2 . therefore we expect a two dimensional set ."
"to the string pol , adds the sequence of symbols ."
applies the diagonal homotopy to intersect two witness sets w1 and w2 of dimensions w1d and w2d in a space of dimension dim .
generates a witness set for the singular locus of the algebraic set of a fixed circle intersected with a one parameter family of lines .
"given a solution , return the 3 - tuple with the x and y coordinates of the tangent point and the slope of the tangent line . the real parts of the coordinates are selected ."
"plots the circle with radius 1 , centered at ( 3 , 2 ) , along with a line with slope one through ( 0 , 0 ) ."
"plots the circle with radius 1 , centered at ( 3 , 2 ) , along with its two lines tangent through ( 0 , 0 ) . the two solutions sol1 and sol2 define 3 - tuples of x and y coordinates and a slope ."
makes a matplotlib figure with a general configuration and the tangent lines defined by sol1 and sol2 .
defines two witness sets and intersects them .
return a server_version_info tuple .
construct a : class:` . json ` type .
optional inlined form of add ( ) which can assume item is n't present in the map
return true if any instancestates present have been marked as ' modified ' .
"prune unreferenced , non - dirty states ."
constructor @repo_id : repository i d @training data : all commits that we are training the models on @testing data : all commits that we are testing the models on ( i.e. glm model )
builds all models and stores them in the metrics table
dumps all commit data into the monthly dataset folder . dataset names after repository i d
"fetchallmetrics ( ) iterate through each commit storing each individual 's metrics into the metrics object , to hold all metrics information necessary to build models . @private"
check if any repo needs to be ingested
checks if any repo needs to be analyzed
check if any repo needs metrics to be generated
checks if any repo is awaiting to build model . we are using a queue because we ca n't concurrently access r
send e - mail notifications if applicable to a repo used by checkbuildmodel
"d.pop(k[,d ] ) - > v , remove specified key and return the corresponding value . if key is not found , d is returned if given , otherwise keyerror is raised ."
"adds a ( name , value ) pair , does n't overwrite the value if it already exists ."
generic import function for any type of header - like object . adapted version of mutablemapping.update in order to insert items with self.add instead of self.__setitem _ _
returns a list of all the values for the named field . returns an empty list if the key does n't exist .
"iterate over all header lines , including duplicate ones ."
"iterate over all headers , merging duplicate ones together ."
read headers from a python 2 httplib message object .
reset num_401_calls counter on redirects .
"takes the given response and tries digest - auth , if needed ."
retrieve the current time . this function is mocked out in unit testing .
check that a timeout attribute is valid .
create a new timeout from a legacy timeout value .
create a copy of the timeout object
"start the timeout clock , used during a connect ( ) attempt"
gets the time elapsed since the call to : meth:`start_connect ` .
get the value to use when setting a connection timeout .
get the value for the read timeout .
"authurl is a random url on the server that is protected by ntlm . user is the windows user , probably in the domain\username format . pw is the password for the user ."
"make a request using : meth:`urlopen ` with the ` ` fields ` ` encoded in the url . this is useful for request methods like get , head , delete , etc ."
generator which traverse through object by fields ( every field is deeper by one level )
"reset analyser , clear any state"
feed a character with known length
return confidence based on existing data
"all arguments except for server_hostname , ssl_context , and ca_cert_dir have the same meaning as they do when using : func:`ssl.wrap_socket ` ."
create flask application and attach taxii server instance ` ` server ` ` to it .
chart plotter . the background message cycle is filtered out . reads until ctrl - c.
gps . displays selected messages until some limit is reached .
creates new flask application
parse cmd line arguments
create http server
server will start a new thread and listen for incoming connections
create web server
starts the web server in own thread
main method that collects the bgp router - id from the spine switches using the native model
main method that prints netconf capabilities of remote device .
main method that adds loopback interfaces and configures an ip address to both the spine switches .
returns a collection of image objects ordered by ' position ' value .
adds ' preview_url_pattern ' attribute to the formset object . the attribute contains the pattern of url used by javascript code to get data of new added image to show its preview .
adds extra url pattern for getting data of images . used by javascript code in inline admin for new added images .
a view that returns data of an image object .
a str version of the object just returns the value of its text field
empties all knowledge models .
add the given statements to the given model .
remove the given statements from the given model .
"add the given statements to the given model , updating the statements with a functional predicate ."
returns all statements involving the resource .
returns true if the statements or partial statements are present in the knowledge models .
returns the rdf classes of the concept .
"do some checks on the light curves supplied to the method , and then calculate the time shifts , time lags and cross correlation ."
"calculate the cross correlation against all possible time lags , both positive and negative ."
plot the : class:`crosscorrelation ` as function using matplotlib . plot the crosscorrelation object on a graph ` ` self.time_lags ` ` on x - axis and ` ` self.corr ` ` on y - axis
the description / announcement of the project
the date / time when the project was marked as completed
the unique id of the project
true if the project is marked as completed and false otherwise
the name of the project
true to show the announcement / description and false otherwise
"the suite mode of the project ( 1 for single suite mode , 2 for single suite + baselines , 3 for multiple suites ) ( added with testrail 4.0 )"
the address / url of the project in the user interface
test that the api will return a boot action context
test that the api will return a 404 for unknown node
test that the api will return a boot action context
test that the api will return a boot action context
add a task and boot action to the database for testing .
create a test harness for the the falcon api framework .
check if this driver support a particular oob type .
run self.action.start ( ) in this thread .
authmiddleware is expected to correctly identify the headers added to an authenticated request by keystonemiddleware in a pastedeploy configuration
"authmiddleware is expected to correctly identify the headers added to an unauthenticated ( no token , bad token ) request by keystonemiddleware in a pastedeploy configuration"
test that a result message for a task can be added .
add dummy task to test against .
add a validation message to the result list .
object initializer .
invoke execution of this action .
object initializer .
invoke execution of this action .
object initializer .
invoke execution of this action .
parse the physical stat csv file given it 's path .
dispatch incoming requests to the correct handler .
helper function to retrieve a playlist from its unique mpd name .
helper function to retrieve the unique mpd playlist name from its uri .
browse the contents of a given directory path .
mpd error code format : :
helper to allow calling of audio listener events
called whenever the end of the audio stream is reached .
called whenever the audio stream changes .
called whenever the position of the stream changes .
called after the playback state have changed .
called whenever the current audio stream 's tags change .
"start a node with requested rpcallowip and rpcbind parameters , then try to connect , and check if the set of bound addresses matches the expected set ."
"start a node with rpcwallow ip , and request getinfo at a non - localhost ip ."
": param fobj : either an integer fileno , or an object supporting the usual : meth:`socket.fileno ` method . the file * will * be put in non - blocking mode using : func:`gevent.os.make_nonblocking ` . : keyword str mode : the manner of access to the file , one of "" rb "" , "" ru "" or "" wb "" ( where the "" b "" or "" u "" can be omitted ) . if "" u "" is part of the mode , io will be done on text , otherwise bytes . : keyword int bufsize : if given , the size of the buffer to use . the default value means to use a platform - specific default other values are interpreted as for the : mod:`io ` package . buffering is ignored in text mode ."
convert raw data into a dictionary with plot - type specific methods .
base method for plotting data and images .
base method for updating data .
base method for appending data .
base method for retrieving user data from a viz .
check and parse a property with either a specific checking function or a generic parser
"check and parse coordinates as either a single coordinate list [ [ r , c],[r , c ] ] or a list of coordinates for multiple regions [ [ [ r0,c0],[r0,c0 ] ] , [ [ r1,c1],[r1,c1 ] ] ]"
"check and parse color specs as either a single [ r , g , b ] or a list of [ [ r , g , b],[r , g , b ] ... ]"
check if cmap is one of the colorbrewer maps
"check and parse size specs as either a single [ s ] or a list of [ s , s , s , ... ]"
"check and parse thickness specs as either a single [ s ] or a list of [ s , s , s , ... ]"
"checks and parses an index spec , must be a one - dimensional array [ i0 , i1 , ... ]"
"check and parse alpha specs as either a single [ a ] or a list of [ a , a , a , ... ]"
"check and parse a one - dimensional spec as either a single [ x ] or a list of [ x , x , x ... ]"
"given a list of pairs of points which define a polygon , return a binary mask covering the interior of the polygon with dimensions dim"
"given a list of pairs of points which define a polygon , return a list of points interior to the polygon"
create a new fragment .
append any positional arguments as child nodes .
append an element or string as child node .
return a markup event stream for the fragment .
"append any positional arguments as child nodes , and keyword arguments as attributes ."
"create the factory , optionally bound to the given namespace ."
create a fragment that has the given positional arguments as child nodes .
return a new factory that is bound to the specified namespace .
create an ` element ` with the given name .
"return a copy of a title , with references , images , etc . removed ."
parse a table block and build table .
"given a row of text , build table cells ."
split a row of text into list of cells .
add an instance of tableprocessor to blockparser .
return module with language localizations .
create the exception .
create the template laoder .
load the template with the given name .
instantiate and return the ` template ` object based on the given class and parameters .
loader factory for loading templates from a local directory .
loader factory for loading templates from egg package data .
factory for a load function that delegates to other loaders depending on the prefix of the requested template path .
initial setup for in - place document transforms .
"store each component 's default transforms , with default priorities . also , store components by type name in a mapping for later lookup ."
return unicode representation of ` self.data ` .
": parameters : - ` stream ` : a file - like object , a string ( path to a file ) , ` none ` ( write to ` sys.stderr ` , default ) , or evaluating to ` false ` ( write ( ) requests are ignored ) . - ` encoding ` : ` stream ` text encoding . guessed if none . - ` encoding_errors ` : how to treat encoding errors ."
"write ` data ` to self.stream . ignore , if self.stream is false ."
close the error - output stream .
verify that a code block with trailing space does not cause a syntax error ( see ticket # 127 ) .
replace superscript with superscriptpattern
"attempts to determine an image 's width and height , and returns a string suitable for use in an < img > tag , or an empty string in case of failure . requires that pil is installed ."
redis_connection can be overriden by a mock object .
hijack the main loop from the original thread and listen on events on the redis and the websocket filedescriptors .
ensure we have list - type views in exact places .
ensure we have good links to all the reports .
test that the admin dashboard is passed some upcoming_events in the context .
make sure we do n't display stalled or completed events on the dashboard .
make new host : self - organized .
"find all events that were self - organized and set administrator for them to be "" self - organized "" ."
replace ' . ' with ' _ ' in every username .
test submitting a minimalistic form ends up in event.invoicerequest_set .
test if invoicerequest long status representation is fine .
generate slug from date and venue .
populate the languages table .
a ' do n't know yet ' knowledgedomain is required for eventrequest forms .
set invoice status for historical ( < 2014 ) events .
set invoice status for historical ( < 2014 ) events .
check that ` pydata.urls ` is included in amy.urls
check that ` pydata.urls ` is included before ` workshops.urls `
test if the form shows correct fields .
test if the submitted form adds a new event submission .
test if the submitted form results in email sent .
ensure none of the above persons are in ` switched_persons ` .
ensure none of the above persons are in ` duplicate_persons ` .
from : https://github.com/pytorch/examples/blob/409a7262dcfa7906a92aeac25ee7d413baa88b67/imagenet/main.py#l108-l113 https://github.com/pytorch/examples/blob/409a7262dcfa7906a92aeac25ee7d413baa88b67/imagenet/main.py#l94-l95
convert name to proper python constant format
create a singlebytecharsetmodel object representing the charset .
convert old singlebytecharsetmodels for the given language
temporarily store a voice clip fn .
"calculate padded bmp line and file length from octets / pixel value , width and height ."
test whether we have a working convert binary .
loaded before installing the module .
loaded after installing the module .
loaded before uninstalling the module .
loaded before any model or data has been initialized .
: param list extra_attrs : string names of extra attributes that may exist on the log record .
super this in your subclass to format the record into a dict
import data from teller.io
initialize tutorial form fields
wrapper that switches to provided form
overridden to switch back to main form
overridden to add handlers and content
"when user clicks cancel , will return to main"
"when user clicks ok , will proceed to next tutorial"
test the options function
test the option function
test the add_option function
test the del_option function
test the del_section function
test the set_option function
test the cores function
test the repo_branches function
test the repo_commits function
test the repo_tools function
test the tools_status function
initialize inventory form objects
override method for creating formbasenew form
send a post request with id / nic / interval / filter / iters and it will start a container for collection with those specifications
create widgets for addform
add the repository
return extra error context info .
"return filename , if relevant ."
apply transformation to all text nodes within node .
strip curly brackets from text .
convert ' \url { ... } ' into a proper docutils hyperlink .
transform each : class:`~sphinxcontrib.bibtex.nodes.bibliography ` node into a list of citations .
returns the linearforwardproblem that defines the inverse problem .
run the iterative method starting from the initial point x0 .
add an object to be called after each iteration .
called during each iteration with the pertinent computations . handy for debugging and visualization .
this method is a hook called at the beginning of a run . it gives an opportunity for the class to set up information needed to decide conditions for the final stopping criterion .
"this method is a hook called at the end of a run , and gives the class a way to make adjustments to x and y before finishing the run ."
"given a current iteration number , current value of x , desired value y of f(x ) , and current residual , returns whether the stop condition has been met ."
returns the linearforwardproblem that defines the inverse problem .
run the iterative method starting from the initial point x0 .
this method is a hook called at the beginning of a run . it gives an opportunity for the class to set up information needed to decide conditions for the final stopping criterion .
"given a current iteration number , current value of x , desired value y of f(x ) , and current residual , returns whether the stop condition has been met ."
run the iterative method starting from the initial point x0 .
"given a current iteration number , current value of x , desired value y of f(x ) , and current residual , returns whether the stop condition has been met ."
filter function to remove builders that require a certain filetype other than the filetype of the current buffer .
builds a status string from a build
run the build command using a subprocess call
special static method that 's automatically called by python when constructing a new instance of this class .
called while initializing this instance in _ _ new _ _
capture the superset of all constraint names
"generate the tuple that represents the constraint e.g. : for the constraint : mode=0 easz=1 the tuple is ( 0,1 ) if a rule does not have constraint over certain operand then we splatter all the possible values"
generate the int value of each tuple . we shift each element by the number of bits that the previous element took
create new cvg that contains only the tuples in the input
return true if there are no constraints
return the full function in order to access the operand given in cname
return the pattern for the give tuple
try to resolve conflicts by applying the conflict resolution functions defined in _ resolution_functions list .
compute l1(conflict resolution ) functions list and eosz lookup tables dict . @param agi : all generators info
return true / false if info list conflicts on eosz resolution function ( eosz nt sequence ) .
write to stderr
write to msgout
write to msgout
write to msgout
write to msgout
"return a tuple of ( vmsize , vmrss , vmdata ) on linux systems with /proc filesystems ."
"take a list with some possible sublists , and return a list of lists of flat lists . all possible combinations ."
"take a dict with some possible sublists , and return a list of dicts where no rhs is a list . all possible combinations"
make a directory if it does not exist
convert a bit string to hex
"take a decimal integer , and return a list of bits msb to lsb"
"take a hex number , no 0x prefix required , and return a list of bits msb to lsb"
return a string of 1s and 0s . could return letter strings as well
"accept a bit list . return a list tuples ( letter , count ) describing bit runs , the same bit repeated n times"
return true if fld exists in obj
return a dictionary whose values are dictionaries of all the values that the operand decider might have
"make a test message with a certain number of records . the test message contains a template with numeric , datetime , address , and string information elements , using both normal and reduced - length encoding ."
get a messagestreamwriter for a given stream
sets the observation domain for subsequent messages sent with this writer .
add a template to this writer . adding a template makes it available for use for exporting records ; see : meth:`set_export_template ` .
set the template to be used for export by subsequent calls to : meth:`export_namedict ` and : meth:`export_tuple ` .
"export a record to the message , using the current template the record is a dictionary mapping ie names to values . the dictionary must contain a value for each ie in the template . keys in the dictionary not in the template will be ignored ."
export an in - progress message immediately .
get a messagestreamreader for a given stream
"iterate over all records in the stream , as dicts mapping ie names to values ."
iterate over all records in the stream containing all the ies in the given ielist . records are returned as tuples in ielist order .
"return the result of ' fmt_str.format(*args , * * kwargs ) ' after transforming ' args ' and ' kwargs ' according to the value of ' use_color ' . if ' use_color ' is false then all color codes in ' args ' and ' kwargs ' are replaced with the empty string ."
return the length of the longest benchmark name in a given list of benchmark json objects
return a float representing the decimal change between old_val and new_val .
calculate and report the difference between each test of two benchmarks runs specified as ' json1 ' and ' json2 ' .
"a layer to normalize and convert images from rgb to bgr this layer converts images from rgb to bgr to adapt to caffe that uses opencv , which uses bgr . it also subtracts the per - pixel mean . parameters ---------- l_in : : class:``lasagne.layers . layer ` ` the incoming layer , typically an : class:``lasagne.layers . inputlayer ` ` bgr_mean : iterable of 3 ints the mean of each channel . by default , the imagenet mean values are used . data_format : str the format of l_in , either ` b01c ` ( batch , rows , cols , channels ) or ` bc01 ` ( batch , channels , rows , cols )"
get gcc version .
get gcc architecture .
return flags for include directories read from $ include environment var
"mock the s3 connection , bucket , and key"
"patch psycopg2 with connection mocks , return conn"
setup postgres table with a few random columns of data for testing . tear down table at end of text fixture context .
"search and remove variants with [ 0/0 , ./. ] search and replace chr from the beggining of the chromossomes to get positionning . sort vcf by 1 ... 22 , x , y , mt and nothing else # discard other variants"
annotation with snpeff
return a pynnotator object with a defined vcf file to be annotated .
sql text creator function .
"check that the vagrant_boxes attribute is not left empty , and is populated by all boxes if left blank"
assertion for a box status
assertion for a box being up
assertion for a box being up
assertion for a box being up
assertion for a box being up
override run to have provide a hook into an alternative to teardownclass with a reference to self
collect the box states before starting
"restore all boxes to their initial states after running all tests , unless teardown handled it already"
restores all boxes to their original states
starts all boxes before running tests
returns boxes to their initial status after each test if self.restart_boxes is true
create database for june .
open a : mod:`tasks . task ` with a : mod:`tasks . addresslayout ` that gets from user : ref:`data ` address . create a result page with count .
open a : mod:`tasks . task ` with a : mod:`tasks . countiflayout ` that gets from user : ref:`data ` address and conditions for getting values . create a result page with count and conditions .
open a : mod:`tasks . task ` with a : mod:`tasks . addresslayout ` that gets from user : ref:`data ` address . create a result page with minimum .
open a : mod:`tasks . task ` with a : mod:`tasks . addresslayout ` that gets from user : ref:`data ` address . create a result page with maximum .
open a : mod:`tasks . task ` with a : mod:`tasks . smalllargelayout ` that gets from user : ref:`data ` address and ` k ` variable representing the ` k`-th value from the : ref:`task ` s output . create a result page with the ` k`-th value .
open a : mod:`tasks . task ` with a : mod:`tasks . smalllargelayout ` that gets from user : ref:`data ` address and ` k ` variable representing the ` k`-th value from the : ref:`task ` s output . create a result page with ` k`-th value .
open a : mod:`tasks . task ` with a : mod:`tasks . freqlayout ` that gets from user :
": return : a keras model pred next value in a time series : param int wsize : num previous time steps : param int num_input_series : number of series ; : param int num_outputs : number of output logits : param int filter_size : filter size : param int num_filt : the number of different filters to learn ( roughly , input patterns to recognize ) ."
"make input features and prediction targets from a ` timeseries ` for use in machine learning . : return : a tuple of ` ( x , y , q ) ` . ` x ` are the inputs to a predictor , a 3d ndarray with shape ` ` ( timeseries.shape[0 ] - window_size , window_size , timeseries.shape[1 ] or 1 ) ` ` . for each row of ` x ` , the corresponding row of ` y ` is the next value in the timeseries . the ` q ` or query is the last instance , what you would use to predict a hypothetical next ( unprovided ) value in the ` timeseries ` . : param ndarray time_series : either a simple vector , or a matrix of shape ` ` ( timestep , series_num ) ` ` , i.e. , time is axis 0 ( the row ) and the series is axis 1 ( the column ) . : param int wsize : the number of samples to use as input prediction features ( also called the lag or lookback ) ."
create a 1d cnn regressor to predict the next value in a ` timeseries ` using the preceding ` window_size ` elements as input features and evaluate its performance . : param ndarray time_series : timeseries data with time increasing down the rows ( the leading dimension / axis ) . : param int window_size : the number of previous timeseries values to use to predict the next .
download and instal dvs plugin on master node .
enable dvs plugin on cluster .
make dvs mapping data to paste it to options
sentence : list of words
"when length = 12000 * 29 and 512/256 dft / hop , melgram size : ( n_mels , 1360 )"
a data set object provide two ways to access an element : by order or by identity that provided by methode { \sf identify ( ) }
there are two way to verify the existence of an element in a dataset object . either element or its identity can be provided for the verification .
add an element to the set
remove an element from the set .
"an example of a query query = query(namepattern='hs ' , nmin=0 , nmax=10 , objectivetype=""n "" , constrainttype=""u "" )"
handle a cfp message that call for a proposal of scoring algorthim at a parameter point
handle the message that informs a solving session is terminated . the content message contains information of identifying the terminated session
cleanup kodi cpython instances
check if skin changed
"returns a list of content flags from the qualitative coding manual available at http://www2.psych.ubc.ca/~psuedfeld/manual.pdf . valid ` level ` inputs are : [ "" all "" , 1 , 2 , 3 , 4 , 5 ] . other inputs will return an empty list ."
"returns a list of modal verbs in english . note that "" dare "" and "" need "" are not always modal , but we include them regardless in case they are helpful ."
"returns a list of modal verbs in english expressing definite intent . note that "" dare "" and "" need "" are not always modal , but we include them regardless in case they are helpful ."
returns a list of modal verbs in english expressing indefinite intent .
returns a list of words indicating relative amount in english .
"returns a list of hedge phrases in english , all lowercase . tries to capture all surface structure in terms of ( a ) verb forms , and ( b ) negation that appears inside the phrase itself , though better might be smarter addressing of these . glove vectors might also be excellent to use to find similar words to this hedge set ."
"returns a list of conjunctive phrases in english , all lowercase . conjunctions , subordinating conjunctions , conjunctive adverbs , etc ."
"returns a list of transitional words and phrases used to connect thoughts . list extracted from gre study guid , including consequence , contrast , diversion , emphasis , etc . if gives good performance , can expand the list using more existing phrase base . adapted from : http://www.studygs.net/wrtstr6.htm"
returns a list of punctuation .
copy code from one environment to another .
retrieve an environment resource .
retrieve a list of environments .
retrieve a task .
retrieve all tasks for the site .
fetch and store server objects .
generate the server uri .
set the base uri for server resources .
tests calling the drushrc ( ) method .
tests fetching a user object .
get the convolutional layers of the model .
"the training model acts on a batch of 128x64 windows , and outputs a ( 1 + 7 * len(common . chars ) vector , ` v ` . ` v[0 ] ` is the probability that a plate is fully within the image and is at the correct scale ."
"the same as the training model , except it acts on an arbitrarily sized input , and slides the 128x64 window across the image in 8x8 strides ."
overridden from solocommand .
overridden from solocommand .
overridden from solocommand .
solo notice board reader .
solo notice board reader for given repository .
check notice board availability .
show interactive notice board selector .
show notice board element .
string representation of repository object
return the repository .
return the repository description .
return the repository status .
return repository markup text .
object constructor .
"finalize the object , release all its resources ."
setup the packageaction .
run the pre - remove phase .
run the remove phase .
"_ remove_phase ( ) , assuming that the installed packages repository lock is held ."
run the first post - remove phase .
"update source package manager < - > entropy package identifiers coupling . entropy can handle multiple packages in the same scope from a spm pov ( see the "" package tag "" feature to provide linux kernel module packages for different kernel versions ) . this method just reassigns a new spm unique package identifier to entropy ."
"post - remove phase of package remove action , this step removes spm package entries if there are no other entropy - tagged packages installed ."
execute the action . return an exit status .
overridden from eitcommand
overridden from eitcommand .
overridden from eitcommand
eit repo add command .
eit repo remove command .
entropyurihandler constructor .
"support for "" with "" statement , this will trigger urihandler connection setup ."
"support for "" with "" statement , this will trigger urihandler connection hang up ."
approve given uri by returning true or false depending if this class is able to handle it .
"given a valid uri ( meaning that implementation can handle the provided uri ) , it extracts and returns the uri name ( hostname ) ."
"given an uri , hide sensible data from string and return it back ."
return copy of previously stored uri .
provide alternative entropy output interface ( must be based on entropy.output . textinterface )
set download / upload speed limit in kb / sec form .
set transceiver tx / rx timeout value in seconds .
disable transceiver verbosity .
set transceiver verbosity .
download uri and save it to save_path .
"download many files at once , taken from remote_paths , stored into save_dir"
upload uri from load_path location to uri .
"create remote "" lock "" file atomically . to drop a lock , just call remove ( ) . the goal here is just being able to create a remote file in mutual exclusion between other entropy server instances . please note : the locking mechanism is guaranteed to work only when callers share the same transceiver plugin ."
"upload many files at once , taken from load_path_list , stored into remote_dir"
rename uri old to uri new .
copy uri old to uri new .
remove the remote path ( must be a file ) .
"remove many files at once , taken from remote_paths ."
return md5 checksum of file at uri .
list content of directory referenced at uri .
"list content of directory referenced at uri with metadata in this form : [ ( name , size , owner , group , permissions < drwxr - xr - x > , ) , ... ] permissions , owner , group , size , name ."
"given a remote path ( which can point to dir or file ) , determine whether it 's available or not ."
"given a remote path ( which can point to dir or file ) , determine whether it 's a directory ."
"given a remote path ( which can point to dir or file ) , determine whether it 's a file ."
"given a remote path , recursively create all the missing directories ."
send a keep - alive ping to handler . @raise transceiverconnectionerror : if problems happen
called when requesting to close connection completely .
clear liststore content ( and icon cache ) .
return the missing icon gtk . image ( ) if needed .
returns whether application ( through pkg_match ) is still visible in the treeview . this method shall be thread safe .
"remove elements that are marked as "" vanished "" due to unavailable metadata ."
overridden from eitcommand
overridden from eitcommand
actual eit search code .
overridden from eitcp
overridden from eitcommand
overridden from eitcp
"execute package move or copy ( depending on self._copy ) from source repository and destination repository . if deps is true , also dependencies are pulled in ."
overridden from eitcommand
overridden from eitcommand
overridden from eitcommand
"expand given package set into a set of package matches , recursively ."
"return a list of available package sets data ( list of tuples composed by ( repository i d [ _ _ user _ _ for use defined set ] , set name , set content )"
"search a package set among available repositories . return a list of package sets data ( list of tuples composed by ( repository i d [ _ _ user _ _ for use defined set ] , set name , set content )"
"match a package set , returning its data . if multi_match is false ( default ) , data returned will be in tuple form , composed by 3 elements : ( repository [ _ _ user _ _ if user defined ] , set name , list ( frozenset ) of package names in set ) . if multi_match is true , a list of tuples ( like the one above ) will be returned ."
add a user - defined package set to entropy client ( changes are permanent )
remove a user - defined package set from entropy client ( changes are permanent )
note : this requires gnupg as test - dependency .
teardown is run after each test
overridden from eitcommand
overridden from eitcommand
overridden from eitcommand
actual entropy repository cleanup function
change gettext language on the fly .
overridden from eitcommand
overridden from eitcommand
overridden from eitpull
teardown is run after each test
tests if a users is authentication if they supply pk = = ' i '
"同属性单个元素，返回单个坐标元组，(x , y ) : args : - attrib - node节点中某个属性 - name - node节点中某个属性对应的值"
"同属性多个元素，返回坐标元组列表，[(x1 , y1 ) , ( x2 , y2 ) ]"
"同属性单个元素，返回单个坐标区域元组,(x1 , y1 , x2 , y2 )"
"同属性多个元素，返回坐标区域列表，[(x1 , y1 , x2 , y2 ) , ( x3 , y3 , x4 , y4 ) ]"
"通过元素类名定位单个元素 usage : findelementbyclass(""android.widget . textview "" )"
"通过元素的resource - id定位单个元素 usage : findelementsbyid(""com.android.deskclock : id / imageview "" )"
通过元素的resource - id定位多个相同id的元素
通过元素的content - desc定位单个元素
通过元素的content - desc定位多个相同的元素
通过元素content - desc获取单个元素的区域
通过元素content - desc获取多个相同元素的区域
通过元素id获取多个相同resource - id元素的区域
"baseado na pergunta do usuário , identifica qual a sua intenção"
initializa o bot
tests that footprint_init creates a tilestache configuration object in the db
"dbentity presentation , analysis module presentation , and builtform presentation can happen in parallel as soon as a config_entity is saved"
"post save starts a chain of asynchronous publishers that run according to a dependency tree . first publishers that are wired to the post_save_built_form_initial signal run , followed by publishers dependent on signals that are dependent on that signal : param built_forms : the builtforms"
sync a configentity 's builtformsets
"constructs and persists buildings , buildingtypes , and placetypes and their associates and then returns them all as a persisted builtformset . one builtformset is returned in an array : param test : if test is set to true , a much more limited set of built forms is created"
resolve the dynamicmodelclass creator subclass instance that created this class : return :
this function handles the update or creation on the environmental constraints geography producing the area for each layer with the environmental constraint behavior . this function will both add and remove constraints and produce the final constraints layer in the primary geography of the active scenario
"resolve the actual model class , since it 's non - trivial to store in the database : return :"
indicates to mixers that the key must be unique in the scope it pertains to . : return :
: param self.dir csv file self.directory : return : importedresidentialbaseline objects imported from urbanfootprint v0.1 default set
": param self.dir csv file self.directory : return : importcommercialenergybaseline objects imported from urbanfootprint v0.1 commercial baseline from default set , csv or a custom set defined for the client"
: param self.dir csv file self.directory : return : importedresidentialbaseline objects imported from urbanfootprint v0.1 default set
every result has an owning resultlibrary which is a resultlibrary of the config_entity . we find all the resultlibraries or that config_entity and search each for the result : return :
"processes the instance or instances given by the kwargs , storing instance_ids , the instance_class , and optional instance_keys , which may all be used for celery calls and client messaging : param kwargs : currently only ' instance ' is required , which is a single or list of instances . optional arguments are : user_id : the user i d of the user that instigated the save on the client instance_key : the attribute that is the key of the instance class_key : for dynamic classes , resolves the key of its scope class ( e.g. ' db_entity_key ' of feature ) class_path : the class path of the instance class . defaults to the class of the first instance model_path : backup to class_path for dynamic model resolution instance_class - optional . overrides the class of the instance for use in communicating with the client . this is used when the client only cares about a base class , such as feature or for dbentityinterest to be a dbentity client_instance_path - optional . property path from the main instance to the instance to show the client ( this is only used to convert dbentityinterest to dbentity )"
loads the full instances from the database
if client_instance_path is specified these are the mapped instances that the client cares about : return :
reconsitutes the class from the class_name
returns a string of the keys or uses ids if keys do n't exist
returns just the final segment of the class name -- module segments are omitted
this property is used with the api to avoid dumpoing extraneous information . see template for overrides : return :
make sure that the api can return all the versions of a feature : return :
parses strings from datetime.timedelta.__str _ _ .
call out to the super . makes docs cleaner .
convert a stored duration into a python datetime.timedelta object .
convert a timedelta to integer for storage .
used by serializers to get a string representation .
raises the window for the wallet if it is open . otherwise opens the wallet and creates a new window for it
"creates the database , the : class:`~flask . flask ` object , the : class:`~flask_restless.manager . apimanager ` for that application , and creates the restful api endpoints for the : class:`testsupport . person ` and : class:`testsupport . article ` models ."
tests for restricting which fields are returned in a : http : method:`post ` request .
tests for including related resources on a : http : method:`post ` request .
tests that the client can create a single resource .
tests for an error response if the client fails to specify the type of the object to create .
tests that the client can specify a uuid to become the id of the created object .
tests that the client can specify a uuid to become the id of the created object .
"tests that if a client specifies a type that does not match the endpoint , a : http : status:`409 ` is returned ."
"tests that if a client specifies a client - generated id that already exists , a : http : status:`409 ` is returned ."
"creates the database , the : class:`~flask . flask ` object , the : class:`~flask_restless.manager . apimanager ` for that application , and creates the restful api endpoints for the : class:`testapp . person ` and : class:`testapp . computer ` models ."
test that the : http : get:`/api / eval / person ` endpoint returns the result of evaluating multiple functions .
tests that a request to the function evaluation endpoint with no query parameter yields an error response .
tests that a request to the function evaluation endpoint with an empty functions query yields an error response .
"tests that if no functions are defined , an empty response is returned ."
tests that an unknown function name yields an error response .
test for json - p callbacks .
tests that filters are applied before functions are called .
tests for invalid json in the ` ` filter[objects ] ` ` query parameter .
tests that providing an incorrectly formatted argument to ` ` filter[objects ] ` ` yields an error response .
tests that providing an incorrectly formatted argument to ` ` filter[single ] ` ` yields an error response .
"creates the database , the : class:`~flask . flask ` object , the : class:`~flask_restless.manager . apimanager ` for that application , and creates the restful api endpoints for the : class:`testsupport . person ` and : class:`testsupport . article ` models ."
tests for updating a to - one relationship via a : http : method:`patch ` request to a relationship url .
tests for removing a to - one relationship via a : http : method:`patch ` request to a relationship url .
tests for replacing a to - many relationship via a : http : method:`patch ` request to a relationship url .
tests that an attempt to replace a to - many relationship with a related resource that does not exist yields an error response .
"tests that full replacement of a to - many relationship is forbidden by the server configuration , then the response is : http : status:`403 ` ."
tests for appending to a to - many relationship via a : http : method:`post ` request to a relationship url .
tests for attempting to append an element that already exists in a to - many relationship via a : http : method:`post ` request to a relationship url .
tests for deleting from a to - many relationship via a : http : method:`delete ` request to a relationship url .
tests for deleting a nonexistent member from a to - many relationship via a : http : method:`delete ` request to a relationship url .
tests that attempting to delete from a to - many relationship via a : http : method:`delete ` request to a relationship url when the server has disallowed it yields a : http : status:`409 ` response .
parse the mime type in to it 's component parts .
"strip the subtype from a mimetype , leaving vendor specific information ."
print a list of .reviewboardrc aliases to the command line .
run the command .
run the test suite .
"if 0x81 ( ' unkown_command ' ) comes back in the status field when authenticating , it is n't needed ."
raise authenticationnotsupported unless we 're using plain auth .
raise memcachedexception for anything unsuccessful .
valid logins return true .
invalid logins raise invalidcredentials
"simply convert a string type to bytes if the value is a string and is an instance of six.string_types but not of six.binary_type in python2 struct.pack(""<q "" ) is both string_types and binary_type but in python3 struct.pack(""<q "" ) is binary_type but not a string_types : param value : : param binary : : return :"
make sure that pytest accepts our fixture .
override keras method to allow multiple feature dimensions .
"return user detail from qq account sometimes nickname will duplicate with another qq account , to avoid this issue it 's possible to use openid as username ."
update user details using data from provider .
taken from test.py
test an event export
: param data_dir : ( str ) directory in which the output file will be saved : param deputies : ( pandas . dataframe ) a dataframe with deputies data : param date_start : ( str ) a date in the format dd / mm / yyyy : param date_end : ( str ) a date in the format dd / mm / yyyy
: param deputies : ( pandas . dataframe ) a dataframe with deputies data : param date_start : ( str ) date in the format dd / mm / yyyy : param date_end : ( str ) date in the format dd / mm / yyyy
get the size of the terminal window .
extract event i d from talk html page .
fetch page for given url and return json python object .
expose available file formats .
filter all availabe live streams for given json and room name .
construct a dataset . one_hot arg is used only if fake_data is true .
return the next ` batch_size ` examples from this data set .
create an instance of the resource .
list the users you have blocked .
check if there is a block between you and the given user .
block the given user .
unblock the given user .
return ` ` true ` ` if the block still exists .
remove the block .
return the attachment as json serializable dict .
create an attachment from data .
create multiple attachments from a list of attachment data .
create a new image attachment from an image file .
upload image data to the image service .
download the binary data of an image attachment .
downlaod the binary data of an image attachment at preview size .
downlaod the binary data of an image attachment at large size .
downlaod the binary data of an image attachment at avatar size .
add a user to the group .
add multiple users to the group at once .
check for results of a membership request .
update your own membership .
remove a member from the group .
post a direct message to the user .
check whether you have the user of the membership blocked .
block the user of the membership .
unblock the user of the membership .
remove the member from the group ( destroy the membership ) .
add the member to another group .
check for and fetch the results if ready .
return the requests that failed .
return the newly added members .
return ` ` true ` ` if the results are ready .
return the results when they become ready .
return the results now .
test simple parts of symbol table
args : model ( model ): view ( view ):
design input data using an optimisated latin hypercube design and save it to a file .
"shall be implemented by tensorflow . this is an example , as a shallow neural network ."
args : xs : numpy array . ys : numpy array with the same shape and dtype as ` xs ` .
"construct a ` independent ` distribution . args : distribution : the base distribution instance to transform . typically an instance of ` distribution ` . reduce_batch_ndims : scalar , integer number of rightmost batch dims which will be regard as event dims . validate_args : python ` bool ` . whether to validate input with asserts . if ` validate_args ` is ` false ` , and the inputs are invalid , correct behavior is not guaranteed . name : the name for ops managed by the distribution . default value : ` independent + distribution.name ` . raises : valueerror : if ` reduce_batch_ndims ` exceeds ` distribution.batch_ndims `"
"returns : math:`kl ( q_1 || q_0 ) ` where the ` qs ` as ` ( q_0 , q_1 ) ` ."
"compare the two inference - distributions . explicitly , what we are to compute is the kl - divergence between ` p(x ) ` and ` q_0(x ) ` , but with the monte - carlo integral sampled from ` q_1(x ) ` ."
"analyze two sounds with the harmonic plus stochastic model inputfile : input sound file ( monophonic with sampling rate of 44100 ) window : analysis window type ( rectangular , hanning , hamming , blackman , blackmanharris ) m : analysis window size n : fft size ( power of two , bigger or equal than m ) t : magnitude threshold of spectral peaks minsinedur : minimum duration of sinusoidal tracks nh : maximum number of harmonics minf0 : minimum fundamental frequency in sound maxf0 : maximum fundamental frequency in sound f0et : maximum error accepted in f0 detection algorithm harmdevslope : allowed deviation of harmonic tracks , higher harmonics have higher allowed deviation stocf : decimation factor used for the stochastic approximation returns inputfile : input file name ; fs : sampling rate of input file , hfreq , hmag : harmonic frequencies , magnitude ; stocenv : stochastic residual"
"transform the analysis values returned by the analysis function and synthesize the sound inputfile1 : name of input file 1 fs : sampling rate of input file 1 hfreq1 , hmag1 , stocenv1 : hps representation of sound 1 inputfile2 : name of input file 2 hfreq2 , hmag2 , stocenv2 : hps representation of sound 2 hfreqintp : interpolation factor between the harmonic frequencies of the two sounds , 0 is sound 1 and 1 is sound 2 ( time , value pairs ) hmagintp : interpolation factor between the harmonic magnitudes of the two sounds , 0 is sound 1 and 1 is sound 2 ( time , value pairs ) stocintp : interpolation factor between the stochastic representation of the two sounds , 0 is sound 1 and 1 is sound 2 ( time , value pairs )"
"inputfile : input sound file ( monophonic with sampling rate of 44100 ) window : analysis window type ( rectangular , hanning , hamming , blackman , blackmanharris ) m : analysis window size ; n : fft size ( power of two , bigger or equal than m ) t : magnitude threshold of spectral peaks ; minsinedur : minimum duration of sinusoidal tracks nh : maximum number of harmonics ; minf0 : minimum fundamental frequency in sound maxf0 : maximum fundamental frequency in sound ; f0et : maximum error accepted in f0 detection algorithm harmdevslope : allowed deviation of harmonic tracks , higher harmonics have higher allowed deviation stocf : decimation factor used for the stochastic approximation"
"apply a filter to a sound by using the stft x : input sound , w : analysis window , n : fft size , h : hop size filter : magnitude response of filter with frequency - magnitude pairs ( in db ) returns y : output sound"
"morph of two sounds using the stft x1 , x2 : input sounds , fs : sampling rate w1 , w2 : analysis windows , n1 , n2 : fft sizes , h1 : hop size smoothf : smooth factor of sound 2 , bigger than 0 to max of 1 , where 1 is no smothing , balancef : balance between the 2 sounds , from 0 to 1 , where 0 is sound 1 and 1 is sound 2 returns y : output sound"
loads the mnist dataset .
prints a summary of a model .
converts all convolution kernels in a model from theano to tensorflow .
utility useful when changing a convnet 's ` data_format ` .
show text with progress bar .
rules : all users with role auto_rlc_coms_roles in commissions or auto_rlc_root_roles in root unit are given auto_rlc_given_role
return the list of available costcenters for a given unit and year plus its children ( except commissions )
return the list of available tva for a user
return the list of available users for a expenseclaim / cashbook ordered nicely ( you / unit_people / rest ) or just you if no right
return the list of available accounts for a given year
display the list of accreds
"display the list of accreds , json call for the list"
display the list of accreds
"display the list of accreds , json call for the list"
renew an accreds
delete an accred
validate an accred
reselloclient should have .reseller = resellermanager instance .
reselloclient should have .domain = domainmanager instance .
reselloclient should have .vps = vpsmanager instance .
list product specific configurations for this reseller .
token should have a type and value .
factor : integer | lparen expr rparen
term : factor ( ( mul | div ) factor ) *
expr : term ( ( plus | minus ) term ) * term : factor ( ( mul | div ) factor ) * factor : integer | lparen expr rparen
prints or returns ngtree in requested format
print all management groups to the screen
print out list of dictionary objects as csv
try to get a filter from the config
filters networks based on vrf : role ( from supernets )
process config for group or custom filter and cache it for each call
"try to find what someone is looking for based on a text string uses a lot of try / except code , best to debug non - universal before debugging here ."
api password verification
returns a new sha256 hash for a password ( lower rounds for speed )
authenticate a user
add a new user to the database
update password for user
delete a user from the database
get a config snippet from a device
normalize ports ( gigabitethernet1/1 - > gi1/1 )
store nglib database handle under thread
store nglib database handle under thread
initialize library on each request
closes the database again at the end of the request .
upgrade the output of ngt api data
make sure version in versions
expects raw 8 - byte setup data request packet
returns request as bytes
"tests an gas model with no ar or sc terms , and that the latent variable list length is correct , and that the estimated latent variables are not nan"
"tests an gas model with 1 ar and 1 sc term and that the latent variable list length is correct , and that the estimated latent variables are not nan"
"tests an gas model with 1 ar and 1 sc term , integrated once , and that the latent variable list length is correct , and that the estimated latent variables are not nan"
"tests an gas model estimated with bbvi and that the length of the latent variable list is correct , and that the estimated latent variables are not nan"
"tests an arima model estimated with bbvi and that the length of the latent variable list is correct , and that the estimated latent variables are not nan"
tests that the elbo increases
tests that the elbo increases
"tests an gas model estimated with metropolis - hastings and that the length of the latent variable list is correct , and that the estimated latent variables are not nan"
"tests an gas model estimated with laplace approximation and that the length of the latent variable list is correct , and that the estimated latent variables are not nan"
"tests a pml model estimated with laplace approximation and that the length of the latent variable list is correct , and that the estimated latent variables are not nan"
tests that the prediction dataframe length is equal to the number of steps h
tests that the prediction is dataframe length is equal to the number of steps h
tests that the predictions are not nans
tests that the in - sample predictions are not nans
we should not really have predictions that are constant ( should be some difference ) ... this captures bugs with the predict function not iterating forward
we should not really have predictions that are constant ( should be some difference ) ... this captures bugs with the predict function not iterating forward
tests prediction intervals are ordered correctly
tests prediction intervals are ordered correctly
tests prediction intervals are ordered correctly
tests prediction intervals are ordered correctly
tests prediction intervals are ordered correctly
tests prediction intervals are ordered correctly
tests sampling function
tests ppc value
"validates a given rfid using a rest web service that takes the rfid as input and returns a simple ' true ' if the key owner has paid their dues in the past 45 days or ' false ' otherwise : param rfid : the rfid read from the reader : return : true if rfid owner is ok , false otherwise"
gets the most recent whitelist of valid rfid card serial numbers based on member payments and up to date accounts . if fields param is blank it will return all the fields from the database . otherwise pass in a comma separated list of field names to return . : param fields : : return :
this method passes the given rfid serial string as a parameter to a rest url that simply logs the serial string with a timestamp in the accesslog table in the seltzer db . this allows for an sql query that answers the questions : who was the last person to swipe their card ? and when was the last time person x swiped their card ? : param rfid : the rfid serial string read by the rfid reader : return : nothing
"return result as list . relavance from high to low in each pos. lookup routine for datamuse.com . when query_from_source is called , return : [ status , [ [ pos , [ word_0 , word_1 , ... ] ] , [ pos , [ word_0 , word_1 , ... ] ] , ... ] ] status : 0 : normal , result found , list will be returned as a nested list 1 : normal , result not found , return empty list -1 : unexpected result from query , return empty list nested list = [ pos , list wordlist ] classifier('str ' ): identifier to classify the resulting wordlist suits . wordlist = [ word_0 , word_1 , ... ] : list of words belonging to a same definition"
query jiport for sysnonym
run anat subnetwork inference * * requires steinprt binary * *
read dataset raw file > > > df = read(**dataset['file ' ] )
"set up an ipython session just once . it 'd be safer to set it up for each test , but for now , i 'm mimicking the ipython team 's logic ."
play a demo script showing most of the oct2py api features .
start a number of threads and verify each has a unique octave session .
create a unique instance of octave and verify namespace uniqueness .
"generic input for vtk data ,"
evaluate the input_array data at the given indices using trilinear interpolation
generate colormap 's lookup table
"mids : [ ( shape_id , model_id ) , ... ] iou : { ' # images ' : { ' threshold ' : iou } } output : iou thresh : shape_ids - mean iou"
hasoffers response body contains networkid & networktoken and they should be replaced with test values .
marks method as generic .
returns the set of the sockets .
eintr safe version of ` select ` . it focuses on just incoming sockets .
dispatches incoming sockets .
"create and send a transaction with a random fee . the transaction pays to a trivial p2sh script , and assumes that its inputs are of the same form . the function takes a list of confirmed outputs and unconfirmed outputs and attempts to use the confirmed list first for its inputs . it adds the newly created outputs to the unconfirmed list . returns ( raw transaction , fee )"
"we need to generate a lot of inputs so we can generate a ton of transactions . this function takes an input from txins , and creates and sends a transaction which splits the value into 2 outputs which are appended to txouts . previously this was designed to be small inputs so they would n't have a high coin age when the notion of priority still existed ."
this function calls estimatefee and verifies that the estimates meet certain invariants .
we 'll setup the network to have 3 nodes that all mine with different parameters . but first we need to use one node to create a lot of outputs which we will use to generate our transactions .
"test decoding scripts via rpc command "" decoderawtransaction "" ."
"_ _ init__(self , tfinputgraph = none , inputmapping = none , outputmapping = none , tfhparms = none )"
"setparams(self , tfinputgraph = none , inputmapping = none , outputmapping = none , tfhparms = none )"
returns a list of placeholder type enums for the input nodes
""" test conversion image array < - > image struct"
serialize the keras model to hdf5 and load the file as bytes . this saves the keras model to a temp file as an intermediate step . : return : str containing the model data
dump hdf5 file content bytes to a local file : return : path to the file
convert a keras model from a byte string to a keras model instance . this saves the keras model to a temp file as an intermediate step .
"retrieves a keras loss function instance . : param : identifier str , name of the loss function : return : a keras loss function instance if the identifier is valid"
check if a named loss function is supported in keras
"retrieves a keras optimizer instance . : param : identifier str , name of the optimizer : return : a keras optimizer instance if the identifier is valid"
check if a named optimizer is supported in keras
must be able to load the api
"computes the interpolation kernel u ( ) for points x given the scaled grid distances : ( x - x_{t})/s where s is the distance between neighboring grid points . note that , in this context , the word "" kernel "" is not used to mean a covariance function as in the rest of the package . for more details , see the original paper keys et al . , 1989 , equation ( 4 ) ."
a special mll designed for exact inference
"given a low rank ( k x n ) matrix v and a shift , returns the matrix r so that r = ( i_k + 1 / shift vv')^{-1}v to be used in solves with ( v'v + shift i ) via the woodbury formula"
solves the system of equations : ( sigma*i + vv')x = b using the woodbury formula .
not a lazy variable
create private keys and addresses for all seeds .
create a genesis - block dict with allocation for all ` accounts ` .
custom new filter implementation to handle bad encoding from geth rpc .
get filter .
save events .
"return the tuple of ( last_applied_state_change_id , snapshot ) or none"
connect to closest node larger than self !
sort nodes by their shortest distance to target_id
try to transfer along a channel with a node that has a lower i d than target . closest node first
resolve solidity dependencies depth first .
configure the logging level .
check the solc prior to running any test .
will move all date ranges from query to period
will move all date ranges from period back to query
easy way to create flask web application . you can use below option with flask init : : --simple - module --single - module
"if text is matched with pattern , return variable names specified(%{pattern : variable name } ) in pattern and their corresponding values . if not matched , return none . custom patterns can be passed in by custom_patterns(pattern name , pattern regular expression pair ) or custom_patterns_dir ."
create an opener object from a list of handlers .
"用来存储比较短的消息 , 消息和资料库的主要区别是消息存储较短的单一信息 - 消息支持状态 - 2017/05/29"
"通用的配置对象 , 比词典多一个type，用来存储个人的一些设置之类的"
获取数据库表，表的创建和访问不必在xtables中定义 @since 2019/04/11
set epsilon and float type
"test if "" obj "" is a sequence ."
"test if "" obj "" is of a sequence type and three long ."
"test if "" val "" is of a number type ."
"test if every item in "" lst "" is of a number type ."
get the argumentparser for the arguments given on the command line .
get the argumentparser for the arguments given on the command line .
"make use of a fixture , ensuring that it will be cleaned up ."
create a temp file and make sure it is removed on teardown .
replace $ country and $ language in message with dat from settings
validates an activation key and activates the corresponding ` ` user ` ` if valid .
"creates a new , inactive ` ` user ` ` , generates a ` ` registrationprofile ` ` and emails its activation key to the ` ` user ` ` . returns the new ` ` user ` ` ."
creates a ` ` registrationprofile ` ` for a given ` ` user ` ` . returns the ` ` registrationprofile ` ` .
removes expired instances of ` ` registrationprofile ` ` and their associated ` ` user``s .
determines whether this ` ` registrationprofile ` ` 's activation key has expired .
return the background in a readable form
true if this person has picked a background that includes the word research
parse xfoil polars and concatente data in dataframe
set up x and y parameters for gp fitting
polar fit for the jho1 airfoil
plot fit compared to data
returns a list of variables with shared varname in model list
elliptical fuselage test
mldb-1018 . try with 2 splitchars .
create a merged dataset out of non existing datasets should not work . connector sends / receives everything as text .
create a merge dataset out of nothing should not work . connector sends / receives everything as text .
sync should work even when connector sends as json .
look for data matching samples from biomfile in the specified stoqs database and add to the biom - format file .
make an image file for each colormap
build images as in http://matplotlib.org/examples/color/colormaps_reference.html
the argparse library is included in python 2.7 and is an added package for stoqs .
read the gps positions from the .csv response and save in an array for easy lookup for the measurement data
read in records from one of the esp drifter and write out as netcdf . the records look like ( time is local ):
read in records from .csv file and write out as netcdf . merge with gps data from mbari tracking . this method builds the netcdf variables dynamically using the python ' exec ' method .
prompts for yes or no response from the user . returns true for yes and false for no .
"set initial metadata if creating a new file or set callback for updating modification time if modifying an existing file . f is the h5gate file object . creating_file is true if creating a new file . see file nwb_file for description of mode , start_time , identifier and description ."
executed on close of nwb file . updates modification time
render signup template : return :
: param session_id : w.i.l.l session i d : param sid : flask session i d update thread that will emit socket.io updates to the user while they 're connected
: param session_id : end the webapp session and the update thread on the users disconnect from the page : return :
render the settings template : return :
: param data : socket.io data about the update thread : authenticate and start the update thread : return :
: param username : : param password : : return login data :
render the webapp index.html template : return index template :
render template for admin - only reporting page or bounce a non admin user back to / : param session : : return report template :
returns a list of names of the abstract base classes that should not be instantiated . can be used to build an ignore list .
returns a list of names of the example fluid classes that should not be treated like the normal fluids . can be used to build an ignore list . use the obj switch to return the objects instead of the names .
returns a list of names of classes that should not be treated like the normal fluids .
"returns a list of coefficientdata objects , which already contain all coefficients . these objects can be written to json without further processing ."
"returns a list of digitaldata objects , which contain data for the fitting . these objects only hold the data and you still have to call the fitting routines . a ) data in these classes is based on equations that can not be converted to the forms available in coolprop . b ) there are no equations available , but the fluid data can be accessed from python in the form of another library . c ) there are data files that contain the experimental data . the fit has to be done after laoding the fluids ."
"returns a list of coefficientdata objects , which already contain all coefficients . these objects can be written to json without further processing . all coefficients are taken from the same reference : "" properties of secondary working fluids for indirect systems "" written by aake melinder and published in 2010 by iir"
"returns a list of solutiondata objects , which contain data for fitting pure fluids . these objects only hold the data and you still have to call the fitting routines ."
"returns a list of solutiondata objects , which contain data for fitting solutions . these objects only hold the data and you still have to call the fitting routines ."
"returns a list of digitaldata objects , which contain data for the fits . all objects here implement the fitfluid ( ) function , which can be called to set the coefficients before writing the json files ."
this is just a shorthand function for getting a parameter from ` ` coolprop.get_global_param_string ` `
run the tests in the test folder
get the include directory for coolprop header files that are needed if you want to compile anything else that uses the coolprop cython extension type
"copy the coolprop bibtex library file to the file given by ` ` file ` ` , or the folder given by ` ` folder ` `"
initialize the configuration .
test function .
test method .
make sure we did n't break the authentication system this assumes that login urls are named ' login '
user2 tries to login and then has to go and agree to terms
user2 tries to login and has already agreed
"redirect to outside url not allowed , should redirect to login url"
get to login url shows login tempalte .
use when dynamic fetching is needed
"returns none , or the exchange rate as a decimal"
"tries to create the lockfile , using o_excl to prevent races . if it succeeds it returns the fd . otherwise try and connect to the server specified in the lockfile . if this succeeds , the server is returned . otherwise remove the lockfile and try again ."
"each cubic segment has 4 coefficients , a_n , b_n , c_n , and d_n : a_n + x b_n + x^2 c_n + x^3 d_n = y"
sets the position of the origin ( upper right corner ) of the viewport in the pixel coordinate system of the quilt tiles .
test with default creation args
test_numbers : 23 + 32 = = 55
test_strings : ' hello ' + ' world ' = = ' hello world '
test_typeerr : mismatched types produce nothing
[ print ] uses default formatter
[ print ] will use format given on inlet 1
"[ print ] will apply tuple to multiple args , but not list"
[ route ] works in simple cases
[ route ] can change its addresses on the fly
[ route ] -- > [ var ] connection remains when addresses resized
"[ var ] trigger , basic form : - on inlet 1 , save value but do not output . possibly update gui display . - bang on inlet 0 : output stored value - anything else on inlet 0 : save and output value possibly update gui display"
"parses a string , replace ansi markup with html"
"replace ansi colors with html color class names . let the client choose how it will display colors , if it wishes to ."
clean out superfluous hilights rather than set < strong > to make it match the look of telnet .
replace ansi underline with html underline class name .
remove ansi specials
removes special escape sequences
extra method for cleaning linebreaks
replace urls ( http:// ... ) by valid html
replaces links with html code
helper method to be passed to re.sub .
"main access function , converts a text containing ansi codes into html statements ."
helper command . makes sure all data are stored as lowercase and do checking on all properties that should be in list form . sets up locks to be more forgiving . this is used both by the metaclass and ( optionally ) at instantiation time .
"the lockhandler works the same as for objects . optional kwargs will be set as properties on the command at runtime , overloading evential same - named class properties ."
print the command
compare two command instances to each other by matching their key and aliases . input can be either a cmd object or the name of a command .
the logical negation of _ _ eq _ _ . since this is one of the most called methods in evennia ( along with _ _ eq _ _ ) we do some code - duplication here rather than issuing a method - lookup to _ _ eq _ _ .
"this implements searches like ' if query in cmd ' . it 's a fuzzy matching used by the help system , returning true if query can be found as a substring of the commands key or its aliases ."
"this is called by the system when searching the available commands , in order to determine if this is the one we wanted . cmdname was previously extracted from the raw string by the system ."
this hook is called by the cmdhandler to determine if srcobj is allowed to execute this command . it should return a boolean value and is not normally something that need to be changed since it 's using the evennia permission system directly .
this is a shortcut instad of calling msg ( ) directly on an object - it will detect if caller is an object or a player and also appends self.sessid automatically .
"this hook is called before self.parse ( ) on all commands . if this hook returns anything but false / none , the command sequence is aborted ."
this hook is called after the command has finished executing ( after self.func ( ) ) .
"once the cmdhandler has identified this as the command we want , this function is run . if many of your commands have a similar syntax ( for example ' cmd arg1 = arg2 ' ) you should simply define this once and just let other commands of the same form inherit from this . see the docstring of this module for which object properties are available to use ( notably self.args ) ."
this is the actual executing part of the command . it is called directly after self.parse ( ) . see the docstring of this module for which object properties are available ( beyond those set in self.parse ( ) )
returns the default value for this field .
"b64decode and unpickle the object , optionally decompressing it ."
"pickle and b64encode the object , optionally compressing it ."
returns list of new items .
disconnect from feed
called when rss returns ( threaded )
data rss - > server
called by portalsessionhandler
initialize ttype by storing protocol on ourselves and calling the client to see if it supporst ttype .
callback if ttype is not supported by client .
handles negotiation of the ttype protocol once the client has confirmed that it will respond with the ttype protocol .
convert a mysql timestamp to a timestamp object .
copies special instance vars after # copy or # dup
: param int i : number of components : return : value type corresponding to the number of components
constructor . initializes the receiver .
allocates a new job .
"terminates the given job , frees the associated recources ."
terminates job manager itself .
returns the status of the job .
"uploads the given file to application server , files are uploaded to dedicated jobid directory : param str jobid : jobid : param str filename : target file name : param pyrofile pyrofile : source pyrofile"
"returns the ( remote ) pyrofile representation of given file . to create local copy of file represented by pyrofile , use pyroutil.downloadpyrofile , see : func:`pyroutil.downloadpyrofile `"
possibility to register the pyro daemon and nameserver .
terminates the application . terminates the allocated job at jobmanager
"catch all attribute access and pass it to self._decoratee , see python data model , _ _ getattar _ _ method"
comment goes here
return a random example based on the converter
wrap a converter to use a function for example generation
"mark a converter to use the "" static "" example generator ( str )"
split a command 's parameters into required and optional parts
generate a working example given a command .
return the emoji representation of the card
return a list of all possible names in a command
walk up a command 's parent chain .
return an iterator of all possible names in a command
"return the category that a command would fall into , using the module the command was defined in ."
issue # 30 : latin de43 names causing issues
/styles / v1/{username}/{style_id}/tiles/{tilesize}/{z}/{x}/{y}{@2x }
"cum4est fourth - order cumulants . parameters : should be invoked via cumest for proper parameter checks y_cum = cum4est ( y , maxlag , samp_seg , overlap , flag , k1 , k2 ) computes sample estimates of fourth - order cumulants via the overlapped segment method . y_cum = cum4est ( y , maxlag , samp_seg , overlap , flag , k1 , k2 ) y : input data vector ( column ) maxlag : maximum lag samp_seg : samples per segment overlap : percentage overlap of segments flag : ' biased ' , biased estimates are computed : ' unbiased ' , unbiased estimates are computed . k1,k2 : the fixed lags in c3(m , k1 ) or c4(m , k1,k2 )"
huge hack to get the registered modeladmin for the model .
given that i have a message pump for a channel when i read a message from that channel then the message should be dispatched to a handler
given that i have a message pump for a channel when there is no message mapper for that channel then we shhould throw an exception to indicate a configuration error
given that i have a message pump for a channel when i can not read the message received from that channel then i should acknowledge the message to dicard it
given that i have a message pump for a channel when i can not read the message received from that channel then i should acknowledge the message to dicard it
given that i have a message pump for a channel when the handler raises a defer message exception for that message then requeue the message
given that i have a message pump for a channel when the handler raises an application exception for that message then ack the message to prevent ' poison pill ' message
"given that i have a channel when i receive a requeue on that channel i should ask the consumer to requeue , up to a retry limit so that poison messages do not fill our queues"
"given that we have a handler registered for a command , when we send a command , it should call the handler"
"given that we have many handlers registered of an event , when we raise an event , it should call all the handlers"
"given that we are missing a handler for a command , when we send a command , it should throw an exception"
"given that we have no handlers register for an event , when we raise an event , it should not error"
assignment to an index position .
assignment to multiple index positions .
assignment to index positions in multiple names .
assignment of index positions and scalars .
different variable types .
reject assignment of list to variable type .
reject if type missing .
reject type of the form name[index ] .
return all the files matching pattern below root dir .
tests that nccl_reduce does the same as reduction with numpy_fn .
tests the gradient of nccl_reduce .
2 layer convnet to predict from sequence of words to a class .
regression tests for https://github.com/chibisov/drf-extensions/pull/24
crop with relative coords
get a list of all * leaf * directories as strings
create filesystem - safe places for url - keyed data to be stored
use safe64 to create a proper directory
use safe64 to create a proper directory
returns a pandas dataframe .
turns string representation of time into an aware datetime object .
"takes a dataframe and drops all generation rows that are empty or more than 1 day old . turns each row into a dictionary and removes any generation types that are unknown . returns a list of tuples in the form ( datetime , production ) ."
"requests the last known production mix ( in mw ) of a given zone arguments : zone_key ( optional ) -- used in case a parser is able to fetch multiple zones session ( optional ) -- request session passed in order to re - use an existing session return : a dictionary in the form : { ' zonekey ' : ' fr ' , ' datetime ' : ' 2017 - 01 - 01t00:00:00z ' , ' production ' : { ' biomass ' : 0.0 , ' coal ' : 0.0 , ' gas ' : 0.0 , ' hydro ' : 0.0 , ' nuclear ' : null , ' oil ' : 0.0 , ' solar ' : 0.0 , ' wind ' : 0.0 , ' geothermal ' : 0.0 , ' unknown ' : 0.0 } , ' storage ' : { ' hydro ' : -10.0 , } , ' source ' : ' mysource.com ' }"
requests the last known production mix ( in mw ) of a given country
requests the last known power price of a given country
requests the last known power exchange ( in mw ) between two countries
fetch andhra pradesh production
fetch andhra pradesh consumption
check that hydro keys correctly merge into one .
reads csv data from the url . returns a pandas dataframe .
gets values for each interconnection . returns a dictionary .
gets net production values for each country . uses system totals for mexico . returns a dictionary .
calculates flow direction for each interconnection using network flow and simultaneous equations . returns a dictionary .
combines interconnection values with flow directions . returns a dictionary .
"gets an exchange pair from the siepac system . return : a dictionary in the form : { ' sortedzonekeys ' : ' cr->pa ' , ' datetime ' : ' 2017 - 01 - 01t00:00:00z ' , ' netflow ' : 0.0 , ' source ' : ' mysource.com ' }"
checks that the key exists in datapoint and that the corresponding value is not none
validates a production datapoint based on given constraints . if the datapoint is found to be invalid then none is returned .
requests the last known production mix ( in mw ) of a given country
requests the last known power exchange ( in mw ) between two countries
find nice fraction with at least n significant digits in both the numerator and denominator .
"feeds is only needed when base ! = bts , to compute the cer ( needs to be priced in bts regardless of the base asset )"
returns the bitshares delegate tools server dashboard application instance
return whether an instance of the bts binary could be found that is running or in a runnable state .
"return a human readable version description of the running binary , either tag version or git revision ."
returns a key given strings
stores all of the keys and values given in the dict ` properties ` as a hash at the key ` i d `
stores a single key with a value as a hash at the key ` i d `
removes the property specified key from ` i d `
retrieves all the keys and values stored as a hash at the key ` i d `
increments the value stored at ` i d ` by 1 .
returns the value stored at ` i d ` .
returns all elements of the set stored at ` i d ` .
adds an item to a set
removes the item ` value ` from the set at ` i d `
stores ` value ` at ` i d `
gets the value stored at ` i d `
deletes the value stored at ` i d `
stores the given vumi message
"retrieves the stored vumi message , given its unique i d"
"retrieves a stored event url , given the channel and message ids"
"retrieves a stored event auth token , given the channel and message ids"
stores an outbound message
stores an event for a message
loads the event with i d event_id
returns a list of all the stored events
"if we remove all other property keys , we will be left with just the events ."
stores a single status . overrides any previous status with the same component .
returns the latest status message for each component in a dictionary
increments the correct counter . should be called whenever a message that should be counted is received .
gets the current message rate in messages per second .
gets the key for the set of routers
gets the key for a router with i d ` ` router_id ` `
gets the key for the set of destinations for the router
gets the key for the destination with id ` ` destination_id ` ` for the router with id ` ` router_id ` `
returns a list of uuids for all the current router configurations
saves the configuration of a router
gets the configuration of a router with the i d ` ` router_id ` `
removes the configuration of the router with i d ` ` router_id ` `
saves the configuration of a destination of a router
returns the list of destinations for a router
returns the stored configuration of a router 's destination
"parse url , and put the ships into our database ."
set up the following test results and get health - test history from
set up the following test results and resulting health scores .
set up the following test results and resulting health scores
cleanup generated document artifacts .
build docs with sphinx - build
check if all links are corect .
open documentation in web browser .
save / update docs under destination directory .
a descendant is a child many steps down .
add attribute access as an option
return an infodict which contains the xml tree
recursively construct an infodict from an elementtree object
strips off the namespace tag prefix
"search for board games by string . if exact is true , only exact matches will be returned"
"gets info on a particular game or games . game_ids can be either an integer i d , a string i d ( "" 12345 "" ) , or an iterable of ids ."
"this will retrieve a user 's collection , with optional flags set . there are just too many options here to have individual options listed here . you can specify any of the options in your call like so :"
gets messages from a forum / game thread .
gets the geeklist given the specified i d.
overload the internal send ( ) to capture and send messages to the backend
empty function for tests
"on initialization , load the coefficients and intercept of the linear model for use in downstream processing of the mse ."
"adapt the read function to be a csv parser , since this is csv data ."
"the mapper will compute the mse for each row in the data set and emit it with a "" dummy key "" that is , we 'll compute the total for the entire data set , so we do n't need to group by a key for multiple reducers ."
main function to run all the things .
adds an item to the queue .
return next item from queue . blocking by default .
acknowledge item as successfully consumed .
report item as not successfully consumed .
logout all connections within given username and password : param username : username str : param password : password str : return : message str
"check current account status , like used quota : param username : username str : param password : password str : return : the raw status str"
login with username and password : param username : username str : param password : password str : return : message str
get configs from command line
this visiting function will remove stress marks from the vowels
"split a version string into major , minor , and bugfix numbers . if any of those numbers are missing the default is zero . any pre / post release modifiers are ignored ."
"generates a header to the version.py module that includes utilities for probing the git repository for updates ( to the current git hash , etc . ) these utilities should only be available in development versions , and not in release builds ."
regenerate the version.py module if necessary .
returns the package 's .version module generated by ` astropy_helpers.version_helpers.generate_version_py ` . raises an importerror if the version module is not found .
: param rows : list or matrix rows : return : a matrix parsed from text ( i.e. a 2d array )
logs out user
view that provides a form for reporting a concern .
view that provides a queryset of concerns .
view that provides a concern instance and form for resolving the concern .
"writes data ( a list of integer words where each word is assumed to have : attr:`bits_per_word ` bits or less ) to the spi interface , and reads an equivalent number of words , returning them as a list of integers ."
list all sgf - files in a dir
check if a group is dead
create a unique representation for a board
string representation of the board !
"transform a matrix to a string , using ' ; ' as the separator"
store board to a file
generate a move - policybot logic
simulate some games for each move and return the best one
generate a move - valuebot logic
handle logs from client ( browser ) .
create event from dictionally ( json message ) .
handle events emitted on browser .
handle response sent by browser .
handle messages from browser .
start web server .
terminate server and close all ws client connections .
make json response for blueprints .
make error for blueprints .
send blog post updates to consumers webhook .
send latest blog post updates to consumers webhook .
check if consumer webhook is enabled by sending a fake http api request .
initialize a : class:`securechangerootcommand ` object .
"the working directory _ inside the chroot _ ( a string or : data:`none ` , defaults to ` ` / ` ` ) ."
the name of a chroot managed by schroot _ ( a string ) .
the name of the user inside the chroot to run the command as ( a string or : data:`none ` ) .
the complete ` schroot ` command including the command to run inside the chroot .
set the working directory inside the chroot .
redirect assignment from ` directory ` to ` chroot_directory ` .
the command used to run the ` schroot ` program .
return a fully - instantiated gtk . builder instance from specified ui file
"return ` ` true ` ` if result ' passed ' , i.e. has no fail or error ."
return ' pass ' or ' fail ' as string .
return summary dict .
return title for test object .
generate report details dict .
assert that ` ` distribution ` ` claims support for python ` ` version ` ` .
assert ` ` host ` ` responds to ping within ` ` timeout ` ` .
test a sequence generator with no contexts and continuous outputs .
test a sequence generator with integer outputs .
test a sequence generator with continuous outputs and attention .
compute mse .
test when pygpu is n't there for unpickle are in test_pickle.py
utility function to work around windows behavior that open windows .
"calls subprocess_popen and discards the output , returning only the exit code ."
"calls subprocess_popen , returning the output , error and exit code in a tuple ."
"returns a dictionary whose keys are implementations ( ' numpy ' , ' numexpr ' , ' theano ' , etc . ) and whose values are numpy arrays of times taken to evalute the given problem ."
exprs is a list of list of expr to evaluate the first level of list is put into different graph section in the same graph . the second level is the expression to put in each section
computes the total l2 norm of a set of tensors .
return an expression for the hessian times a vector .
helper function for diagonalsubtensor and incdiagonalsubtensor .
convolve spatio - temporal filters with a movie .
this function create optimizer that move some inputs to the gpu for op that work on both cpu and gpu .
also work for incdiagonalsubtensor .
sharedvariable constructor for randomstate .
re - initialize each random stream .
retrieve the numpy randomstate instance associated with a particular stream .
set the numpy randomstate instance associated with a particular stream .
create a new random stream in this container .
"tests that when we record a sequence of events , then repeat it exactly , the record class : 1 ) records it correctly 2 ) does not raise any errors"
"tests that when we record a sequence of events , then do something different on playback , the record class catches it ."
"like test_record_good , but some events are recorded by the theano recordmode . we do n't attempt to check the exact string value of the record in this case ."
"like test_record_bad , but some events are recorded by the theano recordmode , as is the event that triggers the mismatch error ."
request data from the dataset or the wrapped stream .
reset the data stream .
"gracefully close the data stream , e.g. releasing file handles ."
switch the data stream to the next epoch .
allow iteration through all epochs .
get data from the dataset .
get an epoch iterator for the data stream .
typed list type should raises an error if the argument passed for type is not a valid theano type
typed list type should raises an error if the argument given to filter is n't of the same type as the one specified on creation
typed list value should raises an error if no iterable variable is given on input
typed list types should only be equal when they contains the same theano variables
simple test on typed list type filter
test checking if values contained are themselves filtered . if they were n't this code would raise an exception .
testing nested list with one level of depth
nested list with different depth are n't the same
test for the ' depth ' optionnal argument
test case for get_depth utilitary function
test for comparison between uneven nested list
load an array from an .npy file .
non blocking send .
blocking send .
non - blocking receive .
blocking receive .
"wait as long as possible on waits , start send / recvs early ."
break mpi ties by using the variable tag - prefer lower tags first .
add a role to a given theano variable .
test if a variable has given roles taking subroles into account .
raises a skiptest exception when requirements are not met .
take a cudandarray and return a pycuda.gpuarray . gpuarray
take a pycuda.gpuarray . gpuarray and make a cudandarray that point to its memory
returns the number of cpus in the system
initialize the quantities .
readout the accumulated values .
accumulate the results for every batch .
create aggregators and collect updates .
compiles theano functions .
initialize the aggregators .
readout the aggregated values .
compiles theano functions .
compute the variables over a data stream .
set the edges of the bounding box based on the observed data .
determine if the given point is within the bounding box .
return the min and max values of the bounding box .
return string representation of the bounding box .
iterate through points in the bounding box .
simple auto - discover for looking through each installed_apps for each ` ` module_name ` ` and fail silently when not found . this should be used for modules that have ' registration ' like behavior .
registers a class with an optional name . the class name will be used if not supplied .
unregisters a class . note that these calls must be made in installed_apps listed after the apps that already registered the class .
returns a 2 - tuple list of all registered class instance names .
copy ovf env file from dvd to hard disk . remove password before save it to the disk
load saved ovf-env.xml
probe protocol endpoints in turn .
get protocol instance based on previous detecting result .
save protocol endpoint
cleanup previous saved endpoint .
detect protocol by endpoints
detect protocol by tag file .
fetches the right credentials either from params or from environment
the plivo api client .
processes the api response based on the status codes and method used to access the api
create a base class with a metaclass .
adds to members all abilities of the hero with ` hero_id ` .
creates abilities object with all heroes ' abilities in the game .
deletes all ` messagelog ` objects in the queryset
retries all ` messagelog ` objects in the queryset
deletes the given ` messagelog ` object
requeue a failed task then calls the ` retrieve ( ) ` method of the newly created ` messagelog ` object
validates that the input is a valid python tuple that can be used as a function 's positional arguments
gets a list of python functions from the task_modules settings in the config
create a new ` scheduledtask ` object
update an existing ` scheduledtask ` object
gets a host object from a given queue name based on the django configuration
"helper function for dealing with task inputs which may either be a callable , or a path to a callable as a string"
creates a : class:`carrot.objects . message ` object without publishing it
"wrapped for : func:`.create_message ` , which publishes the task to the queue"
helper function for creating a : class:`carrot.models . scheduledtask `
helper function that allows dynamic application of decorators to a class - based views
applies a decorator to the dispatch method of a given class based view . can be chained
"loop through a list of string paths to decorator functions , and call : func:`.create_class_view ` for each one"
"similar to : func:`.create_class_view ` , but attaches a decorator to a function based view , instead of a class - based one"
"similar to : func:`.decorate_class_view ` , but for function based views"
the actual handler process . performs the following actions :
this function prints and plots the confusion matrix . normalization can be applied by setting ` normalize = true ` .
calculates an optimal subplot shape for a given number of images
returns a string usable for formating the status line
shows a collection of images using matplotlib and waits for the user to continue
plots several shapes
displays a representation of the tracking graph
"returns an image from a mask that was prepared for the grab cut algorithm , where the foreground is bright and the background is dark"
prints information about a filter chain
save the next video frame to outfile
"loads either a video file or a video file stack , depending on the video_filename_pattern supplied"
saves the video to the file indicated by filename . the extra arguments determine the codec used and similar parameters . the accepted values depend on the backend chosen for the video writer .
initialize the videofilestack .
returns the video and local frame_index to which a certain frame belongs
sets the 0 - based index of the next frame . this opens a potentially closed video and keeps it open afterwards . this also rewinds all successive open videos .
returns the next frame in the video stack
returns a specific frame identified by its index
paramlist is a list of lists of parameters and paramfunc is a list of the corresponding functions to call with the parameters as arguments .
root directory of source code for apgl .
location of data files .
location of output files .
the training error for internal nodes .
: param k : the dimensionality
perform model selection on x and return the best parameters .
perform model selection on x and return the best parameters .
take a 1d numpy array and print in latex table row format i.e. x1 & x2 .. xn
"a method which will print line of a latex table using 2d arrays of x and y. prints in format x[0,0 ] ( y[0,0 ] ) & x[0,1 ] ( y[0,1 ] ) ... one can also supply the optional boolean matrices bold and italic which embolden or italicise the corresponding elements of x."
take a list and convert into a row of a latex table .
take a list of names and add it to the string representing a latex table latextable .
take a set of rows in latex table format and wrap the text in a table with a given caption .
convert a string in iso 8601 format into a datetime.date object .
"this method is a continuation of payloadview process , triggered if header http - x - github - event type is push"
"this method is a continuation of payloadview process , triggered if header http - x - github - event type is pull request"
return a url to redirect the user to for oauth authentication .
exchange the authorization code for an access token .
"depending on the data available when the instance was created , it may be necessary to fetch data ."
may hit server . see cloudcast.sections
return mm per sec wheel velocities
open the serial port with the arduino board
"light every led with the color r , g , b"
light led with green color
light led with red color
light led with blue color
color = first char of color 's name
converts time in seconds to ' hh : mm : ss ' format with leading zeros as appropriate and optional hours
iterates through all of commbuys and extracts bids .
scrapes the given page as a commbuys results page .
scrapes the commbuys bid detail page for the given bid i d.
returns the text in the next ' td ' cell after the one with ' text ' .
returns the list of texts in the next ' td ' cells after the one with ' text ' .
identifies the site type of the notifier
heading text before listings are displayed
"returns the html - formatted item for the new item list , as string ."
this method performs all scraping for this scraper . must be implemented by subclasses .
return the number of links effectively checked .
check which models are covered by linkcheck this view assumes the key for link
test passing auth keys
test ' synthesize ' subcommand
test ' list - voice ' subcommand
test ' list - voice ' subcommand with filter
partition the ` ` addrinfo ` ` list by address family .
connect to the given host and port .
constructor and initializer of the target file . file with extension .mod this is the file we want to modify . : param afile_path : : param akeywordslist : : param aexcludedinst : : param aprefix : default value = '' : param asuffix : default value = ''
"method that opens the target file , with read - only permission"
method that closes the target file .
"method that searches and checks if any line of the target file meets with the rules(patterns ) given . this is use during * to robtarget conversion . if a string meets the rules , it is store in a list declared as subfilearray ."
method that searches and checks if any line of the target file meets with the rules(patterns ) given . this is use when robtarget to * conversion
method that checks if an element of a list is found inside a string . returns true / false
method that checks if a character or string is found inside another string . returns true / false
method that checks if a character or string is found inside another string . the search considers the whole word . returns true / false
method that search for whole word match returns true / false
method that check a string against the rules for robtarget to * conversion . -rule1 : keywords must be in the astr . -rule2 : excluded keywords(instructions ) must not be in the astr . -rule3 : list of points declared as robtarget must be in the astr . returns true / false
method that check a string against the rules for * to robtarget conversion . -rule1 : keywords must be in the astr . -rule2 : excluded keywords(instructions ) must not be in the astr . -rule3 : string must contain ' [ [ ' characters and not ' ! ' character(comment symbol ) . returns true / false
method that reads a file line by line and stores this lines in a list .
method that reads a list of strings and searches if robtarget declaration keyword is in it .
"method that returns a list of strings . in this case , the list represents the file 's line . returns list"
"method that returns a list of strings . in this case , subfilearray list . returns list"
method that processes * to robtarget conversion .
method that processes robtarget to ^ conversion .
return dataframe of image_url and page_url .
return dataframe of the basic ava dataset .
return dataframe of raw and binarized ratings mean and std .
return dataframe of the ava style labels : column per label .
"load the whole ava dataset from files as a dataframe , with columns image_id : string ratings : list of ints , ratings_mean : float , ratings_std : float , semantic_tag_x_name : string ( for x in [ 1 , 2 ] ) , challenge_name : string ."
"load the provided style label information as a dataframe . the provided style labels are split between train and test sets , where the latter is multi - label ."
"construct a mapping from ava image i d to actual url containing the image . this is run in parallel , using rq ."
scrape the dpchallenge page for a given i d for the actual image url . store into a mongodb collection .
return the mongodb collection where image urls are stored .
get the image urls by scraping dpchallenge.net pages . should do in parallel .
"load dataframe , and read lines from input_filename or stdin . if the first word of a line matches to an index in the dataframe , append the label and importance information to the line , and let it through in the vw format ."
form a dataframe where : - index is composed of top_k top values in row_column . - columns are composed of top_k top values in col_column . - cell values are the number of times that the index and column values occur together in the given dataframe .
divide each cell by the sum of its row and return the resulting dataframe .
remove the state set when resources are unpacked .
report the status of the charm .
probe our relations to determine the propper messaging to the end user
deliver the e2e and kubectl components from the binary resource stream packages declared in the charm
prepare the data to feed to create the kubeconfig file .
request authorization creds .
request a service restart in case credential updates were detected .
declare the application version to juju
"create a configuration for kubernetes based on path using the supplied arguments for values of the kubernetes server , ca , key , certificate , user context and cluster ."
return the kubernetes api server address and port for this relationship .
dpkg wrapper to surface the architecture we are tied to
"decrement the lambda version , if possible ."
log a warning if the lambda version can not be rolled back .
decrement the current_version for the alert processor .
decrement the current_version for the alert merger .
decrement the current_version for all of the apps functions in the given clusters .
decrement the current_version for the athena partition refresh function .
decrement the current_version for the threat intel downloader function .
decrement the current_version for the rule processor in each of the given clusters
rollback the current production aws lambda version by 1
load the threat intel downloader configuration from conf / lambda.json file
retrieve threatstream api credentials from parameter store
send api call to threatstream with next token and return parsed iocs
finalize the execution
invoke lambda function itself with next token to continually retrieve iocs
convert expiration time ( in utc ) to epoch time args : time_str ( str ): expiration time in string format example : ' 2017 - 12 - 19t04:45:18.412z ' days ( int ): default expiration days which 90 days from now
"process and filter data by sources and keys args : data ( list ): a list contains ioc information example : [ { ' value ' : ' malicious_domain.com ' , ' itype ' : ' c2_domain ' , ' source ' : ' crowdstrike ' , ' type ' : ' domain ' , ' expiration_ts ' : ' 2017 - 12 - 19t04:45:18.412z ' , ' key1 ' : ' value1 ' , ' key2 ' : ' value2 ' , ... } , { ' value ' : ' malicious_domain2.com ' , ' itype ' : ' c2_domain ' , ' source ' : ' ioc_source2 ' , ' type ' : ' domain ' , ' expiration_ts ' : ' 2017 - 12 - 31t04:45:18.412z ' , ' key1 ' : ' value1 ' , ' key2 ' : ' value2 ' , ... } ]"
store iocs to dynamodb table
"process url before making api call args : event ( dict ): contains lambda function invocation information . initially , threat intel downloader lambda funciton is invoked by cloudwatch event . ' next_url ' key will be inserted to event lambda function invokes itself to retrieve more iocs ."
cli - terraform - s3 events - legacy
cli - terraform - s3 events with valid buckets
cli - terraform - s3 events with missing bucket key
helper function to create a fake context object using mock
setup before each method
teardown after each method
cli - load config
cli - metric toggling
cli - aggregate alarm check
cli - aggregate alarm check
"cli - adding cloudwatch metric alarm , cluster"
"cli - adding cloudwatch metric alarm , aggregate"
cli - add threat intel config with default dynamodb table name
cli - add threat intel config without dynamodb table name from cli
cli - add threat intel downloader config
"this loop generates key / value pairs with a key of length 6 and value of length 148 . when formatted , each line should consume 160 characters , account for newline and asterisk for bold ."
this function generates a sample alert for testing purposes
remove the local secrets directory that may be left from previous runs
backoff logging handler for when polling occurs .
backoff logging handler for when backoff succeeds .
backoff logging handler for when backoff gives up .
decorator which ignores clienterrors due to conditionalcheckfailed .
name of the dynamodb table used to store alerts .
paginate results from a scan ( ) or query ( ) .
find all of the distinct rule names in the table .
find all alerts for the given rule which need to be dispatched to the alert processor .
get a single alert record from the alerts table .
add a list of alerts to the table .
mark a specific alert as dispatched ( in progress ) .
update the table with the set of outputs which have sent successfully .
remove an alert from the table .
cli - terraform generate kinesis events
"suports : ( n , t ) each story has n support sentences(not fixed ) each supporting sentence has t words queries : ( k , t ) each story has k questions(not fiexed ) each query has t words answers : ( k,1 ) each query has an answer as a word"
calculate and return the timeout for an activity .
calculate and return the heartbeat for an activity .
find all the requirements from the list of tasks and return it .
execution of the tasks .
create the external runner .
schedule an activity task .
schedule an activity .
ensure scheduling meets requirements .
initialize the decider worker .
get all the history .
get the activity states from the history .
register the workflow on swf .
create the decisions from the flow .
delegate the decisions .
run the decider .
create a schedule context .
mark the scheduling as completed .
generic task decorator for tasks .
wrapper for a task to define its timeout .
wrapper for a callable to define a task generator .
check if a function is a task list .
add the garcon property to the function .
link the garcon decorator values between two methods .
decorator to take values from the context and apply them to fn .
flatten the tasks .
fill a function calls from values from the context to the variable .
namespace the response
translate feature name .
divide a half - circle into n angles .
grey - level co - occurrence matrix ( glcm ) texture features .
grey - level co - occurrence matrix ( glcm ) texture feature map .
single glcm features for selected area inside minimum bounding box .
local binary pattern ( lbp ) frequency histogram map .
gabor features .
"get gabor feature map of shape ( feats , height , width ) from the filtered image ."
"get sigma x for gabor filter by setting frequency cut - off to -6db , with bandwidth in octaves ."
"get sigma y for gabor filter by setting frequency cut - off to -6db , with bandwidth in octaves ."
gabor texture feature map . this is the ( more ) correct way .
histogram of oriented gradients ( hog ) .
histogram of oriented gradients ( hog ) texture feature map .
the seven moments of hu .
hu moment map .
sobel edge descriptor .
sobel edge descriptor map .
"if df < ds , flip them ."
adc mono : single exponential decay .
adc kurtosis : k reflects deviation from gaussian shape .
adc stretched .
bi - exponential .
"t2 , spin - spin relaxation time ."
return the numeric correspondent of a logging level name .
abbreviate multiword feature name .
"tell whether all members of ( multidimensional ) array are equal , while ignoring nan values ."
get a view of image subwindow defined as python - like start : stop indices .
get a copy of image with only a subwindow selected and everything else set to nan .
"for scalar input , duplicate it into a sequence of rank length . for sequence input , check for correct length ."
multidimensional sliding window iterator with arbitrary window shape .
return the minimum bounding box with optional padding .
like bounding_box ( ) but return slice objects .
"return the tukey five - number summary ( minimum , quartile 1 , median , quartile 3 , maximum ) , while ignoring nan values ."
return the tukey five - number summary as a formatted string .
return the euclidean distance of two vectors .
normalize a signal intensity curve ( divide all by the first value ) .
normalize a signal intensity curve ( divide all by the first value ) .
"apply feature scaling : bring all values to range [ 0 , 1 ] , while ignoring nan values ."
"calculate image centroid , i.e. center of mass , as a tuple of floats ."
"return a view to array with at least n dimensions . this is a generalization of numpy.atleast_{1,2,3}d ( ) except all dimensions are added in front ."
unify a sequence of masks into one .
"gracefully convert a numeric ndarray to boolean . round it and clip to [ 0 , 1 ] . ( simply using np.astype(np.bool ) does not work . )"
zoom by a factor ( float or sequence ) .
"convert to float , zoom , convert back . special boolean handling ."
dump object into a json string .
normalize images within mode - specific range .
"uniform quantization from float [ 0 , 1 ] to int [ 0 , levels-1 ] ."
"return cpu count , if possible ."
try to return system hostname in a portable fashion .
automatically expanded ` path ` . useful as an argparse type from file .
"create a list of indices from a slice string , i.e. start : stop : step ."
return existing default configuration files .
parse configuration files .
get configuration parser .
get basic parser .
get an argument parser with the usual standard arguments ready .
initialize logging .
parse args and configuration as well .
fancier file reading .
parse known arguments from files .
parse command - line arguments .
"create lesiontype array . it contains -1 or 1 depending on lesion type , or zero where no lesion ."
"get mask minimum bounding box as slices , with minimum padding in mm ."
rescale image according to voxel spacing sequences ( mm per voxel ) .
generate slice objects for a grid of windows around given center .
extract output datapoint for a cube .
create and fill grid array based on prostate centroid .
create and fill grid array based on corner .
process one parameter .
do average filtering for image .
add an index to path before possible extension .
set up logging .
add gleason score .
parse command - line arguments .
parse command - line arguments .
return filename lists indexed by slice position .
mask out a slice ( set all unselected voxels to zero ) .
create a new connection to a specified database .
creates all subsystems . you must run this before any commands are instantiated . do not run it more than once .
initialize sonar object .
"break a list into ` ` n ` ` columns , filling up each column to the maximum equal length possible . for example : :"
get the setting byte value that corresponds to ` value `
get a mask of bits in our byte that are relevant to this setting .
"get the default value of this setting , as a byte that can be bitwise or'ed with the other booleans sharing the same byte ."
return the context where this setting can be evaluated as a ( leaf ) predicate .
return the rust code to compute the value of this setting .
open this setting group such that future new settings are added to this group .
close this setting group . this function must be called before opening another setting group .
"make sure that ` pred ` has an assigned number , and will be included in this group 's bit vector ."
compute the layout of the byte vector used to represent this settings group .
compute the number of bytes required to hold all settings and precomputed predicates .
"compute a list of ( mask , byte ) pairs that incorporate all values in this preset ."
"run background job scheduler . this is just a simple scheduler with no job persistence(no redis ) , and run as a separate process from the flask app ."
"to have signed in user for next webtest requests usage : self.signin(email='user@example.com ' , password='password ' ) .... next requests"
extract error field names from html
iterates through the xml file document by document
"usage : > > > for i , j in generate_taxonomy_from_within('science').iteritems ( ): > > > print i , j > > > break astronomy and astrophysics physics"
"> > > for i , j in generate_taxonomy_from_string('science').iteritems ( ): > > > print i , j > > > break morphology meteorology , phonology"
copies an ami
generate a list of all half - lattice vectors .
filter out any incorrect half - lattice vectors .
returns ` n ` regular places on ` x ` .
"a generator of all length n tuples : math:`(m_1, ... ,m_n ) ` such that"
returns an appropriate half - lattice vector for the rcv .
computes a canonical divisor on x.
determine a base value of the riemann constant vector .
evaluate the riemann constant vector at the place ` p ` .
provides the differentials defined for this surface .
specify a list of differentials to use or none to clear .
construct a riemann surface .
"returns a place or places on the riemann surface with the given x - projection and , optionally , given y - projection ."
"returns a place or places on the riemann surface with the given x - projection and , optionally , given y - projection ."
plots all of the monodromy paths of the curve .
returns the monodromy group of the underlying curve .
returns a basis of holomorphic differentials on the surface .
the genus of this riemann surface .
returns the a - cycles of the riemann surface .
returns the b - cycles of the riemann surface .
returns the c - cycles of the riemann surface .
constructs a path to the place ` p ` .
integrate the differential ` omega ` over the path ` gamma ` .
returns the period matrix of the riemann surface .
returns the riemann matrix of the riemann surface .
deep copy constructor
shallow copy constructor
deep copy constructor
shallow copy constructor
apply cut in eta
apply cut in phi
apply cut on vertex - z
request that the track was also in a min . bias event
deep copy constructor
shallow copy constructor
deep copy constructor
shallow copy constructor
"calculate per - event yield above a certain pt , done as sum in 1 gev bins of the binned content from a min . pt to a max . pt ."
"make binned parameterisation . if normbinwith is set to true , the integral is normalised by the bin width"
"make binned parameterisation . if normbinwith is set to true , the integral is normalised by the bin width"
report stored changes and reset report .
clean up report .
"strip commas from any items used in a list in the openssl conf format , becayse they would be interpreted as delimiters ."
"given a log list read from json , writes an openssl log list to a file"
find a file based on its uuid .
flask application fixture .
initialize database .
provide elasticsearch access .
application with es and db .
override pytest 's default test collection function .
fixture for a webdriver instance of the browser .
create demo records .
generate smil file for video record ( on publish ) .
serialize a single record and persistent identifier .
initialize smil formatter with the specific record .
return the contents of the smil file as a string .
returns the subformats sorted in a specific order .
format each video subformat .
flask application initialization .
slaves command line utilities .
create missing subformats given a record i d or deposit i d.
recreate subformats for a video .
recreate subformat for the given quality .
recreate all subformats .
"returns a switchproxy , rather than a switch . it allows us to easily extend the switches method and automatically include our manager instance ."
returns ` ` true ` ` if any of ` ` instances ` ` match an active switch . otherwise returns ` ` false ` ` .
registers a condition set with the manager .
unregisters a condition set with the manager .
"given the identifier of a condition set ( described in conditionset.get_id ( ) ) , returns the registered instance ."
returns a generator yielding all currently registered conditionset instances .
returns a generator which yields groups of lists of conditions .
"try to load data from disk . when data on disk does not exist yet , calls : py : meth:`init ( ) ` to initialize the database and : py : meth:`dump ( ) ` immediately after to save the initial state to disk ."
"save data to disk . when : py : attr:`autocommit ` is ` ` true ` ` , it is called automatically from : py : meth:`init ( ) ` and : py : meth:`update ( ) ` ."
called by : py : meth:`load ( ) ` when data does not exist on disk yet . responsible for :
called from accessors like : py : meth:`__getitem _ _ ( ) ` a cache update . responsible for :
helper method called from the accessors .
access a meta data element .
"return file name where the given page should be stored , relative to ` basepath ` ."
determine if it is necessary to download a page .
"enumerate all pages in given namespace , download if necessary"
"walk output_directory and delete all files not found on the wiki . should be run _ after _ downloading , otherwise all files will be deleted !"
wrapper function to open a subprocess .
wrapper function to kill a subprocess .
test test.correlations ( )
test the star function
test univariate t - test functions
test fmtxt . code
test equation factory
tet fmtext base class
test fmtext image
test fmtxt . report class
test fmtxt.symbol ( )
load a wav file as ndvar
save an ndvar as wav file
rename an mri subject
find the variables participating in an expressions
test optimized error functions
create a new credential .
"revoke , but do not delete , a credential . --- omit_parameters : - query"
list all credentials .
update a credential . --- omit_parameters : - query
retrieve the details of a single credential . --- omit_parameters : - query
update a credential . --- omit_parameters : - query
site - wide context processor .
verify the property returns none if the user is not associated with a usersocialauth .
verify the property returns the value of the access_token stored with the usersocialauth .
test that the user model concatenates first and last name if the full name is not set .
test the site value for site configuration model .
"verify the property retrieves , and caches , an access token from the oauth 2.0 provider ."
verify the method retrieves program data from the catalog api .
verify the site cache is cleared whenever a siteconfiguration instance is saved or deleted from the database .
verify the user api url is composed correctly .
verify the method retrieves data from the user api and caches it .
helper method to render a user certificate .
verify that the view renders certificate without sharing bar .
verify that the view renders certificate with sharing bar .
verify that the view renders awarded certificates with sharing bar .
verify that the view returns 404 when the uuid is valid but certificate status is ' revoked ' .
verify that view returns 404 with invalid uuid .
verify the view returns 404 for attempts to render unsupported credentials .
verify that the view response contain signatory organization name if signatory have organization .
"verify that the view renders certificates in the configured language when it has been set , and in the default language ( english ) when content_language has not been set ."
verify the view renders a credential .
verify htmlescape filter escapes javascript injection
verify that the method for constructing file paths properly creates the set
verify that the filter correctly filters an image
"uses the filepath parameter to construct a set of potential language suffixed file names , and return the template_name of the first template matching the current language , default language if otherwise , or if neither the base path requested . throws a templatenotfound exception if none are found ."
creates an array containing between two and five strings in a guaranteed order : 1 . the requested language added before the svg suffix ( e.g. filepath-es-419.svg ) 2 . ( optional ) the requested language two character code added before the svg suffix ( e.g. filepath-es.svg ) 3 . ( optional ) the default language added before the svg suffix ( e.g. filepath-en-us.svg ) 4 . ( optional ) the default language two character code added before the svg suffix ( e.g. filepath-en.svg ) 5 . the unmodified requested filepath ( e.g. filepath.svg )
"cleaning of the answer field , by checking it 's value ."
initialize the form by setting the valid passwords .
check that the password is valid .
save the password as the authentication token .
check that the password is valid .
show the form if there are any valid passwords .
initialize the form by setting permissions needed for access .
"when receiving the filled out form , check for valid access ."
save the password as the authentication token .
check that the password is valid .
determine if the form should be shown on locked pages .
define a decorator based on the lockdownmiddleware .
returns a constant json object
returns a function json object
returns an ordered list of parameter types
urllib is broken for ssl connections via a proxy therefore we ca n't use urllib.urlretrieve ( ) .
returns the folder path that the package lies in .
generator that reads an separated value file row by row .
pickle some data to a given path .
unpickle some data from a given path .
"automatically determine the number of cores . if that fails , the number defaults to a manual setting ."
a generator that splits a list in k sublists of roughly equal size .
"given an argparse argumentparser , add a new commandline argument that can be used to select a subset of regions"
"given a geojson filename , will register it as a new region"
"given a region specification in the format < regcol.regname > like "" test_zones_1.h10v09_1 "" "" modis_tiles.h10v09 "" returns the polygon for said region"
true if this is a source that can be paused . if false the source will be stopped instead of paused .
add any source - specific information to the inital state when this source starts playing .
iterate over audio packets from this source .
called if the playback is stalled because no packets have been delivered for a while . the source can use this as a signal that it might need to reset itself .
called when playback of the source has been stopped .
"called in response to the next command . given the current state the source should either return itself to indicate no change , return a new source , or return none to signal that playback should stop ."
"same as next_source ( ) , but for the other direction ."
read and parse a toc file generated by cdrdao into a dbdisc instance .
merge a basic toc into an existing model . dbdisc .
merges the toc read by cdrdao into an existing model . dbdisc .
parse a toc generated by cdrdao into a dbdisc instance .
parse out a string argument from a toc line .
parse an msf from a toc line .
parse a cd_text block .
parse an iterable containing the lines of a single card into a dict .
lazily yields each parsed card from a card listing file .
populate the database using a collection of cards .
policyrule - a model defined in swagger
gets the i d of this policyrule . # noqa : e501
sets the i d of this policyrule .
gets the gate of this policyrule . # noqa : e501
sets the gate of this policyrule .
gets the trigger of this policyrule . # noqa : e501
sets the trigger of this policyrule .
gets the action of this policyrule . # noqa : e501
sets the action of this policyrule .
gets the params of this policyrule . # noqa : e501
sets the params of this policyrule .
returns true if both objects are equal
: rtype :
triggerparamspec - a model defined in swagger
gets the name of this triggerparamspec . # noqa : e501
sets the name of this triggerparamspec .
gets the description of this triggerparamspec . # noqa : e501
sets the description of this triggerparamspec .
gets the example of this triggerparamspec . # noqa : e501
sets the example of this triggerparamspec .
gets the required of this triggerparamspec . # noqa : e501
sets the required of this triggerparamspec .
gets the state of this triggerparamspec . # noqa : e501
sets the state of this triggerparamspec .
gets the superceded_by of this triggerparamspec . # noqa : e501
sets the superceded_by of this triggerparamspec .
gets the validator of this triggerparamspec . # noqa : e501
sets the validator of this triggerparamspec .
returns true if both objects are equal
feedgroupmetadata - a model defined in swagger
gets the name of this feedgroupmetadata . # noqa : e501
sets the name of this feedgroupmetadata .
gets the created_at of this feedgroupmetadata . # noqa : e501
sets the created_at of this feedgroupmetadata .
gets the last_sync of this feedgroupmetadata . # noqa : e501
sets the last_sync of this feedgroupmetadata .
gets the record_count of this feedgroupmetadata . # noqa : e501
sets the record_count of this feedgroupmetadata .
returns true if both objects are equal
initialize logging configured to use a standard logger rather than a twistd logger : return :
imagevulnerabilitylisting - a model defined in swagger
gets the user_id of this imagevulnerabilitylisting . # noqa : e501
sets the user_id of this imagevulnerabilitylisting .
gets the image_id of this imagevulnerabilitylisting . # noqa : e501
sets the image_id of this imagevulnerabilitylisting .
gets the legacy_report of this imagevulnerabilitylisting . # noqa : e501
sets the legacy_report of this imagevulnerabilitylisting .
gets the cpe_report of this imagevulnerabilitylisting .
sets the cpe_report of this imagevulnerabilitylisting .
returns true if both objects are equal
errorresponse - a model defined in swagger
returns the dict as a model
gets the code of this errorresponse .
sets the code of this errorresponse .
gets the type of this errorresponse .
sets the type of this errorresponse .
gets the message of this errorresponse .
sets the message of this errorresponse .
"parses a string you 'd give ' docker pull ' into its consitutent parts : registry , repository , tag and/or digest . returns a dict with keys :"
legacyvulnerabilityreport - a model defined in swagger
gets the multi of this legacyvulnerabilityreport . # noqa : e501
sets the multi of this legacyvulnerabilityreport .
returns true if both objects are equal
imageingressresponse - a model defined in swagger
returns the dict as a model
gets the status of this imageingressresponse .
sets the status of this imageingressresponse .
policyruleparams - a model defined in swagger
returns the dict as a model
gets the name of this policyruleparams .
sets the name of this policyruleparams .
gets the value of this policyruleparams .
sets the value of this policyruleparams .
policy - a model defined in swagger
gets the i d of this policy . # noqa : e501
sets the i d of this policy .
gets the name of this policy . # noqa : e501
sets the name of this policy .
gets the comment of this policy . # noqa : e501
sets the comment of this policy .
gets the version of this policy . # noqa : e501
sets the version of this policy .
gets the rules of this policy . # noqa : e501
sets the rules of this policy .
returns true if both objects are equal
return a list of endpoint urls for the given service name . : param service_name : : return : list of url strings
imageselectionrule - a model defined in swagger
returns the dict as a model
gets the i d of this imageselectionrule .
sets the i d of this imageselectionrule .
gets the name of this imageselectionrule .
sets the name of this imageselectionrule .
gets the registry of this imageselectionrule .
sets the registry of this imageselectionrule .
gets the repository of this imageselectionrule .
sets the repository of this imageselectionrule .
gets the image of this imageselectionrule .
sets the image of this imageselectionrule .
return a decorator that validates arguments with provided ` validator ` function .
check that the image 's size superior to ` size `
check that the image width is superior to ` width `
check that the image height is superior to ` height `
"crop the image with a centered rectangle of the specified size image : a pillow image instance size : a list of two integers [ width , height ]"
"resize image according to size . image : a pillow image instance size : a list of two integers [ width , height ]"
"resize image according to size . image : a pillow image instance size : a list of two integers [ width , height ]"
"resize image according to size . image : a pillow image instance size : an integer or a list or tuple of two integers [ width , height ]"
"resize image according to size . image : a pillow image instance size : an integer or a list or tuple of two integers [ width , height ]"
"resize image according to size . image : a pillow image instance size : a list of two integers [ width , height ]"
"helper function to access one of the resize function . method : one among ' crop ' , ' cover ' , ' contain ' , ' width ' , ' height ' or ' thumbnail ' image : a pillow image instance size : a list or tuple of two integers [ width , height ]"
test presence of default list table headers .
verify json is valid .
test json response for nodes list .
test json response for node show .
test json response for node validation .
test json response for node show states .
test json response for node creation .
test json response for node update .
test json response for drivers list .
test json response for driver show .
test json response for driver properties .
test json response for chassis list .
test json response for chassis show .
test json response for chassis create .
test json response for chassis update .
test json response for chassis - node - list command .
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
test steps :
negative test for baremetal node driver options .
test for baremetal node delete without node specified .
test for baremetal node list with wrong argument .
negative test for baremetal node set command options .
negative test for baremetal node unset command options .
reboot node from power off state .
reboot node from power on state .
returns an instance of : class:`httperror ` or subclass based on response .
retrieve the current configured sharedstorages entries : return : [ list ] list containing the current sharedstorages entries
: type quantity : int : type iqn : list[str ] : type name : str : type protocol : sharedstorageprotocols : param quantity : amount of gb : param iqn : list of iqn represented in string format : param name : name of the resource : param protocol : protocol to use : return :
"get a value that can be the boolean representation of a string or a boolean itself and returns it as a boolean . if this is not the case , it returns a string ."
"for most test , provide a client instance with the user - specified handle server url ."
test reading handle record from server .
test reading existent and inexistent handle value from server .
test reading handle value from inexistent handle .
test instantiation of client : no exception if password wrong .
test instantiation of client : exception if username has no index .
test instantiation of client : exception if username does not exist .
test instantiation of client : no exception if password wrong .
test instantiation of client : exception if username does not exist .
test instantiation of client : no exception if password wrong .
test instantiation of client : no exception if password wrong .
testing if instantiating with default handle server'works and if a handle is correctly retrieved .
testing if instantiating with default handle server works and if a handle is correctly retrieved .
test whether username exists .
test exception when contradictory inputs are given .
"replace timestamp values by "" xxx "" because their values do not matter ."
create an instance of the sr830 class .
set the frequency of the amplifier .
get the frequency of the amplifier .
set the input configuration : 0 : a 1 : a - b 2 : i ( 1 mohm ) 3 : i ( 100 mohm )
get the phase of the amplifier .
get the input configuration of the amplifier . 0 : a 1 : a - b 2 : i ( 1 mohm ) 3 : i ( 100 mohm )
set the amplitude of the amplifier .
get the amplitude of the amplifier .
record the current value of two instrument parameters to the internal buffer . possible parameters are : 1 : x 2 : y 3 : r 4 : theta 5 : aux in 1 6 : aux in 2 7 : aux in 3 8 : aux in 4 9 : reference frequency 10 : ch1 display 11 : ch2 display
ramp the output of the amplitude .
set the display of the amplifier .
get the display configuration of the amplifier .
get the current value of a single parameter . possible parameter values are : 1 : x 2 : y 3 : r 4 : theta
get the current value of between two and six instrument parameters . possible parameters are : 1 : x 2 : y 3 : r 4 : theta 5 : aux in 1 6 : aux in 2 7 : aux in 3 8 : aux in 4 9 : reference frequency 10 : ch1 display 11 : ch2 display
"set the time constant of the amplifier . possible values : 0 : 10 us , 10 : 1 s , 1 : 30 us , 11 : 3 s , 2 : 100 us , 12 : 10 s , 3 : 300 us , 13 : 30 s , 4 : 1 ms , 14 : 100 s , 5 : 3 ms , 15 : 300 s , 6 : 10 ms , 16 : 1 ks , 7 : 30 ms , 17 : 3 ks , 8 : 100 ms , 18 : 10 ks , 9 : 300 ms , 19 : 30 ks }"
set the sensitivity of the amplifier . see sr830.getsensitivity for dictionary of values . args : sens_index ( int ): index of associated sensitivity ( see above )
get the current sensitivity value of the amplifier .
get the current temperature in kelvin .
set a target temperature and sweep rate .
pause execution until the chamber reaches its target temperature .
get the current magnetic field in gauss .
set a target magnetic field and sweep rate .
pause execution until the chamber reaches its target field .
connect to an ips 120 - 10 at the specified gpib address
set the local / remote control state of the ips 120 - 10
read the current magnetic field in tesla
read the current set point for the magnetic field in tesla
read the current magnetic field sweep rate in tesla / min
set the field activation method
set the switch heater activation state
"set the magnetic field set point , in tesla"
"set the magnetic field sweep rate , in tesla / min"
set the display to show amps or tesla
wait for the field to reach the set point
"return the path of a data file , these are relative to the current test directory ."
return version string .
generation of mock catalogues : param n : number of catalogs : param m : number of snps per catalog : return : list of catalogs
reduces data for interactive plot : param data : list of catalogs : return : table
help method to change the colorbar to match the cut levels or colormap used in a ginga imageview .
this method is called when the cut level values ( lo / hi ) have changed in a channel . we adjust them in the colorbar to match .
this method is called when the user moves the mouse over the colorbar . it displays the value of the mouse position in the colorbar in the readout ( if any ) .
this method is called when the rgbmap is changed . we update the colorbar to match .
this gets called when the data position relative to the cursor changes .
send view to remote server and do slicing there .
"render the image represented by ( rgbobj ) at dst_x , dst_y in the pixel space ."
get sets of contour points for numpy array ` data ` . ` levels ` is a sequence of values around which to calculate the contours . returns a list of numpy arrays of points -- each array makes a polygon if plotted as such .
get sets of contour points for numpy array ` data ` . ` num_contours ` specifies the number ( int ) of contours to make . returns a list of numpy arrays of points -- each array makes a polygon if plotted as such .
"create and return a compound object for ginga ` canvas ` , consisting of a number of contour polygons . ` contour_groups ` is a list of numpy arrays of points representing polygons , such as returned by calc_contours ( ) or get_contours ( ) . ` colors ` ( if provided ) is a list of colors for each polygon . any other keyword parameters are passed on to the polygon class ."
this is called when image changes .
this is called when image is cleared .
this api requires authenticated users .
"ensure creates , updates and deletes are n't allowed"
create patch completed event for patches with series .
validate we can list cover letters .
validate we can get a specific cover letter .
"mapwidget is not acutally serialized when used with location , so ignore any values ."
see deserialize .
save all versions of an activity as historicalactivity records .
check if data is text instance
check if data is bytes instance
create a self - signed certificate with the given common name .
create a certificate request with the given common name .
a presence server responds to identify messages with the cert stored for the requested domain .
vertex nodes with no portal will not sign cert requests .
' sign ' messages with a cert request result in a cred login with the given password . the avatar returned is then asked to sign the cert request with the presence server 's certificate . the resulting certificate is returned as a response .
debugging method ; returns a string indicating percentage completion
an iterator of all positions that a bit holds in this bitarray .
exports repository 's master branch to a temporary workspace .
"deploy the entire project at local_dir to remote_dir , excluding the given paths ."
publishes web implementation and resources to remote server .
deploys notification script to remote server .
dynamically load a class from a string
"the refactored routes for jurors , coming soon ."
summary : get juror - level index of all campaigns and rounds .
"summary : get juror - level list of rounds , identified by campaign id ."
"summary : get juror - level details for a round , identified by round id ."
message format :
decode a byte sequence representing a datamap grid into a tuple of a scaled latitude and longitude .
"given a tuple of scaled latitude / longitude integers , return a compact 8 byte sequence representing the datamap grid ."
given a lat / lon return the correct shard i d for this grid .
given a lat / lon return the correct db model class for this grid .
return a dict of shard i d to model classes .
execute the view code and return a response .
"given a query and possible results found by other sources , check if this source should attempt to perform a search ."
provide a type specific possibly empty result list .
configure and return a : class:`~ichnaea.geoip . geoipwrapper ` instance .
: returns : the age of the database file in days . : rtype : int
: returns : true if this is a real database with a valid db file . : rtype : bool
: returns : true if the c extension was installed correctly . : rtype : bool
look up information for the given ip address .
return the best radius guess for the given region code .
: returns : none
: returns : -1
: returns : false
configure the web app stored in : data:`ichnaea.webapp.app._app ` .
calculate interval of values that are unique in a correlation block .
calculate detector threshold given the formula 's coefficients .
calculate peak index and estimate sqrt(power ) of peak .
sub - sample soa estimation using parabolic interpolation .
sub - sample soa estimation using gaussian interpolation .
estimate the soa of the given signal .
correlate / despread using fft .
calculate peak index and estimate sqrt(power ) of peak .
estimate noise from signal 's rms / power .
calculate detector threshold given the formula 's coefficients .
generate a gold code template .
sample ` code ` at ` sps ` samples per symbol using an integer sampler .
"check input file to see if a hn link is already present . returns true if present , false if not ."
"find latest "" who is hiring ? "" link from hn . return a string formatted for input file "" itemid year - month """
"append latest hn "" who is hiring ? "" itemid and date to input file ."
"get latest hn "" who is hiring ? "" link , check if already in input file . append it to file if not ."
get text in combobox - this gives it the same interface as qlineedit .
set text in combobox - gives same interface as qlineedit .
input valid ? - gives same interface as qlineedit .
replace the text and place item at top of history .
get name for saving in settings .
load contents of history combo from settings .
save contents of history combo to settings .
show historycombo and load history .
save history as widget is hidden .
translate text .
initialise dialog .
execute dialog .
translate text .
construct list of settings .
return set of lines to plot for length - angle .
return set of lines for point to point .
plot the key on a plotter .
"if control items are moved , update line ."
"for compound datasets , attributes can be given on a per - column basis . this filters the attributes by the column name ."
"convert a value like 0:1:3,:,::-1 to a tuple slice ( ( 0,1,3 ) , ( none , none , none ) , ( none , none , -1 ) ) or reduce dimensions such as : , 3 - > ( ( none , none , none),3 )"
convert tuple slice into text .
"given hdf / numpy dataset , apply slicing tuple to it and return data ."
h5py often returns bytes instead of unicode . this decodes if in bytes
convert numpy / hdf dataset to suitable data for veusz . raise converterror if can not .
return list of names to give hdus given a fits file .
convert fits tform codes into :
get veusz - specific attributes from a hdu header .
translate text .
check step syntax is okay . syntax is min : max : stepsize returns none if fails
open dialog to recreate a datasetexpression / datasetrange .
initialise dialog with document .
escape dataset names if they are not typical python ones .
update controls depending on selected mode .
allow dataset to be edited again .
enable or disable create button .
create button pressed .
translate text .
construct list of settings .
return user - friendly description .
add axes automatically .
get the axes for widgets to plot against . axesnames is a list / set of names to find . returns a dict of objects
return a list of axes widgets given a list of names .
use settings to compute margins .
update the margins before drawing .
graph resized or moved - call helper routine to move self .
translate text .
"sometimes h5py returns non - unicode strings , so hack to decode strings if in wrong format ."
wrap an import statement to check for ioerror .
execute a script for the document .
load all the veusz datasets in the hdf5 file .
tag datasets loaded from hdf5 file .
load an hdf5 of the name given .
load document from file .
translate text .
settings for widget .
extend inrange to range of data .
draw labels for the points .
return parameters for colorbar .
automatic color for plotting .
plot the data on a plotter .
render vsz document to create outfile .
render py embedded script to create outfile .
check documents produce same output as in comparison directory .
only output floats to 1 dp .
translate text .
set the function output is sent to .
send text to the output function .
does nothing as yet .
called if the return key is pressed in the edit control .
overridden to handle history .
"add text to the tail of the error log , with a specified style"
"execute the function within the console window , trapping exceptions ."
"if this window is hidden , show it , then hide it again in a few seconds ."
hide window and notification widget .
write text in stdout font to the log .
write text in stderr font to the log .
inserts the text into the log .
called if the return key is pressed in the edit control .
output information if the document logs something .
translate text .
is this validator ok ?
open dialog to recreate histogram .
setup dialog .
update list of datasets .
validate expression .
generate manual bins .
add an extra bin to the manual list .
remove selected bins .
reset button clicked .
re - edit dataset .
create histogram .
"extract the features from the eeg inputs : eegdata : array of dimension [ number of samples , number of channels ] fs : sampling frequency of eegdata"
generate the name of the features
find the next power of 2 for number i
saves a transition .
put local file to swift
put storlet file to swift
put dependency files to swift with 755 permission
deploy storlet file and required dependencies as swift objects
get token string to access to swift
"print error messages , the parser stack , and the input text -- for human - readable error messages ."
initialize a token .
initialize the scanner .
temporarily parse from a second file .
return a file / line / char tuple .
"print the line of ' text ' that includes position ' p ' , along with a second line with a single caret ( ^ ) at position p"
get more input if possible .
return the next character .
scan for another token .
returns the token type for lookahead ; if there are any args then the list of args is the set of token types to allow
"returns the matched text , and moves to the next token"
temporarily read from someplace else
returns the token type for lookahead ; if there are any args then the list of args is the set of token types to allow
"returns the matched text , and moves to the next token"
create a new context .
"generate a grammar , given an input filename ( x.g ) and an output filename ( defaulting to x.py ) ."
"return the directory where experimental artifacts are placed . if the directory does not exist , it is created ."
return the transifex resource name
fetch translations from transifex .
"commit messages to transifex ,"
see : http://stackoverflow.com/a/266162
method to force the combination of parallel coverage reports .
constructs a collection by initializing its computedobject .
imports api functions to this class .
removes imported api functions from this class .
apply a filter to this collection .
shortcut to add a metadata filter to a collection .
shortcut to add a geometry filter to a collection .
shortcut to filter a collection with a date range .
returns all the known information about this collection .
limit a collection to the specified number of elements .
sort a collection by the specified property .
returns the type of the collection 's elements .
maps an algorithm over a collection .
iterates over a collection with an algorithm .
verifies point constructor behavior with valid arguments .
verifies multipoint constructor behavior with valid arguments .
verifies linestring constructor behavior with valid arguments .
verifies linearring constructor behavior with valid arguments .
verifies multilinestring constructor behavior with valid arguments .
verifies polygon constructor behavior with valid arguments .
verifies rectangle constructor behavior with valid arguments .
verifies multipolygon constructor behavior with valid arguments .
verifies multipoint constructor behavior with invalid arguments .
verifies linestring constructor behavior with invalid arguments .
verifies linearring constructor behavior with invalid arguments .
verifies multilinestring constructor behavior with invalid arguments .
verifies polygon constructor behavior with invalid arguments .
verifies multipolygon constructor behavior with invalid arguments .
verifies that constructors that take arrays fix nesting .
verifies that json parsing and generation preserves the geodesic flag .
check the behavior of the geometry constructor .
verifies the computed object behavior of the geometry constructor .
checks that geometry is valid and has the expected nesting level .
verifies that geometry is invalid .
"test eq ( ) , ne ( ) and hash ( ) ."
verifies that addition of static and instance api functions .
creates a feature a geometry or computed object .
imports api functions to this class .
removes imported api functions from this class .
"fetch and return a map i d and token , suitable for use in a map overlay ."
construct a geojson point .
create a geojson multipoint .
create a geojson rectangle .
create a geojson linestring .
create a geojson linearring .
create a geojson multilinestring .
create a geojson polygon .
create a geojson multipolygon .
returns the set of keywords in a uri template
expand template as a uri template using variables .
verifies a complex serialization case .
verifies serialization finds and removes repeated values .
constructs a collection features .
imports api functions to this class .
"fetch and return a map i d and token , suitable for use in a map overlay ."
get a download url for this feature collection .
verifies basic behavior of ee . string .
"test eq ( ) , ne ( ) and hash ( ) ."
encodes the object in a format compatible with serializer .
verifies that functions can convert positional to named arguments .
verifies that functions can promote and verify their arguments .
verifies the full function invocation flow .
verifies function docstring generation .
verifies that constructors understand valid parameters .
verifies that getmap ( ) uses collection.draw to rasterize features .
initialize the ee library .
reset the library . useful for re - initializing to a different server .
remove the dynamic classes .
configure oauth2 credentials for a google service account .
invoke the given algorithm with the specified args .
call a function with a dictionary of named arguments .
wrap an argument in an object of the specified class .
generate classes for extra types that appear in the web api .
generates a dynamic api class for a given name .
return the timescale label based on begin / end dates .
keyword arguments : width -- visible width of terminal in characters height -- visible height of terminal in rows depth -- depth of terminal in number of colors
write output to the terminal
calculate the length of a string
get the terminal color depth as number of colors
get the terminal width as number of characters
get the terminal height as number of rows
reset terminal formatting back to normal output
keyword arguments : terminal -- instance of terminal emulator theme _ -- instance of theme
apply theme formatting and return the resulting string
adds the cell to the table
adds the row to the table
draw the table on the specified terminal constrained to the specified width
returns a list of the cells stored in the row
appends the cell to the row
calculate and return the width of the row in characters
draw the row on the terminal using the defined column widths
calculate and return the width in characters of the cell contents
return the contents of the cell
draw the cell on the terminal constrained to the specified width
clean away the 10 % of points that have the largest residual errors ( different between the prediction and the actual net worth )
compute the average number of bronze medals earned by countries who earned at least one gold medal .
checks whether the server is reachable by using urllib .
returns a query with sorting / pagination criteria added .
is the instance using fatal exceptions .
creates a client to connect to the barbican service .
stores a secret with the key manager .
creates the url required for accessing a secret .
retrieves the uuid of the secret from the secret_ref .
retrieves the specified managed object .
deletes the specified managed object .
checks if the configuration variables are valid .
checks if the configuration variables are valid .
handle initialization if this is a standalone service .
handler post initialization stuff .
loads plugin using alias or class name
loads service plugins .
helper method to grab engine .
helper method to grab session .
remove database records that have been previously soft deleted .
set rpc timeout ceiling for all backing - off rpc clients .
create plural to singular mapping for all resources .
build resources for advanced services .
computes simple statistics
"estimates the significance of correlations between non iid time series by 3 independent methods : 1 ) ' ttest ' : t - test where d.o.f are corrected for the effect of serial correlation 2 ) ' isopersistent ' : ar(1 ) modeling of x and y. 3 ) ' isospectral ' : phase randomization of original inputs . ( default ) the t - test is parametric test , hence cheap but usually wrong except in idyllic circumstances . the others are non - parametric , but their computational requirements scales with nsim ."
"estimates the significance of correlations between non iid time series by 3 independent methods : 1 ) ' ttest ' : t - test where d.o.f are corrected for the effect of serial correlation 2 ) ' isopersistent ' : ar(1 ) modeling of x and y. 3 ) ' isospectral ' : phase randomization of original inputs . ( default ) the t - test is parametric test , hence cheap but usually wrong except in idyllic circumstances . the others are non - parametric , but their computational requirements scales with nsim ."
estimates the significance of correlations between 2 time series using the classical t - test with degrees of freedom modified for autocorrelation . this function creates ' nsim ' random time series that have the same power spectrum as the original time series but with random phases .
"computes correlation between two timeseries , and their significance . the latter is gauged via a non - parametric ( monte carlo ) simulation of correlations with nsim ar(1 ) processes with identical persistence properties as x and y ; the measure of which is the lag-1 autocorrelation ( g ) ."
generates p realization of a red noise [ i.e. ar(1 ) ] process with same persistence properties as x ( mean and variance are also preserved ) .
return the lag-1 autocorrelation from ar1 fit .
produce p realizations of an ar1 process of length n with lag-1 autocorrelation g
produce m realizations of an ar1 process of length n with lag-1 autocorrelation g
phase randomization correltation estimates
phaseran by carlos gias
map the location of all lat / lon according to some criteria
map one location on the globe
"apply the [ u , v ] optical flow to the data i"
"sniffanswerdhcp('eth0 ' , ' udp and ( port 67 or 68 ) ' , ' dhcp_client ' , 5 ) # "" [ * ] waiting for a dhcp offer ... """
initiate the scan
"> > > genkey({""name "" : "" genericfont "" , "" size "" : 40 , "" bold "" : true } ) ' truegenericfont40 '"
"> > > isincube((10 , 10 ) , ( 5 , 5 , 15 , 15 ) ) true"
> > > keytostring(k_lalt ) u'l - alt ' > > > keytostring(0x31 ) u'1 '
"using a bitmap font represented as a 2d matrix , and some text represented as an ascii string a new matrix is returned . this matrix contains the rendered blocktext ."
test that dhdl has the correct form when extracted from files .
test the u_nk has the correct form when extracted from files
test the u_nk has the correct form when extracted from files
test the file validation function to ensure the function returning false if the file is invalid
test the any none function to ensure if the none value will be caught
this test is mainly used for syntax validation . if the help is printed and written to a text file then the script syntax is both python 2 & python 3 .
check that dnh does n't trip on good commands
check for evil things
check out file permission function works - groups
check out file permission function works - others
test that a text file is read and stripped correctly .
test reading credentials from a file
test show ver ( main function ) against multiple devices
check that connection funtion returns expected hostname
check that connection funtion returns expected hostname
test main function quits properly against a failed router
test main function quit can be disabled ( continue if router connection / authentication fails )
test main function with backup credentials
echo back whatever is received .
calculates the coefficientof variation of the rows or columns of a matrix . the coefficient of variation is given by the standard deviation divided by the mean of a variable :
calculates the covariance matrix of another matrix
"count the number of occurrences from each integer in a list or 1 - d : py : class:`numpy.ndarray ` . if there are gaps between the numbers , then the numbers in those gaps are given a 0 value of occurrences ."
"calculates the scatter matrix of a data matrix . the scatter matrix is an unnormalized version of the covariance matrix , in which the means of the observation values are subtracted ."
"ast must be created from a symbolic state where registers values are named "" sreg_reg- "" looks for registers that if we make the register symbolic then the ast becomes symbolic : param ast : the ast of which we are trying to analyze dependencies : return : a set of register names which affect the ast"
"looks for registers that we can make symbolic then the ast can be "" anything "" : param test_state : the input state : param ast : the ast of which we are trying to analyze controllers : param reg_deps : all registers which it depends on : return : a set of register names which can control the ast"
attempts to check if an ast is completely unconstrained : param state : the state to use : param ast : the ast to check : return : true if the ast is probably completely unconstrained
"attempts to check if an ast has any common unreversable operations mul , div : param state : the state to use : param ast : the ast to check : return : true if the ast is probably unconstrained"
: param reg_offset : tries to find the name of a register given the offset in the registers . : return : the register name
: param state : the state to use for solving : param ast1 : first ast : param ast2 : second ast : return : true if the ast 's must be equal
: return : an initial state with a symbolic stack and good options for rop
converts an input state into a state with symbolic registers : return : the symbolic state
steps up to two times to try to find an unconstrained successor : param state : the input state : param max_steps : maximum number of additional steps to try to get to an unconstrained state : return : a path at the unconstrained successor
tracker x numpy.array --- > none will be called once before processing each test sequence with the appropriate model of the object to track .
tracker x int x int --- > none will be called once before processing each test sequence with the appropriate size of the image frames which will be provided .
"tracker x np.array --- > tuple(rejected : bool , tl : pt , bl : pt , br : pt , tr : pt ) will be called once with each frame to process . you must override this method in child class ."
reloads modules and instantiates a test .
sets up self .
builds own widgets .
inserts a connection information into line edits .
tests a connection .
returns a connection information from line edits .
saves a connection information to settings of the main class .
enables or disables line edits and push buttons .
"discouraged from because if n does not divide number of samples nicely , the sampling is heavily skewed"
this decorator will run the first next of the generator
test case to ensure that the hi - c pipeline code works .
test case to ensure that the bwa indexer works .
test case to ensure that the bwa indexer works .
test case to ensure that the bwa indexer works
test case to ensure that the bwa indexer works
initialise the tool with its configuration .
tool for assessing the quality of reads in a fastq file
initialise the tool with its configuration .
sorts and filters the bam file .
the main function to run biobambamfilter to remove duplicates and spurious reads from the fastq files before analysis .
alternative main function -------------
initialise the class
main run function for generatigng the index files required by bs seeker2 .
alternative main function -------------
initialise the class
main run function for aligning fastq reads with bwa .
initialise the tool with its configuration .
convert bam to bed then make nucleosome peak calls . these are saved as bed files that can then get displayed on genome browsers .
the main function to run inps for peak calling over a given bam file and matching background bam file .
extract the compressed fastq files
test case to ensure that the rna - seq pipeline code works .
extract the compressed fastq files
test that it is possible to call the bsseeker filter
test that it is possible to call the bsseeker filter
returns a layout module given the layout name
revisions candidates to be hidden
revision to be hidden ( disregarding dynamic blocker )
non - cacheable revisions blocking hidden changesets from being filtered .
return sha1 hash of repository data to identify a valid cache .
write hidden data to a cache file
write cache of hidden changesets to disk
"read a cache if the cache exists and is valid , otherwise returns none ."
compute the set of hidden revision to filter
compute the set of revision that should be filtered when used a server
compute the set of revision that should be filtered when used a server
everything impactable by mutable revision
returns set of filtered revision for this filter name
return a filtered version of the changeset
return an unfiltered version of a repo
return a filtered version of a repository
"raises the exception , performs cleanup if needed"
determines this ( self 's ) thread i d
raises the given exception type in the context of this thread
"raises systemexit in the context of the given thread , which should cause the thread to exit silently ( unless caught )"
display all data currently available on pipe as remote output .
wait until some data are available on main or side
"call < methname > on "" main "" , forward output of "" side "" while blocking"
"send a changegroup to the remote server . return an integer similar to unbundle ( ) . deprecated , since it requires locking the remote ."
return path and query that has been split from uri
prepare .socket of new httpserver instance
check states of working directory asynchronously
clean working directory by the specified action
return a configured instance of the lexer
split object i d list into two list with commit sha1s and tag sha1s .
attempt to determine the version of git currently installed .
"require git version > = version , or skip the calling test ."
run a git command .
"run a git command , capture stdout / stderr , and fail if git fails ."
import a repo from a fast - export file in a temporary directory .
check for a running tcp daemon .
import a repo from a fast - export file in a temporary directory .
verify that cert ( in socket.getpeercert ( ) format ) matches hostname . crls is not handled .
return true if this seems to be a pure apple python that * is unfrozen and presumably has the whole mercurial module in the file system * presumably is an apple python that uses apple openssl which has patches for using system certificate store cas in addition to the provided cacerts file
return path to ca certificates ; none for system 's store ; ! to disable
"construct a walker over the svn_fs_root_t root , which must be in the svn_fs_t fs_ptr . invoke notify_cb with a single argument of type changedpath for each change under root ."
"like str.splitlines , but only split on newlines ."
"return ( block , type ) tuples , where block is an mdiff.blocks line entry . type is ' = ' for blocks matching exactly one another ( bdiff blocks ) , ' ! ' for non - matching blocks and ' ~ ' for blocks matching only after having filtered blank lines . if refine is true , then ' ~ ' blocks are refined and are only made of blank lines . line1 and line2 are text1 and text2 split with splitnewlines ( ) if they are already available ."
print base85 - encoded binary diff
encode text in base85 format
decode base85 - encoded text
"ensure a directory exists , creating if necessary ."
rename file with temporary backup file to rollback if rename fails
create a file object that obeys the git file locking protocol .
close and discard the lockfile without overwriting the target .
"close this file , saving the lockfile over the original ."
proxy property calls to the underlying file .
returns false if a path should not be treated as part of a repo .
close and remove all connection objects being kept for reuse .
"return an addinfourl object for the request , using http_class ."
"before the conversion begins , acquire a read lock for all the operations that might need it . fortunately read locks do n't block other reads or writes to the repository , so this should n't have any impact on the usage of the source repository ."
"filters out ghost revisions which hg does not support , see < http://bazaar-vcs.org/ghostrevision >"
reinstall clusters .
determine if the hostname is accociated with this vendor .
open vswitch name .
get ' name ' proptery .
do health check .
runs cobbler check from xmlrpc client .
update progress .
check if the os matcher is acceptable .
update progress .
check if the package matcher is acceptable .
load a module instance .
ssh to execute script on remote machine
valid the format of an ip address .
impelmentation of snmpwalk functionality
impelmentation of snmp get functionality
check if credential is valid snmp v2 credential .
check if credential is valid ssh credential .
snmpget by credential .
snmpwalk by credential .
execute command .
main entry .
get apiclient token .
frommodule . class.__init _ _
frommodule . class.class_method
frommodule . class.static_method
frommodule . parent.__init _ _
frommodule . child.__init _ _
tomodule . class.__init _ _
tomodule . class.class_method
tomodule . class.static_method
tomodule . parent.__init _ _
tomodule . child.__init _ _
adds a test step to the test
starts the driver once the object enters context
closes the driver once the object exits context
navigates to the specified url
tries to find an element on the web page and click it . raises an error if the element ca n't be found or clicked .
tries to click an element on the web page for the time specified as the wait time . does nothing if the element is not found .
""" tries to get an attribute value from an element on the web page . raises errors if the element ca n't be found or if it does n't have the specified attribute ."
tries to get the value of an element on the web page . raises errors if the element ca n't be found .
tries to find an element on the web page . raises an error if the element ca n't be found .
"tries to find an element at the given css path . returns true if one is found , false otherwise ."
finds an element and sends the specified text to it as if the user typed it . raises errors if the element can not be found .
sends the enter key to the page as if the user had pressed the return button on the keyboard .
finds a select element and selects an item by its text . raises errors if the element can not be found or if it is not a select web element .
finds a checkbox element and checks or unchecks it by clicking on it . raises errors if the element can not be found .
switches the context of the web driver to the frame at the specified css path . raises errors if the frame can not be found .
switches the context of the web driver to the default content of the page .
""" gets an exception if one occurred during execution of the step . returns none otherwise ."
""" sets the exception that occurred during execution of the step ."
only set flags if num coincidences is not null
only set flags if num events is not null
only set flags if num config is not null
check for new events since last check
check for updated data files
summarize event numbers per station
get all stations with data on specified date
return path to data file
get configuration messages
get url and check if the response is ok and valid json
get url and check if the response is ok and valid tsv
"returns the home directory , as a string ."
returns the home directory for spykes data .
"pulled from honcho code with minor updates , reads local default environment variables from a .env file located in the project root directory ."
determine all zero - cost action according to current state asserts that the returned action is valid before returning : param state : current state of the parser : param all_actions : actions object used to map actions to ids : param create : whether to create new actions if they do not exist yet : return : dict of action id to action
determine all zero - cost action according to current state : param state : current state of the parser : return : generator of action items to perform
returns sha1 hash of the code
take in account key / values
compiles a latex snippet to png
creates a png if needed .
handle gabc file inclusion and gabc code block .
catch qgis error messages for introspection .
format the title for it to fit the button .
reformat windows path for them to be understood by qgis .
get qgis map canvas current epsg code .
create a date object with the string given as a date by the api .
open the credentials request online form in web browser .
open the bugtracker on the user 's default browser .
calculate the number of pages for a given number of results .
show authentication form with prefilled fields .
make some special actions in certains cases .
check adequation between system and qgis proxy configuration .
runs before each test .
resets the environment .
checks if the environment has completed .
add an agent to the environment .
return the agent specified by the i d.
enter the environment and all agents .
update the environment and all agents .
exit the environment and all agents .
identifies if the task is episodic or not .
event delay .
reset the task .
request termination of the task .
check if termination was requested .
set the termination flag .
check if the task has completed .
gather the state feature information .
retrieve the reward .
configure : class:` . state ` .
configure : class:` . action ` .
return a random initial state .
find valid successors .
returns the cost for the current path .
"assumes valid name , valid name+flags combination , valid condcode . check the operands and return an error string if invalid , empty string otherwise ."
check_blockdatatransop must be called before this . encode the instruction and return it as a bytearray object .
"add a license agreement to the specified disk image file , which should have been unflattened first ."
encode a timestamp send at the timeclock
decode a timestamp retrieved from the timeclock
run vmps for heisenberg model .
run vmps for heisenberg model .
run infinite vmps for heisenberg model .
"corrects the exposure of an image based on its histogram . inputs : img - a grayscale image on which to perform the correction roi - a list of 4 points ( x , y , width , height ) that form the rectangular roi of the white color standard . if a list of 4 points is not given , whole image will be used ."
corrects the background of a mostly white image by setting histogram peak to 255
search image filename in sys.imagepath or sys.path .
- purpose read an image from a file to a numpy array . - synopsis arr = nbread(imagefile ) - input imagefile : image file path . - output arr : numpy array representing an image .
- purpose read an image from a file to a numpy array as grayscale . - synopsis arr = nbread(imagefile ) - input imagefile : image file path . - output arr : numpy array representing an image .
"- purpose write an image from a numpy array to an image file . the format is deduced from the filename extension . - synopsis nbwrite(imagefile , arr ) - input imagefile : image file path . f : the numpy array to save ."
list image files located on sys.path .
"- purpose list image files located on sys.imagepath , if this variable exists , or , otherwise , on sys.path - synopsis imglist = nbimages(glob= ' * ' ) - input glob : default : ' * ' . glob string for the image filename . - output imglist : image filename list ."
opens a file trying with different encodings and returns the contents as a unicode string
"start a node with requested rpcallowip and rpcbind parameters , then try to connect , and check if the set of bound addresses matches the expected set ."
"start a node with rpcwallow ip , and request getinfo at a non - localhost ip ."
"@param items : items to be enumerated @type items : dict or list of tuples { key : ( human readable text , ( helper text ) ) } [ ( key , human readable text , ( helper text ) ) , ( ... ) ]"
"return list of ( key , value ) mappings ."
"return list of ( key , value ) mappings with nicer values ."
[ values ] - > [ keys ] or - > all [ keys ]
@param { str } module_set_dir - directory where all modules are stored @param { str } dir_name - directory of specific module or module - set directory
"find all ini files in the self.dirname path . then read each ini file and save all options in ' preupgrade ' section with their values to self.loded dict : self.loaded[ini_file_path ] = { option1 : value , option2 : value , ... }"
the functions is used for collecting all ini files into the one .
the function is used for storing a group.xml file
the function stores all-xccdf.xml file into content directory
html escape text ; text is a list of strings
"function replaces [ link : sss ] with either < a href=""http : sss"">sss</a > or < a href=""./sss"">sss</a > for file link"
function replaces [ bold : sss ] with < b > sss</b >
"format tags like : [ bold : some text ] - > < b > some text</b > [ link : http://127.0.0.1 ] - > < a href=""http://127.0.0.1"">http://127.0.0.1</a > [ link : /var / cache / description.txt ] - > < a href=""/var / cache / description.txt"">/var / cache / description.txt</a >"
function return a package name and version
assessment_result_path .. path to the directory where all results of the assessment are stored copied_module_set_path .. path to the module set directory copied for the assessment to the assessment_result_path
update xml or html report with relevant solution texts .
load solution texts into a dictionary .
function converts the solution text to html
find all directories that contain a module .
returns user to be auto - logged in or none
add exc handling & logging
"return report paths : ( xml , html )"
create all required global db models
update result with data from report
add data to dabase
"calculate helpful stats functions , like sums -- this is best to be done , when everything 's in db"
"execute import itself , this is the main call"
returns a new boolean property definition .
returns a new vector boolean property definition .
returns a new collection property definition .
returns a new enumerator property definition .
returns a new float property definition .
returns a new vector float property definition .
returns a new int property definition .
returns a new vector int property definition .
returns a new pointer property definition .
removes a dynamically defined property .
returns a new string property definition .
": param name : name of the dataset . : param generator generator : generator of elements in of the dataset : param output_types : list of output types of the generator : param output_shapes : output shapes of the generator : param int min_queue_examples : minimum number of examples to queue , this value should be proportional to the ram of the computer . by default is 0 : param int shuffle_size : size of the buffer for shuffling , this value should be proportional to the ram of the computer : param list[tf . tensor ] padded_shapes : shape for padding the batch : param tf . tensor padded_values : values for the padding"
"reads the data and return a tuple of ( inputs , outputs ) : param batch_size : the batch size of the returned inputs / outputs : param num_epochs : the number of epochs to read the dataset : param shuffle : whether to shuffle the data or not : param task_spec : the task spec of the training . i will help to know whether it is distributed training or not : return : the result of calling dataset.make_one_shot_iterator().get_next ( )"
see tfdataset._map ( )
counts the number of non - empty lines ( the data samples ) from the data_files . this function is called from get_size the first time . : return int : the number of non - empty lines in the data_files
loads the task information from the command line or the enviorment variables ( if the command line parameters are not set ) and returns a taskspec object : return taskspec : a taskspec object with the information about the task
"log dir specification , see : get_logs_path , https://tensorport.com/documentation/api/#get_logs_path : param str path : the path for the logs dir : return str : the real path for the logs"
"dataset specification , see : get_data_path , https://tensorport.com/documentation/api/#get_data_path"
reflect the index vertically .
reflect the index horizontally .
every other row is indexed in reverse .
every other column is indexed in reverse .
transpose rows and columns .
: param str filename : base filename to write the animated gif file
converts an hsv tuple to rgb . intended for internal use . you should use hsv2rgb_spectrum or hsv2rgb_rainbow instead .
generates rgb values from hsv values in line with a typical light spectrum .
generates rgb values from hsv that have an even visual distribution . be careful as this method is only have as fast as hsv2rgb_spectrum .
"python default hsv to rgb conversion for when hue values in the range 0 - 359 are preferred . due to requiring float math , this method is slower than hsv2rgb_rainbow and hsv2rgb_spectrum ."
"order colors by hue , saturation and value , in that order ."
"fill a portion of a strip from start to stop by step with a given item . if stop is not given , it defaults to the length of the strip ."
"` index ` must be an integer , not a slice ."
"` index ` must be an integer , not a slice ."
yield an ordered dictionary if msg['type ' ] is in keys_by_type .
"create input , output queues , call ` function ` in a subprocess or a thread ."
defer an event to run on the eventqueue .
"get all the events in the queue , then execute them ."
should be private
should be private
should be private
should be private
should be private
should be private
test snake case for a long name with camel case .
test snake case for for a long name with pascal case .
test snake case for a short name only small letters .
test snake case for a short name only small letters .
test snake case for a name with numbers resulting in an error .
test column as description for a name ending with an underscore resulting in an error .
test column as description for a long name with camel case .
test column as description for a long name with pascal case .
test column as description for a short name .
test getting the type for a string .
test getting the type for an int
executes the sql query and returns all tables from the database .
returns the table information from the database
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
test the print for a copy
test the print for a edit
test the print for a create
test the output of a generation of a sqlite plugin
test the output of a generation of a sqlite plugin
read from file helper
"test easy file generation without errors and with abort at the end , not generating the files ."
test easy file generation without errors
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
tests the initialization .
tests the getformatstringattributenames function .
tests if the creation of a folder works .
tests if the construction of the folder path works .
tests if the creation of a file none existing beforehand works .
"tests if the creation of a file , none existing beforehand and folder not existing , works ."
tests if the creation of a file none existing beforhand works .
tests if the copying of a file none existing beforhand works .
tests if the editing of a file existing works .
tests if the editing of a file not existing works .
"tests if the method create or modify file with content works , if the file exists"
"tests if the method create or modify file with content works , if the file and folder does not exist"
a prompt for information .
"a prompt for information , with a default value and a required type ."
a prompt for errors .
an echo for information .
an echo for errors .
"ask for a confirmation , either yes or no to a question ."
initialises the formatter data model .
testing the help of the main
testing the main of the sqlite
testing the interaction with main and sqlite
test a normal generation .
test a normal generation .
abstraction class for ts3 servers
login to the ts3 server
get a list of all virtual servers on the connected ts3 instance
send a global message to the current virtual server
use a particular virtual server instance
returns a clientlist of the current connected server / vhost
kicks a user identified by either clid or cldbid
poke a client with the specified message
iterator that produces jobs to run in this worker .
the actual work of the class .
"iterate through available jobs , handling each one . note that this construction leaves the blocking / non - blocking decision up to the job itself : - if jobs is finite , this handles each item once - if jobs is infinite , this yields none when a job is not available this works because none is never a valid job ."
this function creates a separation plot for logistic and probit classification . see http://mdwardlab.com/sites/default/files/greenhillwardsacks.pdf
generate the auth token : return : string
decodes the auth token : param auth_token : : return : integer|string
format output for json response .
gibb 's sampler for bayesian estimation of microbial sample sources .
make a basic mixing proportion histogram .
return the key region if point is on a settings key or none .
return the key name if point is on a settings key or none .
return the last key region preceding the specified point or none .
return the last key name preceding the specified point or none .
return the value region if point is on a settings value or none .
combines leafs with path to sublime 's packages folder .
extract sublime text 's data path from the packages path . requires the api to finish loading on st3 .
combines leafs with sublime 's ` ` data ` ` folder .
"creates a named tuple with the following attributes : file_path , path , file_name , base_name , ext , no_ext"
returns a tuple with the normalized module path plus a boolean .
returns the path to the current sublime text package . parameters are the same as for ` get_module_path ` .
` return os.path.split(get_package_path(_file_))[1 ] `
"utilizes the inspect module to get the caller 's frame . you can adjust ` i ` to find the i - th caller , default is 1 ."
yield generator for bits within bytes .
"consume a "" bitsize "" integer from a bit generator . example : # cast the next 5 bits as an int valu = cast(bits,5 )"
"consume a "" bitsize "" integer from a bit generator ."
generate colum text output from rows .
add on - demand parser callback .
retrieve the results of an on - demand parser callback .
set an explicit value in the on - demand dict .
prints things in bold .
simple postprocessor where we multiply the input values .
simple postprocessor where we compute the size of a feature .
simple postprocessor where we compute the distance between two points .
simple postprocessor where we compute the bearing angle between two points .
simple postprocessor where we compute the cardinality of an angle .
private function used in the affected postprocessor .
private function used in the displacement postprocessor .
private function used in the fatality postprocessor .
helper function to check that list_widget is equal to expected_list .
helper function to check the current step is expected_step
check the current text in list widget is expected_text
helper function to select option from list_widget
test for metadata translation .
test for existing complex keywords in wizard in locale mode .
normalizing value string used as key and field name .
initialize minimum needs fields .
get minimum needs field from a given key .
get minimum needs parameter from a given field .
declaring minimum needs so it can be recognized in module level import .
test init the tool .
main function to run the example .
creates a paragraph object
render a paragraph messageelement as html
render a paragraph messageelement as plain text
calls the overridden method and adds provenance and summary data
json representation of the metadata
read metadata from json and set all the found properties .
xml representation of the metadata .
read metadata from xml and set all the found properties .
read metadata provenance from xml .
get the provenance elements of the metadata
add a step to the provenance of the metadata
add a if provenance step to the provenance of the metadata
update metadata value from a keywords dictionary .
property for labels .
setter for labels .
property for options .
setter for default_values .
property for default_value .
setter for value .
retrieve a value from a field in the analysis summary layer .
retrieve a value from field in the specified exposure analysis layer .
retrieve all values from a field in the exposure summary layer .
"given a number , it will return the place value name ."
"given a number , it will return the coefficient of the place value name ."
"given a number and total , it will return the percentage of the number to the total ."
"given an inasafe analysis time , it will convert it to a date with year - month - date format ."
"given an inasafe analysis time , it will convert it to a time with hour : minute format ."
"given a keyword , it will return the value of the keyword from the hazard layer 's extra keywords ."
compute the summary from the source layer to the aggregate_hazard layer .
helper function to set on which field we are going to report .
extracting impact summary of the impact layer .
extracting impact summary of the impact layer .
helper method to add impact layer to qgis from impact function .
helper method to add debug layers to qgis from impact function .
helper to add layers to the map canvas following a specific order .
helper method to add layer to qgis .
records a breadcrumb for all active clients . this is what integration code should use rather than invoking the ` capturebreadcrumb ` method on a specific client .
installs the logging hook if it was not installed yet . otherwise does nothing .
ignores a logger during breadcrumb recording .
"registers a callback for log handling . the callback is invoked with given arguments : ` logger ` , ` level ` , ` msg ` , ` args ` and ` kwargs ` which are the values passed to the logging system . if the callback returns true value the default handling is disabled . only one callback can be registered per one logger name . logger tree is not traversed so calling this method with ` spammy_module ` argument will not silence messages from ` spammy_module.child ` ."
"registers a callback for log handling . the callback is invoked with given arguments : ` logger ` , ` level ` , ` msg ` , ` args ` and ` kwargs ` which are the values passed to the logging system . if the callback returns true value the default handling is disabled . registering multiple handlers is allowed ."
generate definitions for minimum needs post processors .
creates a bold text object
render as html .
render as plain text
constructor for the class .
read last state of gui from configuration file .
store current state of gui to configuration file .
validate the input before saving a scenario .
save current scenario to a text file .
get the relative path to input_path from reference_path .
fixture run before all tests .
fixture run after each test .
test read and write setting .
test for reading and writing dictionary in qsettings .
test for export_setting method .
test we can do zonal statistics .
helper to return fixture path .
helper to compare file .
testing earthquake in population without aggregation .
set layer and update ui accordingly .
show or hide the help tab in the stacked widget .
hide the usage info from the user .
show usage info to the user .
method invoked when ok button is clicked .
method invoked when ok button is clicked .
select output directory
show metadata of the current selected layer .
emit custom signal when the window is re - sized .
method after resizing the window .
marks test to expect a fail in windows - call assertraises internally .
test if we can store geopackage .
test we can read an existing geopackage .
calls the overridden method
calls the overridden method
calls the overridden method
calls the overridden method
calls the overridden method
update the report .
test we can clip a raster layer .
test logging system .
test initialization with different layers ..
test setup for group select parameter .
test we can reclassify a raster layer .
test that we can compare the installed qt version .
set colors to the layer according to the hazard .
set the layer title according to the standards .
generate an ordered python structure with the classified symbology .
helper to add the ` not exposed ` item to the legend .
helper function to format the label in the legend .
simple style to apply a border line only to a polygon layer .
update proxies ip to reids/10 : return :
": param word : string : return : string , "" "" if word is not in the database"
": param word_list : list of strings : return : dict of { word : pronunciation } if the word does not exist in the database , entry is not returned"
": param word : string : return : string , "" "" if word is not in the database"
": param word_list : list of strings : return : dict of { word : syllabification } if the word does not exist in the database , entry is not returned"
": param table_name : string : return : integer , total number of words in a given table"
": return : all columns for an incorrect syllabification . selects all rows that are incorrect . returns a unicode 4 - tuple ( word , probsyl , celexsylab , issame )"
": return : all columns for an correct syllabification . selects all rows that are correct . returns a unicode 4 - tuple ( word , probsyl , celexsylab , issame )"
: param number_of_words : integer : param word_blacklist : list of strings : return : set of words in ascii encoding
the main function that is called outside of the class args : population(list of chromosomes ): the full population of the ga
stochastic universal sampling(sus ) method . used to select which parts of the population are selected to live . args : population(list of chromosomes ): the whole population in the ga . returns : args :
algorithm for choosing which members of the population mate . the current best and the current worse mate . this is continued until all members of the population are done . args : population(list of chromosomes ): all members of the ga 's population . alter(list of int ): which chromosomes shall be kept .
creates the mating pairs for the ga args : alter(list ): the chromosomes index 's to be used . returns : pairs(list of tuples ): each tuple in the list is a mating pair .
grabs the chromosomes that are to be assigned to continue living args : population(list of chromosomes ): the entire population of the ga . returns : range_list(list ): an integer array where the values coorespond to a spot in the population in the ga .
normalilzes the range_list in order to be understandable by the ga 's population . args : range_list(list ): a list of integers returns : range_list(list ): a list of integers
generates the population to be kept and mated . args : range_list(list ): a list of the areas that the population owns . returns :
selects the population to continue living args : population(list of chromosomes ): the full population of the ga
creates a random vector of 0 's and 1 ' that is then associated with what genes goes into which child from the parents . returns : a vector of 0 's and 1 's .
creates two childern by using the scattered crossover mating algorithm . args : mother(chromosome ): the mother chromosome of the children . father(chromosome ): the father chromosome of the children . returns : child1(chromosome ): the offspring of the parents mating . child2(chromosome ): the offapring of the parents mating .
mates two chromosomes to produce one child args : mother(chromosome ): the mother of the offspring father(chromosome ): the father of the offspring returns : child(chromosome ): the offspring of the mother and father
compute the fitness of all chromosomes in the population . updates the fitness value of all chromosomes . chromosome fitness calculation is done in separate processes .
calculates and puts updated fitness on the results_queue . args : i ( int ): process and population index s ( multiprocessing . semaphore ) pool ( activepool ): manager of the pool and locks results_queue ( multiprocessing . queue ): communication between processes . genes ( list < list < char > > ): genes of a chromosome
fetch and parse the feature feed for this class .
parse a single feed entry into an ifttt trigger item .
get the set of items for this trigger .
handle post requests .
evaluate the log - probability for the given samples .
"sample from this toplevel module and return x ~ p(x ) , log(p(x ) )"
evaluate the log - probability for the given samples .
"given samples from the upper layer y , sample values from x and return then together with their log probability ."
"given samples from the upper layer y , return the probability for the individual x elements"
create a new autotable object which will write data into a file called fname .
close the hdf file behind this autotable instance .
"append the dataset * values * into a table called * name * . if a specified table name does not exist , a new table will be created ."
append the given data to the table .
delete a node from the h5 - table together with all dictionary entries that has been created with the node .
"create a new table within the hdf file , where the tables shape and its datatype are determined by * example * ."
"derive an fname from sys.argv[0 ] by striping the extension and adding "" .h5 "" . as a result , the table will be named just like the executing programm ."
return values and rowmask
ensure that symbol(s ) have contiguous segment ids
chunks the dataframe / series by dates
"takes start , end from to_chunks and returns a "" range "" that can be used as the argument to methods require a chunk_range"
converts parts of a chunk range ( start or end ) to a string . these chunk ids / indexes / markers are produced by to_chunks . ( see to_chunks )
takes the range object used for this chunker type and converts it into a string that can be use for a mongo query that filters by the range
"ensures data is properly subset to the range in range_obj . ( depending on how the chunking is implemented , it might be possible to specify a chunk range that reads out more than the actual range eg : date range , chunked monthly . read out 2016 - 01 - 01 to 2016 - 01 - 02 . this will read all of january 2016 but it should be subset to just the first two days )"
removes data within the bounds of the range object ( inclusive )
check that we do / do n't cleanup chunks based on the dry - run
check that we do / do n't cleanup chunks based on the dry - run
we do n't cleanup any chunks in the range of today . that 's just asking for trouble
"check that a chunk pointed to by more than one version , are n't inadvertently cleared"
check that we do / do n't cleanup chunks based on the dry - run
check that we do / do n't cleanup chunks based on the dry - run
check that we do / do n't cleanup chunks based on the dry - run
set the global multithread compression mode
compress an array of strings
compress a string
decompress a string
decompress a list of strings
chunks data . keyword args passed in from write api
"takes start , end from to_chunks and returns a "" range "" that can be used as the argument to methods require a chunk_range"
takes the range object used for this chunker type and converts it into a string that can be use for a mongo query that filters by the range
"ensures data is properly subset to the range in range_obj . ( depending on how the chunking is implemented , it might be possible to specify a chunk range that reads out more than the actual range eg : date range , chunked monthly . read out 2016 - 01 - 01 to 2016 - 01 - 02 . this will read all of january 2016 but it should be subset to just the first two days )"
removes data within the bounds of the range object ( inclusive )
converts parts of a chunk range ( start or end ) to a string . these chunk ids / indexes / markers are produced by to_chunks . ( see to_chunks )
test the view handler .
test the view handler .
test the view handler .
test the view handler .
test the view handler .
test that the annotations has our test user as owner .
test that the label is associated with our test sketch .
test that the status is associated with our test sketch .
test that the comment is associated with our test event .
initializes a similarity scorer config .
get config for supplied data_type .
initializes a similarity scorer .
splits string into words .
calculate minhash of text .
create a new lsh from a set of timesketch events .
calculate a score based on jaccard distance .
add a similarity_score attribute to the event in elasticsearch .
entry point for a similarityscorer .
"append a return clause to a query so that it returns 3 list - valued columns : - nodes - list of ids of all match - bound nodes in the query - edges - list of ids of all match - bound edges in the query - timestamps - list of lists of timestamps , can be zipped with edges"
test to generate a random color .
test for validating indices .
forward step of the variational autoencoder
variational objective function
"check whether two rectangles intersect . : param rect1 , rect2 : a rectangle represented with a turple(x , y , w , h , approxpoly_corner_count ) : return whether the two rectangles intersect"
load an image from path : param img_path : the path to the image : return :
load an image from a byte array : param img_bytes : the byte array of an image : return :
"find rectangular views given a ui screenshot : param img : numpy.ndarray , representing an image in opencv : return : a list of rectangles , each of which is a tuple ( x , y , w , h ) representing an identified ui view ."
"calculate the dhash value of an image . : param img : numpy.ndarray , representing an image in opencv : return :"
"calculate difference between pixels : param img : numpy.ndarray , representing an image in opencv"
"calculate the hamming distance between two images : param img1 : numpy.ndarray , representing an image in opencv : param img2 : numpy.ndarray , representing an image in opencv : return : int , the hamming distance between two images"
"calculate the hamming distance between two dhash values : param dhash1 : str , the dhash of an image returned by ` calculate_dhash ` : param dhash2 : str , the dhash of an image returned by ` calculate_dhash ` : return : int , the hamming distance between two dhash values"
一条回复的字数，返回(引用字数，回复字数，前两者之和 或 是无引用的长度 )
"checks if a value if an axes . if none , a new one is created . both the figure and axes are returned ( in that order ) ."
"checks that an axis name is in ` ` { ' x ' , ' y ' } ` ` . raises an error on an invalid value . returns the lower case verion of valid values ."
"checks that an axis options is in ` ` { ' x ' , y ' , ' both ' , none } ` ` . raises an error on an invalid value . returns the lower case verion of valid values ."
checks that a valid axis type is requested .
replaces none with an empty string for axis labels .
replaces none with an empty dict for plotting options .
decorator to seed the rng before any function .
"create a future , python 3.4 and 3.5 compatible"
this decorator changes a regular synchronous method that returns a gst . statechangereturn into an asynchronous one which will yield when the state change has actually happened .
this decorator changes a regular synchronous method into an asynchronous one which will yield when the underlying operation has actually completed . the assumption is that the underlying operation will trigger an async_done message .
"builds a new gstreamer pipeline . if ` win_id ` is specified , it is used as a window id to embed the video sink using the gstoverlay interface ."
"if your program does not use the glib loop , call this first . it initializes threads , gstreamer , and starts the glib loop in a separate thread ."
call this before exiting ; it stops and joins the glib loop created by : func:`start_glib_loop ` .
override this to create a custom video sink . warning : this will be called from glib 's main loop thread .
override this to create a custom audio sink . warning : this will be called from glib 's main loop thread .
overload this to be notified on end of stream .
override this to be notified when an error occurs during playback .
"* * asynchronous * * starts playing . if ` filename ` is specified , it 's loaded and starts from scratch ; else the previously loaded file is resumed ."
* * asynchronous * * pauses playback .
* * asynchronous * * stops playback .
"the current stream position , in native gstreamer units . divide by gst . second to get seconds . ( read only )"
"the current stream duration , in native gstreamer units . divide by gst . second to get seconds . ( read only )"
"* * asynchronous * * seek to specified position , in gstreamer units ."
"* * asynchronous * * rewind by specified duration , in seconds ."
"* * asynchronous * * forward by specified duration , in seconds ."
returns available subtitle tracks . this will only be available after the playback starts .
returns available audio tracks . this will only be available after the playback starts .
"given a list of infos , returns a list of new infos grouped together by offset range"
remove duplicate infos . note : equality does not account for the size of the info
checks to see if both lists of opinfos are equal
"gaussian naive bayes . when dealing with continuous data , a typical assumption is that the continuous values associated with each class are distributed according to a gaussian distribution ."
"the multinomial naive bayes classifier is suitable for classification with discrete features ( e.g. , word counts for text classification ) . the multinomial distribution normally requires integer feature counts . however , in practice , fractional counts such as tf - idf may also work ."
"linear support vector classification . similar to svc with parameter kernel = linear , but implemented in terms of liblinear rather than libsvm , so it has more flexibility in the choice of penalties and loss functions and should scale better ( to large numbers of samples ) ."
implementation of support vector machine classifier using libsvm : the kernel can be non - linear but its smo algorithm does not scale to large number of samples as linearsvc does . furthermore svc multi - class mode is implemented using one vs one scheme while linearsvc uses one vs the rest .
": param input_dict ( input ): { u'n_neighbors ' : u'5 ' , u'weights ' : u'uniform ' , u'algorithm ' : u'auto ' } : param n_neighbors : int , optional ( default = 5 ) . number of neighbors to use by default for k_neighbors queries . : param weights : str or callable . weight function used in prediction . possible values : uniform : uniform weights . all points in each neighborhood are weighted equally . distance : weight points by the inverse of their distance . in this case , closer neighbors of a query point will have a greater influence than neighbors which are further away . : param algorithm : { auto , ball_tree , kd_tree , brute } , optional"
"logistic regression , despite its name , is a linear model for classification rather than regression . logistic regression is also known in the literature as logit regression , maximum - entropy classification ( maxent ) or the log - linear classifier . in this model , the probabilities describing the possible outcomes of a single trial are modeled using a logistic function ."
"a decision tree is a decision support tool that uses a tree - like graph or model of decisions and their possible consequences , including chance event outcomes , resource costs , and utility ."
"scan a line of latin pentameter and produce a scansion pattern , and other data ."
"if a pentameter line has 12 syllables , then it must start with double spondees ."
"if a pentameter line has 14 syllables , it starts and ends with double dactyls ."
"for pentameter the last two feet of the verse are predictable dactyls , and do not regularly allow substitutions . : param scansion : scansion line thus far : return : corrected line of scansion"
test latin prosody scanner .
test latin prosody scanner 's ` _ long_by_nature ` method .
test latin prosody scanner 's ` _ long_by_position ` method .
test syllabifier for latin scanner code .
test elidable word beginnings for latin .
test elidable word endings for latin .
test _ clean_text method .
test _ clean_accents method .
test _ tokenize method .
test _ make_syllables method .
test scan_text method .
text macronizer()._retrieve_morpheus_tag ( )
test macronizer()._macronize_word ( )
test macronizer().macronize_tags ( )
test macronizer().macronize_text ( )
turn str into str or tuple .
open file and check for author info .
recursively yield direntry objects for given directory .
"write to file , in current dir , ' contributors.md ' ."
sort values of the lists of a defaultdict(list ) .
"look for files , find authors , sort , write file ."
applicable to brahmi derived indic scripts
applicable to brahmi derived indic scripts
applicable to brahmi derived indic scripts
applicable to brahmi derived indic scripts
is the character a vowel
is the character a vowel sign ( maatraa )
is the character the halanta character
is the character the halanta character
is the character a vowel sign ( maatraa )
is the character a consonant
is the character a velar
is the character a palatal
is the character a retroflex
is the character a dental
is the character a labial
is the character a voiced consonant
is the character a unvoiced consonant
is the character a aspirated consonant
is the character a unaspirated consonant
is the character a nasal consonant
is the character a fricative consonant
is the character an approximant consonant
is the character a number
"initializer for syllabifier , import language syllable data"
checks if char is in the list of vowels in the language
checks if char is in the list of vowels in the language
checks if two sequential characters compose a diphthong
checks if char is in the mute_consonants_and_f list
checks if char is in the mute_consonants_and_f list
"splits input latin word into a list of syllables , based on the language syllables loaded for the syllabifier instance"
convert the source language script ( lang1 ) to target language script ( lang2 )
"load a single vcf , reload the snpeff data using the same vcf ."
"enumerate classes deriving from given base ( as string ) , recursively by default . returns set ."
"only used internally at woo shutdown , to work around issues releasing mixed python / c++ shared_ptr . see http://stackoverflow.com/questions/33637423/pygilstate-ensure-after-py-finalize/33637604 for details ."
set exit handler to avoid gdb run if log4cxx crashes at exit .
"pure - python implementation of the pygts._gts.read function ; it hangs under windows when using woo.gts ( not pure pygts ) , in gts-0.7.6 / src / misc.c:173 in next_char , where fgetc is waiting for the next character indefinitely ( why ? ) ; when fgetc was replaced by lower - level read(fileno , buf,1 ) , gts was complaining about not seeing the first integer ( number of vertices ) at the beginning of the file ."
"run all tests defined in the module specified , return testresult object ( http://docs.python.org/library/unittest.html#unittest.texttestresult ) for further processing ."
"run all tests defined in all woo.tests . * modules . return testresult object for further examination . if * sysexit * is true , call sys.exit with status 0 ( all tests passed ) , 1 ( some tests failed ) , 2 ( an exception was raised ) ."
clustering : simple zero - connectivity clustering
assumes that the install options file is placed in the repo root directory by the user .
sets up a service account for use with tls .
displays the currently reserved resources on all agents via state.json ; currently for infinity-1881 where we believe uninstall may not be always doing its job correctly .
converts the provided service name to a sanitized name as used in task ids .
"returns the taskid prefix to be used for the provided service name and task name . the full taskid would consist of this prefix , plus two underscores and a uuid ."
"enforces the dcos_min_version pytest annotation , which should be used like this :"
determine if the tests are being run against open dc / os . this is presently done by checking the envvar dcos_enterprise .
determine if the tests are being run on a strict mode cluster .
reaches into nested associative data structures . returns the value for path ` ` keys ` ` .
sorts a collection and returns it .
returns a dictionary with its values being its keys and vice - versa .
a pytest fixture that installs a kerberized hdfs service .
converts kmer in reduced alphabet into a feature vector
converts aas into the reduced alphabet
predicts signal for a feature vector
trains svr model
generates theoretical signal for a given peptide
converts peptide into a list of feature vectors
unpack the tar or zip file at the specified path to the directory specified by to_path .
"arguments : * ' file ' can be a string path to a file or a file - like object . * optional ' ext ' argument can be given to override the file - type guess that is normally performed using the file extension of the given ' file ' . should start with a dot , e.g. ' .tar.gz ' ."
"return the proper archive implementation class , based on the file type ."
return a list of the filenames contained in the archive .
return total file size of extracted files in bytes .
performs the actual extraction . separate from ' extract ' method so that we do n't recurse when subclasses do n't declare their own ' extract ' method .
check that all of the files contained in the archive are within the target directory .
creates url patterns to be used in a custom urlconf .
returns submittable problem_instances with test run enabled .
returns a url of an image which will be used as the contest logo .
returns a contest logo link .
returns a list of urls of images which will be used to decorate the user side menu .
decorator which transforms a function into an instance of a given ` ` condition_class ` ` ( subclass of : class:`~condition ` ) .
decorator for views that checks that the request passes the given ` ` condition ` ` .
"checks if user is logged in and if his account is active . logs out inactive users , effectively blocking them from performing actions ."
"determines if participants may choose to stay anonymous , i.e. use their logins as public names ."
returns registration model class used within current registration controller .
opens a file using a cache ( if it 's possible )
a modified url reverser that takes into account the current contest and generates urls that are appropriately prefixed . with it we substitute the original ` ` urlresolvers.reverse ` ` function .
validates ip reported by a region server .
"calculate the numerical gradient of a matrix in x , y and z directions ."
calculate the elevation aspect angle given the gradient .
"calculate the slope inclination angle given the gradient . : param grad : tensor representing the x , y , z gradient : param degrees : : return :"
calculate the unit vector normal to the surface defined by slope and aspect . : param slope_deg : slope inclination in degrees : param aspect_deg : slope aspect in degrees : return : 3 - dim unit normal vector
compute the intensity of illumination on a surface given the sun position . : param grad : : param sun_vector : : return :
on - the - fly linear interpolator
on - the - fly log interpolator
on - the - fly linear - log interpolator
on - the - fly log - linear interpolator
run hyperion tests using py.test . a proper set of arguments is constructed and passed to ` pytest.main ` .
calculate the square root x**2 = n ( mod p ) .
m such that ( n * m ) % p = = 1 .
"return the admin url for the current view . by default , it uses the : func:`get_staff_object ` function to base the url on ."
define a title to be included in the toolbar .
define a literal text to be included in the toolbar .
defining a toolbar item in the settings that also received arguments . it wo n't be loaded until the toolbar is actually rendered .
define a link to be included in the toolbar .
generate readme.rst from readme.md via pandoc .
read the contents of filename or give an alternative result instead .
make sure that urls are grabbed from both mp4_urls and from resources_urls of unit class .
make sure that we only expect units in the list of units .
make sure that we only expect video in the list of unit videos .
make sure stanford subtitle urls are distinguished from edx ones .
run command with arguments and return its output as a byte string .
test most of the functionality .
normalize ` ` url ` ` for underlying nt / unix operating systems .
provide compatible nt file paths for ` ` os.path ` ` functions
fetch the content of ` ` url ` ` .
parse an url .
get bytes in a parsed ` ` url ` ` using ` ` url_fetcher ` ` .
creates pto.mk files for all pto files .
moves the n'th image to the front of each stack .
measures the distance between the histogram of corresponding bands in two images .
"runs luts_calculation_function on in_img and ref_img ( using in_mask and ref_mask , if provided ) and applies luts to in_img ."
"create a look up table for matching the source cdf to the reference cdf . at each intensity , this algorithm gets the value of the source cdf , then finds the intensity at which the reference cdf has the same value ."
checks that cdf monotonically increases and has a maximum value of 1 .
create a look up table to linearly scale the colors of the input image to the reference image based on their relative means and standard deviations .
"loads an image into a colorimage . if no bit depth is supplied , 8 - bit is assumed . if no band indices are supplied , rgb is assumed ."
"saves the colorimage to a new raster , writing the mask as the alpha channel and copying the geographic information from the original raster"
@param target : total number of steps expected
"@param current : index of current step @param values : list of tuples ( name , value_for_last_step ) . the progress bar will display averages for these values ."
expects a binary class matrix instead of a vector of scalar classes
return a day as a table cell .
return a complete week as a table row .
return a weekday name as a table header .
return a header for a week as a table row .
return a month name as a table row .
return a formatted month as a table .
return a formatted year as a table of tables .
return a formatted year as a complete html page .
return a day as a table cell .
return a day as a table cell . este calendario tiene enlaces al día si hay borme .
run the migrations .
revert the migrations .
return a humanized string representation of a number of num_bytes .
spit out how much space the optimization saved .
remove the cwd from the full filename .
record the percent saved & print it .
report the total number and percent of bytes saved .
provide reporting statistics for a skipped file .
initialize required instance variables .
test xtdfile object construction and query functions .
make sure we can get correct direct coordinates .
test arcfile construction and query function .
make sure we can get coordinates correctly .
test query function elements ( ) .
determines total number of cameras available .
get default url of the given repository
execute commands of various vcs systems
should be string representation of uuid
should output microseconds since the epoch
should be in microseconds
should be in microseconds
should decode to unicode or a number array
check each entry is formatted as a single output line
reduces every plugin loader to the globally newest version .
finds a plugin type for given name .
retrieve a plugin from an available loader .
create information for all plugins available .
analyze and parses all plugins in folder .
parse attribute dict from plugin .
"parses a plugin from disk , folder means plugin type in this context . also sets config ."
"iterates over all plugins returning ( type , name , info ) with info as plugintuple ."
iterate over the available plugin types .
check if certain plugin is available .
return plugin info for a single entity .
return all plugins of given plugin type .
removes a plugin from the index .
determine if given plugin name is enable for user_context in any plugin type .
saves a plugin to disk .
returns loaded module for plugin .
same as ` parse_attributes ` for already indexed plugins .
"returns ( type , name ) of a plugin if a match is found ."
"returns ( type , name ) of the plugin that will be loaded instead ."
"inserts matcher at given index , first position by default ."
removes a matcher if it exists .
"parse plugins for given list of urls , separate to crypter and hoster ."
finds the type to a plugin name .
retrieves the plugin tuple for a single plugin or none .
get all plugins of a certain type in a dict .
gives the plugin class of a hoster or crypter plugin .
returns loaded module for plugin .
returns the class of a plugin with the same name .
reloads and reindexes plugins .
a plugin suitable for multiple user .
"load icon for single plugin , base64 encoded ."
check deps for given plugin .
executes info fetching for given plugin and urls .
downloads the resource with additional options depending on implementation .
size in bytes .
name of the resource if known .
download rate in bytes per second .
number of bytes already loaded .
returns a curl handle ready to use for perform / multiperform .
parse data from received header .
the download will not proceed after next call of write_body .
"reset the range , so the download will load all data available ."
flush and close file .
"closes everything , unusable after this ."
sets common options to curl handle .
sets same options as available in pycurl .
sets everything needed for the request .
load and returns a given page .
raise an exceptions on bad headers .
retrieve response from string io .
"decode with correct encoding , relies on header ."
writes response .
writes header .
"cleanup , unusable after this ."
convert file size .
convert value to a list with value inside .
helper method to determine if a user has access to a resource .
takes all params from api and extends cls with it . api class can be removed afterwards .
"returns a proxy version of the api , to call method in user context ."
"login into pyload , this * * must * * be called when using rpc before any methods can be used ."
check authentication and returns details .
checks if the user is authorized for specific method .
return a list of all unique monster types .
return type of a random monster as a string .
return a random monster seed as a string .
given a workflow will return the appropriate contents of a .dot file for processing by graphviz
returns the dot file for use with graphviz given the workflow name ( slug )
returns a png representation of the workflow generated by graphviz given the workflow name ( slug )
updates the state using the previous @state and @inputs . remember the rnn equations are :
json serialization of a given object .
json deerialization of a given string .
replaces template parameters in the given url .
appends the given set of parameters to the given query string .
validates and processes the given query url to clean empty slashes .
encodes a model in a form - encoded manner such as person[name ]
resolves parameters from their model names to their api names .
resolves name for a given object
changes counter by delta .
get the current counter value .
see shard_context.count .
see shard_context.count .
emits a value to output writer .
"build lsh results dictionary . : param score : : param match_found : : param doc_1 : : param doc_2 : : return : results dict that contains candidate documents , threshold and lsh similarity score ."
this method computes hash of object using a dynamic hashing function . : param obj : object we are computing hash code for . : return : hash code ( long integer )
"checks if similarity score against threshold . : param similarity_score : : return : true if similarity score is greater than or equal to threshold , otherwise false"
gets band by idx from bands collection . : param idx : : return : none if bands none or idx is greater than number of length of bands collection .
slices signatures into lists of n rows . : param signatures : list of minhash signatures : param n : number of rows to include in slice : return : list ( vector )
calculate similarity score for givens documents . : param document_1 : : param document_2 : : return : 0.0 if score ca n't be calculated otherwise returns calculated value
"calculate threshold . : return : threshold returned , if threshold ca n't be calculated returns 0.0"
create a list of bands ( dicts ) . each dict represents one band ( bucket ) . : return : list of dicts that represents bands .
shorthand for assert . saves 3 whole characters !
"shorthand for ' assert a = = b , "" % r ! = % r "" % ( a , b )"
construct a linestyle . see class docstring for details on args .
add a new line to the chart .
perform operation .
perform operation .
called after test is complete ( after result.stoptest )
called before test is run ( before result.starttest )
extract exception info .
get a short(er ) description of the test
"return a round - trip name for this test , a name that can be fed back as input to loadtestbyname and ( assuming the same plugin configuration ) result in the loading of this test ."
modified run for the test wrapper .
"run the test . plugins may alter the test by returning a value from preparetestcase . the value must be callable and must accept one argument , the result instance ."
initialize the methodtestcase .
"return a round - trip name for this test , a name that can be fed back as input to loadtestbyname and ( assuming the same plugin configuration ) result in the loading of this test ."
run any setup function attached to the test function
run any teardown function attached to the test function
"get the descriptors of the test function : the function and arguments that will be used to construct the test name . in most cases , this is the function itself and no arguments . for tests generated by generator functions , the original ( generator ) function and args passed to the generated function are returned ."
initialize the methodtestcase .
"return a round - trip name for this test , a name that can be fed back as input to loadtestbyname and ( assuming the same plugin configuration ) result in the loading of this test ."
"get the descriptors of the test method : the method and arguments that will be used to construct the test name . in most cases , this is the method itself and no arguments . for tests generated by generator methods , the original ( generator ) method and args passed to the generated method or function are returned ."
called at the beginning of a shard .
called at the end of a shard .
called at the beginning of a slice .
called at the end of a slice .
lookup country for ip address .
user information .
import string or return object .
load or import value from config .
default permission factory .
test aggregation with aggregation_interval > index_interval .
test bookmark reading .
check that the stataggregator correctly starts from bookmark .
check that the aggregation does n't crash if there are no events .
remove aggregation bookmark and restart aggregation .
test the filter_robots query modifier .
test version import .
test extension initialization .
test that event queues are declared properly .
test that events are published and consumed properly .
check that eventsindexer calls properly the preprocessors .
check that eventsindexer applies time windows to ids .
test anonymize_user preprocessor .
test flag_robots preprocessor .
test that events occurring within a time window are counted as 1 .
add the given ` < nav > ` to this navigation document .
the list of ` < nav > ` objects in this navigation document .
return the ` < nav > ` child with given ` i d ` .
return the ` < nav > ` child with given ` epub : type ` .
the landmarks ` < nav > ` element ( none if not found ) .
the page - list ` < nav > ` element ( none if not found ) .
the toc ` < nav > ` element ( none if not found ) .
the value of the ` dir ` attribute . epub 3 only .
the value of the ` i d ` attribute .
the value of the ` opf : event ` attribute . epub 2 only .
the value of the ` opf : file - as ` attribute . epub 2 only .
the value of the ` opf : role ` attribute . epub 2 only .
the value of the ` opf : scheme ` attribute . epub 2 only .
the tag of this metadatum .
the text of this metadatum .
the value of the ` xml : lang ` attribute . epub 3 only .
"add a refinement , that is , store a reference to the refinement metadatum ."
the manifestation of this publication .
compute and return the size of the publication .
"the value of the epub version ( it should be "" 2.0 "" or "" 3.0 "" ) ."
the value of the dcterms : modified date . ( epub 3 )
the value of the unique identifier .
the value of the release identifier .
the value of the ( first ) dc : identifier metadatum .
the value of the ( first ) dc : title metadatum .
the value of the ( first ) dc : language metadatum .
the value of the ( first ) dc : author metadatum .
the value of the ( first ) dc : date metadatum .
the value of the ( first ) dc : description metadatum .
the value of the ( first ) dc : publisher metadatum .
the value of the ( first ) dc : rights metadatum .
the value of the ( first ) dc : source metadatum .
the list of values of dc : subject metadata .
the value of the ( first ) dc : type metadatum .
"the path of cover image , relative to the container root ."
the contents of the cover image .
the toc .
"the toc , where the src values have been resolved into the corresponding internal paths ( relative to the container root ) ."
the landmarks ( epub 3 only ) .
"the landmarks ( epub 3 only ) , where the src values have been resolved into the corresponding internal paths ( relative to the container root ) ."
"the spine , as a ( ordered ) list of internal paths to the assets referenced in the actual opf ` < spine > ` ."
return the index in the spine of the file located at the given internal path ( relative to the container root ) .
"the spine , as a ( ordered ) list of internal paths to the assets referenced in the actual opf ` < spine > ` , with attribute linear=""yes "" or omitted ."
return the index in the linear spine of the file located at the given internal path ( relative to the container root ) .
get the value(s ) of ` < dc : ... > ` metadatum / metadata .
"return the contents of the asset with the given internal path , relative to the container root ."
the value of the ` href ` attribute .
the value of the ` title ` attribute .
the value of the ` type ` attribute .
add the given child to this ncx toc .
the value of the ` docauthor ` element .
the value of the ` doctitle ` element .
the value of the ` dtb : depth ` attribute .
the value of the ` dtb : generator ` attribute .
the value of the ` dtb : maxpagenumber ` attribute .
the value of the ` dtb : totalpagecount ` attribute .
the value of the ` dtb : uid ` attribute .
the value of the ` version ` attribute .
the value of the ` xml : lang ` attribute .
the children elements of this ncx toc .
script is called from a pipe echo ip | ipinfo
return a json from the request
": param process_type : : param configuration : : param target : : param device : : param program : - > declare a process object as a qobject derivative . - > give it a name and the necessary parameters for its type . - > generate a command for the system call by the popen object that manages the subprocess and allows to redirect the output . - > the process runs into an independent thread . - > a queue is used to collect the logs from the popen output and an other one is used to send it to the qtextedit integrated console . - > logs flags are collected for information . - > exit code is initialized to default value . must change in case of normal exit , error or user interruption ."
: param target_key : - > generate a system command to compile files by a makefile and putting the right arguments if given .
- > generate a system command to run a program and add its options if it has some .
- > start the thread = > start the worker = > call the run method .
- > analyse an process output line to find a flag in it . - > send the item by the sending queue object . - > collect the flag found .
"- > if the process finished , get the exit code . - > else , the process crashed ..."
- > kill the subprocess by getting its processid .
alias for rate
alias for zeta
update view according to ref params
""" upate ref params from view by emitting value - changed . if param was not sensitive , update view with current param from ref"
choose among indexes based on weights using a simple random draw .
construct a set of indexes that can be used to index a complete set of synthetic households .
take new household indexes and create new household and persons tables with updated indexes and relations .
compare the results of a synthesis draw to the target constraints .
draw households and persons according to weights from the ipu .
"return a ( key , value ) tuple from a key = value formatted string ."
first test with the good dynstr section first
second test with the good dynstr section last
call the invalidate_caches ( ) method on all meta path finders stored in sys.meta_path ( where implemented ) .
find the loader for the specified module .
"bootstrap ooo and pyuno runtime . the soffice process is started opening a named pipe of random name , then the local context is used to access the pipe . this function directly returns the remote component context , from whereon you can get the servicemanager by calling getservicemanager ( ) on the returned object ."
method to be run in sub - process ; can be overridden in sub - class
start child process
terminate process ; sends sigterm signal or uses terminateprocess ( )
wait until child process terminates
return whether process is alive
return whether process is a daemon
set whether process is a daemon
set authorization key of process
return exit code of process or ` none ` if it has yet to stop
return identifier ( pid ) of process or ` none ` if it has yet to start
return a file descriptor ( unix ) or handle ( windows ) suitable for waiting for process termination .
this generates a random valid perovskite structure in ase format . useful for testing . binary and organic perovskites are not considered .
@returns session factory on success @returns false on failure
saves user 's settings @returns true on success @returns false on failure
gets main mapping source according to what a data classification is made gets the hierarchy groups ( only for gui ) gets the hierarchy values
nb only used for perovskite_tilting app
"returns views and fields for current model . @param cr : a database cursor @param user : id of the user currently logged in @param view_id : list of fields , which required to read signatures @param view_type : defines a view type . it can be one of ( form , tree , graph , calender , gantt , search , mdx ) @param context : context arguments , like lang , time zone @param toolbar : contains a list of reports , wizards , and links related to current model"
to get default values for the object . @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param fields : list of fields for which we want default values @param context : a standard dictionary @return : a dictionary which of fields with values .
modifies the duration of asset for calculating depreciation and maintains the history of old values . @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param ids : list of ids @param context : a standard dictionary @return : close the wizard .
populate a ledger_lines attribute on each browse record that will be used by mako template
"add cost method "" last purchase price """
al cambiar el agente se le carga la comisión
alerta al usuario sobre la comisión elegida
"match the partner based on the bvr reference field of the invoice . then , call the generic st_line method to complete other values ."
returns all periods from a fiscalyear sorted by date
"skip account.common.journal.report , fields_view_get ( adds domain filter on journal type )"
"values = { ' name ' : expense_line.name , ' product ' : expense_line.product_id , ' product_qty ' : expense_line.unit_quantity , ' product_uom ' : expense_line.uom_id , # optional , is not required . ' account_id ' : expense_line.analytic_account.id , ' unit_amount ' : values.get('unit_amount ' , false ) , # optional , is not required ' date ' : expense_line.date_value + ' 00:00:00 ' , ' ref ' : hr_expense.name , ' origin_document ' : expense_line }"
"( 1 , u'public price ' ) , ( 2 , u'cost price ' ) , ( -1 , u'other pricelist ' ) , ( -2 , u'partner section of the product form ' ) , ( -3 , u'fixed price ' )"
sign the package
remove the signature file of the package
get the first instance of key .
get a list of all values that have attribute_name ' key ' .
returns true if string found in file
returns true if string found in file
test if the result header is correct
test if the service is created correctly
test if the host is created correctly
initilize a new instance of status
returns a dictionary derived from status.dat for one particular contact
returns a dictionary derived from status.dat for one particular contact
returns a dictionary derived from status.dat for one particular service
"smooth(x , n ) takes a 2d array x that has many columns , and averages out n nearby points ."
grouping function for ` ` pairtransformer ` ` .
"given a list of rendered widgets ( as strings ) , returns a unicode string representing the html for the whole lot ."
media for a multiwidget is the combination of all media of the subwidgets .
media for a multiwidget is the combination of all media of the subwidgets .
no keys may be provided to the script
"if the api function is unknown , it should throw an error"
"if we neglect to provide a time , it should throw an error"
"if we provide a non - numeric time , it should throw an error"
enumerate all the ways that it can be malformed
"can track a job and it appears in "" track """
we can stop tracking a job
tracking nonexistent jobs raises an error
jobs know when they 're tracked
jobs know when they 're not tracked
"submit raw data to the lua script , untransformed"
"invoke the lua script with no keys , and some simple transforms"
flush the database
pare phenotype file
parse disease to phenotype
parse an ensembl file with genes
produce a new resource with phenotypes and descriptions
return a generator with hi scores
return a generator with exac constraint scores
parse an ensembl header line
parse a file from ensembl with gene information
docstring for cli
"determines if we are inside virtuozzo container : return : true if inside container , false otherwise"
"if --silent or -q argument provided , do n't print anything , just use exit code otherwise print results ( compatible or unsupported ) else exit with 0 if compatible , 1 otherwise"
"checks if the result is ` none ` or in the error dict . ` if it is , it returns the value in the bellow - stated manner ."
this function maintains the errortable by adding new items and removing obsolete ones .
a nice wrapper to loop over the errors and remove boilerplate .
the default error handler invokes the app logger with the given arguments .
a proposal .
"this method just comfortably combines the boilerplate of observing . give it , what you would pass to the iserror method and it automatically calls on error , if an error happened ."
"orderkey is optional , the primary key is used by default ."
get the last successfull value of the property .
inititalize with keyword arguments for savety !
runs a given shell script and returns stdout . it returns none on error .
a function which performs the action . it is to be overwritten by the subclass .
run the action and get the restult either cached or new .
documentation goes here .
checks required config settings for setup task
"creates required folders ( tmp , releases , shared ) in ` deploy_to ` path"
creates shared ( + protected ) files / dirs and sets unix owner / mode
creates directory / file and sets proper owner / mode .
adds repository host to known hosts if possible
adds current host to the known hosts
task function decorator
"validate that the supplied email address is unique for the site , but allow for the case when the email has been "" registered "" while creating a new submission"
setup a directory for sphinx compilation .
"compiles the rst string , ` ` raw_rst ` , to html . performs no further checking on the rst string ."
convert restructuredtext to html for preview
test the cli .
add event to memory
randomly sample from memory
links the reaction supplied to the component instance
updates the concentration for the given metabolite and returns the new concentration
create a set of media components from a list of exchange metabolites
initialize the media components using initial media dictionary
retrieve component by i d
retrieves the current concentrations of the media components in the simulation
retrieve component using exchange reaction
resets the simulation to the starting state
resets only the media to the starting state
save models and model metadata to disk at the given interval
run the simulation for given iterations for the given epochs
sending an activation email to the users .
"gets the cache ttl for course assets , if present"
"gets the list of cdn user agents , if present"
sets up and returns xml course structure .
sets up the stub sequence module for testing .
sets up the test module system for the given block .
returns the rendered student view for the given sequence and the requested_child parameter .
verifies that the rendered view contains the expected position .
sets the format field on the given sequence to the given value .
event tracker backend that uses a python logger .
retrieves the current event transaction i d from the request cache .
retrieves the current event transaction type from the request cache .
sets the event transaction i d to a newly- generated uuid .
sets the event transaction i d to a uuid object generated from new_id . new_id must be a parsable string version of a uuid .
takes a string and stores it in the request cache as the user action type .
setup test case by adding primary user .
makes the test user staff and logs them in
adds the edx4edx sample course
deletes the sample course from the xml store
create a shell expansion of passed in parameter and iteratively remove them . must only expand to directories .
create directory and add the cleanup for it .
delete mongo log entries after test .
makes the test user staff and logs them in
ensure that we handle a missing repo dir
"this is the same as testsysadmin.test_xml_course_add_delete , but it uses a mongo store"
check to make sure we are getting git info for courses
create a log entry and make sure it exists
make sure the date is timezone - aware and being converted / formatted properly .
make sure we gracefully handle courses that do n't exist .
make sure the template behaves well when rendered despite there not being any logs . ( this is for courses imported using methods other than the git_add_course command )
make sure the pagination behaves properly when the requested page is out of range .
ensure course team users are allowed to access only their own course .
returns whether the push notification feature is enabled .
enqueues a task for push notification for the given update for the given course if ( 1 ) the feature is enabled and ( 2 ) push_notification is selected for the update
"sends a push notification for a course update , given the course 's subscription_id and display_name ."
remove the coupon against the coupon i d set the coupon is_active flag to false
add coupon in the coupons table
update the coupon object in the database
get the coupon information to display in the pop up form
test that some sensitive values can be configured via django settings
test that only backend_names listed in settings . authentication_backends can be used
tests to ensure that only providers that we can use to log in are presented for rendering in the ui .
verify that enabled_for_current_site returns true when the provider matches the current site .
verify that enabled_for_current_site returns false when the provider is configured for a different site .
when http headers contains latin1 characters .
extract the generated event tracking context for a given request for the given path .
extract the generated event tracking context for the given request .
assert that the superset dict contains all of the key - value pairs found in the subset dict .
populate the template context with values required for the authoring app to run .
"generate and return a token , if the integration is enabled ."
"test that if get_current_request returns a request , then get_template_request_context returns a requestcontext ."
"test that if get_current_request returns none , then get_template_request_context returns none ."
test that the requestcontext is cached in the requestcache .
test render_to_string ( ) when makomiddleware has not initialized the threadlocal request_context.context . this is meant to run in lms .
test render_to_string ( ) when makomiddleware has not initialized the threadlocal request_context.context . this is meant to run in cms .
"returns the currently - logged in user , as an instance of xblockuser"
get the anonymous user i d for a user .
a function that returns an xblockuser from the current django request.user
scenario : i am able to export a course or library given that i have a course or library and i click the download button the download will succeed and the file will be of the right mime type .
scenario : i should see the correct text when exporting a course . given that i have a course to export from when i visit the export page the correct header should be shown
ensure a library exists and navigate to the library edit page .
scenario : i should see the correct text when exporting a library . given that i have a library to export from when i visit the export page the correct header should be shown
generates the args for initializing a page object .
scenario : i want to upload a course or library for import . given that i have a library or course to import into and i have a valid .tar.gz file containing data to replace it with i can select the file and upload it and the page will give me confirmation that it uploaded successfully
"scenario : i perform a course / library import on import success , the page displays a utc timestamp previously not visible and if i refresh the page , the timestamp is still displayed"
"scenario : when uploading a library or course , a link appears for me to view the changes . given that i upload a library or course a button will appear that contains the url to the library or course 's main page"
scenario : i should be reprimanded for trying to upload something that is n't a .tar.gz file . given that i select a file that is an .mp4 for upload an error message will appear
scenario : i should see feedback checkpoints when uploading a course or library given that i am on an import page no task checkpoint list should be showing when i upload a valid tarball each task in the checklist should be marked confirmed and the task list should be visible
scenario : i should see a failed checklist when uploading an invalid course or library given that i am on an import page and i upload a tarball with a broken xml file the tasks should be confirmed up until the ' updating ' task and the ' updating ' task should be marked failed and the remaining tasks should not be marked as started
given that i visit an empty course before import i should not see a section named ' section ' or ' entrance exam ' when i visit the import page and i upload a course that has an entrance exam section named ' entrance exam ' and i visit the course outline page again the section named ' entrance exam ' should now be available . and when i switch the view mode to student view and visit courseware then i see one section in the sidebar that is ' entrance exam '
given that i visit an empty course before import i should not see a section named ' section ' when i visit the import page and i upload a course that has a section named ' section ' and i visit the course outline page again the section named ' section ' should now be available
scenario : i should see the correct text when importing a course . given that i have a course to import to when i visit the import page the correct header should be shown
given that i visit an empty course before import when i visit the import page and i upload a course with file name 2015.lzdwnm.tar.gz then timestamp is visible after course is updated successfully and then i create a new course when i visit the import page of this new course then timestamp is not visible
given that i visit an empty library no xblocks should be shown when i visit the import page and i upload a library that contains three xblocks and i visit the library page three xblocks should be shown
scenario : i should see the correct text when importing a library . given that i have a library to import to when i visit the import page the correct header should be shown
helper method that sets a birth year for the specified user .
helper method that sets a level of education for the specified user .
helper method that sets a gender for the specified user .
verify the age calculated correctly .
verify nothing is returned .
verify the level of education is displayed correctly .
verify nothing is returned .
verify the gender displayed correctly .
verify nothing is returned .
verify if we are on correct page
check if bookmarks button is visible
click on bookmarks button
check if bookmarks results are present
returns the bookmarks results header text
returns the bookmarks empty header text
returns the bookmarks empty list text
returns the total number of bookmarks in the list
return list of breadcrumbs for all bookmarks
click on bookmarked block at index ` index `
prepare to handle a login request .
completes third - part - auth authentication
computes social auth username from lti parameters
retrieves user details from lti parameters
validates lti signature and returns lti parameters
validates lti signature and returns lti parameters
retrieves lti consumer details from database
"a newly or recently registered user has completed the social auth pipeline . their account is not yet activated , but we let them login since the third party auth provider is trusted to vouch for them . see details in pipeline.py ."
get the service provider metadata for this edx - platform instance . you must send this xml to any shibboleth identity provider that you wish to use .
this is a combination login / complete due to lti being a one step login
redirect to a custom login / register page .
create and configure an api client for authenticated http requests .
"given a set of completed courses , determine which programs are completed ."
find the ids of all the programs for which the student has already been awarded a certificate .
issue a new certificate of completion to the given student for the given program .
"this task is designed to be called whenever a student 's completion status changes with respect to one or more courses ( primarily , when a course certificate is awarded ) ."
"verify the view returns http status 400 if an invalid registration code is passed . also , verify the data returned includes a message indicating the error , and the is_registration_code_valid is set to false ."
"test lookup for the valid registration code and that registration code has been redeemed by user and then mark the registration code as in_valid when marking as invalidate , it also lookup for registration redemption entry and also delete that redemption entry and un_enroll the student who used that registration code for their enrollment ."
test to lookup for the valid and redeemed registration code and then mark that registration code as un_redeemed which will unenroll the user and delete the redemption entry from the database .
test to apply an invalid registration code when updating the registration code information .
test to mark the invalid registration code as valid
test to mark the already unredeemed registration code as unredeemed .
load the message page and check the status code .
populate the children of the test course fixture .
enables cohorting for the current course .
creates two content groups in studio group configurations settings .
updates 3 of the 4 existing problems to limit their visibility by content group . publishes the modified units .
"adds 2 manual cohorts , linked to content groups , to the course . each cohort is assigned one student ."
"view content as staff , student in cohort a , student in cohort b , and student in default cohort ."
"scenario : can create content that is only visible to students in particular cohorts given that i have course with 4 problems , 1 staff member , and 3 students when i enable cohorts in the course and i create two content groups , content group a , and content group b , in the course and i link one problem to content group a and i link one problem to content group b and i link one problem to both content group a and content group b and one problem remains unlinked to any content group and i create two manual cohorts , cohort a and cohort b , linked to content group a and content group b , respectively and i assign one student to each manual cohort and one student remains in the default cohort then the staff member can see all 4 problems and the student in cohort a can see all the problems except the one linked to content group b and the student in cohort b can see all the problems except the one linked to content group a and the student in the default cohort can ony see the problem that is unlinked to any content group"
tests if bad json string was given .
tests get configuration from saved string .
tests get configuration that is not enabled .
add a new instance of the discussion category .
adds an instance of the advanced component with the specified name .
"click one of the "" add new component "" buttons ."
"adds multiple components of a specific type . item_type should be "" advanced "" , "" html "" , "" problem "" , or "" video "" items is a list of components of specific type to be added . please note that if you want to create an advanced problem then all other items must be of advanced problem type ."
adds an instance of the html component with the specified name .
returns the value of the field matching the css selector .
sets the text field with the given label ( display name ) to the specified value .
"sets the text field with given label ( display name ) to the specified value , and presses save ."
gets the drag handle with index source_index ( relative to the vertical layout of the page ) and drags it to the location of the drag handle with target_index .
verifies the expected ordering of xblocks on the page .
click the studio help link in the page footer .
return the list of studio help links in the page footer .
"click on the help , and also get the dom help element ."
"click on the help , and also get the dom help element ."
add a user and a course
just testing the functionality the view handler adds over the tasks tested in test_clone_course
tests newly created course has web certs enabled by default .
tests course creation workflow should not create course to org link if organizations_app is not enabled .
tests course creation workflow when course organization does not exist in system .
tests course creation workflow when course organization exist in system .
"test the "" test_js_run "" task ."
"test the "" test_js_run "" task ."
parse a string containing the options for a test run
verify that the messages generated when running tests are as expected for the specified options and dev_mode .
"removes < instructions > from the xmltree and returns them as a string , otherwise none ."
renders parameters to template .
assert that activate sets the flag but does not call segment .
generates a set of image files based on image_file and stores them according to the sizes and filenames specified in ` profile_image_names ` .
physically remove the image files specified in ` profile_image_names `
"raises imagevalidationerror if the server should refuse to use this uploaded file as the source image for a user 's profile image . otherwise , returns nothing ."
"given a pil.image object , return a copy cropped to a square around the center point with each side set to the size of the smaller dimension ."
"given a pil.image object , return a copy with the color mode set to rgb ."
"given a pil.image object , get a resized copy with each side being ` side_length ` pixels long . the scaled image will always be square ."
"given a pil.image object , create and return a file - like object containing the data saved as a jpeg ."
"if the original image contains exif data , use that data to preserve image orientation in the new image ."
"given an exif value and an integer value 1 - 8 , reflecting a valid value for the exif orientation , return a new exif with the orientation set ."
"return the orientation value for the given image object , or none if the value is not set ."
return comma separated string of valid file types .
convert size in bytes to user friendly size .
fetch site theme for the current site and add it to the request object .
returns true if the edx notes feature is enabled in the course .
returns the context processors defined in settings . templates .
"returns the template processing context to use for the current request , or returns none if there is not a current request ."
decorator to ensure that the method has all the required parameters .
redirect messages to keep the test console clean .
helper to log a server error .
retrieve the content of the request .
"retrieve the request post parameters from the client as a dictionary . if no post parameters can be interpreted , return an empty dict ."
return the get parameters ( querystring in the url ) .
return the url path without get parameters . removes the trailing slash if there is one .
"allow callers to configure the stub server using the /set_config url . the request should have post data , such that :"
"send a response back to the client with the http ` status_code ` ( int ) , ` content ` ( str ) and ` headers ` ( dict ) ."
"send a response with status code 200 , the given content serialized as json , and the content - type header set appropriately"
format message for logging . ` format_str ` is a string with old - style python format escaping ; ` args ` is an array of values to fill into the string .
respond to an http head request
configure the server to listen on localhost . default is to choose an arbitrary open port .
stop the server and free up the port
return the port that the service is listening on .
setting up tests
test that given none throws value error
test that returns default ( or none if default not set ) if xblock_settings is not set
test that returns default ( or none if default not set ) if xblock_settings is not set
test if settings service returns default if setting not found
test if settings service returns correct bucket
test if settings service respects block_settings_key value
test if settings service uses class name if block_settings_key attribute does not exist
run_eslint encounters an error parsing the eslint output log
"eslint finds violations , but a limit was not set"
test that maintenance index view lists all the maintenance app views .
verify the response contains error message .
reverse the setup .
test that maintenance app requires user login .
test that all maintenance app views are accessible to global staff user .
test that all maintenance app views are not accessible to non - global - staff user .
creates the course and add some changes to it .
test all error messages for invalid course keys .
test that we get a error message on old mongo courses .
test that we get an error message ` course_key_not_found ` for a provided split course key if we already have an old mongo course .
"test that when a course is forcefully publish , we get a ' course is already published ' message ."
verify draft and published versions point to different locations .
get force publish the course response .
test that dry run does not publishes the course but shows possible outcome if force published is executed .
set up the test data used in the specific tests
assert the a requried course survey is when both the flags is set and a survey name is set on the course descriptor
assert that if various data is not available or if the survey is not found then the survey is not considered required
assert that a new course which has a required survey but user has not answered it yet
assert that a new course which has a required survey and user has answers for it
assert that someone with staff level permissions does not have to answer the survey
make sure the alert has gone away .
verify storage returns true on themed assets
verify storage returns correct url depending upon the enabled theme
verify storage returns correct file path depending upon the enabled theme
"user_input is json generated by vsepr.js from dictionary . there are must be only two keys in original user_input dictionary : "" geometry "" and "" atoms "" . format : u'{""geometry "" : "" ax3e0"",""atoms"":{""c0 "" : "" b"",""p0 "" : "" f"",""p1 "" : "" b"",""p2 "" : "" f "" } } ' order of elements inside "" atoms "" subdict does not matters . return dict from parsed json ."
geometry is string . atoms is dict of atoms with proper positions . example :
this function does comparison between user_input and correct_answer .
verify the signal sets deadline to course end when no deadline exists .
verify deadline is set to course end date by signal when changed .
verify deadline is unchanged by signal when explicitly set .
test username can not be more than 30 characters long .
test email can not be more than 254 characters long .
"retrieve the relevant course_info updates and unpack into the model which the client expects : [ { i d : index , date : string , content : html string } ]"
"either add or update the given course update . add : if the passed_id is absent or none , the course update is added . if push_notification_selected is set in the update , a celery task for the push notification is created . update : it will update it if it has a passed_id which has a valid value . until updates have distinct values , the passed_id is the location url + an index into the html structure ."
"return course update item as a dictionary with required keys ( ' i d ' , "" date "" and "" content "" ) ."
"filter course update items which have status "" deleted "" ."
"do n't delete course update item from db . delete the given course_info update by settings "" status "" flag to ' deleted ' . returns the resulting course_updates ."
"from the url w/ index appended , get the index ."
"save list of course_updates data dictionaries in new field ( "" course_updates.items "" ) and html related to course update in ' data ' ( "" course_updates.data "" ) field ."
args : browser ( selenium.webdriver ): the selenium - controlled browser that this page is loaded in . context_selector ( str ): the selector that identifies where this : class:` . acidblock ` view is on the page .
return whether a particular : class:` . acidblock ` test passed .
return whether a particular : class:` . acidparentblock ` test passed .
whether the init - fn test passed in this view of the : class:` . acidblock ` .
whether the tests of children passed
whether the resource - url test passed in this view of the : class:` . acidblock ` .
load the helper for the home page ( dashboard page )
scenario : ensure that the course creation with non existing org display proper error message . given i have filled course creation form with a non existing and all required fields when i click ' create ' button form validation should pass then i see the error message explaining reason for failure to create course
scenario : ensure that the course creation with an existing org should be successful . given i have filled course creation form with an existing org and all required fields when i click ' create ' button form validation should pass then i see the course listing page with newly created course
scenario : ensure that the course creation with an existing org should be successful . given i have filled course creation form with an existing org and all required fields and i selected ` course organization ` input via autocomplete when i click ' create ' button form validation should pass then i see the course listing page with newly created course
"given the name of an idp , get a samlidentityprovider instance"
"get a setting , from samlconfiguration"
check that saml is enabled and that the request includes an ' idp ' parameter before getting the url to which we must redirect in order to authenticate the user .
check if we require the presence of any specific edupersonentitlement .
get an instance of onelogin_saml2_auth
"auto - auth is an end - point for http get requests . by default , it will create accounts with random user credentials , but you can also specify credentials using querystring parameters ."
construct the url .
parse the auto auth page body to extract relevant details about the user that was logged in .
a dictionary containing details about the user account .
finds and returns the user_id
ajax handler .
renders parameters to template .
dump poll information .
pull out the data into dictionary .
return an xml element representing to this definition .
"create , read , or update enrollment information for a user ."
extra context provided to the serializer class with current provider . we need the provider to remove idp_slug from the remote_id if there is any
"checks if request has an authenticated user . if so , checks if request.user has a cart that should be displayed . anonymous users do n't . adds ` display_shopping_cart ` to the context"
"reloads django 's url config . this is useful , for example , when a test enables new urls with a django setting and the url config needs to be refreshed ."
strips port number from host
"creates a new programsapiconfig with defaults , updated with any provided overrides ."
utility for mocking out programs api urls .
returns the common cookie settings ( e.g. expiration time ) .
set cookies indicating that the user is logged in .
sets the user info cookie on the response .
returns information that wil populate the user info cookie .
delete cookies indicating that the user is logged in .
check whether the request has logged in cookies set .
get data from an edx rest api .
traverse a paginated api response .
return the next cls number
return the input key to use when passing get parameters
return the key stored in the capa problem answer dict
optional parameters here are cut down to what we actually use vs. the regular capafactory .
unified create and check code for the tests here .
returns the url key for the given server_url .
returns the nonce for the given parameters .
entry point for subclassed commands to add custom arguments .
finds all dags within the given block structure .
updates dag collected data for the given block .
updates dag collected data for the given block .
open new textbook form by clicking on new textbook button .
return the text of the css selector .
set the value of input field by selector .
uploads a pdf textbook .
submit the new textbook form and check if it is rendered properly .
check if the view live button of textbook is working fine .
fills out form to upload a new textbook
a test function whose results are to be memoized in the request_cache .
a test function with multiple parameters whose results are to be memoized in the request_cache .
tests the memoize_in_request_cache decorator for both single - param and multiple - param functions .
creates a new certificate and verifies that it was properly created .
"scenario : ensure that message telling me to create a new certificate is shown when no certificate exist . given i have a course without certificates when i go to the certificates page in studio then i see "" you have not created any certificates yet . "" message and a link with text "" set up your certificate """
"scenario : ensure that the user can delete certificate . given i have a course with 1 certificate and i go to the certificates page when i delete the certificate with name "" new certificate "" then i see that there is no certificate when i refresh the page then i see that the certificate has been deleted"
scenario : ensure that the certificates can be created with signatories and edited correctly . given i have a course without certificates when i click button ' add your first certificate ' and i set new the course title override and signatory and click the button ' create ' then i see the new certificate is added and has one signatory inside it when i click ' edit ' button of signatory panel and i set the name and click the button ' save ' icon then i see the signatory name updated with newly set name when i refresh the certificates page then i can see course has one certificate with new signatory name when i click ' edit ' button of signatory panel and click on ' close ' button then i can see no change in signatory detail
scenario : ensure that line breaks are properly reflected in certificate
scenario : ensure that course number is displayed in certificate details view
scenario : ensure that course number override is displayed in certificate details view
display the signup form .
display the login form .
tests : - different types of violations - one violation covering multiple lines
a truncated report ( i.e. last line is just a violation )
default behavior is to look for an integer appearing at head of line
default behavior is to look for an integer appearing at head of line
test happy path getting violation counts from safelint report .
test getting violation counts from truncated and malformed safelint report .
test happy path getting violation count from safecommit report .
test getting violation count from truncated safecommit report .
test getting violation count from safecommit report where no files were linted .
"if pep8 finds errors , pylint and eslint should still be run"
"if diff - quality fails on pylint , the paver task should also fail"
"if diff - quality fails on eslint , the paver task should also fail"
"if diff - quality fails for an unknown reason on the first run ( pep8 ) , then pylint should not be run"
"helper method to compare the sequence with the stored exam , which should just be a single one"
"happy path testing to see that when a course is published which contains a proctored exam , it will also put an entry into the exam tables"
"make sure that if we publish and then unpublish a proctored exam , the exam record stays , but is marked as is_active = false"
make sure we filter out all dangling items
make sure the feature flag is honored
make sure the feature flag is honored
configures the course for this test .
"mocks the scores needed by the score_published signal handler . by default , sets the returned score to 1/2 ."
ensures that the problem_weighted_score_changed signal enqueues the correct task .
ensures that the subsection update operation triggers a signal .
ensures that tasks will be retried if integrityerrors are encountered .
ensures that a task retry completes after a one - time failure .
ensures that unknown errors are logged before a retry .
ensures that known errors are not logged before a retry .
calls the recalculate_subsection_grade task with necessary mocking in place .
verifies the task was retried and with the correct number of arguments .
test configuration of a simple backend
test if multiple backends can be configured properly .
test if a backend can be remove by setting it to none .
returns a dictionary containing the http auth header with encoded username+password
issue a get request to the given uri with the api key header
make a request with the given args and return the parsed json repsonse
assert that the allowed methods for the given uri match the expected list
"assert that accessing the "" url "" entry in the given object returns the same object"
assert that the given response has the status code 200
assert that the given response has the status code 403
assert that the given response has the status code 400
assert that the given response has the status code 405
assert that the django rest framework does not interpret basic auth headers for views exposed to anonymous users as an attempt to authenticate .
"course custom settings configuration get html : get the page put , post json : update the course 's custom settings ."
common setup for all tests
create a field override for the test ccx on < field > with < value >
verify that the course property of a ccx returns the right course
verify that caching the propery works to limit queries
verify that the start datetime for a ccx is correctly retrieved
verify that caching the start property works to limit queries
verify that due returns none when the field has not been set
verify that the due datetime for a ccx is correctly retrieved
verify that caching the due property works to limit queries
verify that a ccx marked as starting yesterday has started
verify that a ccx marked as starting tomorrow has not started
verify that a ccx that has a due date in the past has ended
verify that a ccx that has a due date in the future has not eneded
verify that a ccx without a due date has not ended
verify the override value for max_student_enrollments_allowed
by default structure_json does not contain anything
test a json stored in the structure_json
verify that the locator helper property returns a correct ccxlocator
unique identifier for the transformer 's class ; same identifier used in setup.py .
collects any information that 's necessary to execute this transformer 's transform method .
get the student module for the given user for the given block .
helper method to publish events for analytics purposes
gets a user 's anonymous i d from their user i d
replaces all % % -encoded words using keyword_function_map mapping functions
"given an email context , replaces all % % -encoded words in the given string ` context ` is a dictionary that should include ` user_id ` and ` course_title ` keys"
"retrieves the specified course , or raises an http404 error if it does not exist . also checks to ensure the user has permissions to view the course"
decorator responsible for catching errors finding and returning a 404 if the user does not have access to the api function .
determines if the user is staff or an instructor for the course . always returns true if debug mode is enabled .
checks if the request user can access the course . raises 404 if the user does not have course access .
"ensures that the user is authenticated ( e.g. not an anonymoususer ) , unless debug mode is enabled ."
serialize the object 's class name .
retrieve course modes associated with the course .
retrieves the username from the associated model .
"handle a post request from the client used by the apis for comment threads , commentables , comments , subscriptions , commentables , users"
"handle a put request from the client used by the apis for comment threads , commentables , comments , subscriptions , commentables , users"
initialize the mock comment service server instance . * port_num * is the localhost port to listen to * response * is a dictionary that will be json - serialized and sent in response to comment service requests .
execute the command .
check and parse arguments .
retrieve all course keys for a particular org .
context manager for measuring execution time .
write email opt - in preferences to the output file .
"iterate through the results of a database query , fetching in chunks ."
"serialize a list of values for including in a sql "" in "" statement ."
return a database cursor to the read replica if one is available .
updates the course blocks ( in the database ) for the specified course .
view to render the survey to the end user
shared utility method to render a survey form note : this method is shared between the survey and courseware djangoapps
form submission post - back endpoint .
"in the edx wiki , we do n't show the root_create view . instead , we just create the root automatically if it does n't exist ."
"this redirects to whatever page on the wiki that the course designates as it 's home page . a course 's wiki must be an article on the root ( for example , "" /6.002x "" ) to keep things simple ."
"returns the root article , or creates it if it does n't exist ."
"when editing an existing record , all fields should be read - only ."
skipped verifications ca n't be created in django admin .
returns a list of tags to be used when recording metrics about this model .
invokes forum 's post / put service to create / update thread
tests the deprecated_xblocks method
tests the disabled_xblocks method
"tests authorable_xblocks returns an empty list if xblockstudioconfiguration table is empty , regardless of whether or not xblockstudioconfigurationflag is enabled ."
tests authorable_xblocks when name is not specified .
tests authorable_xblocks when name is specified .
cancel the request .
confirm oauth access
boolean for if the page has an error or not .
text of the page 's error message .
create a matlab problem for the test .
open matlab problem page with assertion .
"test "" run code "" button functionality ."
validate user field
validate course i d field
returns whether form is valid
extra context data to add to page
"unenrolls student , issues refund"
return list of section titles and field titles for each section .
check if loading indicator is visible .
wait for loading indicator to become visible .
switch between the different account settings tabs .
"check if tab with the name "" order history "" is visible ."
return the text value of the provided order field name .
check that if hovering over the order history row shows the order detail link or not .
exists only to prove that adding a setup method to a test case does not break exam .
exists only to prove that adding a teardown method to a test case does not break exam .
"spikes_to_states(spikes , kernel , steps , tstep , simdt ) - > states convert spikes to liquid states using a given convolution kernel input arguments : - spikes : the spike train to be converted - kernel : the convolution kernel ( a function of a vector which returns a vector ) - steps : number of timesteps in the resulting vector in the analog domain - tstep : timestep ( sampling period ) of the resulting vector in the analog domain - simdt : simulation timestep"
"inputs_to_spikes(x , inp2spikes_conversion ) - > in_spikes convert an n - d analog signal to spiketrains , using the given spiketrain conversion function input arguments : - x : the dataset to be converted ( a numpy array ) - inp2spikes_conversion : the function that performs the spike conversion"
deltasigma(input ) - > spikes apply a delta - sigma modulator the input to generate spikes .
"hsa(input , filter , threshold ) - > spikes apply the hough spiker algorithm to the input to generate spikes using the given filter and threshold"
"bsa(input , filter , threshold ) - > spikes apply the bens spiker algorithm to the input to generate spikes using the given filter and threshold"
"exp_kernel(tau , dt ) - > kernel_result exponential kernel for filtering spike trains"
"gauss_kernel(tau , dt ) - > kernel_result gaussian kernel for filtering spike trains"
"create a poisson generator , using the given seed for the random number generator"
poissongen(xi ) - > spikes return a poisson spike train for the given signal xi
use this decorator to audit an operation and to log the visit external conceptschemes wo n't be logged
"fills a ringbuffer with positions from the most recent games , then continually rsync 's and updates the buffer until a new model is promoted . once it detects a new model , iit then dumps its contents for training to immediately begin on the next model ."
explicitly make a golden chunk for a given model ` model_num ` ( not necessarily the most recent one ) .
new_games is list of .tfrecord.zz files of new games
creates local directories if they do n't exist .
parse an sgf result string into value target .
"like sum ( ) , but with multiplication ."
yield from an iterator in chunks of chunk_size .
context manager for timing snippets of code .
context manager for timing snippets of code . echos to logging module .
"test the "" in "" operator for safe references ( cmp )"
test that the references are valid ( return instance methods )
test that creation short - circuits to reuse existing references
test that the reference object 's representation works
dumb utility mechanism to increment deletion counter
create a new signal .
connect receiver to sender for signal .
disconnect receiver from sender for signal .
send signal from sender to all connected receivers .
send signal from sender to all connected receivers catching errors .
"filter sequence of receivers to get resolved , live receivers ."
remove dead receivers from connections .
aquire a distributed global lock for ` ` name ` `
return an http session handler for a given concurrency model
close this : class:` . taskbackend ` .
start this consumer
register this consumer with channels
called periodically by the monitor and before closing by all workers .
return a future which should be called back once the consumer is closed
split the data to train - test sets so there are same amounts of classes .
"parameters ---------- random_seed : int random seed for env . if 0 , random seed will be randomly chosen ."
generic view for displaying feed items .
returns feed and count of remaining items not returned after limiting the query .
"get list of dereferenced feed items ( actually load the posts , profiles , etc . ) for the given user profile . each item gets a ` trusted ` attribute set if its feed_poster is trusted by the requesting profile ."
build a query for feed items corresponding to a particular feed .
"updates tsearch column ( created by custom sql in feed / sql / feed.sql ) . takes a list of ( text , weight ) pairs , where text is a string and weight is in ( ' a ' , ' b ' , ' c ' , ' d ' ) ( postgres tsearch weightings ) ."
signal receiver to create or update a feed item automatically when a model object is created .
signal receiver to clean up feed items when an object is deleted .
"decorator for function that takes two nodes , allowing it to take two profiles instead . makes sure nodes exist for the profiles , and passes the nodes to the original function ."
"performs payment . routed = false just creates an entry on account between payer and recipient , and creates the account with limits=0 if it does not already exist ."
"returns ( 1 - ratio of credits used in balance direction ) as a percentage , or zero , whichever is larger . if there is no credit limit in balance direction , returns none ."
proxy attribute lookups to self.entry .
proxy attribute lookups to self.payment .
change bvr to isr in reference_type field
atribui férias ao funcionário . cria um holidays nos dias que o funcionario ira gozar as ferias .
criar um novo contrato para o funcionario : param name : str - nome referencia do contrato : param wage : : param struct_id : : param date_start : : return :
criar um employee apartir de um nome e sua quantidade de dependentes : param nome : str nome do funcionario : return : hr.employee
criacao de um contrato simples
verificar a criação do controle de férias : return :
"para editar a data de admissao no contrato , nao se pode ter nenhum holiday aprovado de férias do tipo remove , atrelado ao contrato ."
se apagar algum controle ou por algum motivo o usuario deseja acionar o botão da visão e recalcular o controle de ferias
"não é possível editar um contrato que ja possui férias ( holidays do tipo ' remove ' ) atrelado a ele ,"
testes das informacoes do ultimo controle de ferias para o bloco de testes do item 05
"ao atribuir uma data de demissao ( ' date_end ' ) , o controle de ferias deve parar a contabilizacao do saldo de dias para ferias e atribuir a data de demissao para o ultimo controle de ferias"
"após finalizar um contrato , o controle de ferias é atualizado com informacoes da data de demissao . quando um contrato é reativado , o controle de ferias deve voltar a calcular"
finalizar um contrato quando nao há um controle de férias
"criar holidays do tipo ' add ' de férias para as duas ultimas linhas do controle de férias . sempre que um contrato for criado , o funcionario ja pode selecionar seus holidays de férias do tipo ' remove ' ."
função que gera xml da rubrica atual
sets a command function as the default command .
"do a simple fuzzy match of us presidents , returning results in refine reconciliation api format ."
like jsonify but wraps result in a jsonp callback if a ' callback ' query param is supplied .
return an atom object with the specified name
"remove the terminal hydrogens , and make the terminal carbon a hydrogen , also re - distribute charges ."
find the index of the terminal carbon
bind the route with function .
start ioloop listen on the specific port .
make the application based on the router_list
returns true if local versions of entrez files are up - to - date .
download and extract the gene2accession and gene_info files
returns the number of rows and columns in a convolution / pooling output .
expands the kernel spec into a length 2 list .
expands the stride spec into a length 4 list .
adds a convolution to the stack of operations .
should never return a sequence longer than the length of the contig
returns full path for resource
loads resource by name
checks equality of etree.roots
should sign a pre - constructed template file using a key from a pem file .
should sign a dynamicaly constructed template file using a key from a pem file .
"should sign a file using a dynamicaly created template , key from pem and an x509 cert ."
"should sign a file using a dynamically created template , key from pem and an x509 cert with custom ns ."
"should sign a file using a dynamicaly created template , key from pem file and an x509 certificate ."
args : package_db : package database .
generate an ebuild for a package .
a hook allowing changing ebuild_data before ebuild generation .
fill ebuild template with data .
generate ebuild template . should be overriden .
a hook for changing of a generated ebuild .
generate ebuild template .
get template filename for a package . should be overriden .
add a list of variables to the end of template .
generate ebuild template .
for security reasons only specific objects are allowed internals are ignored
loads libmultimarkdown for usage
"expands source text to include headers , footers , and expands multimarkdown transclusion directives ."
returns a flag indicating if a given block of multimarkdown text contains metadata .
"converts a string of multimarkdown text to the requested format . transclusion is performed if the compatibility extension is not set , and dname is set to a valid directory"
"reads in a file and performs multimarkdown conversion , with transclusion ocurring based on the file directory . returns the converted string ."
extracts file manifest for a body of text with the given directory .
extracts metadata keys from the provided multimarkdown text .
extracts value for the specified metadata key from the given extension set .
returns a string containing the multimarkdown library version in use .
return flag indicating if the library was correctly loaded .
returns value represented as currency for the give locale .
returns the given value as an int type .
removes all < br > tags in the given string .
returns whether the given value starts with the given string arg . < arg > must be a string .
hides parts of strings such as credit card or bank account numbers to show only the last amount of numbers .
returns the verbose value of a choicefield .
set up the return and argument types and the error checker for a ctypes function
"create a mobile address , can be moved to and referenced from anywhere in the network . @param path : the mobile address string ."
"create a topological address , references a specific router . @param router_id : id of target router . @param path : path part of address . @param area : routing area ( placeholder )"
tests the delegation of sasl auth to an external auth service .
tests the delegation of sasl auth to an external auth service .
initialize an instance of a router for a domain .
return the router 's id
this is the ioadapter message - receive handler
emit a log message to the host 's event log
emit a log message to the host 's event log
emit a log message to the host 's event log
emit a log message to the host 's event log
send a control message to another router .
: param compressed : path to boiler - compressed file
use a predefined python library to expand the given string . return the decompressed string
verify the generation of hash from email string .
verify that the gravatar_url method returns the expected output .
verify that the has_gravatar helper method correctly determines if a user has a gravatar or not .
verify that the get_gravatar_profile_url helper method correctly generates a profile url for gravatar user .
verify the profile url generated from template gravatar_profile_url tag .
"instantises the ewset_core class , which loads sequences from disc into memory , and provides methods for compressing , adding , new sequences as well as computing , storing and searching for snp distances between sequences . a number of parameters are required to do this . these need to be passed as a ' configuration dictionary ' providing key - value pairs . _ _ init _ _ checks that the required key are present : inputref : the path to fasta format reference file . persistencedir : the directory where the reference compressed sequences are stored . must be writable by the server daemon . excludefile : a file containing the zero - indexed positions in the supplied sequences which should be ignored in all cases . typically , this is because the software generating the mapped fasta file has elected not to call these regions , in any samples , e.g. because of difficulty mapping to these regions . such regions can occupy up 5- 20 % of the genome and it is important for efficient working of this software that these regions are supplied for exclusion on sequence loading . not doing so will slow loading , and markedly increase memory requirements , but will not alter the results produced . snpdir : if an sqlite database is used to persist edges , this is the directory in which it will be placed . must be writable by the server daemon . debugmode : false by default . if true , will stop loading after 500 sequences have been incorporated . servername : the name of the sqlite database , if used . edgedb_connstring : a valid sql alchemy connection string . will accept one parameter , servername , formatted using .format . if < < default > > is included in t he string , snpdir will be incorporated . example : "" sqlite:///<<default>>/{0}.db "" sql server connection strings have also been tested and work correctly . maxn : the maximum number of ns in the sequence < excluding those defined in > excludefile which should be indexed . other files , e.g. those with all ns , will be tagged as ' invalid ' . although a record of their presence in the database is kept , they are not compared with other sequences . example settings are below : config= { ' port':8184 , ' ip':'localhost ' ' inputref':os.path.join(""/home / compass / elephantwalk2/"",""reference"",""reference.fasta "" ) , ' persistencedir':""/home / compass / r039 / data/ "" , ' excludefile':os.path.join(""/home / compass / r039/"",""reference"",""tb.txt "" ) , ' snpdir':""/home / compass / r039 / sqlite "" , ' debugmode':0 , ' servername':'tbsnp ' , ' edgedb_connstring':""sqlite:///<<default>>/{0}.db "" , ' maxn_storage':100000 , } as part of startup , the _ _ init _ _ method will load all reference compressed sequences from persistencedir into ram . typical load rate is 100 - 200 sequences/ second ( i.e. between 6,000 and 12,000 sequences per minute ) . therefore , server restart can take a few minutes . doing so is normal . exemplar usage follows : if _ _ name__==""__main _ _ "" : # configuration parameters relevant to the server config= { ' inputref':os.path.join("" .. "",""reference"",""reference.fasta "" ) , ' persistencedir':""/home / local / gel / dwyllie / data / ew2 / compressedseqs_test "" , ' excludefile':os.path.join("" .. "",""reference"",""tb.txt "" ) , ' snpdir':""/home / local / gel / dwyllie / data / ew2 / snpstore "" , ' debugmode':true , ' servername':'tbsnp ' , ' edgedb_connstring':""sqlite:///<<default>>/{0}.db "" , ' maxn':100000 } # instantiate ewsc = ewsetcore(config = config ) # we are going to read the sequences from a test file provided by trien . testfile=""/mnt / microbio / pipeline / tb - fasta / maskedsamples.txt "" ntested=0 guidsadded = list ( ) with open(testfile , ' rt ' ) as f : for line in f : ( tag , guid , seq)=line.split ( ' ' ) ntested+=1 seq = seq.rstrip ( ' ' ) seq = seq.rstrip ( ' ' ) if config['debugmode']==true and ntested>50 : break if ntested % 50==0 : print(""loaded { 0}"".format(ntested ) ) guidsadded.append(guid ) # insert the sequence into the store . ewsc.insert(guid = guid , seq = seq ) # now exemplify recovery ; print(""testing for guid presence : "" ) for guid in guidsadded : print(guid , ewsc.exist_sample(guid ) ) print(""returning edges < 5 "" ) for item in ewsc.query_get_values_snp(cutoff=5 ): print(item ) print(""returning neighbours of a single guid with cutoff < 5 . "" ) for guid in guidsadded : print(""neighbours of { 0}"".format(guid ) ) for item in ewsc.query_get_values(guid = guid , cutoff=5 ): print(item ) print(""returning neighbours of a pair of guids "" ) for guid1 in guidsadded : for guid2 in guidsadded : print(guid1 , guid2 ) result = ewsc.query_get_value(guid1 = guid1 , guid2 = guid2 ) print(result ) print('finished ' )"
"compresses seq , which is a string comprising the sequence , identified by guid , and store it in ram and on disc ."
returns true or false depending on whether the guid has been stored .
returns all pairwise distances between samples < = distance cutoff
returns the pairwise links associated with one guid .
returns the pairwise distance ( if stored ) associated with one pair of guids
"returns the pairwise distance , number and positions of ns provided the sequences are of sufficient quality to be stored at all ) associated with one pair of guids"
initialization of the main parameters by constructor
this method take the ip address and the port of the server from command line input . nick authentication is going to be developed .
"this method run the client object and connect it to the server specified from login ( ) function the client can be closed typing q or q to quit , also you can press ctrl+c for quitting client . there will be a way to change color of the command line and the theme aspect ( colored module ) ."
"this method is used to quit the client every time that is needed , like an connectionerror or whatever error could be throwed on runtime ."
this method is called when client ca n't communicate with the server anymore .
": param time_series : current time series : param baseline_time_series : baseline time series : param percent_threshold_upper : if time_series is larger than baseline_time_series by this percent , then its a candidate for an anomaly : param percent_threshold_lower : if time_series is smaller than baseline_time_series by this percent , then its a candidate for an anomaly . percent_threshold_lower should be a negative number to work as intended . : param offset : baseline will be adjusted by this amount prior to computing percentage timeseries > offset + ( 1 + percent_threshold_upper/100 ) * baseline or for lower value timeseries < offset + ( 1 + percent_threshold_lower/100 ) * baseline : param scan_window : number of data points to evaluate for anomalies default of 24 = 5 minute period for 2 hours : param confidence : confidence to use for determining anomaly , default is 0.01 : return :"
compute anomaly scores for the time series anomaly regions are computed with sign test which also assigns a likelihood to the entire region
merge ranges which are closer than max_gap : param ranges : assumed to be sorted on start : param max_gap : allowed gap between ranges : return : new ranges
"sign test ccompares x to y counts how many are over do a rolling comparison over all x , y x is compared against shift + alpha * y : param x : values to be compared : param y : values to compared against : param k : how many values to compare default is 24 ( 5 minute intervals * 2 hours ) : param alpha scaling for y in percents 0.5 = 5 % increase : param shift : amount to shift baseline by : param conf : likelihood to use for anomaly : param gap : allowed gap between anomalies"
initializer : param timeseries time_series : a timeseries object . : param timeseries baseline_time_series : baseline timeseries .
set anomaly scores using a weighted sum .
": param time_series : current time series : param baseline_time_series : baseline time series : param percent_threshold_upper : if time_series is larger than baseline_time_series by this percent , then its an anomaly : param percent_threshold_lower : if time_series is smaller than baseline_time_series by this percent , then its an anomaly"
compute anomaly scores for the time series this algorithm just takes the diff of threshold with current value as anomaly score
registers a blueprint .
check if a key exists and is true in a dictionary .
gets a logger given a logger and a package .
set up a bind mount .
various argparse checks .
various command line interaction checks .
load obstacle graph and visibility graph .
save obstacle graph and visibility graph .
build visibility graph based on a list of polygons .
update visgraph by checking visibility of points in list points .
find and return shortest path between origin and destination .
"return polygon_id if point in a polygon , -1 otherwise ."
return closest point outside polygon from point .
"calculates the manhattan distances , d , between two numpy arrays of representations ."
"calculates the l2 distances , d , between two numpy arrays of representations ."
"calculates the p - norm distances between two numpy arrays of representations . the value of the keyword argument ` ` p = ` ` sets the norm order . e.g. ` ` p = 1.0 ` ` and ` ` p = 2.0 ` ` with yield the manhattan and l2 distances , respectively ."
sample partial assignment vector
"return log probability of data , given sufficient statistics of a partial assignment vector [ x_0, ... ,x_{n-1 } ]"
"return log of posterior predictive probability given sufficient statistics of a partial assignments vector [ x_0, ... ,x_{n-1 } ]"
"reverse transition probability of score_add_value , given sufficient statistics of the partial assignment vector [ x_0, ... ,x_n } ]"
"ad hoc approximation , see ` python derivations / clustering.py postpred ` see ` python derivations / clustering.py approximations `"
"ad hoc approximation , see ` python derivations / clustering.py dataprob ` see ` python derivations / clustering.py approximations `"
read the test users tsv file
read the test events tsv file
read the train user - event tsv file
read the count_users_per_train-event_train.csv
read the partition times csv file and extract the partition_time
function that trains and recommend events to all test users for that it uses an eventcontentmodel object
recommend events to users given a trained content based model are generated n recommendations to the same user one recommendation for each user profile type ( i.e. for each personalization approach )
"persist the recommendation results in the given ' result_dir ' with the given tsv file named ' model_name'.tsv each line has the following format : < user_id > < event_id1>:<similarity1>,<event_id2>:<similarity2>, ... ,<event_id100>:<similarity100 >"
"screen : the screen on which the waypoint lives wid : waypoint i d wtype : waypoint type ( birth , death , normal ) position : 2d location of the waypoint in ( x , y ) format in metres radius : radius of the waypoint ( all waypoints are circular ) in metres"
draw waypoints as filled circles . all drawing works in px units
"compute the force towards the waypoint from a single agent ( direction only ) the force is returned raw ( not clipped to agents maximum speed , the controllers handle that )"
entry 's value a canonical name to be used in place of the synonyms . example : ` new york `
"the array of synonyms . example : ` [ "" new york "" , "" @big apple "" , "" city that @{never , seldom , rarely } sleeps "" ] `"
construct a ` entry ` and fill default values .
entity entries . array of ` entry ` class objects
lang property used for server determination current request language . in ` voicerequest ` used for determinate language for asr ( speech recognitions ) service . default equal ' en ' . for detail information about support language see https://docs.api.ai/docs/languages
resetcontexts used for reset ( cancel / disable ) all previous all contexts . all contexts provided in current request will be setted after reset . default equal false .
array of context objects . for detail information see https://docs.api.ai/v6/docs/concept-contexts
session_id user for unique identifier of current application user . and it provide different contexts and entities for different users .
"time zone from iana time zone database ( see http://www.iana.org/time-zones ) . examples : ` america / new_york ` , ` europe / paris ` . time zone used for provide information about time and other parameters depended by time zone . default equal ` strftime(""%z "" , gmtime ( ) ) ` - > used current system time zone ."
array of entities that replace developer defined entities for this request only . the entity(ies ) need to exist in the developer console .
client access token provided by http://api.ai/
send a given data chunk of voice data .
send all data and wait for response .
"query parameter , can be string or array of strings . default equal none , nut your should fill this field before send request ."
encrypt user 's home folder
使用上下文管理的方式忽略错误 。 with ignored(oserror ): print(1 ) raise(oserror )
"若某一函数出错(一般是网络请求 ) , 会再次进行2次重新请求，否则会传回false @requestsexceptionfilter def test ( ): requests.get('http://www.therearenothing.com ' )"
默认以get方式请求 ， get方式附加内容用add参数，post方式提交内容用data参数 。 编码用urlencode参数，默认utf-8 。 默认cookies为空 。
filter : class:`civis.response . response ` objects .
return one satisfying : class:`civis.response . response ` object .
return the database id for a given database name .
return the credential id for a given username in a given database .
find an aws credential id .
return the table id for a given database and table name .
the current user 's default credential .
the current user 's username .
deduces the full path to the occam shared / dynamic library .
returns the path to the occam logfile .
returns the path to the occam logfile .
returns the appropriate tool .
returns the tool as defined in the user 's environment .
returns the path to the occam shared / dynamic library .
returns the appropriate tool .
gathers all call nodes ( recursively ) in a given ast node
run a top down mergesort on a list a
run a mergesort on a list m
qiitaのコードを取り除きます : param html_text : : return :
this is a fullrmc api method to set the group engine . use with caution and better not to .
this is a fullrmc api method to get the group engine . normally a group does n't need to know the engine .
atoms index array .
group 's move generator instance .
refine flag .
set the selector refine flag .
set group atoms index . indexes redundancy is not checked and indexes order is preserved .
set group move generator .
set group move generator .
"sets the group indexes . for an emptygroup , this method will disregard given indexes argument and will always set indexes property to none ."
alias to message at fixed level
alias to message at move accepted level
alias to message at move rejected level
alias to message at move not tried level
alias to message at save engine level
alias to message at implement engine level
alias to message at usage engine level
alias to message at usage engine level
initialize the rule with the expression and mode .
returns true or false . evaluates the expression of the rule against the provided values . if the expression fails because parsing fails or the expression does not evaluate to a boolean values the function returns false .
"extract messages from xml form configuration files . : param fileobj : the file - like object the messages should be extracted from : param keywords : a list of keywords ( i.e. function names ) that should be recognized as translation functions : param comment_tags : a list of translator tags to search for and include in the results : param options : a dictionary of additional options ( optional ) : return : an iterator over ` ` ( lineno , funcname , message , comments ) ` ` tuples : rtype : ` ` iterator ` `"
set up the about dialog
"prints a log message . : param namespace : a namespace . if none , uses the current thread name . : param message : a message to be logged ."
prints a log message namespaced with the current thread . : param message : a message to be logged .
"split toots , if need be , using many magic numbers ."
associates a tweet and a toot in the associations file . : param toot_id : the toot id : param tweet_id : the tweet id
transfers a media from a network to another .
take a string and build an errbot object from it .
"take a message i d , return an errbot message object"
implement the send_card functionality for cisco spark . cisco spark does n't really support cards or html formatting this is subject to breakage
event will be a dict of the webhook payload
test that the activity only meets the execution criteria when it 's amount is greater than 0 .
test that the activity run method creates a transaction with an amount of 5000 .
test that the activity run method get_referenced_accounts accounts matches the debit and credit accounts self.object was initialised with .
test that the activity only meets the execution criteria when it 's amount is greater than 0 and its duration is greater than 0 .
test that the activity run method creates a transaction with an amount of 180000 on the first month . no other transactions
test that the activity run method accrued the interest correctly .
test that the activity run method creates settled the loan on the loans ' last month and that the transactions
test that the activity run method get_referenced_accounts accounts matches the debit and credit accounts self.object was initialised with .
other = materialpackage test whether the add operator calculates the resulting package correctly .
"other = tuple ( size_class , mass ) test whether the add operator calculates the resulting package correctly . results were checked against factsage results . they are not exactly the same , since the magnetic and other non - cp contributions are omitted by the thermo module ."
calculate the thermal expansion coefficient at the specified temperature :
calculate the density at the specified temperature .
calculate the density at the specified temperature and pressure .
"calculate the density at the specified temperature , pressure , and composition ."
"read a .csv , and create a map for each line"
use the self.data to put all information into a csv with the right format for tacke70 's spreadsheet [ see http://exiletools.com/tackle70/ ]
writes a map object into a sequence of bytes in the dustforce level format .
create a new empty bitwriter .
writes ` val ` as a ` bits ` bit integer in little endian order to the bit stream .
writes ` val ` as a ` bits ` bit integer in big endian order to the bit stream .
returns a bytes object containing all written data so far .
returns the number of bytse written so far .
aligns the bit stream to a given multiple of bits . default alignment is 8 - bit alignment .
write the bytes given by ` data ` to the stream .
"converts an input 1 - d vector of integers into an output 2 - d array of one - hot vectors , where an i'th input value of j will set a ' 1 ' in the i'th row , j'th column of the output array ."
construct a dataset .
return the next ` batch_size ` examples from this data set .
: type key : str | basestring : rtype any | none
: type keys : list | tuple : rtype dict :
: type key : str | basestring
: type data_dict : dict
: type key : str | basestring
creates a temporary filename .
"given an on - disk pex , extract all of the unique first - level paths under ` .deps ` ."
"write content to disk where content is map from string = > ( int , string ) ."
write a pex file that contains an executable entry point
simulate running pex command for integration testing .
"additionally , tests that the module does not raise at import"
is this distribution compatible with the given interpreter / platform combination ?
register a concrete implementation of a package to be recognized by pex .
convert from a url to package .
determine whether this package matches the requirement .
is this link compatible with the given tag set ?
a heuristic used to split a string into version name / fragment :
return a list of packages that satisfy the requirement .
basically turn a top level ' landscape ' entry with a ' client ' dict and render it to configobj format under ' [ client ] ' section in /etc / landscape / client.conf
merge together configobj objects or things that configobj ( ) will take in later entries override earlier
merge values from c{cand } into c{src } . if c{src } has a key c{cand } will not override . nested dictionaries are merged recursively .
return a list of devices that may contain the context disk .
"read_context_disk_dir(source_dir ): read source_dir and return a tuple with metadata dict and user - data string populated . if not a valid dir , raise a noncontextdiskdir"
verify a valid seeddir is read as such .
verify extra files do not affect seed_dir validity .
verify that invalid seed_dir raises maasseeddirmalformed .
verify that empty seed_dir raises maasseeddirnone .
verify that missing seed_dir raises maasseeddirnone .
verify that valid seed_url is read as such .
verify that invalid seed_url raises maasseeddirmalformed .
verify seed_url with no found entries raises maasseeddirnone .
static method which returns the solution : sin((x - 0.5)^2 + ( y - 0.5)^2 ) .
static method which returns the solution second derivative : 4 * cos((x - 0.5)^2 + ( y - 0.5)^2 ) - 4 * sin((x - 0.5)^2 + ( y - 0.5)^2 ) * ( ( x - 0.5)^2 + ( y - 0.5)^2 ) .
static method which returns the solution mixed second derivative : -4 * sin((x - 0.5)^2 + ( y - 0.5)^2 ) * ( ( x - 0.5 ) * ( y - 0.5 ) ) .
"method which evaluates the solution . it calls the method "" solution "" to obtain it ; at a first glance can appear useless , but it has the capability to be independent from the exact solution , so for the user is useful ; one has to change only the method "" solution "" to mantain independence ."
"method which evaluates the second derivative . it calls the method "" s_s_der "" to obtain it ; at a first glance can appear useless , but it has the capability to be independent from the second derivative , so for the user is useful ; one has to change only the method "" s_s_der "" to mantain independence ."
"method which evaluates the mixed second derivative . it calls the method "" s_s_der "" to obtain it ; at a first glance can appear useless , but it has the capability to be independent from the second derivative , so for the user is useful ; one has to change only the method "" s_s_der "" to mantain independence ."
"method which tests that the number of intercommunicators created is equal to the total number of grids minus 1 , for each grid ."
"method which tests that the number of couple keys - values inserted into the dictionary by the method "" main.set_comm_dict "" is equal to 9 ( as they should be ) ."
method which tests that the length of the list containing the centers of the quadtree is equal to the number of the octants ( aka quadtree in 2d ) returned by the octree .
"method which just see if the call to "" main.main "" is going without problems inside the called function ."
"compute a z - matrix ( cluster co - assignment matrix ) . the ij - th entry of a z - matrix is a real value scalar between [ 0 , 1 ] indicating the frequency of how often entities i and j appear in the same cluster ."
generate a bag of samples from the posterior distribution of each mixturemodel state object .
sample many values and combine each feature independently using the given ` merge ` strategy .
initialize scheduler .
a date module that converts a text string into a datetime value . useful as terminal data . loopable .
an operator that reverses the order of source items . not loopable . not lazy .
an operator that asynchronously returns a specified number of items from the top of a feed . not loopable .
an operator that returns a specified number of items from the top of a feed . not loopable .
a string module that asynchronously hashes the given text . loopable .
a string module that hashes the given text . loopable .
"override of its parent 's on_touch_down , used to reverse the state of checkbox ."
default handler for ' on_active ' event .
used to determine where touch is down and to change values of to_open .
event handler for on_enter event
event to hide the contextualmenu when a actionbutton is pressed
"this function first converts the value of the propwidget , then sets the new value . if there is some error in setting new value , then it sets the property value back to oldvalue"
default handler for ' on_propvalue ' .
display the option chooser
"override of : class:`~kivy.uix.textinput . textinput`.insert_text , it first checks whether the value being entered is valid or not . if yes , then it enters that value otherwise it does n't . for example , if property is numericproperty then it will first checks if value being entered should be a number or decimal only ."
default handler for ' on_widget ' .
to clear : data:`prop_list ` .
to discover all properties and add their : class:`~designer.components.property_viewer . propertylabel ` and : class:`~designer.components.property_viewer . propertyboolean`/ : class:`~designer.components.property_viewer . propertytextinput ` to : data:`prop_list ` .
creates a eventhandlertextinput for each property given its name
"( internal ) unselects any currently selected menu buttons , unless they represent the current panel ."
return the value of the section / key from the : attr:`config ` configparser instance . this function is used by : class:`settingitem ` to get the value for a given section / key .
read the buildozer.spec and update the codeinput
"try to save the spec file . if there is a error , show the label . if not , save the file and dispatch on_change"
event handler to dispatch a .spec modification
this function loads project settings : param proj_dir : project directory with buildozer.spec
override the original method to use the custom specsettingspanel
returns the version of the ` observables ` ` ` observables ` ` node .
raises an exception if ` version ` is not a valid cybox version .
decorator which checks that the input document is a cybox document .
yields a unique list of prefetch entries from all pf_headers
checks of a prefetch header structure is valid
this standardizes the output formatting
this yields data according to the unified output format
renders the prefetch entries as text
provide a function level scoped filestore instance talking to temporary database on localhost:27017 with both v0 and v1 .
provide a function level scoped filestore instance talking to temporary database on localhost:27017 with both v0 and v1 .
get scrapyd url : param ip : host : param port : port : return : string
get log url : param ip : host : param port : port : param project : project : param spider : spider : param job : job : return : string
judge if the file is ignored : param ignores : ignored list : param path : file path : param file : file name : return : bool
judge name is valid : param project_name : : return :
copy tree : param src : : param dst : : return :
get tree structure : param path : folder path : param ignores : ignore files : return : json
render template : param tpl_file : template file name : param dst_file : destination file name : param args : args : param kwargs : kwargs : return : none
get last line of error : return : string
process request : param request : : return :
process response to dict : param response : : return :
"process html , add some tricks such as no referrer : param html : source html : return : processed html"
opens default gui text editor .
"opens default text editor , preferring cli editors to gui editors ."
a decorator to execute a function in a directory relative to the current file .
"a decorator to run a function in a temporary directory , cleaning up afterwards ."
run a scenario and return the exit code and output .
register the current options to the global configopts object .
return a list which contains all the available options .
register the current options to the global configopts object .
"tests that when ordered = false , the schema columns are associated with data frame columns by name , not position . in this case , the schema 's column order is [ a , b ] , while the data frame 's order is [ b , a ] . there is an error in column b in the data frame ( leading whitespace ) , and a validation on column b in the schema ."
"tests that when ordered = false , validation is possible by passing a subset of the columns contained in the schema"
"tests that when ordered = false , validation is possible by passing a subset of the columns contained in the schema"
"tests that when ordered = false , validation is possible by passing a subset of the columns contained in the schema"
"tests that when ordered = true , the schema columns are associated with data frame columns by position , not name ."
the entire warning message as a string
f(x ) = x
"verifies the provided axis is of the correct shape , and creates one if needed ."
ravel the dimensions after the first .
1d kde plot taking into account boundary conditions
a fft - based gaussian kernel density estimate ( kde ) the code was adapted from https://github.com/mfouesneau/faststats
plot energy transition distribution and marginal energy distribution in order to diagnose poor exploration by hmc algorithms .
create a new caching sequence matcher
clean the cache if necessary
reads the specified onc file and sends it as a policy .
verify the list of remembered networks contains those in wifi_expect .
test adding open network .
test adding wep network .
test adding wpa network .
test adding three different onc files one after the other .
test adding three different onc files one after the other .
test adding an onc file with unknown fields .
generate the expected stdout and stderr for the dummy test .
test the --shards_per_core parameter .
test the --total - slaves and --slave - index parameters .
return the file path when invoked with the str ( ) function
get architecture and dependency information for given files
finds the set of libraries matching |name| within lib_path
collect the list of dependencies for the main_files
copies over the dependencies into a given destination directory
create a json formatted dict containing the files
returns a json - formatted dict containing the nacl dependencies
returns the manifest as a json - formatted string
returns the document root needed by the test suite .
returns true if the test suite requires mock test server .
returns the filename of gtest filter .
returns the filename of additional gtest filter for emulator .
returns a list of disabled tests .
updates test_suite_disabled file with the new filter ( deletes if empty ) .
returns a list of data files / dirs needed by the test suite .
launches helper tools for the test suite .
strips and copies the required data files for the test suite .
"runs a tests via a small , temporary shell script ."
"runs all available tests , restarting in case of failures ."
"runs all tests ( in rebaseline mode , runs each test in isolation ) ."
sets up necessary test enviroment for the test suite .
cleans up the test enviroment for the test suite .
constructs a dataset converter object .
constructs and returns a dictionary from a record in the dataset file .
function to convert input data into the desired output format .
get a list of file:// urls for use in this test case .
"open , verify given urls in the window at the given index ."
verify multiple tabs and windows .
verify tabs open / close .
verify forward / backward actions .
"open a page , duplicate it and make sure the new tab was duplicated"
"open "" many "" windows and tabs ."
return the header file that specifies the api of this wrapper . we do not generate the header files .
return true if the interface has any methods that need wrapping .
return true if the interface+version has any methods that need wrapping .
return true if a particular member function at a particular release needs wrapping .
return true if any parameter in the list needs wrapping .
"return true if a parameter type needs wrapping . currently , this is true for byval aggregates ."
generate shim code for a range of releases .
helper that returns immediately after running a javascript command .
waits until the javascript condition is true .
returns the path to the webapp .
logs a user in for chromoting and accepts permissions for the app .
generates an access code and waits for incoming connections .
connects to a chromoting host and starts the session .
stops sharing the desktop on the host side .
disconnects from the chromoting session on the client side .
login to chromeos using default testing account .
checks the tsan suppressions files for bad suppressions .
reads the webkit version.xcconfig file looking for major_version and minor_version . this function does n't attempt to support the full syntax of xcconfig files .
"get the webkit revision , in the form ' trunk@1234 ' ."
"given webkit 's version file , emit a header file that we can use from within webkit_glue.cc ."
test _ range . parse with a valid range .
test _ range . parse with a valid range with default counts .
test _ range . parse with invalid ranges .
test function _ changehunk._difflinetype .
test function _ changehunk . parse with valid diff lines .
test function _ changehunk . parse with invalid diff lines .
test function _ changehunk . apply .
test function _ patchheader . parse with a valid header .
test function _ patchheader . parse with invalid headers .
test function _ patch . parse .
generates code to get an array from a src.name into dst .
generates code to get an array from src into dst .
generates code to create a scoped_pt < value > from the array at src .
"args : adb : adb interface the tests are using . device : device to run the tests . test_suite : a specific test suite to run , empty to run all . timeout : timeout for each test . rebaseline : whether or not to run tests in isolation and update the filter . performance_test : whether or not performance test(s ) . cleanup_test_files : whether or not to cleanup test files on device . tool : name of the valgrind tool . dump_debug_info : a debug_info object . symbols_dir : directory to put the stripped binaries ."
returns a list of all tests available in the test suite .
creates a test runner script and pushes to the device .
runs all the tests and checks for failures .
strips and copies the executable to the device .
"convert to dict . ( yes , doing it manually is n't nice but its ok with a limited number of fields and gives us more control ) : return :"
: param context 上下文对象 : param path 加载路径，可以是文件路径，也可以是web url : param style json数据格式，允许三种格式 ： 1 . line : 文件每行是一个json对象 2 . array : 文件内容是一个json数组 3 . extract : property 文件是一个json对象，但是只提取某一部分进行处理 4 . block : 区块，不在同一行 : param record_handler 行处理器，返回的每行都是字典对象，通过该函数可以进行包装 如果返回none，那么将对该行忽略 : param record_filter 行过滤器 : param result_wrapper 对最终结果进行包装 : param variable 结果写入上下文的变量名，如果为none，那么将返回值交给框架自身来保存
: param path 写入路径，默认为文件路径，如果是http或者https开头，那么将会post到对应的地址 : param style 写入格式，line - 按行写入 array - 作为json数组写入 object - 作为单独对象写入 : param table 要操作的对象，可以是具体的对象，也可以是context中的变量名 : param record_handler 行处理器，可以在此进行格式转换，比如把时间对象转换为字符串 : param record_filter 行过滤器 : param http_method http写入方法，默认为post，可以指定put : param variable 将json写入上下文变量
获取函数的默认参数名 - 值映射
解析上下文中的变量 如果以'$'字符开头，那么返回上下文中的对应变量 其它的情况会直接返回字符串 开头两个$$连续为转义，比如'$$aa$$a'为'$aa$$a ' : param context 上下文 : param variable_name
log in to reddit using the given credentials .
return the response from getting the url as the signed in user .
"builds features i.e. a matrix with columns [ x , x^2 , x^3 , x^4 ] ."
approximated function .
creates a string description of a polynomial .
"builds a batch i.e. ( x , f(x ) ) pair ."
create a new job queue object for a given thoonk feed .
return the set of redis keys used exclusively by this feed .
return the set of ids used by jobs in the queue .
completely remove a job from use .
add a new job to the queue .
retrieve the next job from the queue .
"mark a job as completed , and store any results ."
move a claimed job back to the queue .
move a job out of the queue in order to pause processing .
move a job from a stalled state back into the job queue .
perform periodic house cleaning .
add a new item to the queue .
retrieve the next item from the queue .
第三方帐号oauth认证登录，只有设置了using_social_login = true才会使用到此功能
使用此get方法的class，必须制定这两个属性 ： self.tpl - 此view要渲染的模板名 self.ctx_getter - 渲染模板是获取额外context的方法名
注册和登录都是通过ajax进行的，这里渲染表单模板的时候传入referer ， 当ajax post返回成功标识的时候，js就到此referer的页面 。 以此来完成注册 / 登录完毕后自动回到上个页面
"convert aws inconvenient tags model of a list of { "" key "" : < key > , "" value "" : < value > } pairs to a dict of { < key > : < value > } for easier querying ."
load necessary resources tables into db to execute given query .
load resources as specified by given table into our db .
simple generic json serializer for common objects .
this emulates the hstore ` - > ` get value operation . it get value from json serialized column by given key and return ` null ` if not present . key can be either an integer for array index access or a string for object field access .
"create a table , schema_name.table_name , in given database with given list of column names ."
"insert all item in given items list into the specified table , schema_name.table_name ."
configures / validates the storage configuration
creates a connection to s3
gets the configured bucket
determines the s3 key to store the file under
uploads the file to s3
the fingerprint for the public gpg key
the public gpg key
get the fingerprints of keys currently loaded on the system
performs a one - time configuration of gpg keys
encrypts the local file with gpg
uploads the file to s3
audits the given file - this means we encrypt it and store it on s3
"audits the given response file , see audit ( ) for details"
"audits the given request file , see audit ( ) for details"
args : col_names ( dict ): mapping of rowprops property name to the name of the column in the csv
parses a row of grade adjustment info and makes sure it does n't contain bad data
parses all rows of grade adjustment info from a csv and yields each proctoredexamgrade object with its associated grade adjustment row from the csv
upload the given tsv files to the remote
tests that financialaidfactory.create ( ) will create a profile for the user field if a user is not specified
tests that financialaidfactory.create ( ) will still work normally if provided a user object
returns true if the user has the can_edit_financial_aid permission for a program . args : request ( request ): drf request object view ( view ): drf view object obj ( financialaid ): financialaid object returns : boolean
returns true if the financialaid.user matches the logged in user args : request ( request ): drf request object view ( view ): drf view object obj ( financialaid ): financialaid object returns : boolean
"convert warnings to errors . this should only affect unit tests , letting pylint and other plugins raise deprecationwarnings without erroring ."
sets default settings to safe defaults
fixture that patches all indexing api functions that communicate directly with elasticsearch
fixture that resets all of the patched elasticsearch api functions
set discussion - specific settings
"patch on_commit to execute immediately instead of waiting for transaction to commit . since tests run inside transactions this will delay execution until after the test . since uses of on_commit are usually meant to delay executing tasks , and since tasks are executed immediately in unit tests , executing immediately should n't cause problems here ."
should have properly formed payload if working .
"if the user only has one name , last_name should be blank ."
exponential backoff for retried tasks
returns true if user is eligible exam authorization process . for that the course must have exam settings and user must have paid for it .
if a field is filled out match it to the cp-1252 character set .
make sure all the required fields fall within the cp-1252 character set
fetches the given user 's edx data and sets object properties
returns cached data for the user in a specific course run
helper function to return cached data .
updates the usercacherefreshtime model timestamp for the provided cache type
checks if the specified cache type is fresh .
checks if all cache types are fresh .
updates the cached enrollment based on an enrollment object
updates cached enrollment data for an user .
updates cached certificate data .
updates cached current grade data .
checks if the specified cache type is expired and in case takes care to update it .
updates only certificates and current grade . used before a final grade freeze .
tests that anonymous users gets no token
tests that anonymous users gets no token
tests that anonymous users get a 403
tests that logged in user gets cookie and redirect
tests that logged in user gets cookie and redirect
tests that logged in user gets cookie and redirect
generate parameters for create api
superuser can create a channel using the rest api
anonymous users should get a 401 error
if a user is not a superuser they should get a forbidden status
a staff role user who is not superuser should also get a forbidden status
a missing param should cause a validation error
a bad program id should cause a validation error
creating a duplicate channel should return an error
helper to make a lock
a lock with a long expiration ( relative to unit tests anyway )
a lock with a very short expiration
a lock should hold the lock and release it after the context block is finished
a lock should acquire a lock and release it
a lock should get released
an expired lock will show up as acquired but is_still_locked is false
release_lock can take a separate token and release the lock that way
test that generate_course_certificates_for_fa_students creates certificates for appropriate finalgrades
test create_combined_final_grade creates the grade when it is missing
verify that when a retryable error occurs that the task retries
verify that when a improperlyconfigured error occurs that the task logs exception
verify that when a any error occurs that the task logs exception
verify that when the auditor raises an improperlyconfigured error that the task logs exception
verify that when the auditor raises any other error that the task logs exception
test that tasks do not run when feature flag ` pearson_exams_sync ` is off
verify that export_exam_profiles makes calls to export the pending profiles
verify invalid profiles are not writen to file and set to ' invalid '
verify that export_exam_authorizations exports pending exam auths
verify that batch_process_pearson_zip_files works in the happy path
verify that batch_process_pearson_zip_files does n't error when a retryablesftpexception raises
test update_exam_run ( )
test authorize_exam_runs ( )
get coupon code from an httprequest
"creates a batch of tierprograms that obey a few constraints : ( 1 ) discount amounts decrease as income increases ( 2 ) discount amounts will not exceed the program price ( 3 ) one tierprogram in the batch will have a 0 discount amount , and one will have a 0 income threshold"
"overrides the default .create ( ) method so that if no user is specified in kwargs , this factory will create a user with an associated profile without relying on signals ."
test /pearson / success url
test /pearson / error url
test /pearson / error url
test /pearson / logout url
test a url under /pearson that does n't exist
test issuing a get request when user has no examprofile
test issuing a get request when user has an examprofile in non - success status
test issuing a get request when user has an examprofile in profile_success status
test issuing a get request when user has an examprofile in profile_success status
test that the user can only search the programs she has permissions on
"if user profile does not have terms of service , redirect to terms of service if user profile is not filled out , redirect to profile"
users are allowed to use safe methods without owning the profile .
users are allowed to edit their own profile
users are not allowed to edit if it 's not their profile .
helper method to get social_auth uid for a user
users are not supposed to view private profiles .
anonymous are not supposed to view public_to_mm or private profiles .
anonymous can view public profiles .
non verified micromaster users are not supposed to view public_to_mm profiles .
users can not open profiles with ambiguous account_privacy settings .
users are allowed to view their own profile .
users are allowed to view public profile .
verified mm users are allowed to view public_to_mm profile .
users are not allowed to view public_to_mm profile if there are no common programs .
staff and instructors can see private profile of user with same program
sync any outstanding profiles
sync any outstanding profiles
fetch zip files from pearsons sftp periodically .
an updated examrun means all authorizations should be updated
check for outstanding exam runs
compute the sso_digest value we need to send to pearson
authorize user for exam if he has paid for course and passed course .
this walks the cachedenrollments backwards chronologically and authorizes the first eligible one .
authorize all eligible users for the given exam run
authorizes a user for all schedulable examruns for a courserun
updates outstanding exam authorizations so we send them to pearson with new data
test that a course can be purchased with a 100%-off coupon
test the financial aid review page
test viewing the program page
page should contain the appropriate number of results on each page
the querystring should not be affected when the learner search page loads
switching programs should show a different set of users
nothing should break when navigating to the profile and back to learners search page
there should be more than 20 countries in current country and birth country facets
ensure a url has a trailing slash
return the correct public_path for webpack to use
update bundle urls to handle webpack hot reloading correctly if debug = true
render the script tags for a webpack bundle
outputs tags for template rendering . adapted from webpack_loader.utils.get_as_tags and webpack_loader.templatetags.webpack_loader .
set the metric and objective for this search should be ' accuracy ' or ' loss '
run genetic search on dataset given number of generations and population size
this sends a message to the connected host encoded as utf-8 .
this receives a message from the host and decodes it as utf-8 .
this closes the connection to the host .
adds the passed road to the player inventory and removes the resources .
adds the passed settlement to the player inventory and removes the resources .
adds the passed city to the player inventory and removes the resources .
adds the passed dev_card to the player inventory and removes the resources .
checks if the player has the resources to build a road .
checks if the player has the resources to build a settlement .
checks if the player has the resources to build a city .
checks if the player has the resources to build a dev card .
estimate frequency using pisarenko harmonic decomposition . it returns frequency ` omega ` in the unit radian / steps . if ` x[n ] = cos(omega*n+phi ) ` then it returns an estimat of ` omega ` . note that mean of ` x ` must be 0 . see equation ( 6 ) from [ kenneth w. k. lui and h. c. so ] _ .
estimate frequency using ` phd1 `
use aiohttp to make a request to alarm.com
login to alarm.com .
fetch the latest state .
generic function for sending commands to alarm.com
send disarm command .
send arm hom command .
send arm away command .
0시 0분을 기준으로 분 단위로 계산된 시작 시간을 반환한다 .
0시 0분을 기준으로 분 단위로 계산된 종료 시간을 반환한다 .
0시 0분을 기준으로 분 단위로 계산된 시작 시간을 반환한다 .
0시 0분을 기준으로 분 단위로 계산된 종료 시간을 반환한다 .
returns results whole
returns results to a specified csv file
: param factory : the new default factory for the package .
: param cache_dir : absolute path to the existing cache directory
: param cache_max_size : the maximum number of cache entries to hold in memory
: param cache_dir : absolute path to the existing cache directory : param cache_max_size : the maximum number of cache entries to hold in memory
"builds ` ` player.aps ` ` and ` ` player.apm ` ` dictionaries where an action is any selection , hotkey , or command event ."
combines two strings to one if both are not empty if they are equal return one if one empty return the other
creates a file for use with googleearth and launches googleearth if in system
writes the header part of the kml / kmz file .
writes the tail part of the kml / kmz file .
writes the point data of the kml / kmz file .
write data for table
get report and options class for this module
update the filter list based on the selected person
"handle filter change . if the filter is not specific to a person , disable the person option"
changes the wrap / font of text flow .
based on src / editors/_editnote.py
"if person or family changes , the relatives of active person might have changed"
verify that the matrix operations return the expected results .
create the class with the values and dimentions . a 1 - dimention list will be converted to a matrix .
return a string representation of the arrays
return the result of simple multiplication between this matrix and the other .
return the result of adding another matrix to this one .
return the requsted row as a list .
return the parent of a directory .
decorator for flask view functions .
return modeltranslation usage . returns : bool : modeltranslation usage .
additional commands for development tasks .
first screen : displays start button that will open second_screen
the heating screen : sets the temperature of the extruder to 230 display heating status to user open third screen when temperature hits 230
pull filament screen : display instructions to user -- pull out filament display button that will open fourth screen
load filament screen : display instructions to user -- load filament display button that will open fifth screen
final screen / confirm successful load : extrude filament display instruction to user -- press okay when you see plastic extruding display button that will move_to_main ( ) and stop extruding filament
layouts are similar in fashion : text and call to action button creates layout with text and button and binds f to button
` ` before_request ` ` handler for blueprints for which all requests need to be made supplying an api key .
` ` after_request ` ` handler for blueprints for which cors is supported .
` ` after_request ` ` handler for blueprints which shall set no caching headers on their responses .
` ` after_request ` ` handler for blueprints which shall set no caching headers on their responses to any requests that are not sent with method ` ` get ` ` .
shortcut for request handling for cors options requests to set cors headers .
start blanking system . screen will blank after bl_interval seconds .
shutdown blanking system .
code and file to be removed in upcoming version
"construct a fast internal relaxation engine ( fire ) minimization integrator . parameters ---------- timestep : unit . quantity compatible with femtoseconds , optional , default = 1*femtoseconds the integration timestep . tolerance : unit . quantity compatible with kilojoules_per_mole / nanometer , optional , default = none minimization will be terminated when rms force reaches this tolerance . alpha : float , optional default = 0.1 velocity relaxation parameter , alpha \in ( 0,1 ) . dt_max : unit . quantity compatible with femtoseconds , optional , default = 10*femtoseconds maximum allowed timestep . f_inc : float , optional , default = 1.1 timestep increment multiplicative factor . f_dec : float , optional , default = 0.5 timestep decrement multiplicative factor . f_alpha : float , optional , default = 0.99 alpha multiplicative relaxation parameter n_min : int , optional , default = 5 limit on number of timesteps p is negative before decrementing timestep . notes ----- velocities should be set to zero before using this integrator ."
utility function to generate replicas and call the mixing function a certain number of times
"this function accepts a list of permutation vectors , and for each replica , produces a list of the number of occurrences of each state ."
testing cython mixing code with 1000 swap attempts and uniform 0 energies
test generate_signature_schema ( ) function .
defines paths for icons
"update hightlights ( red underline ) in all files , using the errors in project"
"displays the error message in the sublime status line if the cursor is above an error ( in source code ) . for the click on the error list , see t3sviews.error.on_click ( )"
returns the error at pos in filename
"obsolete adds /usr / local / bin to path on mac osx , because that is where nodejs lives . this function has not worked out its intension . popen does not use this path as a search base for the executable . default_node_path ( ) is back to it 's previous state ."
"returns the normalized dir , in which the tsconfig.json file is located"
return path to tss.js
return path to expandglob.js
return < root filename > of file < filename > or none
"returns the { "" refs "" : [ ] , "" root "" : , "" file "" : } dictionary for filename"
returns weather or not this instance contains filename
adds or updates the dict for filename
removes filename from list
remove all files which have this file as root file
calculate the difference between phase start and end times
return color code for installer phase
constructor for ocvolume
property function for route
setter function for route
return whether a route exists
return route information
create the object
update the object
verify an update is needed
get the data for a particular value
run the idempotent asnible code
main module function
hook to ignore symlink files and directories .
some fields do not need to be searched because they will be migrated for users automatically
"check type of val , append to strings_to_check if string , otherwise if it 's a dictionary - like object call walk_mapping , if it 's a list - like object call walk_sequence , else ignore ."
"walk recursively through a list , items"
walk recursively through map_to_walk dictionary and add strings to strings_to_check
"check the strings we found to see if they look like file paths and if they are , fail if not start with /etc / origin / master"
run this action module
takes list of functions and prints thier docstring with retun values
input is serializer class type object and list of dictionaries save to database
"for testing purposes , returns new_swipe , original_swipe tupple"
only some sequences of swipes are allowed ( in after in is not allowed and so on )
construct rankedmetrics from basemetrics .
"powerset([1,2,3 ] ) -- > ( ) ( 1 , ) ( 2 , ) ( 3 , ) ( 1,2 ) ( 1,3 ) ( 2,3 ) ( 1,2,3 )"
convert filter description to list of matching filter configurations .
build metric from tokenized list based on * .metrics line .
batch construct metrics from text file .
compute memory value of iotree with respect to metric
typest name as ranked version of basemetric names
typeset multiple filters in a nicer way
compute memory value of iotree with respect to ranked metric
retrieve or compute value of metrictree with respect to metric
determine viability of metric based on computed values
"compute metric viability from two ( bool , bool ) pairs ."
compare two iotrees with respect to ranked metric
store self 's value under metric in profile
"convert string to list of tokens , breaking after [ and ]"
delete string suffix after first comment marker
tokenizer for forest files
convert forest string to gorn node specification .
convert forest tree to tuples for a gorntree .
check that file exists and is accessible .
convert * .linear file to linearization specification
convert * .move.forest file to movevement specification
construct metrictree from forest & linearization files .
batch create trees from files in a folder .
check * .linear files for consistency with * .tree.forest
batch create trees from files in a folder and print their forest specification .
start a service
benchmark n requests
get ' count ' fractions following power law distn according to parameter ' power '
"for the general intent and design of the tumbler algo , see the docs in joinmarket - org / joinmarket . alterations : donation removed for now . default final setting for "" amount_fraction "" is zero , for each mixdepth . this is because we now use a general "" schedule "" syntax for both tumbler and any other taker algo ; it interprets floats as fractions and integers as satoshis , and zero as sweep ( as before ) . this is a modified version of tumbler.py/generate_tumbler_tx ( )"
"if a tx in a schedule failed for some reason , and we want to make a best effort to complete the schedule , we can tweak the failed entry to improve the odds of success on re - try . both the size / amount and the number of counterparties may have been a cause for failure , so we change both of those where possible . returns a new , altered schedule file ( should continue at same index )"
returns any existing attr for the wrapped module or returns a mock function for anything else . never raises an attributeerror .
returns a list of installed modules
test module name is installed
convert a filetime 64 - bit integer to a timestamp .
convert a timestamp to a filetime 64 - bit integer .
"find offsets in the given buffer that contain a filetime timestamp between 2010 and tomorrow . note : tomorrow depends on the current date , so its a bit impure ."
find places in the given buffer at which class definitions may be carved .
notify all clients of updated public user data
construct square using built in geometry .
construct circle using built_in geometry module .
construct surface using builtin and boolean methods .
cconstruct surface using boolean fragments .
test planar surface with holes .
test planar suface square with circular hole .
test planar surface with holes .
construct surface using boolean .
evaluates the transit model given a time array and necessary parameters .
"for continuous usage , allow changes to the scope and stimuli frequencies at any event . the stimuli can also be started and stopped by the user ."
"for discrete usage , only allow changes when a trial is not underway . handle the transition between trial and output ."
initializes a jsonconfiguredruntime .
starts the unlockruntime .
load a rexpaint image from the given ` ` .xp ` ` path .
": param str file_string : string contents of a ` ` .xp ` ` file generated by rexpaint : param bool reverse_endian : controls whether the slices containing data for things like layer width , height , number of layers , etc . is reversed . so far as i can tell python is doing int conversions in big - endian , while the ` ` .xp ` ` format stores them in little - endian . i may just not be aware of it being unneeded , but have it there in case ."
takes a single layer 's data and returns the format listed in the module docstring for a single layer .
"pulls out the keycode and the foreground / background rgb values from a single cell 's data , returning them in the format listed at the top of this file for a single cell ."
makes multi - indexed dataframe of subject data
creates egg data object from zero - indexed recall matrix
fills in default distance metrics for fingerprint analyses
"takes a list of eggs , stacks them and reindexes the subject number"
takes an egg and returns a subset of the subjects or lists
convert a multiindex df to list
fills in missing lists ( assumes end lists are missing )
parses an egg and returns fields
helper function to merge pres and features to support legacy features argument
verify that the search npm endpoint returns the expected response .
this function is called whenever a new baseregistry class is created and these variables also pass onto inheriting classes .
a generic requests wrapper that handles appending the user agent for me automatically .
a generic ping function that makes a get request to the root of the inheriting registry ( ie ; https://registry.npmjs.com ) and makes a get request .
a generic fetch function that takes the name of a package and then performs everything requests to fetch details about that package .
a generic object reshaping function . i do n't know what you 'd call it but it just checks what was found and what was n't .
main program .
"smooth an object by setting the interior control points to the average of itself and all neighbours ( e.g. 9 for surfaces , 27 for volumes ) . the edges are kept unchanged , and any rational weights are kept unchanged ."
a context manager for running code in a modified state .
instantiate a yelpapi object . an api key from yelp is required .
query the yelp autocomplete api .
query the yelp business api .
query the yelp business match api .
query the yelp event lookup api .
query the yelp event search api .
query the yelp featured event api .
query the yelp phone search api .
query the yelp reviews api .
query the yelp search api .
query the yelp transaction search api .
clean the parameters by filtering out any parameters that have a none value .
"all query methods have the same logic , so do n't repeat it ! query the url , parse the response as json , and check for errors . if all goes well , return the parsed json ."
"return a javascript callback that subscribes to a given topic , or a list of topics ."
"return a javascript callback that unsubscribes to a given topic , or a list of topics ."
simulate running the reactor for ` duration ` milliseconds
test that we can subscribe for and receive a message .
test that we can subscribe to a few different topics .
test that the ws server only sends desired topics .
test that the ws server can differentiate clients .
returns a list that can be concatenated to the list of handlers passed to the ` ` tornado.web . application ` ` object . this list contains handlers for the networktables websocket and the necessary javascript to use it . example usage : :
if we receive a facebook uid then the cookie has already been validated .
if we receive a facebook uid then the cookie has already been validated .
transforms a single item into a tuple if it is not already a tuple .
a heuristic to find out if a function is simple enough .
return the pyobject of the underlying event so that this object can be waited on by the : func:`ipc.all ` or : func:`ipc.any ` functions
: returns : ` true ` if the io has completed
wait for the io to complete in such a way that the wait can be interrupted by a keyboardinterrupt .
wait until the io has completed and return the data from the read . this is expected to be called after is_complete is true .
takes the replacement template and some info about the match and returns filled template
create a simulated aneaaling learner .
run the learner .
"create a posterior object from a list of sorted , scored networks ."
creates a posterior object .
return a consensus network with the given threshold .
the information entropy of the posterior distribution .
iterate over the networks in the posterior in sorted order .
retrieve a specific network ( and score ) from the posterior .
retrieve a subset ( as a new posterior object ) of the networks .
return the number of networks in this posterior distribution .
basic example script to demonstrate the usage of pymzml . requires a mzml file as first argument .
"filename = filename of a file in the example directory if the file "" filename "" is not present in the example directory , the file is downloaded . path with filename is returned ."
"filename_with_path = path and filename , where to save downloaded file url = url to download path with filename is returned ."
basic example script to demonstrate the usage of pymzml . requires a mzml file as first argument .
"ensure that a version has 3 components , defaulting to .0 for the missing components ."
add a new dict to the translator .
check if idtag equals name in currently used obo version .
add builders and construction variables for wix to an environment .
add builders and construction variables for forte c and c++ compilers to an environment .
add a builder factory function and construction variables for perforce to an environment .
add builders and construction variables for zip to an environment .
decorator to validate all the arguments to function are of the type of calling class
returns a mayadt instance for this exact moment .
""" returns a mayadt instance for the human moment specified ."
""" returns a mayadt instance for the machine - produced moment specified ."
return 's the datetime 's format
returns the utc tzinfo name . it 's always utc . always .
returns the utc tzinfo object .
"returns the name of the local timezone , for informational purposes ."
returns the local timezone .
converts a datetime into an epoch .
returns mayadt instance from datetime .
returns mayadt instance from iso8601 string .
returns mayadt instance from rfc2822 string .
returns a timezone - aware datetime ... defaulting to utc ( as it should ) .
returns an iso 8601 representation of the mayadt .
returns an rfc 2822 representation of the mayadt .
return the day of the week as an integer . monday is 1 and sunday is 7
""" returns human slang representation of date ."
""" returns human slang representation of time ."
"when saving file function is there and expected data type is different than file , let 's call it . when we 're expecting file in response , saving file function is obligatory"
reads and parses the config file
encrypts the message with recipient keys
encrypts the payload with the given keys
returns the gpg key for the given email address
sends the given message through the smtp relay
"all our losses assume ( y_score , y_true ) order , while sklearn assumes the reversed one ."
implements the idea from the paper riemannian pursuit for big matrix recovery
riemannian sgd method optimization for a linear model with weights in tt .
parse feed using the current feed parser .
import feed .
get and save categories .
create new category .
update ( refresh ) feed .
create new enclosure .
get and create enclosures for feed .
parse post fields .
import feed post entry .
convert : class:`datetime.timedelta ` to seconds .
get all : class:`post`s for this : class:`feed ` in order .
expire old posts .
automatically generate a new guid from the metadata available .
builds an outgoing message .
sends a built outgoing message .
the domain to be manipulated .
the hosts of this domain to be manipulated . keyed by fqdn .
"take the host list and create a dictionary . the keys of this dictionary are the fqdn representation of the host ( i.e. , host.domain.tld )"
connection endpoint . returns operations in xml as element
retrieve current resource records from namesilo for self.domain .
dynamic dns updater
returns additional .pyc files from main directory
runs unpyc3 or uncompyle2 decompiler
runs re algorithm in correct order
diverge from the baseinstaller implementation in order to allow language selection
create the firefox developer launcher
"parse phantomjs download link , expect to find a sha and a url"
add phantomjs necessary env variables
register these classes with the ` linkfactory `
run this analysis
run this analysis
hook to build job configurations
hook to build job configurations
register these classes with the ` linkfactory `
run this analysis
hook to build job configurations
make the list of input files for a particular energy bin x psf type
register these classes with the ` linkfactory `
map from the top - level arguments to the arguments provided to the indiviudal links
hook to build job configurations
plot the ( negative ) log - likelihood as a function of normalization
make a color plot ( castro plot ) of the log - likelihood as a function of energy and flux normalization
make a color plot ( castro plot ) of the delta log - likelihood as a function of energy and flux normalization
make a color plot ( castro plot ) of the ( negative ) log - likelihood as a function of energy and flux normalization
compare two seds
convert git release tag into a form that is pep440 compliant .
read the release version from ` ` _ version.py ` ` .
write the release version to ` ` _ version.py ` ` .
c'tor : copies keyword arguments to data members
return a filter string by key
return the iterator over keys
"return the itratetor over key , value pairs"
return the itratetor over values
build a list of components from a yaml file
this is a function that returns a python like level from a heasoft like level .
this method sets up the default configuration of the logger . once this method is called all subsequent instances logger instances will inherit this configuration .
create a python logger instance and configure it .
tells you whether current script already has administrative rights .
waits till spawned process finishes and closes the handle for it
this will re - run current python script requesting to elevate administrative rights .
stop the thread
start listening to the server
connect to the server
disconnect from the server
send a command to the server
read a line from the server . data is read from the socket until a character ` ` ` ` is found
read a block from the server . lines are read until a character ` ` . ` ` is found
read a block and return the result as xml
create a form of the given class . form_id should be a string which will niquely identify the form . * args and * * kwargs will be passed to the form constructor . forms created in this way are handled entirely by the npsappmanaged class .
form_id should be a string which should uniquely identify the form . fm should be a form .
set the form that will be selected when the current one exits .
immediately switch to the form specified by form_id .
"this function starts the application . it is usually called indirectly through the ` run ` method . you should not override this function , but override the ` on_in_main_loop ` , ` on_start ` and ` on_clean_exit ` methods instead , if you need to modify the application 's behaviour ."
called between each screen while the application is running . not called before the first screen . override at will .
override this method to perform any initialisation .
override this method to perform any cleanup when application is exiting without error .
"returns v , limited to low / high threshold"
renders a font and blits it to the given window
"returns a tuple of x , y coordinates that represents the center position for the given surface . x_offset and y_offset will offset the appropriate axis by n pixels . passing in a value for x or y will override the calculated value ."
runs the model on the given data .
"make tensorflow sparsetensor from list of targets , with each element in the list being a list or array with the values of the target sequence ( e.g. , the integer values of a character map for an asr target string ) see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/ctc/ctc_loss_op_test.py for example of sparsetensor format"
"takes a list of input matrices and a list of target arrays and returns a list of batches , with each batch being a 3 - element tuple of inputs , targets , and sequence lengths . inputlist : list of 2 - d numpy arrays with dimensions nfeatures x timesteps targetlist : list of 1 - d arrays or lists of ints batchsize : int indicating number of inputs / targets per batch returns : databatches : list of batch data tuples , where each batch tuple ( inputs , targets , seqlengths ) consists of inputs = 3 - d array w/ shape ntimesteps x batchsize x nfeatures targets = tuple required as input for sparsetensor seqlengths = 1 - d array with int number of timesteps for each sample in batch maxsteps : maximum number of time steps across all samples"
uses the mwmatching library to assign teams in a pairing
calculate the penalty for a given pairing
validates all links in the given html file .
validates all image links in the given html file .
returns all the text content without markup from given html file .
"determines the von neumann entropy of data at varying matrix powers . the user should select a value of t around the "" knee "" of the entropy curve ."
returns the x - location of a ( single ) knee of curve y = f(x )
note : setting l does nothing here anymore ! everything is done in fit this l option can be deprecated !
return predictions for x
return confidence predictions for x note : for multi - label ( binary ) data only at the moment .
configure the logger object and read the command line arguments for invoking the generator .
"if ask = ` true ` prompt the user to continue or stop , otherwise pretend that the file exists ."
ask a yes / no question via raw_input ( ) and return the answer as a boolean .
verify we can store linkage rows
set the test database engine / session
create rule rows
verify we can store partner rows
drop the tables created
"only export i d , vulnerability , file_path , line_number , commit_time , commit_author : return :"
returns dictionary of psivariable definitions .
run migrations in ' offline ' mode .
run migrations in ' online ' mode .
delete an article from the database .
returns the previous article ( older ) .
returns the next article ( newer ) .
test that a defunct buildername will be pruned
test getting runnable jobs without providing decision task i d
store the contents of the job info artifact in job details
store the contents of the text log summary artifact
store a list of job artifacts . all of the datums in artifact_data need to be in the following format :
ensure that json artifact blobs passed as dicts are converted to json
3 days ago
2 days ago
1 day ago
"return a sample data structure , with default values ."
"return a sample data structure , with default values ."
"return a sample data structure , with default values ."
switch to new active watched repo
"given any number of dicts , shallow copy and merge into a new dict , precedence goes to key value pairs in latter dicts ."
"given four points of a rectangle , translate the rectangle to the specified x and y coordinates and , optionally , change the width ."
"for core otu data file , returns genus - species identifier for each data entry . : type core_fp : str : param core_fp : a file containing core otu data . : rtype : str : return : returns genus - species identifier based on identified taxonomical level ."
"given a list of otus and a number of groups containing subsets of the otu set , plot a presence / absence bar chart showing which species belong to which groups ."
parses the given options passed in at the command line .
calculate the relative abundance of each otuid in a sample .
calculate the mean otu abundance percentage .
calculate the mean relative abundance percentage .
calculate the total number of sequences in each otu or sampleid .
function to transform the total abundance calculation for each sample id to another format based on user given transformation function .
takes the proportion data from relative_abundance ( ) and applies the variance stabilizing arcsine square root transformation :
plot pcoa principal coordinates scaled by the relative abundances of otu_name .
parse the records in a fasta - format file by first reading the entire file into memory .
"parse the records in a fasta - format file keeping the file open , and reading through one line at a time ."
"opens a qiime mapping file and stores the contents in a dictionary keyed on sampleid ( default ) or a user - supplied one . the only required fields are sampleid , barcodesequence , linkerprimersequence ( in that order ) , and description ( which must be the final field ) ."
"given a list of mapping items ( in the form described by the parse_mapping_file method ) and a header line , write each row to the given input file with fields separated by tabs ."
"greengenes provides a file each otu a full taxonomic designation . this method parses that file into a map with ( key , val ) = ( otu , taxonomy ) ."
return either the full or truncated version of a qiime - formatted taxonomy string .
"check to make sure the supplied directory path does not exist , if so , create it . the method catches oserror exceptions and returns a descriptive message instead of re - raising the error ."
"takes either a file path or an open file handle , checks validity and returns an open file handle or raises an appropriate exception ."
find the user specified categories in the map and create a dictionary to contain the relevant data for each type within the categories . multiple categories will have their types combined such that each possible combination will have its own entry in the dictionary .
parses the unifrac results file into a dictionary
function to parse data from older version of unifrac file obtained from qiime version 1.8 and earlier .
function to parse data from newer version of unifrac file obtained from qiime version 1.9 and later .
"determine color - category mapping . if color_column was specified , then map the category names to color values . otherwise , use the palettable colors to automatically generate a set of colors for the group values ."
split up the column data in a biom table by mapping category value .
this script prints some colors . if colorama is installed this will also work on windows . it will also automatically remove all ansi styles if data is piped into a file .
"s - > ( s0 , s1 ) , ( s2 , s3 ) , ( s4 , s5 ) , ..."
instanciates a phoneme from a line of espeak 's phoneme output .
set pitches variations from a list of frequencies . the pitch variation are set to be equidistant from one another .
return file content .
initialize a finder to get motifs .
find all motifs of the given size in the passed seqrecords .
return a dictionary with information on motifs .
find motifs in two sets of records and return the differences .
add a motif to the given dictionary .
initialize an input producer with motifs to look for .
represent a sequence as a set of motifs .
convert a tree object to a networkx graph .
"display a tree or clade as a graph , using the graphviz engine ."
draw an ascii - art phylogram of the given tree .
plot the given tree using matplotlib ( or pylab ) .
draw out the distribution information .
add the title of the figure to the drawing .
draw all of the distributions on the page .
add a legend to the figure .
initialize a bar chart display of distribution info .
draw a bar chart with the info in the specified range .
add the title of the figure to the drawing .
calculate the position of the chart with blank space .
iteratively parse a file and return each of the trees it contains .
parse a file in the given format and return a single tree .
write a sequence of trees to file in the given format .
convert between two tree file formats .
do a blast search using the qblast server at ncbi .
"extract a tuple of rid , rtoe from the ' please wait ' page ( private ) ."
called if no url matches .
the main wsgi application . dispatch the current request to the functions from above and store the regular expression captures in the wsgi environment as ` myapp.url_args ` so that the functions from above can access the url placeholders .
parse enzyme records .
read one enzyme record .
get output from primersearch into a primersearchoutputrecord
add primer information to the record .
approximate the log - odds threshold which makes the type i error ( false positive rate ) .
approximate the log - odds threshold which makes the type ii error ( false negative rate ) .
approximate the log - odds threshold which makes fnr equal to fpr times rate_proportion
"threshold selection mimicking the behaviour of patser ( hertz , stormo 1999 ) software ."
sort the atom objects .
add an atom object .
set the disordered flag .
return 1 if the residue contains disordered atoms .
"returns the list of all atoms , unpack disorderedatoms . """
sort the atoms in the child residue objects .
add a residue object and use its resname as key .
parse the trees in a nexus file .
write a new nexus file containing the given trees .
parses a handle containing a genepop file .
returns ( reconstructs ) a genepop textual representation .
splits a gp record in a dictionary with 1 pop per entry .
splits a gp record in a dictionary with 1 locus per entry .
removes a population ( by position ) .
removes a locus by position .
removes a locus by name .
join given arguments into the same set . accepts one or more arguments .
returns true if a and b are members of the same set .
returns an iterator returning each of the disjoint sets as a list .
returns the set that a certain key belongs .
"iterates over a des file , returning a des record for each line in the file ."
parses des records .
gets a demograpy template .
writes a simcoal2 loci template part .
writes a complete simcoal2 template file .
parse prosite records .
read one prosite record .
sudden flash at t=0 of extra beam
"simplified bateman , decay part only , the second activity in the chain"
"bateman for second in the chain , both grow and decay part of the cycle"
two half - lives ( isomer ) of one line
ions escape from tape ( diffusion ) t2 is diffusion time p2 is percentage of diffusable ions p1 is total number of ions
returns external resources .
"prefix that we use for redis storage , used for all keys related to this object . default to class name ."
convenience method for computing the redis object instance key from the identifier
key used for storage of object instance in redis .
dict version of this object
returns cli parse arguments .
returns bare cli parser object without arguments . arguments should be added to parser manually .
overriding dictionary values .
"reduces provided list in two steps : 1 ) removes all elements from list that appear prior to any ' no ' element , 2 ) removes duplicates and sorts elements ."
removes optional arguments that precede mandatory arguments .
returns input list with additional entries that represent choices without priority specifiers .
"normalizes list a so that among multiple choices that differ only in priority modifier , just the highest priority one is present in the output list . all the members in the output list are in the canonic form < type>.<priority > ."
implementation of textwrap.indent ( textwrap.indent not available on python 2 ) .
arguments are :
carefully handles directory creation . notifies about special occurrences .
carefully handles recursive directory copying . notifies about special occurrences .
carefully handles file writing . notifies about special occurrences .
generates well formated url of the contest according to user input .
fetches data from the provided contest url and generates contest object .
generates list of well formated problem urls according to user input .
fetches data from the provided problem urls and generates list of problem objects .
readline completion function : filenames
set the title of the terminal .
convert two quaternions and the time difference to angular velocity .
convert a quaternion q and apply the angular velocity omega to it over dt .
convert a vector from global to body coordinates .
convert a vector from global to body coordinates .
initialize with shape .
check if element is contained .
return arbitrary element .
return dimension of the space .
test : measure : bestperformance .
test : measure : safetymeasure .
returns the geolocation as a lat / lng pair
returns a boolean whether this address is dpv confirmed
returns the input i d
returns the input_index
constructor for an addresscollection
returns an address by user controlled input id
"returns an address by input index , a value that matches the list index of the provided lookup value , not necessarily the result ."
ensures that * args consist of a consistent type
ensures that * args do not exceed a set limit or are truncated to meet that limit
"ensure all values in the dictionary are strings , except for the value for ` candidate ` which should just be an integer ."
constructs the client
executes the http post request
api method for verifying street address and geolocating
"geocode one and only address , get a single address object back"
publish the converted value to mqtt using client parameter
print the converted value
publish the converted value to mqtt using client parameter
print the converted value
store formula image metrics and image ids in the database
save metrics and images
": param file_loc : location of the file : param data_type : type of data , can be "" l "" for int / long , "" c "" for string : param init_params : the init_params for opening csv : param block_unit_size : block size for storage system , 0 when disabled : param disk_sector_size : size of disk sector : param open_c_reader : bool for whether open reader in c backend : param kwargs : not used now"
"read one request , return the lbn / objid : return :"
"read the complete line , including request and its all related info : return : a list of all info in the request"
return a dict with column header->data note this function does not convert lbn even if disk_sector_size and block_unit_size are set : return :
a generator for reading all the information of current request / line : return : a tuple of current request
"return real_time information for the request in the form of ( time , request ) : return :"
skip n requests from current position
reset reader to initial state : return :
"reader a deep copy of current reader with everything reset to initial state , the returned reader should not interfere with current reader"
return all the parameters for this reader instance in a dictionary : return : a dictionary containing all parameters
"calculate the hit ratio of a given range of reuse distance : param rd : reuse distance list : param last_access_dist : how far in the past is last request , absolute distance : param cache_size : size of cache : param start : the start pos of reuse distance : param end : the end pos of reuse distance ( not included ) : param kwargs : real_start : return : hit ratio"
"the computation function for heatmap hr_st_et of lru , it calculates a vertical line of hit ratio"
"the computation function for heatmap hr_st_et of lru , it calculates a vertical line of hit ratio"
"retrieve the breakpoints given time_mode and time_interval or num_of_pixel_of_time_dim , break point breaks the trace into chunks of given time_interval"
"plot hit ratio curve of the given trace under given algorithm : param kwargs : figname , cache_unit_size ( unit : byte ) , no_clear , no_save : return :"
change figures : param kwargs : : return :
"maps a stretched color palette against the data range according to a particular method ( e.g. , linear from min to max value ) ."
image is always rendered high to low .
convert rasters to netcdf and stack them according to a dimension .
: param y_slice : slice or tuple of y_offset to y_max + 1 : param x_slice : slice or tuple of x_ffset to x_max + 1
returns a subset view of values within domain represented by this instance .
test that fingerprinting can be disabled .
test that fingerprinting provides existing urls .
test that fingerprinting can be restricted to certain filetypes .
"locate a cactus executable and ensure that it 'll run using the right interpreter . this is meant to work well in a tox environment . that 's how we run our tests , so that 's all that really matters here ."
test that we can build a site in a custom folder .
"return true in the case we succeed in running , false otherwise . this means we can use several processors and have one or the other work ."
ensure that the cache control headers are properly set
"> > > euclidean_distance((0,0 ) , ( 1,0 ) ) 1.0"
> > > km_na_metry(1 ) 1000 > > > km_na_metry(0 ) 0 > > > km_na_metry(-1 ) traceback ( most recent call last ): ... valueerror > > > km_na_metry('adas ' ) traceback ( most recent call last ): ... typeerror
return a graph object ready to be populated .
make a networkx graph from a known data structure .
return adjacency representation of graph as a dictionary of lists .
return a graph from a dictionary of lists .
return adjacency representation of graph as a dictionary of dictionaries .
return a graph from a dictionary of dictionaries .
return a list of edges in the graph .
return a graph from a list of edges .
compute the number of triangles .
"return an iterator of ( node , degree , triangles , generalized degree ) ."
"return an iterator of ( node , degree , weighted_triangles ) ."
compute the average clustering coefficient for the graph g.
compute the clustering coefficient for nodes .
"compute graph transitivity , the fraction of all possible triangles present in g."
compute the squares clustering coefficient for nodes .
compute the generalized degree for nodes .
checks whether the given joint degree dictionary is realizable as a simple graph .
"releases one free stub for saturated node ` ` w ` ` , while preserving joint degree in graph g."
generates a random simple graph with the given joint degree dictionary .
compute the eigenvector centrality for the graph ` g ` .
compute the eigenvector centrality for the graph g.
a tournament must have no self - loops .
a tournament must not have any pair of nodes without at least one edge joining the pair .
a tournament must not have any pair of nodes with greater than one edge joining the pair .
tests that : func:`networkx.tournament.hamiltonian_path ` returns a hamiltonian cycle when provided a strongly connected tournament .
tests for a reachable pair of nodes .
tests that a node is always reachable from itself .
tests for an unreachable pair of nodes .
tests for a strongly connected tournament .
tests for a tournament that is not strongly connected .
class variables : identifier local variables : _ identifier
class variables : model_parameters local variables : _ params
class variables : agents local variables : _ agents
class variables : interactions local variables : _ interactions
"class variables : identifier , model_parameters , agents , interactions local variables : ret_str , entry , value , agent"
"class variables : local variables : _ params , model_config"
class variables : local variables : _ i d
compute the reciprocity in a directed graph .
"return an iterator of ( node , reciprocity ) ."
compute the reciprocity for the whole graph .
"tests that an approximate dominating set for the star graph , even when the center node does not have the smallest integer label , gives just the center node ."
write networkx graph g to graphviz dot format on path .
return a networkx multigraph or multidigraph from a dot file on path .
return a networkx graph from a pydot graph .
return a pydot graph from a networkx graph n.
create a pydot graph from a networkx graph .
create a networkx graph from a pydot graph .
create node positions using pydot and graphviz .
create node positions using pydot and graphviz .
eigenvector centrality : k5
eigenvector centrality : p3
eigenvector centrality : p3
class variables : config local variables : _ config
class variables : filename local variables : _ filename
class variables : file local variables : _ file
class variables : csv_writer local variables : _ csv_writer
class variables : environment local variables : _ environment
class variables : runner local variables : _ runner
tests that computing the longest path does not depend on nodes being orderable .
conversion to incidence matrix
conversion to adjacency matrix
return minimum weight dominating set .
return minimum weight dominating edge set .
class variables : parameters local variables : _ params
class variables : state_variables local variables : _ variables
"class variables : parameters , state_variables local variables : _ identifier , _ params , _ variables"
"class variables : identifier , parameters , state_variables local variables : ret_str , entry , value"
tests that the generated graph is ` k`-out - regular .
tests for forbidding self - loops .
tests that the generated graph is ` k`-out - regular .
tests for forbidding self - loops .
produce edges in a depth - first - search ( dfs ) .
return oriented tree constructed from a depth - first - search from source .
return dictionary of predecessors in depth - first - search from source .
return dictionary of successors in depth - first - search from source .
produce nodes in a depth - first - search post - ordering starting from source .
produce nodes in a depth - first - search pre - ordering starting from source .
produce edges in a depth - first - search ( dfs ) labeled by type .
returns a dominating set that approximates the minimum weight node dominating set .
return minimum cardinality edge dominating set .
tests that the cycle graph on five vertices is strongly regular .
tests that the petersen graph is strongly regular .
tests that the path graph is not strongly regular .
tests that an empty degree sequence yields the null graph .
tests that a degree sequence of all zeros yields the empty graph .
tests that the degree sequence of the generated graph matches the input degree sequence .
tests that each call with the same random seed generates the same graph .
tests that attempting to create a configuration model graph using a directed graph yields an exception .
tests that a degree sequence whose sum is odd yields an exception .
"returns ` ` true ` ` if and only if the nodes whose attributes are ` ` du ` ` and ` ` dv ` ` should be joined , according to the threshold condition for geographical threshold graphs ."
tests that pairs of vertices adjacent if and only if they are within the prescribed radius .
tests for providing an alternate distance metric to the generator .
tests using values other than sequential numbers as node ids .
tests that pairs of vertices adjacent if and only if their distances meet the given threshold .
tests for providing an alternate distance metric to the generator .
tests for providing an alternate distance metric to the generator .
relabel the nodes of the graph g.
return a copy of the graph g with the nodes relabeled using consecutive integers .
"combinatorial optimization : algorithms and complexity , papadimitriou steiglitz at page 140 has an example , 7.1 , but that admits multiple solutions , so i alter it a bit . from ticket # 430 by mfrasca ."
address issue raised in ticket # 617 by arv .
check if digons are handled properly . taken from ticket # 618 by arv .
raise an exception for multidigraph .
tests that the null graph has empty node boundaries .
check boundaries in the petersen graph
tests the node boundary of a directed graph .
tests the node boundary of a multigraph .
tests the edge boundary of a multdiigraph .
tests the edge boundary of a directed graph .
tests the edge boundary of a multigraph .
tests the edge boundary of a multdiigraph .
returns true if and only if ` nodes ` is a clique in ` g ` .
returns true if and only if ` nodes ` is an independent set in ` g ` .
tests that the maximal clique is computed according to maximum cardinality of the sets .
return incidence matrix of g.
return adjacency matrix of g.
"opens the given setup.cfg file , locates the version option in the [ metadata ] section , updates it to the new version ."
"releaser.middle hook to monkey - patch zest.releaser to support signed tagging -- currently this is the only way to do this . also monkey - patches to disable an annoyance where zest.releaser only creates .zip source distributions . this is supposedly a workaround for a bug in python 2.4 , but we do n't care about python 2.4 ."
"fix the irritating .dev0 default appended to new development versions by zest.releaser to just append "" .dev "" without the "" 0 "" ."
returns a list of all dictionaries of all items in a user 's content including their subfolders
"returns the number of hosted feature services and total size in mb of hosted feature services in a user 's content . requires a list of dictionaries as the input , this can be aquired from the allitems function ."
reports hidden oids
appends the records into a new dataset .
set up some items we can reuse .
verify backend.exists raises .
verify backend.is_active raises .
verify backend.turn_on raises .
verify backend.turn_off raises .
verify backend.toggle raises .
verify backend.is_off raises .
: param connection_str : information can be found at http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html example : sqlite:///test.db : type connection_str : str : rtpe : sqlalchemybackend
checks if a feature exists .
checks if a feature is on .
turns a feature on .
"compound actions can hammer this . 0.005 seconds per call * 100 actions = no longer insignificant . we thus cache it for a very short time as a crude hack , so that when executing a single action it is n't called too many times . until we get an optimizer into dragonfly , this will have to do ."
"returns whether the proxy is enabled , based on context and file settings ."
dynamically enables proxy .
dynamically disables proxy .
return concatenation of each element of the direct product .
get the aliases for string .
aliases should be an iterable of tuples where the first element is the primary string and the others are aliases for it .
add the iterable of aliases for string to this object .
remove string_or_alias if it is present .
return a dragonfly spec string for any string that can be obtained from string by making substitutions for individual words in string .
return a dragonfly spec string for any string that can be obtained from string by making substitutions .
find all substrings in text that are strings in this object . return an iterable of all such strings that the non - matching strings between them in the order they are encountered .
return a dragonfly spec string that allows aliases to be used instead of strings in spec .
return the strings that can be obtained from phrase by performing substitutions .
"try to init & configure the bot from configurations read from ` ` .responsebot ` ` file , from cli arguments or from direct call in code"
"try to init the main sub - components (: func:`~responsebot.utils.handler_utils.discover_handler_classes ` , : func:`~responsebot.utils.auth_utils.auth ` , : class:`~responsebot.responsebot_stream . responsebotstream ` , etc . )"
try to detect repetitive errors and sleep for a while to avoid being marked as spam
return a list of results for the page
return the page number for the next page or none if there is n't one .
return the page number
return the page number for the previous page or none if there is n't one .
return the offset for an item in the page
return the total number of items being paginated
return the number of orphan results that will be allowed in the last page of results .
return the total number of pages
return a list of page numbers
return the number of results per page ( with the exception of orphans ) .
reset the item index
"return a random integer 0 < = n < = len(weights ) - 1 , where the weights determine the probability of each possible integer ."
given a weighted set and sample size return the probabilty that the weight ` i ` will be present in the sample .
"return a set of random integers 0 < = n < = len(weights ) - 1 , where the weights determine the probability of each possible integer in the set ."
make a new port from nested data .
validate the port . the port must be non - empty and type must a possible type .
resolve dependencies in for type and hide
get a list of all possible port types . @throw notimplementederror
get all connections that use this port .
get all enabled connections that use this port .
rank : param main_rect : : param sub_rect : : param method : : return :
returns a loggertest integration object
default tester with no logger obj . useful for html contains and status code not useful for testing loggers
"in order to do test - level parametrization ( is this a word ? ) , we have to bundle the test data from rulesets into tuples so py.test can understand how to run tests across the whole suite of rulesets"
"dynamically names tests , useful for when we are running dozens to hundreds of tests"
destination address override for tests
destination port override for tests
destination protocol override for tests
return an http object listening on localhost port 80 for testing
return full path of the testing journal
set table name for journaling
adds command line options to py.test
"pre - test configurations , mostly used for parametrization"
prepare sql statement to be inserted into the ftw journal
create journal database for ftw runs
list of ruleset objects extracted from the yaml directory
take a directory and an extension and return the files that match the extension
take a list of yaml_files and load them to return back to the testing program
setup and install dependencies for the test .
build posixtest source : http://ufpr.dl.sourceforge.net/sourceforge/posixtest/posixtestsuite-1.5.2.tar.gz
build integrity test
execute integrity tests
build libunwind library source : https://github.com/pathscale/libunwind/archive/vanilla_pathscale.zip
execute regression tests for libunwind library
to check and install dependencies for the test
ping pong exec function
test options are mandatory ext test options are depends upon user
time the bulding of the kernel
converts a string in m+:ss.ss format to s+.ss
"extract user , system , and elapsed times into a list of tuples"
setting up the env for the kernel building
kernel build test
"install all the dependency packages required for building source tarball specific to os , if not tests will stop ."
runs the gcc ` make check `
set_poweron_time schedules the power on time
sys_ident provides unique system identification information
lsmcode provides fw version information
"drmgr can be used for pci , cpu or memory hotplug"
lsprop provides device tree information
lsslot lists the slots based on the option provided
lsvio lists the virtual i / o adopters and devices
nvram command retrieves and displays nvram data
ofpathname translates the device name between logical name and open firmware name
rtas_ibm_get_vpd gives vpd data
rtas_errd adds rtas events to /var / log / platform and rtas_dump dumps rtas events
run ' make ' of given command and write the summary to respective files
run valgrind test with different categories
to check and install dependencies for the test
removing the data in peer machine
lists all available avago adapters ( does not need ctlr # >
decides which functions to run for given raid_level
this function does only create and delete raid
lists all the lsi adapters attached to the mahcine : return :
deletes the existing raid in the lsi controller
lists all the lsi adapters attached to the mahcine : return :
"display controller , volume and physical device info"
this function creates raid array
this is a helper function to create hot - spare
"checks if bgi starts automatically , and if so waits till it is completed"
this function starts cc on a raid array
this function stores all the ir logs
this functions waits for the rebuild to complete on a raid
"this is a helper function , to change the state of the drives"
"this is a helper function , to check the status of the adapter"
this function deletes raid array
this function returns volume id of the ir volume
"this function waits , till the current operation is complete"
"install genwqe packages , and downloads test tarball ."
tests genwqe_echo on the device .
tests genwqe_mt_perf on the device .
tests genwqe_test_gz on the device .
tests genwqe_memcopy on the device .
tests genwqe_gzip and genwqe_gunzip on the device .
tests genwqe_poke on the device .
tests genwqe_peek on the device .
creates namespace on the device .
creates namespace on the device .
build interbench source : http://ck.kolivas.org/apps/interbench/interbench-0.31.tar.bz2
build dbench source : http://samba.org/ftp/tridge/dbench/dbench-3.04.tar.gz
test execution with necessary args
we should be able to upload
we can optionally provide a callback
we can get the results of our batch operations
we can get confirmation of a successful batch .
we can get confirmation of a failed batch .
cette fonction permet d'additionner deux tuples
"renvoie un generateur sur un iterable qui enleve tous les elements en double dans une liste , conservant l'ordre ."
remplit l'espace entre deux cases non consecutives : param path : - > liste de coordonnees du chemin : param obstacles : - > liste de coordonnees des obstacles : return : - > une liste linearisee
algorithme de bresenham prend en entree deux tuples de coordonnees et indique les cases traversees par une ligne passant de l'une à l'autre
"calcule le chemin entre une case de depart et une case d'arrivee , par une linearisation de l'algorithme a * : param start : - > coordonnees de la case de depart : param end : - > coordonnees de la case d'arrivee : param obstacles : - > obstacles sur la carte : return :"
permet case = = autre_case
permet case ! = autre_case
permet case > autre_case
permet case > = autre_case
permet case < autre_case
permet case < = autre_case
"initie la representation de la grille , avec prise en compte des obstacles"
: param cell : : return : - > distance manhattan entre la case visitee actuellement et la case d'arrivee
: param x : - > coordonnee x de la case à extraire : param y : - > coordonnee y de la case à extraire : return : - > la case à ces coordonnees
: param cell : - > cellule etudiee : return : - > liste de toutes les cases voisines à cette case
: return path : - > le chemin entre la premiere case et la derniere case
met a jour les valeurs de la case voisine : param neighbor : - > un voisin de cette case : param cell : - > la case en question
trouve un des plus courts chemins entre la case de depart et celle d'arrivee
lazy load on first access from configured file source
helper test for test_binaries
check that bin/ * can execute with --help
test rz - user - tool
used for random node generation
@param n_type : is converted to a label set
@param l_type : is converted to a single item type array
@return : a ~minimal topo_diff containing three nodes and two links
stringify the argument and convert it to a valid python identifier according to hy 's mangling rules .
"stringify the argument and try to convert it to a pretty unmangled form . this may not round - trip , because different hy symbol names can mangle to the same python identifier ."
reject the spurious dots from items
try to interpret ` obj ` as a number or keyword .
test the exception class .
test actor . actor class .
"return the value of key at path in vault , or entire secret"
set secret at the path in vault . the vault policy used must allow this .
delete secret at the path in vault . the vault policy used must allow this .
list secret keys at the path in vault . the vault policy used must allow this . the path should end with a trailing slash .
return the tanimoto similarity between v1 and v2 ( numpy arrays )
return the cosine similarity between v1 and v2 ( numpy arrays )
read the filename for each file in the evaluation directory
compute spearman rank coefficient for each evaluation file
compute statistics on results
return the cosine similarity between v1 and v2 ( numpy arrays )
read the file < filename > and generate the embedding matrix . only load embeddings of words in < list_words > . there is no reason to load the embedding of a word if we are not going to do computation with it .
generate weak and strong pairs of words based on definitions in defs_fn . a and b are a strong pair if : - a is in definition of b - b is in definition of a all others pairs of words ( ie a word and a word from its definition ) are considered as a weak pair .
assert that listing routes will return a json list .
"assert that creating a route , will result in the appropriate route ."
assert that creating a route with the ` enforce_https ` settings returns the expected results
"assert that deleting a route , will actually delete it ."
get a permission object from a permission name .
get a boolean map of the permissions available to a user based on that user 's roles .
grant a user a specified permission .
revoke a specified permission from a user .
"converts any urls in text into clickable links . works on http:// , https:// and www . links . links can have trailing punctuation ( periods , commas , close - parens ) and leading punctuation ( opening parens ) and it 'll still do the right thing ."
it totally prints a horse .
display results in table format
retrieve the decrypted value of a key in a giraffez configuration file .
set a decrypted value by key in a giraffez configuration file .
move the particles
euler - forward advection
runge - kutta second order = heun scheme
runge - kutta second order = heun scheme
runge - kutta fourth order advection
runge - kutta fourth order advection
random walk diffusion
test state initiation
append to the state
this global method is a front - end to the matplotlib library which receives a set of regression analyses and plots each one of them onto the canvas .
abstract initialization method for a solution to some optimization function : param solution : a numpy array ( much faster than lists )
overload of the len operator for the solution class : rtype : sized ?
this method is used for updating a solution
this method is used to retrieve the numpy array for direct manipulation
diffusion maps [ coifman05 ] _ [ haghverdi15 ] _ [ wolf17 ] _ .
"set resolution / size , styling and format of figures ."
determines whether run from ipython .
verifies xml output for a google test binary without actual tests .
checks whether the timestamp attribute in the xml output is valid .
confirms that google test produces an xml output file with the expected default name if no name is explicitly specified .
tests that no xml file is generated if the default xml listener is shut down before run_all_tests is invoked .
verifies xml output when a filter is applied .
"returns the xml output generated by running the program gtest_prog_name . furthermore , the program 's exit code must be expected_exit_code ."
"asserts that the xml document generated by running the program gtest_prog_name matches expected_xml , a string containing another xml document . furthermore , the program 's exit code must be expected_exit_code ."
get the * key*\ th event from all events that have an item available in the corresponding store 's item queue .
return ` ` true ` ` if the queue contains an event for which an item is available in the corresponding store 's item queue .
the maximum capacity of the store .
get retrieves session for given access token .
"context works like get but takes access token from metadata within context . it expects "" authorization "" key to be present within metadata ."
standard release build
standard debug build
static musl release build
wrapper for pdf_gen.generator.pdf_gen_file for call from pp
get the config from drivers_info.ini file . : param section : the file 's section . : param option : the option to get the value from . : return : the option 's value .
gets the entire section of drivers_info.ini file . : param section : the file 's section . : return : the entire section .
gets or creates the version_matcher file to put the chrome driver versions . : return : the full file 's path .
gets the latest version of the driver . : return : the latest version of the driver .
gets the supported version of the driver . : return : the supported version .
gets the installed version . : return : the installed version .
gets the latest ie driver version . : return : the latest ie driver version .
gets the latest chrome driver version . : return : the latest chrome driver version .
gets the right version to the installed version . : return : the right version to work with installed browser .
gets the latest gecko driver version . : return : the latest gecko driver version .
creates the file that matches the version with installed chrome .
parse the arguments from the command line for this program
build an abba url using data from a postgresql connection and query
parser for none [ 0 ] issue mode
"parser for custom [ 1 ] issue mode , please provide your custom parser as argument"
parser for once [ 2 ] issue mode
parser for multi [ 4 ] issue mode
parser for mono [ 8 ] issue mode
parser for unflushable [ 16 ] issue mode
": network = peercoin [ ppc ] , peercoin - testnet [ tppc ] ..."
take care of specifics of cryptoid naming system
query block using < blockhash > as key .
test that we can get data for code links .
test if shelve can be caches information retrieved after file is deleted
compute the pairwise distance matrix of x with itself .
"the mean correction , correcting distances using the mean between both manifold metrics to correct for pairwise distances in x."
simulate cell division times for n_divisions . the division times are drawn between 0 and maxtime .
"simulate splitting events in the latent space . the input time t is a one dimensional array having the times in it . the labels is a int array - like , which holds the labels for the wanted cell types . basically it is an array of repetitions of 1 to number of cell types , e.g. : array([1 .. 1,2 .. 2,3 .. 3,4 .. 4 ] ) for 4 cell types ."
simulate an rnaseq experiment .
"check if this credential has already been added to the database , if not add it in ."
check if this credential id is valid .
check if this credential id is valid .
return credentials from the database .
removes a credential id from the database
"inject if set to true , this allows powerview to work over ' stealthier ' execution methods which have non - interactive contexts ( e.g. wmi ) ( default : true )"
returns a json collection of all power types defined in beaker .
deletes a power type by the given i d.
creates a new power type . the request must be : mimetype:`application / json ` .
test that the update_repo ( ) call runs as expected .
allow unpickling to return the symbol linked to the declenum class .
returns an xml - rpc structure ( dict ) with information about the currently logged in user . provided for testing purposes .
"renew session , here to support the login method that was migrated from kobo ."
authenticates the current session using the given username and password .
authenticates the current session using oauth2 .
authenticates the current session using kerberos .
invalidates the current session .
check that the right action buttons appear in the right circumstances .
tests that we do n't get a traceback if the user invokes the wizard with a nonexistend command .
direct_column ( ) will return a datagrid column and is intended to be used to generate columns to be inserted into a grid without any other sideaffects ( unlike custom_systems_grid ( ) ) . they are also free of control from other elemnts such as the result_columns ( )
result_columns ( ) will return the list of columns that are able to bereturned in the system search results .
asserts that the given sequence is in sorted order .
"asserts that the given datetime is within tolerance of reference . by default , the reference point is now ."
"given an iterable of anything with start_time and finish_time attributes , asserts that there are no overlaps in the durations ."
creates a character diff comparing the two strings . can be used as a message for a test assertion .
handle the user parameters for pbcount.py .
pbcount command line .
test for get_dihedral ( )
test for api loader function on pdbs
test for api load function on xtc files
tests for read_from_pdb ( )
test when pdb line is too short
tests for read_from_pdbx ( )
test when pdbx line is not correctly formated
tests for read_from_xtc ( )
run before each test .
tests for size ( )
tests for get_phi_psi_angles ( )
tests for coordinates update
tests for single chain in one pdb
tests for multiple chains in one file .
tests for multiple models in one pdb
tests for multiple chains in one file .
test for parsing mulitple fastas
slice a matrix given the lower and upper bond in parameters . the matrix has to be a numpy array with one row per residue . the slice will occurs on the rows and the sub - matrix is returned .
compute a pb frequency matrix from an occurence matrix .
computes substitution score between two sequences position per position
compute the substitution score to go from ` ` seqa ` ` to ` ` seqb ` `
support configuration of scanner recursive property
the type of this scanner
the broker types supported by this scanner
loads the given configuration
runs the scanner until signaled to stop by the stop ( ) method or processing complete .
sets up the workspaces that will be used by this scanner
signals the scanner to stop running .
validates the given configuration .
method for handling files identified by list_files generator
check the ingest records to ensure these ingests are not already created by previous scan run
processes the ingest file by applying the scan configuration rules .
performs the ingest for the given ingest id
completes the given ingest in an atomic transaction
deletes the given ingest file
returns the ingest for the given id
returns an existing or new ( un - saved ) source file model for the given file name
saves the given source file model in the database
starts the given ingest and links it to the source file that is being ingested
creates an ingest trigger condition
returns the file media type for this ingest trigger condition
returns the message that should be logged when this condition is triggered
indicates whether the given ingested source file meets this ingest trigger condition
tests calling sourcedatafileparsesaver.save_parse_results ( ) successfully
see : meth:`django.core.management.base . basecommand.handle ` .
creates a node model for unit testing
returns the trigger rule handler that is registered with the given type
registers the given trigger rule handler with the given type
creates and returns a trigger rule configuration from the given dict
creates and returns a trigger rule model with the given configuration . the returned trigger rule model will be saved in the database .
creates a parse trigger from the given configuration
returns the condition for this parse trigger rule
returns the name of the input data that the parsed file should be passed to
returns the name of the workspace to use for the triggered job / recipe
see : meth:`trigger.configuration.trigger_rule . triggerruleconfiguration.validate `
see : meth:`job.triggers.configuration.trigger_rule . jobtriggerruleconfiguration.validate_trigger_for_job `
see : meth:`recipe.triggers.configuration.trigger_rule . recipetriggerruleconfiguration.validate_trigger_for_recipe `
populates any missing default values in the configuration
converts the model field to a list of data type tags
converts the model field to wkt
converts the model field to geojson
creates messages to update the given job ids to blocked
adds the given job id to this message
indicates whether more jobs can fit in this message
see : meth:`messaging.messages.message . commandmessage.to_json `
see : meth:`messaging.messages.message . commandmessage.from_json `
see : meth:`messaging.messages.message . commandmessage.execute `
tests calling recipegraph.get_topological_order ( ) successfully
adds the given rule to the handler
"checks the given file name and returns the first rule that matches it , returning none if no match is made"
validate initialization specific to amqp backend is completed
validate message is sent via the amqp backend
validate message is sent via the amqp backend
validate successful message retrieval via amqp backend
validate successful message retrieval via amqp backend of first 2 messages
validate message ack is not done with yield returns false in amqp backend
validate add message backend functionality
validate successful retrieval of message backend from factory
validate missing message backend behavior from factory
validate listing behavior of backends from factory
validate correct initialization of backend internal properties
validate initialization specific to sqs backend is completed
validate message is sent via the sqs backend
validate message is sent via the sqs backend
validate successful message retrieval via sqs backend
validate exception handling during message consumption from sqs backend
tests calling generate_status_json ( ) successfully
tests calling get_tasks_to_kill ( ) successfully
tests calling get_tasks_to_schedule ( ) successfully
tests calling handle_task_update ( ) successfully
gets the current master scheduler instance for the cluster .
initializes the scheduler table by creating a model if one does not already exist
checks whether the current master scheduler is ready to schedule .
update the data for the scheduler .
update mesos master information .
fetch summary hardware resource usage for the scheduler framework .
see : meth:`django.core.management.base . basecommand.handle ` .
returns the job execution for the id with its related job and job type models
see : meth:`job.execution.tasks.exe_task . jobexecutiontask.determine_error `
see : meth:`job.tasks.base_task . task.get_resources `
adds the given jobs to the recipe handler
returns the jobs within this recipe that should be updated to blocked status
returns the ids of the jobs that depend upon the job with the given id
returns all of the existing recipe jobs that are ready to be queued
"returns the models for each job in the recipe that is ready for its input . the new inputs have been set on each model , but not saved in the database ."
returns the models for each job in the recipe that is ready to be queued for the first time
returns a dict where recipe job_name maps to a list of job models that need to be created
returns the jobs within this recipe that should be updated to pending status
indicates whether this recipe has been completed
executes the given command list on the command line
"creates a new trigger event and returns the event model . the given rule model , if not none , must have already been saved in the database ( it must have an id ) . the returned trigger event model will be saved in the database ."
archives the trigger rule ( will no longer be active ) with the given id
creates a new trigger rule and returns the rule model . the returned trigger rule model will be saved in the database .
django method to retrieve a trigger rule for the given natural key . note : all trigger rule names are not unique . this is implemented to allow the loading of defined system trigger rules which do have unique names .
returns the configuration for this trigger rule
django method to define the natural key for a trigger rule as the name
tests doing a successful database update
tests coverting a reprocessrecipes message to and from json
tests calling reprocessrecipes.execute ( ) successfully
registers the product implementations with other applications .
returns the next integer
returns the command to execute for the task
returns the command to execute for the task
"returns the container name for the task , possibly none"
"returns the name of the docker image to run for this task , possibly none"
returns the docker parameters used to run this task
"when this task ended , possibly none"
"returns the exit code for this task , possibly none"
indicates whether this task has been launched
indicates whether this task has ended
indicates whether this task has started
indicates whether this task has timed out
returns the unique id of the task
indicates whether this task 's docker container should be run in privileged mode
"when this task launched , possibly none"
returns the name of the task
"when this task started , possibly none"
indicates whether this task uses docker or not
checks this task 's progress against the given current time and times out the task if it has exceeded a timeout threshold
sets a task setting to force kill messages for this task
sets a task setting to force immediate reconciliation for this task
returns the resources that are required / have been scheduled for this task
indicates whether this task needs to be killed
indicates whether this task needs to be reconciled due to its latest status update being stale
marks this task as having been launched
handles the given task update
creates the full image name to use for running the scale docker image
tries to parse the container name out of the task update . assumes caller already has the task lock .
tests creating a batchconfiguration from a json
tests calling batchconfiguration.validate ( )
returns the driver
sets the driver
see : meth:`scheduler.threads.base_thread . baseschedulerthread._execute `
see : meth:`trigger.handler . triggerrulehandler.create_configuration `
processes the given ingested source file by checking it against all ingest trigger rules and creating the corresponding jobs and recipes for any triggered rules . all database changes are made in an atomic transaction .
creates in the database and returns a trigger event model for the given ingested source file and trigger rule
creates messages to requeue the given jobs
adds the given job to this message
indicates whether more jobs can fit in this message
see : meth:`messaging.messages.message . commandmessage.to_json `
see : meth:`messaging.messages.message . commandmessage.from_json `
see : meth:`messaging.messages.message . commandmessage.execute `
creates an input file from a scale_file model
saves the given parse results
"retrieves the workspaces with the given ids . if no workspace has a given id , it will not be retrieved ."
stores the given data files and writes them to the given workspaces .
see : meth:`django.core.management.base . basecommand.handle ` .
resets the robot back to the initial position and drift . you 'll want to call this after you call ` run ` .
"creates robot and initializes location / orientation to 0 , 0 , 0 ."
sets a robot coordinate .
sets the noise parameters .
sets the systematical steering drift parameter
"steering = front wheel steering angle , limited by max_steering_angle distance = total distance driven , most be non - negative"
utility function to load bottleneck features .
"purpose : provide calibrated camera info . inputs : image array , object points array , and image points array . outputs : objectpoints - > ( x , y , z ) ciirdubates of chessboard corners in the world , and image points - > ( x , y ) pixel positions of each corner ."
signal handler to apply new permissions to repositories only in case the sender is learningresources .
give the creator of a repository admin permissions over that repository .
will run in parallel
the main function : takes an alignment and returns bubbles
outputs list of bubbles into file
checks if the kmer at given position is solid
checks if the kmer with center at the given position is simple
computes alignment profile
partitions genome into sub - alignments at solid regions / simple kmers
"given genome landmarks , forms bubble sequences"
invokes polishing binary
concatenates bubbles consensuses into genome
setup hotkeys for builds and removing marking menus on hotkey press and release .
remove all hotkeys for the given menu
build any marking menus that were registered for a menu name .
destroy any marking menus that are currently built .
register a markingmenu class by name
unregister a markingmenu that was previously registered by name .
return the menu class that is registered under the given name
return all registered menus
override to implement custom logic for whether or not this menu should be built
build the popup menu that all menu items will be attached to
remove and destroy this menu
build all menu items for the current popup menu . called each time the menu is about to be displayed .
build the popup menu that all menu items will be attached to
create build and run all jobs
stackdistiller converts all times to utc .
invokes the uv index endpoint
returns the data in this node
returns the next linkedlistnode in the list
: param linked_list_node : the new reference to the next linkedlistnode element : type linked_list_node : linkedlistnode
"compatibility for python 2.x , delegates to function : ` _ _ next _ _ ( ) ` returns the next * weather * item"
returns the next linkedlistnode item in the list
returns the number of elements in the list
creates a frontlinkedlistiterator instance
"adds a new data node to the front list . the provided data will be encapsulated into a new instance of linkedlistnode class and linked list pointers will be updated , as well as list 's size ."
"removes a data node from the list . if the list contains more than one node having the same data that shall be removed , then the node having the first occurrency of the data is removed ."
checks if the provided data is stored in at least one node of the list .
finds the position of a node in the list . the index of the first occurrence of the data is returned ( indexes start at 0 )
removes the last node from the list
returns the gmt time telling when the o3 data have been measured
returns the gmt time telling when the o3 observation has been received from the owm web api
returns the * location * object for this o3 observation
returns the time granularity interval for this o3 observation
returns the o3 dobson unit of this observation
tells if the current o3 observation refers to the future with respect to the current date : return : bool
dumps object fields into a json formatted string
dumps object fields to an xml - formatted string . the ' xml_declaration ' switch enables printing of a leading standard xml line containing xml version and encoding . the ' xmlns ' switch enables printing of qualified xmlns prefixes .
dumps object data to a fully traversable dom representation of the object .
returns the gmt time telling when the observation has been received from the owm web api
returns the * location * object for this observation
returns the * weather * object for this observation
dumps object fields into a json formatted string
dumps object fields to an xml - formatted string . the ' xml_declaration ' switch enables printing of a leading standard xml line containing xml version and encoding . the ' xmlns ' switch enables printing of qualified xmlns prefixes .
dumps object data to a fully traversable dom representation of the object .
checks if the weather status code of a * weather * object corresponds to the detailed status indicated . the lookup is performed against the provided * weathercoderegistry * object .
checks if the weather status code of any of the * weather * objects in the provided list corresponds to the detailed status indicated . the lookup is performed against the provided * weathercoderegistry * object .
filters out from the provided list of * weather * objects a sublist of items having a status corresponding to the provided one . the lookup is performed against the provided * weathercoderegistry * object .
checks if the supplied unix time is contained into the time range ( coverage ) defined by the most ancient and most recent * weather * objects in the supplied list
extracts from the provided list of weather objects the item which is closest in time to the provided unixtime .
"parses an * observation * instance out of raw json data . only certain properties of the data are used : if these properties are not found or can not be parsed , an error is issued ."
returns the gmt time telling when the co samples have been measured
returns the gmt time telling when the co observation has been received from the owm web api
returns the * location * object for this co index measurement
returns the time granularity interval for this co index measurement
returns the co samples for this index
returns the co sample with the highest volume mixing ratio value : return : dict
returns the co sample with the lowest volume mixing ratio value : return : dict
tells if the current co observation refers to the future with respect to the current date : return : bool
dumps object fields into a json formatted string
dumps object fields to an xml - formatted string . the ' xml_declaration ' switch enables printing of a leading standard xml line containing xml version and encoding . the ' xmlns ' switch enables printing of qualified xmlns prefixes .
dumps object data to a fully traversable dom representation of the object .
returns the utc time of creation of this aggregated measurement
dumps object fields into a dict
dumps object fields into a json formatted string
returns the utc time of creation of this raw measurement
dumps object fields into a dictionary
returns the gmt time telling when the uv has been observed from the owm web api
returns the gmt time telling when the uv has been received from the api
returns the * location * object for this uv observation
returns the uv intensity for this observation
returns a string stating the risk of harm from unprotected sun exposure for the average adult on this uv observation : return : str
dumps object fields into a json formatted string
dumps object fields to an xml - formatted string . the ' xml_declaration ' switch enables printing of a leading standard xml line containing xml version and encoding . the ' xmlns ' switch enables printing of qualified xmlns prefixes .
dumps object data to a fully traversable dom representation of the object .
initialize the tms global mercator pyramid
converts given lat / lon in wgs84 datum to xy in spherical mercator epsg:900913
converts xy point from spherical mercator epsg:900913 to lat / lon in wgs84 datum
converts pixel coordinates in given zoom level of pyramid to epsg:900913
converts epsg:900913 to pyramid pixel coordinates in given zoom level
returns a tile covering region in given pixel coordinates
move the origin of pixel coordinates to top - left corner
returns tile for given mercator coordinates
returns bounds of the given tile in epsg:900913 coordinates
returns bounds of the given tile in latutude / longitude using wgs84 datum
resolution ( meters / pixel ) for given zoom level ( measured at equator )
maximal scaledown zoom of the pyramid closest to the pixelsize .
converts tms tile coordinates to google tile coordinates
converts tms tile coordinates to microsoft quadtree
converts lat / lon to pixel coordinates in given zoom of the epsg:4326 pyramid
returns coordinates of the tile covering region in pixel coordinates
resolution ( arc / pixel ) for given zoom level ( measured at equator )
returns bounds of the given tile
"returns the argument mapped in to ( -pi , pi ]"
"iterate through a list returning [ i],[(i+1)%n ] circular pairs , including the ( last , first ) pair"
records a new outgoing being sent
this is where we keep track of dailycounts for users within organisations
should return the data that should be used to create the display for the pod .
should perform the action specified by the type and params ( which are specified in the read function ) .
the load_pod function should load the pod with the correct app label specified by ' type ' .
the load_pod function should set the index on the pod config .
"the load_pod function should set the config title , or default it title field to the pod type title if it is n't given ."
the load_pod function instantiate and pass through the pod 's config .
"on import , the pods specified in the settings file should be loaded with correct index numbers and types ."
"on import , the pod types specified in the settings file should be registered ."
does actual export . called from a celery task .
child classes implement this to populate the excel book
return our custom comment model
use existing django comments form since we do n't need to touch it
"convert a str , a packet to bytes"
rectified linear activation function .
"predictions is a real number , whose sigmoid is the probability that the target is 1 ."
"just a plain old neural net , nothing to do with molecules . layer sizes includes the input size ."
"composes a fingerprint function with signature ( smiles , weights , params ) with a fully - connected neural network ."
no llamamos a super porque tendriamos que igualmente hacer un read para obtener la compania y no queremos disminuir la performance
no llamamos a super porque tendriamos que igualmente hacer un read para obtener la compania y no queremos disminuir la performance
no llamamos a super porque tendriamos que igualmente hacer un read para obtener la compania y no queremos disminuir la performance
no llamamos a super porque tendriamos que igualmente hacer un read para obtener la compania y no queremos disminuir la performance
get statement lines of the specified statements or all unreconciled statement lines and try to automatically reconcile them / find them a partner . return ids of statement lines left to reconcile and other data for the reconciliation widget .
create or return an existing trajectory group
return a list of new / existing datasets corresponding to the given fields
find the first row to write new trajectory data .
"write a result at a given row in a trajectory . if needed , the dataset is extended ."
check if the datasets with the new trajectory data have consistent sizes .
create a parameters instance from one or more text files .
return an independent copy
write the parameters back to a file
return an independent copy
analyze the signal with the block average method .
analyze the signal to determine the statistical inefficiency . the statistical inefficiency of a signal is defined as the limiting ratio of the observed variance of its long - term averages to their expected variance . it can hence be regarded as the factor ( > 1 ) with which the sample size should be multiplied in order to compensate for correlation . this is derived in :
initialize a comlist
evaluate the relative vectors for ` ` self.system.pos ` `
derive gpos and virial from the derivatives towards the relative vectors
return all session configurations from the ` rc_file ` file .
return the session configuration identified by ` name ` from the ` rc_file ` file .
save the ` data ` session configuration under the name ` name ` in the ` rc_file ` file .
remove the session configuration identified by ` name ` from the ` rc_file ` file .
"verifies that the parameters specified are actual parameters for the function ` func ` , and that the field types are field _ * types in fields ."
decorator to make a function into a rule action
construct a callinginfo value from a target container name .
return an azure blobservice instance .
get and decompress a url
return blobstore instance for a given storage layout args : layout ( storagelayout ): target storage layout .
helps skip integration tests without live credentials .
imports ` pkg ` into self.col .
generates a deck with several notes and verifies that the nid / ord combinations on the generated cards make sense .
tests for a bug in an early version of genanki where notes with < 4 fields were not supported .
return the statsresult object for this statistic
return the statsresult object for this statistic
return the statsresult object for this statistic
return the statsresult object for this statistic
return the statsresult object for this statistic
traverse the convolution ! !
"add either a "" flat_val "" or of "" vocab_list "" to the object"
"given a list of datasetfield ids : - retrieve any controlled vocabulary - return a dict of { dataset i d : [ datasetvalue , datasetvalue , etc ] }"
return as a json string
return as an ordereddict
reference table of all file extensions with counts
reference table of file extensions with unknown content type
here we ensure the user is in the thread .
we always required a logged in user .
"this test ensures the middleware creates the participant corresponding to request.user , if not done yet ."
"this test ensures the middleware creates the participant corresponding to request.user , if not done yet ."
test vowel count in a given string
test consonant count in a given string
"return a linearsegmentedcolormap : http://stackoverflow.com/a/16836182 args : seq : a sequence of floats and rgb - tuples . the floats should be increasing and in the interval ( 0,1 ) ."
initialize logging .
apply function of enchantments ' + value attack ' .
apply function of enchantments ' + value health ' .
apply function of enchantments ' set health to value ' .
apply function of enchantments ' + a / + h ' .
set the target attribute ` ` key ` ` to ` ` value ` ` .
modify the target aura temporary value of ` ` key ` ` with ` ` op ` ` .
push death events into death event cache .
": param auth_client : client to make authorized requests ( currently only apikeyauthclient is supported ) : param archive : archive can be a pointer to a remote location , a path to a local file or a stringio object : type auth_client : : class:`carto.auth . apikeyauthclient ` : type archive : str"
actually creates the import job on the carto server
get a filtered list of file imports
creates a file import on the server
returns a user manager that can be reused in tests : param api_key_auth_client : fixture that provides a valid apikeyauthclient object : return : usermanager instance
"currently not supported by the user api . if we actually tried to perform this test , an exception would be raised : param user_manager : user manager to work with"
"test retrieval of a single user from the api : param user : there is a fixture that returns a user object , so let 's use it instead of specifically requesting a user"
test modifying a user : param user_manager : user manager to work with : param user : user to be modified
test creating a user and then deleting it : param user_manager : user manager to work with
"used to copy api requests to make sure test data does n't depend upon a connection to the one codex server ( basically like ` betamax ` , but for our requests / responses setup ) ."
"check that the metadata patch method is n't passing ` sample ` which will 400 . note this actually erases the sample attribute , which is kind of unfortunate , but a pain to patch without ( we 'd need to load the mocked metadata obj here and re - inject the sample )"
instantiated api client
sets the learning rate to the initial lr decayed by 10
load .md ( markdown ) file and sanitize it for pypi . remove unsupported github tags : - code - block directive - travis ci build badges
output standard pre > code block with language class by default
output pygments rendered div.highlight > code block
pass frontmark_pygments options to pygments
pygments should not fail on unkown language
vocabulary constructor . args : given_vocab : list of given tokens .
"> > > test(r""+\ ⍬ "" ) ⍬"
"> > > test(r""-\ ⍬ "" ) ⍬"
"> > > test(r""×\ ⍬ "" ) ⍬"
"> > > test(r""÷\ ⍬ "" ) ⍬"
"> > > test(r""⌈\ ⍬ "" ) ⍬"
"> > > test(r""⌊\ ⍬ "" ) ⍬"
"> > > test(r""|\ ⍬ "" ) ⍬"
"> > > test(r""*\ ⍬ "" ) ⍬"
"> > > test(r"" ⍟ \ ⍬ "" ) ⍬"
"> > > test(r""!\ ⍬ "" ) ⍬"
"> > > test(r""?\ ⍬ "" ) ⍬"
"> > > test(r"" ○ \ ⍬ "" ) ⍬"
"> > > test(r""∨\ ⍬ "" ) ⍬"
"> > > test(r""∧\ ⍬ "" ) ⍬"
"> > > test(r"" ⍱ \ ⍬ "" ) ⍬"
"> > > test(r"" ⍲ \ ⍬ "" ) ⍬"
"> > > test(r""<\ ⍬ "" ) ⍬"
"> > > test(r""≤\ ⍬ "" ) ⍬"
"> > > test(r""≥\ ⍬ "" ) ⍬"
"> > > test(r"">\ ⍬ "" ) ⍬"
"> > > test(r""=\ ⍬ "" ) ⍬"
"> > > test(r""≠\ ⍬ "" ) ⍬"
"> > > test(r""≡\ ⍬ "" ) ⍬"
"> > > test(r""≢\ ⍬ "" ) ⍬"
"> > > test(r"" ⍴ \ ⍬ "" ) ⍬"
"> > > test(r"",\ ⍬ "" ) ⍬"
"> > > test(r""∊\ ⍬ "" ) ⍬"
"> > > test(r"" ⍷ \ ⍬ "" ) ⍬"
"> > > test(r"" ⍉ \ ⍬ "" ) ⍬"
"> > > test(r"" ⌽ \ ⍬ "" ) ⍬"
"> > > test(r""⊂\ ⍬ "" ) ⍬"
"> > > test(r""⊃\ ⍬ "" ) ⍬"
> > > io = saveindexorigin ( ) > > > setindexorigin(1 )
"> > > test(r""~\ ⍬ "" ) ⍬"
"> > > test(r""∪\ ⍬ "" ) ⍬"
"> > > test(r""∩\ ⍬ "" ) ⍬"
"> > > test(r""↓\ ⍬ "" ) ⍬"
"> > > test(r""↑\ ⍬ "" ) ⍬"
"> > > test(r""/\ ⍬ "" ) ⍬"
"> > > test(r""\ \ ⍬ "" ) ⍬"
"> > > test(r""⊤\ ⍬ "" ) ⍬"
"> > > test(r""⊥\ ⍬ "" ) ⍬"
> > > io = saveindexorigin ( ) > > > setindexorigin(1 )
> > > io = saveindexorigin ( ) > > > setindexorigin(1 )
true if a = b to within the current comparison tolerance
"b but , if b is within comparison toleranace of an integer , the integer"
the boolean - domain value of b ( if within comparison tolerance - else throw domain error )
the integer - domain value of b ( if within comparison tolerance - else throw domain error )
the real - domain value of b
the current index origin ( 0 or 1 )
set the index origin ( from command line flags )
true is evaluation mode is set to eager
set the eager / lazy evaluation mode ( from command line flags )
set or get the value of a system variable ( from the shell )
return the apl quantity
validate and set the apl quantity
"apl shell implemented in python 3 , copyright 2017 newforester"
"version 0.1.++ , developed on python 3.2.3"
"scalar calculator complete , vector calculator in progress"
invocation without any flags or arguments will enter an interactive apl shell . use an apl command such as ) off to exit .
logging and scripting ---------------------
"read lines from a tty or a file , evaluate them and print the results"
separate command line args into ( optional ) flags and an ( optional ) apl expression
deal with command line flags ( if any )
deal with command line args ( if any )
the main routine
return the python function that handles an apl operator given the operator 's symbol
"ignore errors in rmtree , but log them ."
return a list of unique keypairs to be copied into the docker certificates directory .
check if the python - rhsm delivered ca pem exists .
returns the base filenames of each file in the destination directory .
number of updates .
"this method check if notifier should be terminated or not : param notifier : notifier object : return : true , when notifier should be terminated ."
thread worker using inotify for checking changes in directory with consumer certificates : param server : reference to instance of server : return none
this method is executed every time new file is created in directory with certificates of consumer : param event : inotify event : return : none
this method is executed every time any file is deleted in directory with certificates of consumer : param event : inotify event : return : none
"returns reasons for sub_id , or empty list if there are none ."
returns a dictionary that maps valid entitlements to lists of reasons .
returns a list of reason messages that apply to the installed product
returns a list of subscriptions that provide the product .
method run in the worker thread .
glib idle method to watch for thread completion . runs the provided callback method in the main thread .
run pool stash refresh asynchronously .
"selection is only passed to maintain the gui error message . this can be removed , because it does n't really give us any more information"
processes the override mapping and sends the overrides to the server for addition / removal .
return an http connect request to send to the proxy .
copied verbatim except for adding the timeout
remove the scheme component from a uri .
check a url for an invalid or unuseful schema .
"parse hostname , port , and webapp prefix from the string a user entered ."
attempt to get a meaningful command name from argv .
` post_register_consumer ` hook
` pre_register_consumer ` hook
an iterator that yields the actual configsection objects instead of just the names of the sections .
"initialize the entry - this way the map does not have to specify all keys , and a ' none ' value is inserted by default into positions that are omitted"
"create a new list store from the given type_map , which is a dictionary in the format type_map[identifier ] = type - where ' identifier ' is a string that identifies the item and ' type ' is a gobject type or some built - in python type that is suitable for conversion to a gobject type ."
"add an entry to the store , where item_map is a dictionary in the format item_map[identifier ] = value - where ' identifier ' is a string that was used as a key in the constructor , and ' value ' is the value of that item ."
turn a list of package objects into an rpmprofile object .
how many facts were updated .
returns a list of tuples .
returns the filtered queryset based on the value provided in the query string and retrievable via ` self.value ( ) ` .
"useful to compare two timespans from different subtopics : return : true if they match , false if they do n't"
source metadata is encoded in various tag sets - this returns the set and the list of available tags you can use
"evaluates log of variational approximation , vectorized ."
"evaluates the gradient of the log of variational approximation , vectorized ."
form score function estimator based on samples lmbda .
read points from a l{sensor_msgs . pointcloud2 } message .
create a l{sensor_msgs.msg . pointcloud2 } message .
"create a l{sensor_msgs.msg . pointcloud2 } message with 3 float32 fields ( x , y , z ) ."
: param dict native_data : module native data to parse
parse the list of native modules into a list of module objects
parse the resource dependencies and adds its relations
parse gromacs per residue decomposition file into a pandas dataframe and calculate trajectory average energy values
etox allies per - residue energy decomposition ad analysis
etox allies deltag vdw / elec energy applicability domain analysis
etox allies deltag range applicability domain test
teardown method called after each unittest to cleanup the working directory
create empty workflow from default workflow json schema included in the module . empty workflow has one task ( node ) of type start that is root
load a predefined and valid workflow specification from json file .
load a predefined invalid workflow specification from json file . this workflow is build as undirected graph that should be directed . the root node is not of type ' start ' .
save a constructed workflow specification to file and load it again
query for global and local metadata on a finished workflow
construct a simple linear workflow specification of 6 nodes
construct a branched workflow specification that behaves as a map - reduce style workflow .
test graph orm functionality
run numpy fft on the dataset . replace all frequencies higher than fftfreq by 0
"fit splines to data as an option , print knots and coefficients"
replace all values below cutoff by zeroes
remove data points at beginning and end of list to remove artefacts
determines the range of stable minima in the data set
run the fft filtering and spline fitting workflow . by default on all columns for which the column name starts with vdw and coul or the column headers defined in the column argument list .
plot the results of the fft filtering and spline fitting for all bound coulomb and van der waals pairs in the dataframe .
serialize a non - keyword based iterable object
serialize a keyword based iterable object
iteratively serialize a nested object in which each python primitive type group is processed separately .
base method for encoding ( serializing ) a log dictionary
configwrapper decorated function that has keyword arguments defined in the global configuration .
configwrapper decorated function that does not have it 's keyword arguments defined in the global configuration . keyword arguments will not be overladed .
configwrapper decorated function that has keyword arguments defined in the global configuration .
configwrapper decorated function that has keyword arguments defined in the global configuration .
emulate a change to the global configuration from elsewhere in the python runtime .
run lie_graph module unit tests
perform multivariate gaussian distribution outlier detection .
converts a hierarchical cluster linkage to a matrix representing the cluster tree
creates test and train sets for cross - validation
retrieve the docking results as tar zipped archive
retrieve the status of a submitted haddock project
submit a docking project to the haddock web server
command line interface to the liestudio application
import a few structures
test generation of all descriptors
plantsdockingtest class setup
test tanimoto fingerprint comparison
test pairwise similarity matrix creation
test non - pairwise similarity matrix creation
aggregates over all voxels within each roi in the input image .
"imposes a 3d grid on the brain volume and averages across all voxels that fall within each cell . args : dataset : data to apply grid to . either a dataset instance , or a numpy array with voxels in rows and features in columns . masker : optional masker instance used to map between the created grid and the dataset . this is only needed if dataset is a numpy array ; if dataset is a dataset instance , the masker in the dataset will be used . scale : int ; scaling factor ( in mm ) to pass onto create_grid ( ) . threshold : optional float to pass to reduce.average_within_regions ( ) . returns : a tuple of length 2 , where the first element is a numpy array of dimensions n_cubes x n_studies , and the second element is a numpy array , with the same dimensions as the masker instance in the current dataset , that maps voxel identities onto cell ids in the grid ."
returns mappable data for a random subset of voxels .
return top forty words from each topic in trained topic model .
perform topic modeling using latent dirichlet allocation with the java toolbox mallet .
trigger spike to given neuron at specified times .
construct b64 encoded header for http basic auth
construct header to send access or refresh token to server
write refresh token to file . filenotfound exception will be thrown if file does n't exist and should be caught any time this function is called .
read refresh token from file
send login request and return wholenotecredentials object on success . raise exception on failure .
use refresh token to get useable access token .
"share clim across multiple axes parameters ---------- axes : plt.axes clim : np.array | list , shape(2 , ) , optional defaults is min and max across axes.clim ."
"parameters ---------- x : list | np.array ( ) y : list | np.array ( ) robust : bool if false use mean + std , if true median + mad ax alpha color line_args err_args"
parameters ---------- x : list | np.array ( ) y : list | np.array ( ) yerr : list | np.array ( ) | float ax alpha color line_args err_args
fill betwwen x even if x is discontinuous clusters parameters ---------- ax : axis x : list
adapted from http://stackoverflow.com/questions/12848581/ is - there - a - way - to - rotate - a - matplotlib - plot - by-45 - degrees
"does nothing , for sklearn compatibility purposes"
generate windows from x.
generate windows from x.
wip : only works for chance at .5
"creates a user profile to which you can attach saved payments . requires an internal_id to uniquely identify this user . if a list of saved payments is provided , as generated by create_saved_payment , these will be automatically added to the user profile . returns the user profile i d."
"creates a payment profile . if profile_id is provided , this payment profile will be created in authorize.net attached to that profile . if it is not provided , the payment profile will be returned and can be provided in a list to the create_profile call ."
gets the charset encoding used in the given urlopen response .
the main entrypoint of our murals search engine .
get the environment setting variable or return explicit exception .
yields an instance of the flask application .
removes the files in upload folders that could have been created during tests execution .
list of murals .
generate the auth header needed to contact with the kubernetes api server .
"method in charge of monitoring the job queue of mesos plus marathon the mesos info about jobs has to be obtained from frameworks and not from tasks , because if there are not available resources to execute new tasks , mesos do not create them but frameworks are created"
copy another ` ` stereocalibration ` ` object 's values .
export / import matrices as * .npy files to / from an output folder .
initialize camera calibration .
load values from ` ` * .npy ` ` files in ` ` input_folder ` ` .
export matrices as ` ` * .npy ` ` files to an output folder .
"rectify frames passed as ( left , right ) pair of opencv mats ."
find subpixel chessboard corners in image .
show chessboard corners found in image .
store variables relevant to the camera calibration .
record chessboard corners found in an image pair .
calibrate cameras based on found chessboard corners .
check calibration quality by computing average reprojection error .
web mercator bounds .
tile generation from gespatial coordinates and zoom .
parent of a tile .
children of a level 0 tile .
children of a level > 0 tile .
quadkey generation from tile coordinates .
upper left coordinates of input tile .
bottom right coordinates of input tile .
bounding boxes of tiles .
tile to quadkey .
quadkey to tile exceptions .
quadkey to tile .
emit an action_plan.create notification .
emit an action_plan.update notification .
emit an action_plan.delete notification .
emit an action_plan action notification .
emit an action_plan cancel notification .
return whether collection has more items .
return a link to the next subset of the collection .
description of the action
emit an audit.create notification .
emit an audit.update notification .
emit an audit action notification .
"leave only nodes , pools and volumes proposed in the audit scope"
default strategy selector
selects a strategy
initialize the wrapper .
flag determining if libpci resources have been released .
release libpci resources .
enter a context manager .
exit a context manager .
release wrapper resources .
generate numeric names .
do n't generate numeric names .
use both names and numbers .
allow network access during lookup .
skip local database when performing lookups .
cache names retrieved from the network .
refresh cache during the next lookup .
lookup the name of a given vendor .
lookup the name of a given device .
lookup the name of a given subsystem device .
"calls appropriate conversion function , depending on direction ."
"returns the original file name , but with a different extension"
"takes a fasta and qual file , generates fastq file(s )"
"takes a fastqfile , generates fasta and qual file(s )"
add 3 columns in the mapping file representing the alpha diversity data
accommodate a value into the ' levels ' list ; return a string or an integer
mean collated alpha diversity data at a given depth
creates a histogram given the bins and the vals : parameters : bins : list bins to use vals : list values to bin
creates semivariogram values from two distance matrices . : parameters : x_file : array matrix distance matrix for x distance matrix y_file : file handle distance matrix file handle model : string model to fit ranges : list the list of ranges to bin the data
run denoiser on input flowgrams
libs_from_seqids should identify correct libs
seqids_from_otu_to_seqid should return right seqids
make_otu_table should work without tax ( new - style otu table )
make_otu_table should work with taxonomy
generate a lookup dictionary from an otu map
remove tmp files
extract_read_to_sample_mapping pulls info from label line
combine_mappings works as expected
"decodes a nucleotide string of 12 bases , using bitwise error checking"
"takes any 12 bits , returns the golay 24bit codeword in nucleotide format"
decode a recieved 24 bit vector to a corrected 24 bit vector
"return list of all bitvectors with < = 3 bits as 1 's , rest 0 's"
"e.g. : "" aag "" - > array([0,0,0,0,1,0 ] ) output is array of ints , 1 's and 0 's"
"e.g. : array([0,0,0,0,1,0 ] ) - > "" aag """
parses mapping file to get dictionary of sampleid : rev primer mapping_fp : mapping filepath
returns output fasta filepath and log filepath
"locally aligns reverse primers , trucates or removes seqs"
writes log file
"main program function for finding , removing reverse primer seqs"
returns the data source name for elephantsql .
please leave this method unchanged
do something like show a window
"fix server defaults for datetime columns , because 0 ( "" 0000 - 00 - 00 00:00:00 "" ) is deprecated as default for those colum types as of mysql 5.7.8 , and will fail with mysql installed with default config ."
"fixture for getting a user object . if we already created one , we can just get it rather than making another ."
fixture for getting a reference object .
fixture for getting an experiment object .
fixture for getting an ionchannel object .
fixture for getting a patchclamp object .
fixture for getting a graph object
fixture for getting a graphdata object . the data here should be representative of what we can expect from the digitization process .
test that we can make a reference object manually .
test that we can map a reference object to a pyopenworm experiment object .
test that we can create a patchclamp object manually .
test that we can map a patchclamp object to a pyopenworm patchclamp object .
can we create an ionchannel manually ?
test that we can map a ionchannel object to a pyopenworm channel object .
test that we can map some graphdata to a pyopenworm data object .
the algorithm use tables with precalculated values
callback for a signal sent when user model involkes it 's save ( ) method . this will automatically create an associated profile ( ) instance .
callback for a signal sent when a user model involkes it 's save ( ) method . this will automatically save the associated profile ( ) instance .
"not currently in use , will have the view handle this ."
not currently in use . will have the view handle this
function to set ' approved ' flag . only approved threads will be shown . admin users will have to approve a thread request .
return list of random colors for number of classes given .
draw bounding boxes on image .
"select shiptype , count(name ) from ( select distinct invtypes . ""typename "" as "" shiptype "" , characters.eve_name as name from fittings join invtypes on fittings.ship_type = invtypes . ""typeid "" join comp_history_fits on fittings.id = comp_history_fits . ""fitid "" join comp_history on comp_history_fits . ""historyid "" = comp_history . ""historyid "" join characters on comp_history . ""targetid "" = characters.id where ( comp_history.action = ' comp_mv_xup_etr ' or comp_history.action = ' comp_mv_xup_fit ' ) and datediff(now(),comp_history.time ) < 30 ) as temp group by "" shiptype "" order by count(name ) desc limit 15 ;"
"select name , count(fitid ) from ( select distinct accounts.username as name , comp_history_fits.id as fitid from fittings join invtypes on fittings.ship_type = invtypes . ""typeid "" join comp_history_fits on fittings.id = comp_history_fits . ""fitid "" join comp_history on comp_history_fits . ""historyid "" = comp_history . ""historyid "" join accounts on comp_history . ""sourceid "" = accounts.id join characters on comp_history . ""targetid "" = characters.id where ( comp_history.action = ' comp_mv_xup_etr ' or comp_history.action = ' comp_mv_xup_fit ' ) and datediff(now(),comp_history.time ) < since ) as temp group by name order by count(fitid ) desc limit 15 ;"
distane two planar points
"return abs distance and type 0 = start , 1 = end , -1 = inside of line"
"returns a dict of myfleets , availfleets , and fleetcount ."
includes sitetracker scripts .
displays the sitetracker status bar .
displays the status text .
displays the details for a fleet member in the boss panel .
list of fleets which user is a member .
details of a sitetracker fleet .
list of sites for a user in a fleet .
list of available fleets .
details of a sitetracker fleet when we are the boss .
this view instnatiates the proper search class and returns the result_json as an httpresponse .
accepts a list of corp poses and returns a list of poses with status information attached .
returns a list of groups for a given registration code .
registers a user for all groups associated with a registration code .
send an alert through all methods for sub_group .
compute the pearson score between 2 lists of vectors
generate a dataset with the queryset and specified fields
generate whole dataset
generate key for this list of vectors
flush the dataset
filtering manytomany field
update the context with plugin 's data
icon source of the plugin
update the context with plugin 's data
update the context with plugin 's data
custom spam checker backend for testing gstudio
returns the uri of the node .
returns the model the i d belongs to .
returns a reference to the model object
bit.ly url shortener backend for objectapp
set a trackback for an gbobject
generate a description text for the pingback
"pingback.ping(sourceuri , targeturi ) = > ' pingback message '"
"pingback.extensions.getpingbacks(url ) = > ' [ url , url , ... ] '"
filtering manytomany field
update the context with plugin 's data
icon source of the plugin
update the context with plugin 's data
update the context with plugin 's data
init the command and add custom styles
convenient method for outputing
suite of testcases for django
return the published tags
return only the nodetypes published
return only the nodetypes published
return published authors
return published nodes
return nodes published on current site
top level search method on nodes
advanced search on nodes
basic search on nodes
return published nodetypes
return nodetypes published on current site
top level search method on nodetypes
advanced search on nodetypes
basic search on nodetypes
tests detection of peaks in randomized data .
tests that peaks are separated by minimum peak distance .
tests detection of peaks in randomized sin wave with min peak distance .
tests detection of valleys instead of peaks .
checks that edges are detected for flat peaks .
tests that peaks are separated by threshold value .
creates and returns an instance of the model given its class name . the created model has a single placeholder node for feeding images .
compute the top_k classification accuracy for the given network and images .
function called by the related button of the wizard
check mfcc can run with reasonable parameters
check dest cvec is still reachable after source was deleted
test creating fvec with negative length fails ( pure python )
test creating fvec with zero length fails ( pure python )
test assiging fvec out of bounds fails ( pure python )
"return an object by name , if name is none the first found object is returned"
simple command - line program demonstrating how to update esxi advanced settings
"given the service instance si and tasks , it returns after all the tasks are complete"
adds additional args to allow the vm name or uuid to be set .
create contrainer view and search for object in it
this sample uses different arguments than the standard sample . we also need the vihost to work with .
simple command - line program demonstrating vsphere perfmanager api
adds additional args to allow the vm uuid to be set .
"given image and iteration_step , saves ' image ' concatenated with ' iteration_step ' . this function is only for debug purposes ."
find a list of new transactions .
load the previously saved account .
update our class with new values .
save the account in a file .
create a dict with sum of transactions and days .
preprocess a file using cpp .
parse a c file using pycparser .
"an api definition consists of the following : ( rettype , retname , callconv , funcname , ( ( argtype , argname ) , ... ) )"
return ( optionally construct ) a menu to use for handling a context click at the given virtual address or envi expression .
shows or flips the status of the eflags register bits .
make it happen .
hook up with the github api
make it happen .
hook up with the github api and prepare to create issues .
make it happen .
create a github issue for the provided model and field .
"only works if run in this repo , and if cloned from origin . for safety , only run on travis"
create an embedded document instance from mongodb data
update the embedded document with the given data .
dump the embedded document .
generate a random ascii token of length n
generate screen token data for storing
"check whether the given screen token is valid , raises exception if not"
generate a new screen token and store it in redis
validate the given token and bind it to the ip
"sse ( server side events ) , for an eventsource"
initialize mcp9808 device on the specified i2c address and bus number . address defaults to 0x18 and bus number defaults to the appropriate bus for the hardware .
"start taking temperature measurements . returns true if the device is intialized , false otherwise ."
read sensor and return its value in degrees celsius .
sensor_id is port number
no operation . returns nothing
returns argument x
return the current date and time .
create a tag value of a specific kind .
raises typeerror or valueerror in case the user supplied value is n't valid .
may raise atomerror
return if all data could be read and the atom payload
render raw atom data .
recursively find all child atoms by specified name .
"look up a child atom , potentially recursively ."
look up and return the complete path of an atom .
look up a child atom .
helper to access the log instance
creates the default material
creates a render state based on a material
construct a reading pool for this entry .
"parses the kanjidic file for its contents , updating this class with a kanji - > info mapping ."
"parses a single line in the kanjdic file , returning an entry ."
"for modules that require a encoding as ` ` str ` ` in both python 2 and python 3 , we ca n't just encode automatically ."
s : a ( possibly multiline ) string containing lambdascript code context : the context in which the functions are to be mirrored internal : lambdascript global variables
import or export activation keys
import or export content hosts
import or export subscriptions
search for provisioning template permissions . set ` ` cls.ct_perms ` ` .
create a filter and assign it some permissions .
create a filter and delete it afterwards .
create a filter and delete the role it points at .
create content product providing different names and minimal input parameters
create content product with same name but in another org
create content product with invalid names
create content product with same name input parameter
update content product name with minimal input parameters
rename product back to original name .
update content product with too long input parameters
delete content product
create sync plan with specified start time
create sync plan with specified start date
creates new organization to be used for current session the session_user will login automatically with this org in context
create product with puppet repository assigned to it . search for modules inside of it
create product with puppet repository assigned to it . search for modules inside of it using different criteria ( e.g. ' author ' )
create product with puppet repository assigned to it . search for module inside of it and then open it . check all the details about that puppet module
create product with puppet repository assigned to it . search for module inside of it and then open it . check that proper repositories are displayed for puppet module in library repositories tab
navigate to job template entity page
specify locator for job template entity search procedure
configures different entities of selected job template .
creates a job template from ui .
updates a job template from ui .
"add new input to existing job template . at that moment only ' user input ' type is supported , but method can be expanded to support all types"
clones a given job template .
creates a virtual machine on the libvirt server using virt - install
destroys the virtual machine on the provisioning server
add a new nic to existing host
return a list of various kinds of valid strings for environment entity
create an environment and provide a valid name .
create an environment and assign it to new organization .
create an environment and assign it to new location .
create an environment and provide an invalid name .
create an environment and provide an illegal name .
"create environment entity providing the initial name , then update its name to another valid name ."
update environment and assign it to a new organization
update environment and assign it to a new location
"create environment entity providing the initial name , then try to update its name to invalid one ."
create new environment entity and then delete it .
create an ` ` environment ` ` .
update an environment . inspect the server 's response .
update an environment . inspect the server 's response .
create policies for openscap .
create policies for openscap with 256 chars .
delete policies of openscap .
create openscap content .
create openscap content with 256 chars .
create openscap content and then delete it .
openscap should have it 's own compliance reporting page .
should be able to periodically set openscap audit .
should be able to periodically set custom openscap audit .
should be able to search openscap audit results .
openscap should be able to audit foreman managed infrastructure(reports from default capsule . )
openscap should be able to audit foreman managed infrastructure ( reports from non - default capsule )
should be able to search openscap content .
should be able to search openscap policies .
should be able to search non - audited hosts / systems
"should be able to search non - compliant "" hosts""/systems"
"should be able to compare multiple audit results of "" hosts""/systems ."
should be able to assign policies for the hosts .
"dashboard views that can tell audited / un - audited , compliant / non - compliant and trends ."
upload a manifest .
upload a manifest and refresh it afterwards .
"upload a manifest , refresh it and upload a new manifest to an other organization ."
delete an uploaded manifest .
upload the same manifest to two organizations .
create a new azure compute resource with valid name .
create azure compute resource with description .
create a new azure compute resource with invalid names .
update an azure compute resource name .
update an azure compute resource organization .
delete an azure compute resource .
add images to the azure compute resource with valid name .
add images to the azure compute resource with invalid name .
list the virtual machines from azure compute resource .
provision a host on azure compute resource with the help of hostgroup .
fetch command info from expected commands info dictionary .
format the commands differences into a human readable format .
walk through the hammer commands tree and assert that the expected options are present .
check all provided options for every hammer command
navigate to audit entity page
there is no locator in audit that can be directly associated with search result
filter audit logs to represent only necessary entities
read last entity from audit logs and return its values in a dictionary
provision a satellite 's client .
show login status
enable repo from reposet
disable repo from reposet
verify that ' --test - connection ' option for redhat - access - insights client rpm tests the connection with the satellite server connection with satellite server
list all filters
clone a role
gets information for gpg key
navigate to statistics entity page
there are no search functionality for statistic page
get title information that located inside of the chart
prepare some data for charts
create new host and check operating system statistic for it
create new host and check architecture statistic for it
returns the handle of the curve
make the register storage .
load the transitions file .
"sometimes we load states from the database . in order to avoid loading an arbitrary class , we list here the state classes that are allowed ."
"if we 're confused , find which state to call ."
public method to handle a message . it requires :
return a config value . get it from the internal dict .
"define a configuration value . internally , it is stored as a dictionary entry ."
load the configuration from a plain python file . this file is executed on its own .
initialize internal cache .
"return the actual settings object , or create it if missing ."
delete the inner settings object so it gets reloaded .
proxy to ` settings.__getattr _ _ `
proxy to ` settings.__setattr _ _ `
save attributes and generate the proper stack of calls .
generates the stack of functions to call . it looks at the ordered list of all middlewares and only keeps those which have the method we 're trying to call .
"do n't call directly , use ` instance ( ) ` instead ."
"creates , initializes and returns a unique middlewaremanager instance ."
checks that the configuration makes sense .
imports and caches all middleware classes .
get the function to call which will run all middlewares .
download all sheets as configured .
fetch the credentials ( and cache them on disk ) .
gets valid user credentials from storage .
download the cell range from the sheet and store it as csv in the ` file_path ` file .
report an error to the reporting system . give as much context as possible .
list directory of modules
list directories holding config files
"if we 're going through a syntax error , add the directory of the error to the watchlist ."
list all directories known to hold project code .
this triggers an exit with the appropriate signal for the parent to reload the code .
start the parent that will simply run the child forever until stopped .
extracts just the domain name from an url and adds it to a list
generates the list of whitelisted domains for webviews . this is especially useful when you create your facebook messenger configuration .
computes the root to a given lang 's root directory
initializes a consul connection with : mod:`consulate ` .
reads services from a consul catalog into a cluster .
return true if the number of requested instances are available .
return true if the num of requested security groups are available .
get the pafy video that best matches the requested track
iterate over youtube video ids that match the queried track
given a populated som generate a rom image
given a populated som return the total number of elements in the rom ( this is used to calculate the size of the rom within the fpga )
"parse a bus , starting with the actual interconnect and then all the way through the final device , this stores the busses to be processed later and putting a birdge in the spot where the new bus will be"
call this function with anything besides a bridge or an interconnect
"using a field name optionally prefixed by ` ^ ` , ` = ` , ` @ ` , return a case - insensitive filter condition name usable as a queryset ` filter ( ) ` keyword argument ."
return a ` q ` object usable by ` filter ( ) ` based on a list of fields to search in ` search_fields ` for string ` q ` .
": param request : cid ( computer i d ) int , category int , level int , q string ( name or description contains ... ) , page int : return : applicationserializer set"
{ { mac_address|mac_address_list } } http://stackoverflow.com/questions/8346735/ inserting - a - character - at - regular - intervals - in - a - list
usage : sls [ --auth - token=<token > ] sls -h | --help sls -v | --version
creates a new slackshell which can be used to query various data from the slack server .
lists all channels registered at the slack team the access token is associated with .
lists all users registered at the slack team the access token is associated with .
the list command can be used to query various information fon the slack server .
quits the slackshell . : params : all specified parameters will be dropped .
adds a sub - stanza to this stanza
"direct access to the interfaces dictionary , used by ank modules"
allows for checking if edge exists
allows for checking if edge exists
return data the node belongs to
return graph the node belongs to
"for consistency , edge.get(key ) is neater than getattr(edge , key )"
returns edge property
sets edge property
restores latest saved anm
sets input graph . converts to undirected . initialises graphics overlay .
initialises input graph
adds overlay graph of name name
returns node label from physical graph
separate and order tests into groups sharing the same prefixes .
parse arguments or sys.argv[1 :] .
runs a single workflow .
: return : sorted list of projects with configs
": param group_and_project : "" project_name / project_group "" : return : merged configuration for this project , from common , group and project level . merging is additive ."
: return : sorted list of groups with configs
: param group : project_group : return : configuration for this group
: return : common configuration
": return : list of "" project_name / project_group "" to ignore"
": return : list of "" project_group "" to ignore"
automatically find / download setuptools and make it available on sys.path
download setuptools from a specified location and return its filename
install or upgrade setuptools and easyinstall
update our built - in md5 registry
access driver performance logs and find the stream url by matching with the regular expression for the server .
[ not implemented yet ] anime streaming websites do n't have consistent dom structures when it comes to new episode releases . this method executes a js script in the browser that attempts to convert the current page to an old - form page which the scrapers are originally compatible with .
create a fake session for upload process
create a fake session and clone git repo
create a fake session and copy user files
"upload directory contents , complie and commit"
upload yang files from a directory or git location
build one proto xml instance
build device profile xml instance
build collection profile xml instance
http request handler for profile request
returns : yang file name with version suffix .
returns : list of dependency ( yang imports and includes )
"compile yang model and return tuple ( boolean , list - of - errors )"
"compile yang model and return tuple ( boolean , list - of - errors )"
return dependencies for given yang models
invoke pyang compilation and return result
get the tb from the radiance using the planck function
e.g. : platform_name = ' meteosat-9 ' instrument = ' seviri ' band = 3.75
"get the relative spectral responses from file , find the bandname , and convert to the requested wave - spave ( wavelength or wave number )"
"get the satellite name used in the rsr - reader , from the platform and number"
get the radiance from the brightness temperature ( tb ) given the band name .
generate a tb to radiance look - up table
read the tb to radiance look - up table
get the tb from the radiance using the planck function and the central wavelength of the band
e.g. : platform_name = meteosat-9 band = 3.75
"overload the _ get_rsr method , since rsr data are ignored here"
get the tb from the radiance using the simple non - linear regression method .
get the radiance from the tb using the simple non - linear regression method . si units of course !
derive brightness temperatures from radiance using the planck function . wavelength space . assumes si units as input and returns temperature in kelvin
derive brightness temperatures from radiance using the planck function . wavenumber space
"the planck radiation or blackbody radiation as a function of wavelength or wavenumber . si units . _ planck(wave , temperature , wavelength = true ) wave = wavelength / wavenumber or a sequence of wavelengths / wavenumbers ( m or m^-1 ) temp = temperature ( scalar ) or a sequence of temperatures ( k )"
"the planck radiation or blackbody radiation as a function of wavenumber si units ! blackbody_wn(wavnum , temperature ) wavenumber = a wavenumber ( scalar ) or a sequence of wave numbers ( m-1 ) temp = a temperatfure ( scalar ) or a sequence of temperatures ( k )"
"the planck radiation or blackbody radiation as a function of wavelength si units . blackbody(wavelength , temperature ) wavel = wavelength or a sequence of wavelengths ( m ) temp = temperature ( scalar ) or a sequence of temperatures ( k )"
create the instance either from platform name and instrument or from filename and load the data
check the version of the rsr data from the version file in the rsr directory
check and try fix instrument name if needed
"get the rsr filname from platform and instrument names , and download if not available ."
read the internally formatet hdf5 relative spectral response data
calculate the integral of the spectral response function for each detector .
convert spectral response functions from wavelength to wavenumber
look for any ` ` games ` ` modules in installed apps to ensure they get registered .
"called each time a player bets . when there are no players , a greenlet is spawned that will trigger the play of a turn of the game ."
piggyback the first connected player 's namespace to broadcast a message .
"pause for settings . betting_period - used to simulate dice roll , wheel spin , etc ."
"takes an actual turn of the game - called within a separate greenlet on the first call to bet ( ) . we iterate through each of the players passing their bet_args to outcome ( ) which multiplies the amount bet , and build a results dict we can broadcast back to all sockets ."
create an initial account balance for new users .
download the user 's twitter or facebook avatar once they 've authenticated via either service .
show the main page of the host statistics section .
creates empty args : network :
obtains data for headmap chart in a time range
"gets flows , packet and bytes time series for a given host"
gets tcp flags statistics for a given host
"gets flows , packet and bytes time series for a given host"
"gets flows , packet and bytes time series for a given host"
"args ids ids of the monitors to list . if none , then get all contacts . [ list < int > ] logs show logs [ boolean ] alert_contacts show alert contacts [ boolean ] show_monitor_alert_contacts show monitors alert contacts [ boolean ] custom_uptime_ratio number of days to calculate uptime over [ list < int > ] show_log_timezone show the timezone for the log times [ boolean ]"
args name human - readable name to assign to the monitor [ str ] . url url [ str ] type monitor type [ int ] subtype subtype of the monitor [ int ] keyword_type type of keyword to use ( requires keyword be set ) [ int ] keyword keyword to use ( requires keyword_type be set ) http_username username to use for private site ( requires http_password be set ) http_password password to use for private site ( requires http_username be set ) alert_contacts alert contacts to give the monitor [ list < int > ]
args i d id number of the monitor to edit [ str ] status status to set [ int ] name human - readable name to assign to the monitor . url url to monitor type monitor type [ int ] subtype subtype of the monitor [ int ] keyword_type type of keyword to use ( requires keyword be set ) [ int ] keyword keyword to use ( requires keyword_type be set ) username username to use for private site ( requires http_password be set ) password password to use for private site ( requires http_username be set ) alert_contacts alert contacts to give the monitor [ list < int > ]
args i d id of the monitor to delete [ str ]
"args ids ids of the alert contacts to list . if none , then get all contacts [ list ."
args type type of the new alert to create [ int ] value email address ( or ) to alert [ str ]
args i d id of the alert contact to delete [ str ]
check if the given path exists .
check if the given file exists .
determine the prefix for files we care to check .
hook registered as event handler .
return boolean indicating whether the blueprint exists .
"given one blueprint name , check to see if it is valid ."
"message constructor with ( [ buf ] , [ field = val , ... ] ) prototype ."
encode the message and return a bytestring .
extract the test results from the protocol buffer data .
build the loss periods list showing packet drop patterns
build the jitter summary dictionary if the appropriate data was reported
build the voip result dictionary if the appropriate data was reported
convert direction enum into a human readable string
extract the udpstream test results from the protocol buffer data
"get a list of mapped files , if there are any found"
"mappings are stored in a list of ( srcdir , destdir ) , preserves order unlike dict ."
returns the first candidate that exists
"look up the current file , tell scite to open the next file"
"if there 's no selection , cut the entire line"
"if there 's no selection , copy the entire line"
"if there 's no selection , and the clipboard contents start and end with newlines , then insert the text * above * the current line instead of inside the current line ."
"first , run paste . if the contents look normal , leave the text there and exit . or if contents start and end with newlines , move them above the current line . note : should only call this function if there is no selection ."
"execution algorithm , introduces all blocks on a set , when a block is executed it is taken out of the set until the set is empty ."
"execute a block , if any dependency is not yet executed we recurse into it first ."
istanzia un nuovo comando dello stesso tipo
"la funzione legge il colore impostato da qgis per il rubber band di tipo < geometrytype > . se < alternativeband > = true , il rubber band sarà impostato con più trasparenza"
"la funzione crea un rubber band di tipo < geometrytype > con le impostazioni di qgis . se < alternativeband > = true , il rubber band sarà impostato con più trasparenza e tipolinea punteggiato"
serie rettangolare ent = entità qad di cui fare la serie ( qadentity o qaddimentity ) basept = punto base in map coordinate ( qgspoint ) rows = numero di righe cols = numero di colonne distancebetweenrows = distanza tra le righe in map coordinate distancebetweencols = distanza tra le colonne in map coordinate angle = angolo della serie ( radianti ) itemsrotation = true se si vuole ruotare gli elementi come l'angolo della serie addtolayer = se è true aggiunge le nuove entità al layer highlightobj = se è diverso da none vengono aggiunge le geometrie all'oggetto qadhighlight la funzione restituisce true in caso di successo e falso in caso di errore
serie traiettoria ent = entità qad di cui fare la serie ( qadentity o qaddimentity ) basept = punto base in map coordinate ( qgspoint ) rows = numero di righe cols = numero di colonne distancebetweenrows = distanza tra le righe in map coordinate distancebetweencols = distanza tra le colonne in map coordinate tangentdirection = specifica il modo in cui gli elementi disposti in serie sono allineati rispetto alla direzione iniziale della traiettoria itemsrotation = true se si vuole ruotare gli elementi come l'angolo della serie pathlinearobjectlist = traiettoria da seguire ( qadlinearobjectlist ) in map coordinate distancefromstartpt = distanza dal punto iniziale della traccia addtolayer = se è true aggiunge le nuove entità al layer highlightobj = se è diverso da none vengono aggiunge le geometrie all'oggetto qadhighlight
serie polare ent = entità qad di cui fare la serie ( qadentity o qaddimentity ) basept = punto base in map coordinate ( qgspoint ) centerpt = punto centrale in map coordinate ( qgspoint ) itemsnumber = numero di copie da fare anglebetween = angolo tra un elemento e l'altro ( radianti ) rows = numero di righe distancebetweenrows = distanza tra le righe in map coordinate itemsrotation = true se si vuole ruotare gli elementi intorno al cerchio addtolayer = se è true aggiunge le nuove entità al layer highlightobj = se è diverso da none vengono aggiunge le geometrie all'oggetto qadhighlight
"get absolute path to resource , works for dev and for pyinstaller"
return a fov from a string
all field - of - view functionality in one call .
iterate over points in a bresenham line .
create an a * pathfinder using a callback .
get the shortest path from origxy to destxy .
wrapper around ` ` django.core.mail.send_mail ` ` that generates the subject and message body from a template .
validate price against manufacturer remote api
return * * first - level * * comments of the post .
reply to the post
upvote the post
downvote the post
vote the post
return a float value of estimated total sbd reward .
return a timedelta on how old the post is .
"retuns true if main post , and false if this is a comment ( reply ) ."
"retuns true if main post , and false if this is a comment ( reply ) ."
retuns true if post is a comment
"if post is less than 30 minutes old , it will incur a curation reward penalty ."
this method returns a dictionary that is type - safe to store as json or in a database .
default function to generate keys .
function to decide which key function to use .
returns the timeout value usable by this backend based upon the provided timeout .
"constructs the key used by all other methods . by default it uses the key_func to generate a key ( which , by default , prepends the ` key_prefix ' and ' version ' ) . a different key function can be provided at the time of cache construction ; alternatively , you can subclass the cache backend to provide custom key making behavior ."
"set a value in the cache if the key does not already exist . if timeout is given , that timeout will be used for the key ; otherwise the default cache timeout will be used ."
"fetch a given key from the cache . if the key does not exist , return default , which itself defaults to none ."
"set a value in the cache . if timeout is given , that timeout will be used for the key ; otherwise the default cache timeout will be used ."
"delete a key from the cache , failing silently ."
"fetch a bunch of keys from the cache . for certain backends ( memcached , pgsql ) this can be * much * faster when fetching multiple values ."
"fetch a given key from the cache . if the key does not exist , the key is added and set to the default value . the default value can also be any callable . if timeout is given , that timeout will be used for the key ; otherwise the default cache timeout will be used ."
returns true if the key is in the cache and has not expired .
"add delta to value in the cache . if the key does not exist , raise a valueerror exception ."
"subtract delta from value in the cache . if the key does not exist , raise a valueerror exception ."
returns true if the key is in the cache and has not expired .
"set a bunch of values in the cache at once from a dict of key / value pairs . for certain backends ( memcached ) , this is much more efficient than calling set ( ) multiple times ."
"delete a bunch of values in the cache at once . for certain backends ( memcached ) , this is much more efficient than calling delete ( ) multiple times ."
remove * all * values from the cache at once .
warn about keys that would not be portable to the memcached backend . this encourages ( but does not force ) writing backend - portable cache code .
adds delta to the cache version for the supplied key . returns the new version .
subtracts delta from the cache version for the supplied key . returns the new version .
close the cache connection
return a file - like object for the latest public suffix list downloaded from publicsuffix.org
return the public suffix for a ` domain ` dns name . convenience function that builds and caches a publicsuffixlist object .
"read and parse a public suffix list . ` psl_file ` is either a file location string , or a file - like object , or an iterable of lines from a public suffix data file ."
return the public suffix for a ` domain ` dns name .
test_1 good pin and good token
test_2 bad pin and good token
test_2 good pin and bad token
test_4 make sure all client secret are unique
test_5 make sure all one time passwords are random i.e. they should collide
test_6 make sure all random values are random i.e. they should collide
test_7 aes - gcm : successful encryption and decryption
test_8 aes - gcm : failed encryption and decryption by changing a ciphertext byte
test_9 aes - gcm : failed encryption and decryption by changing a header byte
: return : a logger with the given ` name ` and optional ` level ` .
convert an ibpy order object to a dict containing any non - default values .
convert an ibpy contract object to a dict containing any non - default values .
converts naive ( usually local ) timezone to utc )
generate a top - level json schema
return the json schema form of the given pfm_type
generate a json schema object from a pfm item i.e an item in the schema that has at least a pfm_name .
generate a json schema object as a dict from a parsed plist manifest given as a dict
build a python extension for samba
generate all python environments
returns a new instance from config settings .
"returns entire url of the filename , joined to the base_url"
"returns absolute file path of the filename , joined to the base_path ."
"deletes the filename . filename is resolved with the absolute path based on base_path . if file does not exist , returns * * false * * , otherwise * * true * *"
checks if file exists . resolves filename 's absolute path based on base_path .
checks if a filename has an allowed extension
"checks if a file can be saved , based on extensions"
"checks if an extension is permitted . both e.g. "" .jpg "" and "" jpg "" can be passed in . extension lookup is case - insensitive ."
saves contents of a * * cgi . fieldstorage * * object to the file system . returns modified filename(including folder ) . if there is a clash with an existing filename then filename will be resolved accordingly . if path directories do not exist they will be created .
saves a filename in local filesystem to the uploads location .
"saves a file object to the uploads location . returns the resolved filename , i.e. the folder + the ( randomized / incremented ) base name ."
"resolves a unique name and the correct path . if a filename for that path already exists then a numeric prefix will be added , for example test.jpg - > test-1.jpg etc ."
performs a fake saved operation
send initial node information
main function .
"drop into pycharm debugger , if available , on uncaught exceptions ."
tests that the home page loads .
tests that the health check is successful .
log in as an email address .
logout in testing mode .
create a backup with specific message info .
full credit if question is correct or at least one testcase passed
full credit if question has at least three attempts
points should ceil to nearest point ( no decimals )
sanitize filename and add random prefix to file to handle duplicate names and potentially empty sequences from secure_filename
"upload ( and overwrite ) files on storage provider . to avoid overwriting files see ` _ safe_object_name ` in flask - cloudy . or use sanitize_filename(name , prefix = true ) . file names will always be sanitized to prevent directory traversal ."
return the unsigned url of the object : param secure : bool - to use https : return : str
mostly from https://github.com/mardix/flask-cloudy/blob/master/flask_cloudy.py
data stream of the libcloud object .
generates a signed url compatible with google cloud and aws s3
generates a signed url compatible with azure blob storage
"highlights an input string into a list of html strings , one per line ."
"given a source file , generate a sequence of ( line index , html ) pairs ."
"given two input strings , generate a sequence of 4 - tuples . the elements of each tuple are : * ' delete ' , ' insert ' , ' equal ' , or ' header ' ( the tag ) * the line number of the first file ( or none ) * the line number of the second file ( or none ) * the rendered html string of the line"
write ddl to truncate the specified ` table `
write ddl to create the specified ` table ` .
write ddl of ` table ` indexes to the output file
write ddl of ` table ` constraints to the output file
write the data contents of ` table ` to the output file .
closes the output : py : obj:`file `
python datetime to a time tag with js date.parse - parseable format .
takes an event object and returns a shortened description .
"aka ` ` thousands separator '' - 1000000 becomes 1,000,000"
allow some of the text 's html tags and escape the rest
returns a report of all events that have pictures in the picture gallery but none has been picked yet .
returns a report of all events that very few tags
split sequence into chunks .
get all keys and values from dictionary where key is not ` self ` .
check http status code and raise exception if incorrect .
get ` result ` field from betfair response or raise exception if not found .
cast response json to betfair model(s ) .
build betfair json - rpc payload .
decorator to check that the user is logged in . raises ` betfairerror ` if instance variable ` session_token ` is absent .
"tests designed for mail_mail tracking ( opened , replied , bounced )"
test an usual related field
test a related field with a single indirection like fields.related('foo ' )
test a related field referring to a related field
write on a related field
"test basic project access rights , for project and portal_project"
main entry point for the openerp - command tool .
"crm lead report @param cr : the current row , from the database cursor"
replace default fontname use in header and setfont tag
this function print the report for all picking_ids associated to the picking wave
utility method to send a publisher warranty get logs messages .
"send a message to openerp 's publisher warranty server to check the validity of the contracts , get notifications , etc ..."
"override to verify that the email_to is the bounce alias . if it is the case , log the bounce , set the parent and related document as bounced and return false to end the routing process ."
"called by ` ` message_process ` ` when a bounce email ( such as undelivered mail returned to sender ) is received for an existing thread . the default behavior is to check is an integer ` ` message_bounce ` ` column exists . if it is the case , its content is incremented ."
override to update the parent mail statistics . the parent is found by using the references header of the incoming message and looking for matching message_id in mail.mail.statistics .
override mail_mail creation to create an entry in mail.mail.statistics
override to add the tracking url to the body .
cancels the repair @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param ids : list of ids selected @param context : a standard dictionary @return :
changes the view dynamically @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param context : a standard dictionary @return : new arch of view .
returns the names of visible groups which have been granted ` ` access_mode ` ` on the model ` ` model_name ` ` . : rtype : list
create or retrieve root id of sharing menu in portal menu
create sharing menus in portal menu according to share wizard options .
return lines from a specified invoice or sale order grouped by category
returns invoice lines from a specified invoice ordered by sale_layout_category sequence . used in sale_layout module .
returns order lines from a specified sale ordered by sale_layout_category sequence . used in sale_layout module .
save the layout when converting to an invoice line .
"function called by the js , when no google doc are yet associated with a record , with the aim to create one . it will first seek for a google.docs.config associated with the model ` res_model ` to find out what 's the template of google doc to copy ( this is usefull if you want to start with a non - empty document , a type or a name different than the default values ) . if no config is associated with the ` res_model ` , then a blank text document with a default name is created . : param res_model : the object for which the google doc is created : param ids : the list of ids of the objects for which the google doc is created . this list is supposed to have a length of 1 element only ( batch processing is not supported in the code , though nothing really prevent it ) : return : the config i d and config name"
override to add case management : open / close dates
escalates case to parent level
overrides mail_thread message_new that is called by the mailgateway through message_process . this override updates the document according to the email .
"@param self : the object pointer @param cr : the current row , from the database cursor , @param uid : the current user ’s id for security checks , @param ids : list of process continue ’s ids"
"@param self : the object pointer @param cr : the current row , from the database cursor , @param uid : the current user ’s id for security checks , @param ids : list of process stop ’s ids"
"@param self : the object pointer @param cr : the current row , from the database cursor , @param uid : the current user ’s id for security checks , @param ids : list of process start ’s ids"
"@param self : the object pointer @param cr : the current row , from the database cursor , @param uid : the current user ’s id for security checks , @param ids : list of test ’s ids"
changes the view dynamically @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param context : a standard dictionary @return : new arch of view .
to merge similar type of purchase orders .
collects require data for vat intra xml : param ids : i d of wizard . : return : dict of all data to be used to generate xml for partner vat intra . : rtype : dict
creates xml that is to be exported and sent to estate for partner vat intra . : return : value for next action . : rtype : dict
to get default values for the object . @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param fields : list of fields for which we want default values @param context : a standard dictionary @return : a dictionary with default values for all field in ` ` fields ` `
creates return picking . @param self : the object pointer . @param cr : a database cursor @param uid : id of the user currently logged in @param ids : list of ids selected @param context : a standard dictionary @return : a dictionary which of fields with values .
return default period value
"opens chart of accounts @param cr : the current row , from the database cursor , @param uid : the current user ’s id for security checks , @param ids : list of account chart ’s ids @return : dictionary of open account chart window on given fiscalyear and all entries or posted entries"
construct a new brain : param ninputs : number of inputs : param nactions : number of possible actions
provides actions for inputs : param inputs : dictionary of id : input to think about : return : dictionary of id : actions
train the brain for a bit based in rewards previously provided : param iters : : param batch : : return :
if overridden make sure to call super
if overridden make sure to call super
rewards last actions using q learning approach : param inputs : dictionary of id:[inputs ] : param actions : dictionary of id:[actions ] : param rewards : dictionary of id : reward : param newinputs : dictionary of id:[inputs ]
makes a constructor to combine the two brain constructors given : param brainconsa : constructor for brain a : param brainconsb : constructor for brain b : param p : p of choosing a over b : return : constructor for a - b hybrid
: param buffersize :
provide dicts of { id : item } : param inputs : : param actions : : param rewards : : param newinputs :
make a generator which provides batches of items : param batchsize : size of batch : param niters : number of batches to produce : return :
provide dicts of { id : item } : param inputs : : param actions : : param rewards : : param newinputs :
returns sql simulating date_trunc
""" order by null "" prevents mysql from implicitly ordering by grouped columns . if no ordering would otherwise be applied , we do n't want any implicit sorting going on ."
mysql requires special cases for ^ operators in query expressions
returns a list of table names in the current database .
returns a dictionary of { field_name : field_index } for the given table . indexes are 0 - based .
"returns a dictionary of { field_index : ( field_index_other_table , other_table ) } representing all relationships to the given table . indexes are 0 - based ."
"returns a list of ( column_name , referenced_table_name , referenced_column_name ) for all key columns in given table ."
returns the name of the primary key column for the given table
retrieves the storage engine for a given table . returns the default storage engine if the table does n't exist .
"retrieves any constraints or keys ( unique , pk , fk , check , index ) across one or more columns ."
return list of all category range mappings return : list of category range mapping dictionaries
return category range mapping associated with the given i d return : category range mapping dictionary
create category range mapping retun : category range mapping dictionary
"update category range mapping associated with the given i d from data : category ( str ) , range_min ( int ) , range_max ( int ) return : category range mapping dictionary"
delete category range mapping associated with the given i d return : none
return all config states return : list of config state dictionaries
return config state associated with given i d return : config state dictionary
"create config state from data : state ( str ) , is_release_state ( bool ) return : config state dictionary"
"update config state associated with the given i d from data : state ( str ) , is_release_state ( bool ) return : config setting dictionary"
delete config state associated with the given i d return : none
return all tag mappings return : list of tag mapping dictionaries
return tag mapping associated with the given i d return : tag mapping dictionary
return tag mapping associated with the given source_table and source_id return : list of entity dictionaries associated with the tag
abstract factory function for dynamic patcher initialization same params as in constructor !
evaluate hands of players and determine winners .
this method performs value - based validation for a given html field .
"this method is called whenever a field object 's value has been validated , and is ready to be submitted ."
decorator function that instantiates the retrying object @param * dargs : positional arguments passed to retrying object @param * * dkw : keyword arguments passed to the retrying object
stop after the previous attempt > = stop_max_attempt_number .
stop after the time from the first attempt > = stop_max_delay .
do n't sleep at all before retrying .
sleep a fixed amount of time between each retry .
sleep a random amount of time between wait_random_min and wait_random_max
"sleep an incremental amount of time after each attempt , starting at wait_incrementing_start and incrementing by wait_incrementing_increment"
"return the return value of this attempt instance or raise an exception . if wrap_exception is true , this attempt is wrapped inside of a retryerror before being raised ."
the ` ` gunicorn_paster ` ` command for launching paster compatible applications like pylons or turbogears2
a paster server .
"convert an image slice to [ top , bottom , left , right ] form"
"convert center , size information to [ top , bottom , left , right ] form"
"convert [ top , bottom , left , right ] information a image slice form"
"convert [ top , bottom , left , right ] information center , size form"
takes a list of rois and returns an roi that contains them all
"the roi can be specified using the following keywords 1 ) ' tblr ' : edge coordinates [ top , bottom , left , right ] 2 ) ' center ' : center point ( y0 , x0 ) , ' size ' : edge size ( dy , dx ) 3 ) ' slices ' : roi given as a tuple of array slice objects , e.g. ( slice(top , bottom+1 , 1),slice(left , right+1 , 1 ) ) additional options : 4 ) ' framesize ' : specifies the max allowed range of the roi ( defaults to ( 2048,2048 ) if not specified )"
changes the size of the roi without changing the center
"changes the center ( x , y ) of the roi without changing the size"
makes the roi into a square of edge length equal to its longest side
scale the size of the roi by a multiplicative factor
"checks to see that input values arein order min , max where min < max , makes sure no values are outside the frame size , and if any problems are found it tries to coerce the values to valid ones returns true if coerced , false otherwise"
defines behavior for adding two roi class instances : takes this roi and another and returns the smallest rectangular roi containing both
defines behavior for subtracting two roi class instances : takes this roi and another and returns and roi containing their intersection
determines the representation of the roi class instance in the console
test a good is_valid_pull_request .
test with missing action
test with missing pull_request dict
test with missing html_url on pull_request dict
test with non matched action
test with non matched action
should return the requested reviewers username
should return the requested reviewers username
should raise a badrequest
test lookup_github_full_name .
test lookup_github_full_name with a network request to github .
adds the specified item if it is not exists in this set .
adds the elements in the specified collection if they 're not exist in this set .
adds an item listener for this container . listener will be notified for all container add / remove events .
clears the set . set will be empty with this call .
determines whether this set contains the specified item or not .
determines whether this set contains all of the items in the specified collection or not .
returns all of the items in the set .
determines whether this set is empty or not .
removes the specified element from the set if it exists .
removes all of the elements of the specified collection from this set .
removes the specified item listener . returns silently if the specified listener was not added before .
"removes the items which are not contained in the specified collection . in other words , only the items that are contained in the specified collection will be retained ."
returns the number of items in this set .
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
decode response from client message
calculates the request payload size
encode request into client_message
atomically adds the given delta value to the currently stored value .
alters the currently stored value by applying a function on it .
alters the currently stored value by applying a function on it and gets the result .
"applies a function on the value , the actual stored value will not change ."
atomically sets the value to the given updated value only if the current value = = the expected value .
atomically decrements the current value by one .
gets the current value .
atomically adds the given value to the current value .
alters the currently stored value by applying a function on it on and gets the old value .
atomically sets the given value and returns the old value .
atomically increments the current value by one .
atomically increments the current value by one .
atomically sets the given value .
try to initialize this idgenerator instance with the given i d. the first generated i d will be 1 greater than i d.
"generates and returns a cluster - wide unique i d. generated ids are guaranteed to be unique for the entire cluster as long as the cluster is live . if the cluster restarts , then i d generation will start from 0 ."
calculates the request payload size
encode request into client_message
"transactional implementation of : func:`multimap.put(key , value ) < hazelcast.proxy.multi_map.multimap.put > `"
transactional implementation of : func:`multimap.get(key ) < hazelcast.proxy.multi_map.multimap.get > `
"transactional implementation of : func:`multimap.remove(key , value ) < hazelcast.proxy.multi_map.multimap.remove > `"
transactional implementation of : func:`multimap.remove_all(key ) < hazelcast.proxy.multi_map . multimap.remove_all > `
transactional implementation of : func:`multimap.value_count(key ) < hazelcast.proxy.multi_map . multimap.value_count > `
transactional implementation of : func:`multimap.size ( ) < hazelcast.proxy.multi_map.multimap.size > `
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
calculates the request payload size
encode request into client_message
generate a simple energy disaggregation data .
: parameters : - num_units : int number of output features .
": returns : a tensor . the dimensions are : 1 . batch_size 2 . num_units 3 . number of mixture components 4 . the last dimension always has exactly 3 elements : 1 ) mu , 2 ) sigma , 3 ) mixing ."
border_mode needs to be ' full ' to get back to original shape .
: parameters : - num_units : int number of segments the layer can represent .
"parameters ---------- source_type : { ' multisource ' , ' real_appliance_source ' }"
results : learning rate of 0.1 still nans .
"convenience function to apply batch norm to a given layer 's output . will steal the layer 's nonlinearity if there is one ( effectively introducing the normalization right before the nonlinearity ) , and will remove the layer 's bias if there is one ( because it would be redundant ) ."
"instantiates a layer performing batch normalization of its inputs , following ioffe et al . ( http://arxiv.org/abs/1502.03167 ) ."
"parameters ---------- appliance : string architecture : { ' rnn ' , ' ae ' , ' rectangles ' }"
enable library wide debugging to a file - like object .
utility function that is ran once on library import .
@inherits : : class:`driver.__init _ _ `
@inherits : : class:`driver.create_balancer `
helper method to convert list of : class:`member ` objects to get params .
: param creds : credentials : type creds : ` ` str ` `
: param unique_field : unique field : type unique_field : ` ` bool ` ` : rtype : : class:`uuid `
list the nodes known to a particular driver ; there are two default nodes created at the beginning
sets the node state to rebooting ; in this dummy driver always returns true as if the reboot had been successful .
sets the node state to terminated and removes it from the node list
returns a list of images as a cloud provider might have
returns a list of node sizes as a cloud provider might have
returns a list of locations of nodes
creates a dummy node ; the node i d is equal to the number of nodes in the node list
: param i d : member id . : type i d : ` ` str ` `
: param i d : load balancer id . : type i d : ` ` str ` `
return a list of supported protocols .
list all loadbalancers
create a new load balancer instance
destroy a load balancer
return a : class:`loadbalancer ` object .
"sets the name , algorithm , protocol , or port on a load balancer ."
attach a compute node as a member to the load balancer .
attach a member to balancer
detach member from balancer
return list of members attached to balancer
return algorithms supported by this driver .
return : class:` . algorithm ` based on the value .
return string value for the provided algorithm .
return a list of zones .
return a list of records for the provided zone .
return a zone instance .
return a record instance .
create a new zone .
create a new record .
delete a zone .
use this method to delete a record .
convert existent zone to slave .
convert existent zone to master .
return the string representation of the state object attribute : param str value : the state object to turn into string : return : the uppercase string that represents the state object : rtype : str
return the state object attribute that matches the string : param str value : the string to look up : return : the state object attribute that matches the string : rtype : str
parses iso 8601 time zone specs into tzinfo offsets
parses iso 8601 dates into datetime objects
check post path will render in /post/<path >
"make sure pageview , distinct viewers correct for post"
check post metadata
check who should receive a subscription email about this post
send an email to all those subscribed to a tag if a new post with that tag was published to the repo
send an email to all those subscribed to a tag if a new post with that tag was published to the repo
testing classification problem with 3 class values
testing classification problem with 2 class values
testing regression rmse problem
testing regression r2 problem
create an instance attribute for each field in the fields class property unless if the field name is empty ( in order to leave a column empty in the row )
"return the field name and its max length ( optional ) as declared in the class for one slot of the class attribute "" fields """
"according to the class attribute "" fields "" , generate a row with all the value of the line . if a width is defined on some fields , their content is cut to their maximal length ."
"returns a list of field 's names respecting the order of the class attribute "" fields """
generate a label from a webkit report
call the creation of the delivery carrier label of the missing labels and get the existing ones then merge all of them in a single pdf
get all the logo urls .
"this is the first basic test for eim / deim , based on the test case of section 3.3.1 of s. chaturantabut and d. c. sorensen nonlinear model reduction via discrete empirical interpolation siam journal on scientific computing 2010 32:5 , 2737 - 2764 * eim : test interpolation of a scalar function * deim : test interpolation of form with scalar integrand on a scalar space"
the aim of this test is to check the interpolation of vector valued functions . * eim : test interpolation of a scalar function * deim : test interpolation of form with integrand given by the inner product of a vector valued function and some derivative of a test / trial functions of a scalar space
"solve the linear program min c^t x s.t . a x > = b x_{min } < = x < = x_{max } where c is the first input parameter a is the second input parameter b is the third input parameter ( x_{min } , x_{max } ) are given as a list of ( min , max ) tuples in the fourth input parameter"
"convert integer powers in an expression to muls , like a**2 = > a*a . https://stackoverflow.com/questions/14264431/expanding-algebraic-powers-in-python-sympy"
duplicate of sympy 's xreplace but with non - evaluate statement included . https://stackoverflow.com/questions/14264431/expanding-algebraic-powers-in-python-sympy
"this test is similar to test 13 . * eim : not applicable , no relevant difference with respect to test 13 . * deim : the solution component is not further split between x and y. this results in a single coefficient of type listtensor ( rather than two coefficients of type indexed ) ."
set the allowed / harmless list of metadata
remove all metadata with help of exiftool
check if the file is clean with help of exiftool
return every harmful meta with help of exiftool
make sure that the lib remove all compromizing meta
test removal with clean files
check if get_meta returns all the expected meta
check that a listing of a clean file return an empty dict
test is_clean on clean files
test is_clean on dirty files
"an ugly hack to find where is the "" formats "" file ."
securely remove the file
"return a $ filetypestripper ( ) class , corresponding to the filetype of the given file"
called when entering into xml balise
called when exiting a xml balise
concatenate the content between opening and closing balises
return true if the field is compromizing
return true if the field is compromizing
"return list of word tokens , with internal milestone markup , as strings"
make an edge between a parent node and a child node . a - parent b - child
export the graph in graphviz dot language .
in order to make this sort deterministic we will use the variable name as a secondary sort
column 2 of upper half of table
column 3 of upper half of table
column 4 of upper half of table
column 5 of upper half of table
column 6 of upper half of table
column 7 of upper half of table
column 2 of upper half of table
column 3 of upper half of table
column 4 of upper half of table
column 5 of upper half of table
column 6 of upper half of table
column 7 of upper half of table
"convert an host : port string into ( host , port ) tuple ."
"convert an ( host , port ) tuple into a host : port string . if one of the member is missing , the other is returned ."
dump the buffer in wireshark style
pick a free port choosen by the operating system
"search for a configuration file in current , user home or /etc ( not suitable for windows ... ) folders"
entry point for the websocket client tunnel service endpoint
stops the windows service
starts the windows service
entry point for the websocket client tunnel daemon endpoint
do its best to return an unicode string .
create or update books from given metadata files .
"create or update books from given isbn , using openlibrary api ."
": param data_shape : tuple with order ( rows , columns , channels ) : param zoom_range : percentage that the input will dynamically be zoomed turing training ( 0 - 1 ) : param rotation_range : random rotation of the input image during training in degree : param optimizer : the used optimizer for the training , currently supported are either ' sgd ' , ' adam ' or ' adadelta ' ."
returns the classifier of this configuration
returns the name of this configuration
returns wether this configuration has a regression head that performs object localization or not
returns the configured optimizer for this configuration : return :
returns the string that summarizes this configuration
sends a message as trainingfather .
show a critical qmessagebox : param title : title 's box : param text : text 's box : return : none
show a information qmessagebox : param title : title 's box : param text : text 's box : return : none
show a question qmessagebox : param title : title 's box : param text : text 's box : return : none
initialize the view object and all attributes that it needs
this function is executed when pushbutton update is clicked .
this function is executed when pushbutton upgrade is clicked .
this function checks if ui file exists and then show the view
set the number of exploits available for upgrade . : param auxiliary : number of exploits auxiliary : param generic : number of exploits generic : param routers : number of exploits routers : return : none
initialize the view object and all attributes that it needs
this function is executed when buttonbox ok is clicked .
this function is executed when buttonbox cancel is clicked .
"check if lineedit location is well formed : return : true if we can create a project on this path , false otherwise"
this function checks if ui file exists and then show the view
this function is executed when toolbutton is clicked .
initialize the generator and all attributes that it needs
this function check that patterns an their lengths are correct . : param pattern : the pattern : param lengths : the pattern 's lengths : param maximum : the max number of iterations : return :
this function create array with all combinations : return : array with all combinations
this function find all ranges that appear on the pattern : return : array with ranges like ' [ a - z ] '
this function split the range and identify it him type : param pattern : the pattern : return : a var like ' a - z '
recursive function that create all possibilities : param pattern : the pattern : param lengths : the pattern 's lengths : param ranges : : return : all patterns
initialize the controller object and all attributes that it needs
get a project file . : return : a project file
set a project file object : param projectfile : a project file object : return : none
create a pdf and write the information on it . : param location : where we save the pdf : param comment : the comment : return : none
"show ' report view ' : return : true if project is create successfully , false otherwise"
write an optional comment . : param pdf : the pdf : param comment : the comment that we will write : return : none
write the exploits that we use it . : param pdf : the pdf object : return : none
"write the general information about the project like name , ip , mac ... : param pdf : the pdf object : return : none"
write the ports and services we are scanned : param pdf : the pdf object : return : none
adds commonly used arguments to command line
standardizes some environment parameters and sets new values
adds a list of commands to a subparser
registers arguments definition in command parser
"returns a tuple ( bool , disabled reason to know why a command is currently disabled"
executes the command
returns true if errors were emitted during program execution
returns true if warnings were emitted during program execution
writes summary to destination
"grating density blaze , description"
wrapper of logging method for pycmds
"holds value , a list of hardware wait_until_still methods"
mono setpoint in nm
"get the axis properties to record for the given scan , given hardware positions ."
cleanly shut down
"for given module , return list of full module path names for all submodules recursively ."
"for given module , return list of full module path names for all model submodules recursively ."
just try to import given module .
check that all names of all classess from models modules ends with ' model ' suffix .
yaml config getter function .
config generation function .
initilizes the anilist scraper plugin .
str : returns the name of the plugin .
str : returns the url of anilist .
"gets all shows from the db and seperates into watching , tv , movies , and specials . keyword args : search_results ( str ): a list of database shows to parse into the separate lists instead of all shows ."
checks our anilist for shows and updates them in the database if they 're there .
access token decorator function .
checks if the access token is valid and not expired .
"if the locally cached token has n't expired , use it . otherwise , get a new token from anilist ."
season string generator .
gets a show 's information from anilist .
"gets the list of this season 's shows from anilist . returns : list . a list of shows in the anilist format . these are expected to be run through _ get_remote_show_info , as anilist does not provide everything for every show in this output ."
adds or edits a show in the local database based on anilist i d.
inputs a list containing ap information and the ap color information returns a graph object that holds ap information ( colors and details ) todo : get sample data for each line ?
"creates a label for the client information passed in ( mac , color ) returns a graph object todo : pass a label in that may hold additional client data that could in turn be written on the client ."
take in the encryption used by the ap and return the proper color scheme based on that value . returns a list containing the ap fill color and ap font color
return a graph object that links 2 objects together . both objects are passed in with a separator
close the graphiz config file return final output to be written
write all the information obtained to a configuration file
create a subgraph based on the incoming values todo : figure out what this does and clean it up
configures the oauth extension ' flask - dance ' for use with the ekklesia id server
"site modelinde her save işlemi sonrasında "" kabul e - postalarının onaylama tarihi bitiminde e - postası gönderilmemis kullanicilara e - posta gonderilebilmesi icin "" cronjob tanimlaması yapılıyor ."
"site modelinde her save işlemi sonrasında "" kabul e - postalarının onaylama tarihi bitiminde e - postası gönderilmemis kullanicilara e - posta gonderilebilmesi icin "" cronjob tanimlaması yapılıyor ."
simple wrapper around django 's login view
simple wrapper around django 's logout view
initialize the underlying dictionary for our statistics .
return all unique error codes stored .
add the fact that the error was seen in the file .
generate statistics for the prefix and filename .
create a key from : class:`flake8.style_guide . error ` .
determine if this key matches some constraints .
initialize our statistic .
create a statistic from a : class:`flake8.style_guide . error ` .
increment the number of times we 've seen this error in this file .
initialize the object .
set the source code context for this error .
return the message to print to the user .
return the source code lines for this error .
create a new error group and return it .
yield all registered codes .
"output the registry as restructuredtext , for documentation ."
initialize object to find config files .
read and parse the config file specified on the command - line .
find and generate all local config files .
find all local config files which actually exist .
parse all local config files into one config object .
find the user - level config file .
parse the user config file into a config object .
initialize the mergedconfigparser instance .
check if the specified config parser has an appropriate section .
parse and return the local configuration files .
parse and return the user configuration files .
parse and return the file specified by --config .
merge the parsed user and local configuration files .
parse and return the local and user config files .
monkey - patch the specified module with the appropriate stdin .
set the package / module up for plugins management .
get master passwd ( md5 encrypted )
"update account @param title : account title @param description : account description @param account : account name / username , emailaddr , .... @param secret : secret text from user @param password : password , it will not get updated if value is none @param tagids : a list of related tagids"
"add a user input account to database @param title : account title @param description : account description @param account : account name / username , emailaddr , .... @param password : password @param secret : the secret text from user @param tagids : a list of related tagids"
agent update apart from training the q function
"image preprocessing from the paper playing atari with deep reinforcement learning , 2013 takes an rgb image and converts it to grayscale , downsizes to 110 x 84 and crops to square 84 x 84 , taking bottomost rows of image"
"convert a dict of param ranges into a list parameter settings corresponding to a line search of the param range for each param all other parameters set to default vals note that this is order - preserving , as required by design"
no action needed here for exhaustive trials
no action needed here for exhaustive trials
convenient method to get exp at [ last_ind ]
初始化 参数 ： path：数据存放位置根目录
加载用于计算的数据列表 参数 ： type：选取的数据集类型 train 训练集 dev 开发集 test 测试集
获取数据的数量 当wav数量和symbol数量一致的时候返回正确的值，否则返回-1，代表出错 。
读取数据，返回神经网络输入值和输出值矩阵(可直接用于神经网络训练的那种 ) 参数 ： n_start：从编号为n_start数据开始选取数据 n_amount：选取的数据数量，默认为1，即一次一个wav文件 返回 ： 三个包含wav特征矩阵的神经网络输入值，和一个标定的类别矩阵神经网络输出值
数据生成器函数，用于keras的generator_fit训练 batch_size : 一次产生的数据量 需要再修改 。 。 。
定义cnn / lstm / ctc模型，使用函数式模型 输入层：39维的特征值序列，一条语音数据的最大长度设为1500（大约15s ） 隐藏层一：1024个神经元的卷积层 隐藏层二：池化层，池化窗口大小为2 隐藏层三：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层四：循环层、lstm层 隐藏层五：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层六：全连接层，神经元数量为self . ms_output_size，使用softmax作为激活函数 ， 输出层：自定义层，即ctc层，使用ctc的loss作为损失函数
训练模型 参数 ： datapath : 数据保存的路径 epoch : 迭代轮数 save_step : 每多少步保存一次模型 filename : 默认保存文件名，不含文件后缀名
读取数据，返回神经网络输入值和输出值矩阵(可直接用于神经网络训练的那种 ) 参数 ： n_start：从编号为n_start数据开始选取数据 n_amount：选取的数据数量，默认为1，即一次一个wav文件 返回 ： 三个包含wav特征矩阵的神经网络输入值，和一个标定的类别矩阵神经网络输出值
数据生成器函数，用于keras的generator_fit训练 batch_size : 一次产生的数据量 需要再修改 。 。 。
定义cnn / lstm / ctc模型，使用函数式模型 输入层：39维的特征值序列，一条语音数据的最大长度设为1500（大约15s ） 隐藏层一：1024个神经元的卷积层 隐藏层二：池化层，池化窗口大小为2 隐藏层三：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层四：循环层、lstm层 隐藏层五：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层六：全连接层，神经元数量为self . ms_output_size，使用softmax作为激活函数 ， 输出层：自定义层，即ctc层，使用ctc的loss作为损失函数，实现连接性时序多输出
训练模型 参数 ： datapath : 数据保存的路径 epoch : 迭代轮数 save_step : 每多少步保存一次模型 filename : 默认保存文件名，不含文件后缀名
读取数据，返回神经网络输入值和输出值矩阵(可直接用于神经网络训练的那种 ) 参数 ： n_start：从编号为n_start数据开始选取数据 n_amount：选取的数据数量，默认为1，即一次一个wav文件 返回 ： 三个包含wav特征矩阵的神经网络输入值，和一个标定的类别矩阵神经网络输出值
数据生成器函数，用于keras的generator_fit训练 batch_size : 一次产生的数据量 需要再修改 。 。 。
初始化 参数 ： path：数据存放位置根目录
加载用于计算的数据列表 参数 ： type：选取的数据集类型 train 训练集 dev 开发集 test 测试集
获取数据的数量 当wav数量和symbol数量一致的时候返回正确的值，否则返回-1，代表出错 。
读取数据，返回神经网络输入值和输出值矩阵(可直接用于神经网络训练的那种 ) 参数 ： n_start：从编号为n_start数据开始选取数据 n_amount：选取的数据数量，默认为1，即一次一个wav文件 返回 ： 三个包含wav特征矩阵的神经网络输入值，和一个标定的类别矩阵神经网络输出值
数据生成器函数，用于keras的generator_fit训练 batch_size : 一次产生的数据量 需要再修改 。 。 。
定义cnn / lstm / ctc模型，使用函数式模型 输入层：39维的特征值序列，一条语音数据的最大长度设为1500（大约15s ） 隐藏层一：1024个神经元的卷积层 隐藏层二：池化层，池化窗口大小为2 隐藏层三：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层四：循环层、lstm层 隐藏层五：dropout层，需要断开的神经元的比例为0.2，防止过拟合 隐藏层六：全连接层，神经元数量为self . ms_output_size，使用softmax作为激活函数 ， 输出层：自定义层，即ctc层，使用ctc的loss作为损失函数，实现连接性时序多输出
训练模型 参数 ： datapath : 数据保存的路径 epoch : 迭代轮数 save_step : 每多少步保存一次模型 filename : 默认保存文件名，不含文件后缀名
获取wav文件最终输入的特征向量的函数 参数 ： wav_file : wav文件对象 返回值 ： 神经网络可直接用的输入层向量
compute mfcc features from an audio signal . 从一个声音信号中计算mfcc特征向量 args : 参数 ： signal : the audio signal from which to compute features . should be an n*1 array 通过这个声音信号计算特征向量，它应当是一个n*1的数组 samplerate : the samplerate of the signal we are working with . 要处理的信号的采样率 conf : feature configuration 特征的配置
compute fbank features from an audio signal . 从一个声音信号中计算fbank特征向量 args : 参数 ： signal : the audio signal from which to compute features . should be an n*1 array 要计算特征的声音信号，一个n*1维的数组 samplerate : the samplerate of the signal we are working with . 要处理信号的采样率 conf : feature configuration 特征的配置
compute log - fbank features from an audio signal .
compute ssc features from an audio signal .
convert a value in hertz to mels
convert a value in mels to hertz
compute a mel - filterbank .
apply a cepstral lifter the the matrix of cepstra .
compute the first order derivative of the features
concatenate the first order derivative to the features
concatenate the first and second order derivative to the features
tests a regression in pgctl where services using pgctl - poll - ready fail to stop because the background process started by pgctl - poll - ready is n't dying quickly .
"attempt to show the user a better message on failure , and handle the race condition"
idempotent start of a service or group of services
idempotent stop of a service or group of services
"forcefully stop a service ( i.e. , ` kill -9 ` all processes locking on ` self.path.strpath ` )"
ensure that the scratch directory exists and symlinks supervise .
"run supervise(1 ) , while ensuring it is properly symlinked ."
returns an environment dict to use for running supervise .
pytest creates some weird pipe on fd3 when running under xdist this prevents tests from ending due to subprocesses
wait for all subprocesses to finish .
solve the linear assignment problem using the hungarian algorithm .
the hungarian algorithm .
steps 1 and 2 in the wikipedia page .
"cover each column containing a starred zero . if n columns are covered , the starred zeros describe a complete set of unique assignments . in this case , go to done , otherwise , go to step 4 ."
"find a noncovered zero and prime it . if there is no starred zero in the row containing this primed zero , go to step 5 . otherwise , cover this row and uncover the column containing the starred zero . continue in this manner until there are no uncovered zeros left . save the smallest uncovered value and go to step 6 ."
"construct a series of alternating primed and starred zeros as follows . let z0 represent the uncovered primed zero found in step 4 . let z1 denote the starred zero in the column of z0 ( if any ) . let z2 denote the primed zero in the row of z1 ( there will always be one ) . continue until the series terminates at a primed zero that has no starred zero in its column . unstar each starred zero of the series , star each primed zero of the series , erase all primes and uncover every line in the matrix . return to step 3"
"add the value found in step 4 to every element of each covered row , and subtract it from every element of each uncovered column . return to step 4 without altering any stars , primes , or covered lines ."
"find the first prime element in the specified row . returns the column index , or -1 if no starred element was found ."
clear all covered matrix cells
alexnet network architecture with random parameters . parameters can be loaded using ` ` neupy.storage ` ` module .
validate discrete matrix .
context manager that catches output in terminal and returns stringio instance .
compare two network arcitectures .
add to image name prefix that identify python versions .
context manager that initialize figure that should contain figure that should be compared with expected one .
make a reproducible train for gradient descent based neural network with a xor problem and return trained network .
function generate different possible variations of one vector . that feature useful for testing algorithms input data .
"decorator identifies tests that involve image comparison . before run test function check if environemnt variable ` skip_plot_test ` exists and has non - empty value . if it exists , step will be skipped ."
when pipeline state is n't passed or failed the pipeline should be assumed to be in progress .
handle physical line after tab expansion .
handle processing after each token processed .
handle processing at end of statement .
handle processing at end of block .
handle processing at end of function .
handle processing at end of class .
handle processing at end of module .
handle processing at end of run .
compute the metric given all needed info known .
initialize class with user - defined keywords .
pretty print token .
display accel cal for a log file
"calculate a 8 - bit checksum of the key fields of a message , so we can detect incompatible xml changes"
merge enums between xml files
configparser write method modified to correct process data from / to json write an .ini - format representation of the configuration state .
returns readme.md contents as str
gets the html to display for recaptcha
submits a recaptcha request for verification . returns recaptcharesponse for the request
convert note to int
convert int to note
transpose a note
encode an ean13 barcode
"given a flattened idx , return the position in the 3d image space ."
"given a position in the 3d image space , return a flattened idx ."
returns true iff the window is minimized or has been sent to the tray
convert a string to bytes .
"given foreground / background ansi color codes , return a string that , when printed , will format the supplied string using the supplied colors ."
"returns a string that , when printed , will display the supplied string in ansi bold ."
returns boolean indicating whether or not the supplied stream supports ansi color .
"this will only work if you have django - celery installed ( for now ) . in case you only need to work with status codes to find out if the workers are up or not . this will only work if we assume our db only contains "" active workers "" . to use this feature , you must ensure you use only named workers , for example : "" -n worker1@localhost:8000 "" . http://docs.celeryproject.org/en/latest/userguide/workers.html#starting-the-worker"
f - measure from precision and recall scores .
equal error rate ( eer )
look at the url and mid . returns true iff an email was sent
"find all messages in the html data , return true iff at least one email was sent"
add command line arguments for launchpad to the argument parser
return a live launchpad connection
"returns a transformed , triangulated copy of the mesh"
"object / edit mode get mesh , use bmesh_to_object ( ) to write back ."
object / edit mode update the object .
calculate the surface area .
check if any faces self intersect
caller must remove .
"constructor for a document that can take text using the simpletag xml format , or a set of entities and relations with associated text ."
string representation of document
string representation of document
add an entity to this document
add a relation to this document
add a sentence to this document
clones the document
get all the classes ( i.e. indices of relation types ) for all the candidate relations ( of a given n - ary ) in this document .
get all the candidate relations ( of a given n - ary ) in this corpus .
get the entities for this document
get the entity ids for the entities in this document
get a mapping of entity ids to entities
get a mapping of entity ids to entity types
get a mapping of entity ids to source entity ids
get the relations associated with the document
get a mapping of source entity ids to entity ids
get the source filename for the document
get the text associated with the document
remove all relations in this corpus
load a set of documents with annotations from pubmed given a list of pubmed ids ( pmids )
constructor for vectorizer class with options for what features to use and whether to normalize using tfidf
"get the names for each feature ( i.e. each column in matrix generated by the fit_transform ( ) and transform ( ) functions . fit_transform ( ) must have already been used , i.e. the vectorizer needs to have been fit to training data ."
fit the vectorizer to a training corpus ( using the candidate relations found in the corpus ) and vectorize the candidate relations to generate the feature matrix .
vectorize the candidate relations to generate the feature matrix . must already have been fit .
constructor for token class
create a csvclient for use with ibis
returns the keyword arguments for instantiating the form . include ` ` questions ` ` for initiating survey .
make text bold .
"print the decrypted content of the configuration file . - in : an opened "" msd "" file ."
print the decrypted content of the given string . - in : the hexadecimal string representing the encrypted configuration .
generates the bar code .
list the available bar codes .
list the available image formats .
calculates the upc - a checksum .
calculates a upc - a code checksum .
builds the bar code pattern .
returns an ascii representation of the bar code .
test : py : func:`upca.build ( ) ` .
test : py : func:`upca.calculate_checksum ( ) ` .
test : py : func:`upca.__init _ _ ( ) ` .
test : py : func:`upca.validate ( ) ` .
( int ): code checksum .
return the path to the test data files .
returns all repeats in ` ` rl ` ` with a p - value below a certain threshold .
returns all repeats in ` ` rl ` ` with a divergence below a certain threshold .
returns all repeats in ` ` rl ` ` with a attribute below ( above ) a certain threshold .
returns all repeats in ` ` rl ` ` none - overlapping with ` ` rl_fixed ` ` .
returns all none - overlapping repeats in ` ` rl ` ` .
helper method to test the overlap of ` ` repeat1 ` ` and ` ` repeat2 ` ` .
do two trs share at least one char ?
do two trs share at least one pair of chars with common ancestry ?
create string for repeatlist instance .
read ` ` repeatlist ` ` from file .
serialize and write ` ` repeatlist ` ` instances .
filter ` ` repeats ` ` according to ` ` func_name ` ` .
cluster ` ` repeats ` ` according to ` ` overlap_type ` ` .
test tineyeapi.backlink object .
test tineyeapi.match object .
test tineyeapi.tineyeresponse object .
test methods with api sandbox .
test if tineyeapi.tineyeresponse contains total_results .
initialization of grass environmental variables ( except gisrc ) .
"create grass mapset in current directory . mapsets name is ' mapset ' . at the end , grass will believe , it has run correctly ."
create default wind file
set grass environmental variables
text exception raise from maxfilesize
convert a list of ranges to a set of numbers : :
convert a list of numbers to a list of ranges : :
args : base_class ( type ): the base model class .
sets the converter strategy to the given function .
builds a custom json deserialization strategy .
builds a custom json serialization strategy .
convert match object into json : return : json data containing match info
return a list of sources files / directories ( to check with flake8 / pylint )
"return the verbosity setting of the currently running unittest program , or none if none is running ."
"happens when the user really wants to open a completion list , even if a function call is needed ."
"happens when it would be nice to open a completion list , but not really neccesary , for example after an dot , so function calls wo n't be made ."
"happens when the user wants to complete his word , and if neccesary , open a completion list after that ( if there is more than one completion )"
"find the completions and create the autocompletewindow . return true if successful ( no syntax error or so found ) . if complete is true , then if there 's nothing to complete and no start of completion , wo n't open completions and return false . if mode is given , will open a completion list only in this mode ."
return a pair of lists of completions for something . the first list is a sublist of the second . both are sorted .
lookup name in a namespace spanning sys.modules and _ _ main.dict _ _
create a new mutex -- initially unlocked .
test the locked bit of the mutex .
"atomic test - and - set -- grab the lock if it is not set , return true if it succeeded ."
"lock a mutex , call the function with supplied argument when it is acquired . if the mutex is already locked , place function and argument in the queue ."
"unlock a mutex . if the queue is not empty , call the next function with its argument ."
"wrapper function that initializes curses and calls another function , restoring normal keyboard / screen behavior on error . the callable object ' func ' is then passed the main window ' stdscr ' as its first argument , followed by any other arguments passed to wrapper ( ) ."
build an assignment statement
a function call
a list comprehension of the form [ xp for fp in it if test ] .
check that something is n't an attribute or function name etc .
works like ` does_tree_import ` but adds an import statement if it was not imported .
"will reuturn node if node will import name , or node will import * from package . none is returned otherwise . see test cases for examples ."
dummy implementation of thread.start_new_thread ( ) .
dummy implementation of thread.exit ( ) .
dummy implementation of thread.get_ident ( ) .
dummy implementation of thread.allocate_lock ( ) .
dummy implementation of thread.stack_size ( ) .
set _ interrupt flag to true to have start_new_thread raise keyboardinterrupt upon exiting .
dummy implementation of acquire ( ) .
release the dummy lock .
create a new hashing object and return it .
create a new hmac object .
update this hashing object with the string msg .
return a separate copy of this hashing object .
return a hash object for the current state .
return the hash value of this hashing object .
"like digest ( ) , but returns a string of hexadecimal digits instead ."
pstats.add_callers should combine the call results of both target and source by adding the call time . see issue1269 .
return the application 's base uri ( no path_info or query_string )
"return the full request uri , optionally including the query string"
update ' environ ' with trivial defaults for testing purposes
remove an event from the queue .
execute events until the queue is empty .
return the name and optional version number of a provision .
判断股票id对应的证券市场 : param stock_code : 股票id : return ' sh ' or ' sz '
"识别验证码，返回识别后的字符串，使用 tesseract 实现 : param image_path : 图片路径 : param broker : 券商 [ ' ht ' , ' yjb ' , ' gf ' ] : return recognized : verify code string"
"获得用于查询的默认日期 , 今天的日期 , 以及30天前的日期 用于查询的日期格式通常为 20160211 : return :"
creates a new object pretreated input data .
return a list of entries in the table or single entry if there is an pk .
updates the object by primary_key :
delete the object by primary_key :
update the object directly .
delete the object directly .
a deterministic function of x and y
a non - deterministic function of x and y
test basic running of a dill - encoded function
test dispatching of a task to the multiprocessing pool
test apply_async on a class method
test apply_async on a non - deterministic class method
test that the tree kernel works on a simple example
test that the tree kernel works on a larger example
test that rcolgem is initialized as expected
test that an si tree is correctly simulated
test that si2 reduces to si when beta1 = = beta2
checks the distribution of a kinetic energy trajectory .
checks the equipartition of a simulation trajectory .
parameters ---------- argument : string or list of strings message : string
parameters ---------- message : string
parse client country and ppb country
parse client id
parse client name
parse client state and ppb state
parse client status
parse client contact name
parse client description
parse client state or local government status
create contact based on given contact name
returns stock balance quantity at given warehouse on given posting date or current date .
get incoming rate based on valuation method
get average value of serial numbers
get valuation method from item or default
get fifo ( average ) rate from queue
"split serial nos , validate and return list of valid serial nos"
"create two default territories , one for home country and one named rest of the world"
"update activity feed and create todo for creation of item , customer , vendor"
test notification config entries for targets as percentages
apply shipping rule on given doc . called from accounts controller
sort shipping rule conditions based on increasing from value
output a list of available data calls .
output the methodology for a given data call .
"return data for a single data call , possibly including some line - oriented maninpulation ."
recursively remove all but the first item in lists .
"select one or more data items , optionally using fnmatch ( * ) wildcards ."
overidden api method that converts ' . ' usage to ' [ ] ' indexing .
take a list or a dict and return a formatted string .
process the command line from the user and print a response to stdout .
internal method for responding to a command line .
output the public ripestat - text version label .
output the given lines in a whois style format .
convert positional key = value arguments to a python dict .
convert the ssh key to its fingerprint
"the ` sshkey ` 's ` ` i d ` ` field , or if that is not defined , its ` ` fingerprint ` ` field . if neither field is defined , accessing this attribute raises a ` typeerror ` ."
the endpoint for general operations on the individual ssh key
fetch & return a new ` sshkey ` object representing the ssh key 's current state
"update ( i.e. , rename ) the ssh key"
delete the ssh key
make sure info works
make sure the c option works
make sure the i option works
make sure the c and i options work together
make sure the t option works
make sure info raises an exception if not given a file name
test list_instances function in awss .
test invalid response exception
test api response exception
test api response exception
test withdraw api response exception
"calculate reads coverage over gene body , from 5'to 3 ' . each gene will be equally divided into 100 regsions . bigfile is bigwig format file"
print progress into stderr and log file
tile maf blocks onto an interval . the resulting block will span the interval exactly and contain the column from the highest scoring alignment at each position .
factory class method for chain
crate a chain of collinear rings from the given components .
"return the slice entry ( in a bed6 format ) , as is in the chain header"
"return a bed6 entry , thus does coordinate conversion for minus strands"
"parse a .chain file into a list of the type [ ( l{chain } , arr , arr , arr ) ... ]"
factory method for an epoitem
"load an entire file in the epo format into a dictionary of the type { gab_id = > [ epoitem , ... ] }"
"self.cigar = > [ ( length , type ) ... ] iterate the cigar"
return a list of ( 0 - based half - open ) intervals representing the match regions of the cigar
read a length - prefixed string
"read the next maf block from ` file ` and return as an ` alignment ` instance . if ` parse_i_rows ` is true , empty components will be created when e rows are encountered ."
"read a line from provided file , skipping any blank or comment lines"
parse list of key = value strings into a dict
read the maf block at the current position in ` file ` and return an instance of ` alignment ` .
the ctcf primary site motif
reads one image file from imgloc
reads all captcha files and their labels from directory . directory should have this structure as provided by the problem : -directory -input -0.txt -1.txt - ... -output -0.txt -1.txt - ...
external identifier to pass to the cloud .
human readable version of external .
apply the config information to the current logging config .
construct a pretty table output
generate output for webapp results
"strict : bool if true will throw 400 error if args are defined and not in request default : bool if true , wo n't return defaults args : dict the args to parse , if none , self.attrs will be used"
create a single new object
retrieve a single object
"update an object , new attrs should be passed in the payload"
delete a object
"retrieve several objects . filters can be set in the payload on the different fields of the object , and a limit can be set in there as well"
"creating several objects . payload should be : > > > payload [ { attr1 : val1 , attr2 : val2 } , { attr1 : val1 , attr2 : val2 } ]"
"updating several objects . payload should be : > > > payload [ [ obj_id1 , { attr1 : val1 , attr2 : val2 } ] [ obj_id2 , { attr1 : val1 , attr2 : val2 } ] ]"
"will delete several objects , a list of their ids should be in the payload"
will return each i d that was n't found in the database .
sort articles by year and month .
return string identifying database name that stores alerts for specified identifier . : param owner_id : : return :
"find string s in statement of type t in csp policy p. : param p : full policy string : param t : policy type to search in , such as script - src , style - src etc : param s : string to find : return : true if found , false otherwise"
invoked by flask when json parsing fails on request.get_json ( ) call
generate new identifier : return :
"obtain real client ip address , either directly or from cloudflare headers . : param req : : return :"
get client geolocation country from nginx or cloudflare variable . : return : country code such as pl
"helper function . copy an existing sw4 input file , add ` name ` to the filename , open the new file in append mode and write the string to the end of the file ."
place stations to record synthetics on a line .
place stations to record synthetics on a line .
place stations to record synthetics at specific locations .
place stations to record synthetics at specific locations .
returns an http basic authentication encrypted string given a valid username and password .
"decode an encrypted http basic authentication string . returns a tuple of the form ( username , password ) , and raises a decodeerror exception if nothing could be decoded ."
parse a patch to extract the description and or bug if it exists
get file deltas from a patch using diffstat
creates a sources_path . returns exception when it arises
retrieves a patch format from /debian / source / format
determines whether a ` _ format ` is supported
retrieves the patch series from debian / patches / series
parse a file deltas summary to create links to debsources
"parse a list of patches available in ` series ` and create a dict with important information such as description if it exists , file changes ."
parse exuberant ctags tags file
"returns the packages prefixes ( a , b , ... , liba , libb , ... , y , z ) cache_dir : the cache directory , usually comes from the app config"
"return all versions of a packagename . if suite is specified , only versions contained in that suite are returned . if suite order is specified , then ordering is suite first and then by debian version ."
"return versions with suites . if suite is provided , then only return versions contained in that suite . if as_object is true , the version is returned as a package object with suites list added to it ."
"returns the path hierarchy with urls , to use with ' you are here : ' [ ( name , url(name ) ) , ( ... ) , ... ]"
"returns the filetype and permissions of the folder / file on the disk , unix - styled ."
"returns places in the code where a ctag is found . tuple ( count , [ sliced ] results )"
return suiteinfo of a ` suite `
count files with ` checksum `
returns the package filtered by name ` pkg ` filter by ` suite `
get non exact package result based on name ` pkg ` filter by ` suite `
filter ` result ` with suite
returns a list of files whose hexdigest is checksum . filter with package
return a list of files with a specific ` path ` and ` package ` filter with ` suite `
get packages filter by ` prefix `
get the list of packages
count the packages
"retrieve license of file using its ` path ` , ` package ` and ` version `"
get ratio of machine readable files in ` suite `
add solver to losses
choose which param to restore
the main function that runs training
convert a scipy sparse matrix to a tensorflow sparsetensorvalue .
generate an adjacency matrix out of a given segmentation .
"return a strong strong prime deterministically determined from the input parameters , and what remains of the seed ."
"return true if alpha , 2*alpha+1 , and 2*(2*alpha+1 ) + 1 are invertible modulo p , and false otherwise ."
"return a list of len(max_indexes ) indexes computed from the seed , such that 0 < = indexes[i ] < max_indexes[i ] . also return what remains from the seed ."
tries to validate a hostname .
tries to validate an ip .
"parse mimikatz 2.0 output and return 4 lists : msv1_0 , kerberos , wdigest , and tspkg results found"
parse hashdump output and return a unique set of hashes .
"returns a random string of "" length "" characters . if no length is specified , resulting string is in between 6 and 15 characters ."
take a number and modulus and return an obsucfated form .
"called by a particular module , save ' data ' to pillage_output_path / module_name / target/[timestamp]filename"
"take a powershell command , encode it properly with base64 and build the architecture - independent launcher command ."
return the local ip .
"change text color for the linux terminal , defaults to green ."
print a long title : message with our standardized formatting . wraps multiple lines into a nice paragraph format .
print a option description message in a nicely wrapped and formatted paragraph .
sorts a list of ips in place .
"take a veil - evasion shellcode object , extract out options and build a handler script if possible ."
get the url to this acme challenge : return : the url as a string
@param [ string ] secret in the form of base32 @option options digits [ integer ] ( 6 ) number of integers in the otp google authenticate only supports 6 currently @option options digest [ callable ] ( hashlib.sha1 ) digest used in the hmac google authenticate only supports ' sha1 ' currently @returns [ otp ] otp instantiation
"@param [ integer ] input the number used seed the hmac usually either the counter , or the computed integer based on the unix timestamp"
"turns an integer to the oath specified bytestring , which is fed to the hmac along with the secret"
adds options to control notifications .
display a nsusernotification on mac os x > = 10.8
swizzle [ nsbundle bundleidentifier ] to make nsusernotifications work .
returns a dictionary of the response headers .
returns a given response header .
perform requests .
custom error messages for exception
cfr . http://flask.pocoo.org/docs/0.12/patterns/sqlalchemy/
description : send an email args : email : type : string example : test email
userpostsample - a model defined in swagger
gets the data of this userpostsample . # noqa : e501
sets the data of this userpostsample .
returns true if both objects are equal
test case for 1
test case for 1_0
test case for 1_1
test case for 1_2
test case for 2
test case for 2_0
test case for 2_1
test case for 3
test case for 3_0
test case for 4
test case for 4_0
test some common primes .
"convert a coordinate string like ' b12 ' to a tuple ( ' b ' , 12 )"
convert a coordinate to an absolute coordinate string ( b12 - > $ b$12 )
convert a column number into a column letter ( 3 - > ' c ' )
convert a column index into a column letter ( 3 - > ' c ' )
convert a column name into a numerical index ( ' a ' - > 1 )
"convert a range string into a tuple of boundaries : ( min_col , min_row , max_col , max_row ) cell coordinates will be converted into a range with the cell at both end"
get individual addresses for every cell in a range . yields one row at a time .
get individual addresses for every cell in a range . yields one row at a time .
"convert an excel style coordinate to ( row , colum ) tuple"
convert a worksheet range to the sheetname and maximum and minimum coordinate indices
split statements at semicolons ignoring the ones inside quotes and comments . the comment symbols that come inside quotes should be ignored .
"normalize_form_dict(form , attr_list ) - > a dictionary of ( attr , value )"
"normalize_formset_dict(formset , attr_list ) - > a list of dictionary of ( attr , value )"
"denormalize_form_dict(data_dict , form , attr_list ) - > a querydict with the attributes set"
"denormalize_formset_dict(data_dict , form , attr_list ) - > a querydict with the attributes set"
"as a convenience , we remove trailing semicolons from queries ."
initialize the design from a valid form data .
returns an hqldesign from the serialized form
": param property_type : ' settings ' , ' file resources ' , or ' functions ' : param properties : list of properties as dict : param req_attr_list : list of attributes that are required keys for each dict item"
returns the serialized form of the design in a string
test binding in a date
test binding in a python 2.3 and higher date time
test binding in a date after setting input sizes to a string
test binding in a null
test binding in a date array
test binding in a date array ( with setinputsizes )
test binding in a date array ( with arrayvar )
test binding in / out a date array ( with arrayvar )
test binding out a date array ( with arrayvar )
test binding out with set input sizes defined
test binding in / out with set input sizes defined
test binding out with cursor.var ( ) method
test binding in / out with cursor.var ( ) method
test cursor description is accurate
test that fetching all of the data returns the correct results
test that fetching data in chunks returns the correct results
test that fetching a single row returns the correct results
adds a new authentication method . assumes not more than one authentication method per authncontext specification .
given the authentication context find zero or more places where the user could be sent next . ordered according to security level .
create a password hash from a given string for protecting a worksheet only . this will not work for encrypting a workbook .
set a password on this sheet .
"return the password value , regardless of hash ."
"set a password directly , forcing a hash step ."
statement : name equals expression
statement : expression
expression : expression plus expression | expression minus expression | expression times expression | expression divide expression | expression exp expression
expression : minus expression % prec uminus
expression : lparen expression rparen
expression : number
expression : name
convert from a datetime to a timestamp string .
convert from a timestamp string to a datetime object .
convert a time value to fractions of day
convert a timedelta value to fractions of a day
reads an int specified buffer into a string and returns the string and the new offset in the buffer
"given bytes and the current bytes offset , return the type , state , path , and new offset"
"given bytes and the current bytes offset , return a : class:`replyheader ` instance and the new offset"
tests making migrations with django 1.7 + 's migration framework
"download(results , format ) - > httpresponse"
"searchdataadapter(results , format , db ) - > headers , 2d array of data ."
create a sha1 digest credential
"given a scheme and credential , return an : class:`acl ` object appropriate for use with kazoo ."
create a digest acl for zookeeper with the given permissions
create a password hash from a given string .
return the name of the app from installed_apps that is most recently present on the call stack .
"returns one of the classifiers ' dav ' , ' xmlpost ' , or ' browser ' , depending on the imperative logic below"
called if no url matches .
the main wsgi application . dispatch the current request to the functions from above and store the regular expression captures in the wsgi environment as ` myapp.url_args ` so that the functions from above can access the url placeholders .
create a new des cipher .
resolves to the web page or the websocket depending on the path .
"return all rows , and any cells that they contain"
write worksheet data to xml .
write worksheet columns to xml .
write merged cells to xml .
write conditional formatting to xml .
write data validation(s ) to xml .
write worksheet hyperlinks to xml .
add link to drawing if required
write a worksheet to an xml file .
test binding in a timestamp
test binding in a null
test binding out with set input sizes defined
test binding in / out with set input sizes defined
test binding out with cursor.var ( ) method
test binding in / out with cursor.var ( ) method
test cursor description is accurate
test that fetching all of the data returns the correct results
test that fetching data in chunks returns the correct results
test that fetching a single row returns the correct results
"cast an xml attribute that should be a boolean to a python equivalent none , ' f ' , ' 0 ' and ' false ' all cast to false , everything else to true"
read in custom numeric formatting rules from the shared style table
read in the list of indexed colors
read in the dxfs effects - used by conditional formatting .
read in the fonts
read in the list of fills
read in the boarders
extract named styles
extract style names . there can be duplicates in which case last wins
extract individual cell styles
read styles from the shared style table
"convert a coordinate string like ' b12 ' to a tuple ( ' b ' , 12 )"
convert a coordinate to an absolute coordinate string ( b12 - > $ b$12 )
convert a column letter into a column number ( e.g. b - > 2 )
convert a column number into a column letter ( 3 - > ' c ' )
"check string coding , length , and line break character"
cast value to int or float if necessary
coerce values according to their explicit type
"given a value , infer the correct data type"
"given a value , infer type and display options ."
"return the value , formatted as a date if needed"
set the value and infer type and display options .
set value and display for hyperlinks in a cell
return the hyperlink target or an empty string
"return the i d pointed to by the hyperlink , or none"
set a new formatting code for numeric values
check if the parent worksheet has a style for this cell
returns the : class:`openpyxl.style . style ` object for this cell
return the data type represented by this cell
return the coordinate string for this cell ( e.g. ' b12 ' )
return the coordinate string for this cell ( e.g. ' b12 ' )
returns a cell location relative to this cell .
returns whether the value is * probably * a date or not
used to store call info .
convert the text form of a ttl to an integer .
return one of the standard format codes by index .
return the i d of a standard style .
returns a dictionary mapping of job names together with their respective application class .
statement : expression
find the deepest match to i{name } in the dictionary .
normalizes paths .
creates a local file system for a given app 's help directory .
views and renders a file at a given path .
return a fresh instance of a shake256 object .
continue hashing of a message by consuming the next chunk of data .
compute the next piece of xof output .
generate ` _ _ init _ _ ` function based on tpayload.default_spec
create a signature object : class:`dss_sigscheme ` that can perform ( ec)dsa signature or verification .
create a new digital signature standard ( dss ) object .
return ` ` true ` ` if this signature object can be used for signing messages .
produce the dsa / ecdsa signature of a message .
check if a certain ( ec)dsa signature is authentic .
see 2.3.2 in rfc6979
see 2.3.3 in rfc6979
see 2.3.4 in rfc6979
generate k in a deterministic way
"verify that sha-1 , sha-2 or sha-3 are used"
verify that sha-[23 ] ( 256|384|512 ) bits are used to match the 128 - bit security of p-256
initialize the design from a valid form data .
returns sqldesign from the serialized form
"in 1.6 , the ` user.username ` field gained some validation rules to check that it conformed to a particular regex . unfortunately we use to support a more liberal username scheme . the proper solution would be to use our own custom user model , but that touches a lot of code . it 's easier if we just modify the regular expression inside the username validator ."
html representation of a dataset .
html representation of a databook .
a subclass of gauge should implement this method
constructor expects a callable
returns the result of callback which is executed each time
constructor accepts initial value
getter returns current value
setter changes current value
nothing to reverse migrate here
perform an ssl handshake ( usually called after renegotiate or one of set_accept_state or set_accept_state ) . this can raise the same exceptions as send and recv .
"works like a blocking call to ssl_read ( ) , whose behavior is described here : http://www.openssl.org/docs/ssl/ssl_read.html"
"works like a blocking call to ssl_write ( ) , whose behavior is described here : http://www.openssl.org/docs/ssl/ssl_write.html"
"send "" all "" data on the connection . this calls send ( ) repeatedly until all data is sent . if an error occurs , it 's impossible to tell how much data has been sent ."
checks for a syntactically valid email address .
base64 decodes and then inflates according to rfc1951
deflates and the base64 encodes a string
returns a string of random ascii characters or digits
returns rndstr always as a binary type
creates an unique sid for each session . 160 - bits long so it fulfills the saml2 requirements which states 128 - 160 bits
"expects a file with each line being composed of the oid for the attribute exactly one space , a user friendly name of the attribute and then the type specification of the name ."
: param identity : a dictionary with fiendly names as keys : return :
generates a signature . all strings are assumed to be utf-8
checks that the signature is correct
safely and consistently format numeric values
rem . *
[ a - z][a - z0 - 9 ] *
redact a string using the global redaction engine .
"` add_redaction_filter ` injects the redaction filter into all of the ` logger ` handlers . this must be called after all of the handlers have been added to ` logger ` , otherwise those handlers may expose unredacted strings ."
insure that password.__eq _ _ hashes test value before compare .
get all the identity information that has been received and are still valid about the subject .
get session information about a subject gotten from a specified idp / aa .
stores session information in the cache . assumes that the subject_id is unique within the context of the service provider .
scrap the assertions received from a idp or an aa about a special subject .
"returns all the entities of assertions for a subject , disregarding whether the assertion still is valid or not ."
another name for entities ( ) just to make it more logic in the idp scenario
returns the status of assertions from a specific entity_id .
return identifiers for all the subjects that are in the cache .
add fonts part to root return { font.crc = > index }
write styles combinations based on ids found in tables
create a new mac object .
authenticate the next chunk of message .
"return a copy ( "" clone "" ) of the hmac object ."
return the * * binary * * ( non - printable ) mac tag of the message authenticated so far .
verify that a given * * binary * * mac ( computed by another party ) is valid .
return the * * printable * * mac tag of the message authenticated so far .
verify that a given * * printable * * mac ( computed by another party ) is valid .
returns full file path for test files .
opens filename with encoding and return its contents .
convenience factory for creating chart data series .
return a list of parameters in the various fields
change the values of the model object by replacing the param variables with actual values .
"return the concrete action object , not just a generic oozieaction"
return a newly saved instance .
multiply two polynomials in gf(2 )
"compute division of polynomials over gf(2 ) . given a and b , it finds two polynomials q and r such that :"
initialize the element to a certain value .
"return the field element , encoded as a 128 - bit integer ."
"return the field element , encoded as a 16 byte string ."
return the inverse of this element in gf(2 ^ 128 ) .
split a secret into * n * shares .
"recombine a secret , if enough shares are presented ."
create a new mac object .
authenticate the next chunk of message .
update a block aligned to the block boundary
"return a copy ( "" clone "" ) of the cmac object ."
return the * * binary * * ( non - printable ) mac tag of the message that has been authenticated so far .
return the * * printable * * mac tag of the message authenticated so far .
utility function for the zeromqlogrecord .
retrieves email from inbox
returns the number of emails in inbox
returns a list of messages subjects
returns a list of message ids
returns a message object with a subject line
returns a message object by i d
returns a filtered list of messages by where message.field = value
"takes a merged table , and a pair of columns that constitute a certain match . returns statistics on the number of good matches found etc ..."
makes the json response to a call to the api
add a twitter api response .
get tweets by all of the accounts that have users .
get tweets by all of the accounts that have users .
all public tweets from this account .
all public favorites from this account .
adds the tweet object in media.tweet to the many - to - many relationship in media.tweets
"adds a ` scrobble_count ` field to the queryset 's objects , and orders the results by that , descending ."
pre - fetch all the tracks ' artists .
pre - fetch all the albums ' artists .
"given a list of dictionaries , return the first key encountered in the first dict so given datalist = [ { ' name ' : ' name1 ' , ' val1 ' : ' val1 ' } , { ' name ' : ' name2 ' , ' val ' : ' val2 ' } ] we can get only the second item : get_components(datalist , ( ' name ' , ' name2 ' ) )"
: param base_url : url to connect to : type base_url : str : param username : username for querying : type username : str : param password : password for querying : type password : str : param verify : whether to accept self - signed ssl : type verify : bool : param organization : organization to use : type organization : str : returns : katelloconnection object : rtype : katelloconnection
"succesively query the api , appending "" ? page=<int > "" to the url , each time incrementing the int by one . when we get no results , return the collected data ."
dynamically defer the requested attribute to the api
call the katello api ( https://url / katello / api / v2 )
call the foreman api ( https://url / api / v2 )
get the organizational i d of our organization
get the compute profiles
create a compute profile
add the compute attributes to the compute profiles
get the hosts that belong to a host_collection
: param c_id : content view i d : type c_id : int or str : param data : additional post data : type data : dict : return : json output of the api query : rtype : dict
: param c_id : content view i d : type c_id : int or str : param data : additional post data : type data : dict : return : json output of the api query
: param v_id : content view i d : type v_id : int or str : return : json output of the api query
"to be overloaded if specific initialization code is needed . shall return true if setup has succeeded , otherwise shall return false ."
to be overloaded if specific termination code is needed .
shall return a operation object that contains the operations that you want fuddly to perform .
this action is executed after data has been sent to the target and that all blocking probes have returned . but just before data is logged .
is the object out of sync with its file .
return the full path to the file .
overwrite the file with new contents and update its created time .
points of entry are not up - to - date until they 're run .
go up the call graph and return all calls that happened before the given one .
"set up the environnment , ran before every tests ."
create some basic projects to work with .
test the get_version function of the custom backend .
test the get_versions function of the custom backend .
test the check_feed method of the pecl backend .
"set up the environnment , ran before every tests ."
create some basic projects to work with .
test the get_version function of the custom backend .
test the get_versions function of the custom backend .
split the tag ' { http://cs.sfsu.edu/csc867/myscheduler}patients ' ns = http://cs.sfsu.edu/csc867/myscheduler name = patients
parse a xml file to a dict
parse a string
"assert when the environment is set to dev , the dev topic is used ."
"assert when the environment is set to prod , only the prod topic is used ."
assert that messages about platforms we do n't support are handled gracefully
libraries.io events should n't create projects if the configuration is off .
assert that a libraries.io event about an unknown project creates that project
assert failures to create projects are logged as errors .
assert that a libraries.io event about an existing project updates that project
assert that when an existing project fails a version check nothing happens
"assert when libraries.io and anitya disagree on version , it 's logged"
used to reload a : class:`user ` object from the session .
load a user from a flask request by examining the ` ` authorization ` ` header .
a decorator for api functions that enforces authentication .
"set up the environnment , run before every test"
create some basic projects to work with .
test the get_version function of the crates backend .
assert an exception is raised if a project does n't exist and get_version is called
test the get_versions function of the crates backend .
test the get_ordered_versions function of the crates backend .
assert we handle getting non - json responses gracefully
assert http urls are handled by requests
assert http urls are handled by requests
assert finding versions with a simple regex in text works
assert prefixes are stripped from regex matches
assert prefixes are sliced rather than lstripped
assert regex that result in tuples are joined into a string
assert an exception is raised if no matches are found
"method called to retrieve the latest version of the projects provided , project that relies on the backend of this plugin ."
"method called to retrieve all the versions ( that can be found ) of the projects provided , project that relies on the backend of this plugin ."
return a generator over the latest 40 uploads to pypi
colapse outer dimensions into one and preserve inner dimension this allows for easy cpu convolution in numpy
build a list of test arguments .
perform an fprop path and beam search on a given set of network inputs .
arguments : t ( int ): time step z_list ( list of tensors ) : fprop outputs for all beams
"generates the hdf file with the data for testing arguments : fn ( str ): filename lshape ( tuple / list ): shape of the input data n ( int ): number of data points ( input / output pairs ) mean ( optional , tuple / list or ndarray ): mean values"
generates dictionary with the required parameters to describe this object
helper function for downloading test files will download and unzip the file into the directory self.path
helper to validate passed path directory and append any subsequent filename arguments .
download the file specified by the given url .
"method that generates the data set iterators for the train , test and validation data sets . this method needs to set the instance data_set attribute to a dictionary of data iterators ."
helper method to get the data iterator for specified dataset
helper method to return training set iterator
helper method to return validation set iterator
helper method to return test set iterator
returns a dictionary of arg_name : default_values for the input function
class constructor .
"helper method to check whether the definition dictionary is defining a nervanaobject child , if so it will instantiate that object and replace the dictionary element with an instance of that object"
returns the class name .
returns the full module path .
returns a ` ` dict ` ` that contains all necessary information needed to serialize this object .
dump image number ` image_index ` in data ` index ` to a random file in ` output_directory ` .
generate random filename
"parses possible language description header from a file . if a header is found returns it as dict , otherwise returns none ."
resolves dependencies and returns the list of actual language filenames
"wraps a language file content for the browser build . the "" compressed "" parameter selects which wrapping code to use :"
glues files together for the browser build .
"return a dict with label , callback , altclick , js , and css lists"
an iterator for a template string that yields on line breaks
create a technical server error response . the last three arguments are the values returned from sys.exc_info ( ) and friends .
return a dictionary containing traceback information .
return html version of debug 500 http error page .
"returns context_lines before and after lineno from file . returns ( pre_context_lineno , pre_context , context_line , post_context ) ."
returns the traceback frames as a list
return the same data as from traceback.format_exception .
test for newlines .
test for multiple lines .
test for double quotes .
test output .
test fuzzy .
test end comment .
"this method is called when a prototype is created "" statically "" :"
"this method is called when a prototype is created "" dynamically "" :"
test input .
associates a namespace handler to a namespace uri .
"returns the namespace handler associated to the given uri . if there is none the default namespace handler will be returned , and a warning message will be issued ."
returns true if there is namespace handler associated to the given uri .
returns a dictionary that defines the schema for the given element .
return host .
return username .
return password .
return credentials for current user .
construct and return the url for a specific api service .
"send http request , and return the success and the result on success ."
queries changes visible to the caller .
retrieves a change .
"retrieves a change with labels , detailed labels , detailed accounts , and messages ."
returns the version of the gerrit server .
lists the caches of the server . caches defined by plugins are included .
flush all caches
flushes a cache .
retrieves information about a cache .
retrieves a summary of the current server state .
lists the capabilities that are available in the system .
"lists the tasks from the background work queues that the gerrit daemon is currently performing , or will perform in the near future ."
"retrieves a task from the background work queue that the gerrit daemon is currently performing , or will perform in the near future ."
"kills a task from the background work queue that the gerrit daemon is currently performing , or will perform in the near future ."
"test : open firmware.gzip , scan for signatures . verify that only one gzip signature was detected ."
description : login into the system
description : logout the user from the system
"perform the initialization of resource handling data here , after the superclass initialization"
start the internal driver resource mgmt mechanisms
perform the cleanup of the internal driver mechanisms .
assign the value of one resource or configuration parameter in the gcs
acquire the value of one resource or configuration parameter in the gcs
acquire the current status of one resource or configuration parameter in the gcs
check if the current value of one resource or configuration parameter in the gcs is correct or incorrect
"enable or disable a gcs link ( tm , tc or others )"
"check if a gcs link ( tm , tc or others ) is enabled or disabled"
"perform the initialization of data here , after the superclass initialization"
start the internal driver task mechanisms
perform the cleanup of the internal driver task resources .
invoked by the system in order to start a gcs task .
invoked by the system in order to stop a gcs task .
invoked by the system in order to check the status of a gcs task .
invoked by the system in order to open a telemetry display on the gcs
invoked by the system in order to print a telemetry display from the gcs
invoked by the system in order to close a telemetry display on the gcs
helper function . performs simple cull algorithm
simple cull . can recursively determine all fronts .
assumes models in lexicographical sorted .
nsga2 based sorting
productfeature x_i * x_i**2 = = x_i**3
the main part of exp4.p.
return the action to perform
reward the previous action with reward .
update reward_time and rewards .
"get the previous context , recommendations and rewards with history_id ."
"get the previous unrewarded context , recommendations and rewards with history_id ."
add a history record .
add reward to a history record .
"get the previous context , recommendations and rewards with history_id ."
"get the previous unrewarded context , recommendations and rewards with history_id ."
add a history record .
add reward to a history record .
find all files under ' path '
"find all files under ' dir ' and return the list of full filenames . unless dir is ' . ' , return full filenames with dir prepended ."
return a list all python packages found within directory ' where '
"all the packages found in ' where ' that pass the ' include ' filter , but not the ' exclude ' filter ."
does a directory look like a package ?
"given a list of patterns , return a callable that will be true only if the input matches at least one of the patterns ."
"construct the command for dist , updating vars(self ) with any keyword parameters ."
converts the type of lookups specified in a foreignkey limit_choices_to attribute to a dictionary of query parameters
outputs a < ul > for this set of radio fields .
helper function for building an attribute dictionary .
"initializes on the given sequence -- may take lists , tuples , numpy arrays of x , y pairs , or point objects . if point objects are used , ownership is _ not _ transferred to the linestring object ."
allows iteration over this linestring .
returns the number of points in this linestring .
returns a tuple version of the geometry from the coordinate sequence .
internal routine that returns a sequence ( list ) corresponding with the given function . will return a numpy array if possible .
returns a numpy array for the linestring .
returns the line merge of this linestring .
returns a list or numpy array of the x variable .
returns a list or numpy array of the y variable .
returns a list or numpy array of the z variable .
a decorator for connecting receivers to signals . used by passing in the signal ( or list of signals ) and keyword arguments to connect : :
create a new signal .
connect receiver to sender for signal .
disconnect receiver from sender for signal .
send signal from sender to all connected receivers .
send signal from sender to all connected receivers catching errors .
"filter sequence of receivers to get resolved , live receivers ."
for geos unary topology functions .
python 3 implementation of execfile .
"monkey - patch tempfile.tempdir with replacement , ensuring it exists"
context in which imported modules are saved .
> > > _ needs_hiding('setuptools ' ) true > > > _ needs_hiding('pkg_resources ' ) true > > > _ needs_hiding('setuptools_plugin ' ) false > > > _ needs_hiding('setuptools.__init _ _ ' ) true > > > _ needs_hiding('distutils ' ) true > > > _ needs_hiding('os ' ) false > > > _ needs_hiding('cython ' ) true
remove references to setuptools ' modules from sys.modules to allow the invocation to import the most appropriate setuptools . this technique is necessary to avoid issues such as # 315 where setuptools upgrading itself would fail to find a function declared in the metadata .
"run a distutils setup script , sandboxed in its directory"
"always return a dumped ( pickled ) type and exc . if exc ca n't be pickled , wrap it in unpickleableexception first ."
restore and re - raise any exception
run ' func ' under os sandboxing
"called to remap or validate any path , whether input or output"
called for path inputs
called for path outputs
"called for path pairs like rename , link , and symlink operations"
called for path inputs
"called for path pairs like rename , link , and symlink operations"
called for low - level os.open ( )
get a urlopen ( ) replacement that uses ca_bundle for verification
"return an existing ca bundle path , or none"
protect against re - patching the distutils if reloaded
patch write_pkg_file to also write requires - python / requires - external
workaround issue # 197 - python 3 prior to 3.2.2 uses an environment - local encoding to save the pkg_info . monkey - patch its write_pkg_info method to correct this undesirable behavior .
patch func_name in target_mod with replacement
patch functions in distutils to use standalone microsoft visual c++ compilers .
"move everything under ` src_dir ` to ` dst_dir ` , and delete the former ."
"list tags ( py_version , abi , platform ) supported by this wheel ."
is the wheel is compatible with the current platform ?
install wheel as an egg directory .
returns a list of the create table sql statements for the given app .
returns a list of the drop table sql statements for the given app .
returns a list of the sql statements used to flush the database .
returns a list of the custom table modifying sql statements for the given app .
returns a list of the create index sql statements for all models in the given app .
returns a list of the drop index sql statements for all models in the given app .
serve static files below a given point in the directory structure .
"process a directive which either adds some files from ` ` allfiles ` ` to ` ` files ` ` , or removes some files from ` ` files ` ` ."
translate a shell - like wildcard pattern to a compiled regular expression .
pre - parse the command line to extract the value of the --testrunner option . this allows a test runner to define additional command line arguments .
"oracle refuses to change a column type from / to lob to / from a regular column . in django , this shows up when the field is changed from / to a textfield . what we need to do instead is : - add the desired field with a temporary name - update the table to transfer values from old to new - drop old column - rename the new column"
"get the properly shortened and uppercased identifier as returned by quote_name ( ) , but without the actual quotes ."
generates temporary names for workarounds that need temp columns
this is my first my_sol2 function
this is my second my_sol2 function
this is my third sol2 function
error in serialized tree
initialize htmlserializer .
import a dotted module path and return the attribute / class designated by the last name in the path . raise importerror if the import failed .
import a dotted module path and return the attribute / class designated by the last name in the path . raise improperlyconfigured if something goes wrong .
auto - discover installed_apps modules and fail silently when not present . this forces an import on them to register any admin bits they may want .
redirect to a given url while setting the chosen language in the session or cookie . the url and the language code need to be specified in the request parameters .
returns all formats strings required for i18n to work
"returns "" identity "" versions of the javascript i18n functions -- i.e. , versions that do n't actually do anything ."
returns the selected language catalog as a javascript library .
returns the given session dictionary serialized and encoded as a string .
returns true when there is no session_key and the session is empty
returns session key that is n't being used .
"lazily loads session from storage ( unless "" no_load "" is true , when only an empty dict is stored ) and stores it in the current instance ."
get the number of seconds until the session expires .
get session the expiry date ( as a datetime object ) .
"sets a custom expiration for the session . ` ` value ` ` can be an integer , a python ` ` datetime ` ` or ` ` timedelta ` ` object or ` ` none ` ` ."
"returns ` ` true ` ` if the session is set to expire when the browser closes , and ` ` false ` ` if there 's an expiry date . use ` ` get_expiry_date ( ) ` ` or ` ` get_expiry_age ( ) ` ` to find the actual expiry date / age , if there is one ."
removes the current session data from the database and regenerates the key .
"creates a new session key , whilst retaining the current session data ."
returns true if the given session_key already exists .
creates a new session instance . guaranteed to create a new object with a unique key and will have saved the result once ( with empty data ) before the method returns .
"saves the session data . if ' must_create ' is true , a new session object is created ( otherwise a createerror exception is raised ) . otherwise , save ( ) can update an existing object with the same key ."
"deletes the session data under this key . if the key is none , the current session key value is used ."
loads the session data and returns a dictionary .
remove expired sessions from the session store .
returns a list of filenames referenced in sys.modules and translation files .
checks for changed code using inotify . after being called it blocks until a change event has been fired .
returns a _ pointer _ to c geos geometry object from the given wkb .
returns the wkb representation of the given geometry .
"ensures that we always use an absolute uri in any location header in the response . this is required by rfc 2616 , section 14.30 ."
proxy initializes on the given geometry class ( not an instance ) and the geometryfield .
"this accessor retrieves the geometry , initializing it using the geometry class specified during initialization and the hexewkb value of the field . currently , only geos or ogr geometries are supported ."
"this accessor sets the proxied geometry with the geometry class specified during initialization . values of none , hexewkb , or wkt may be used to set the geometry as well ."
drop out insert parameters for null placeholder . needed for oracle spatial backend due to # 10888
"returns a 3 - tuple of class import path ( or just name if it lives under django.db.migrations ) , positional arguments , and keyword arguments ."
"takes the state from the previous migration , and mutates it so that it matches what this migration would perform ."
performs the mutation on the database schema in the normal ( forwards ) direction .
"performs the mutation on the database schema in the reverse direction - e.g. if this were createmodel , it would in fact drop the model 's table ."
outputs a brief summary of what the action does .
"returns true if there is a chance this operation references the given model name ( as a string ) , with an optional app label for accuracy ."
"returns true if there is a chance this operation references the given field name , with an optional app label for accuracy ."
returns if we 're allowed to migrate the model .
returns the default wsgi handler for the runner .
"runs the server , using the autoreloader if needed"
checks to see if the set of migrations on disk matches the migrations in the database . prints a warning if they do n't match .
function to create a cache backend dynamically . this is flexible by design to allow different use cases :
get a treewalker class for various types of tree with built - in support
convert the string from rest to an xhtml fragment .
"returns the contenttype object for a given model , creating the contenttype if necessary . lookups are cached so that subsequent lookups for the same model do n't hit the database ."
"given * models , returns a dictionary mapping { model : content_type } ."
lookup a contenttype by id . uses the same shared cache as get_for_model ( though contenttypes are obviously not created on - the - fly by get_by_id ) .
"clear out the content - type cache . this needs to happen during database flushes to prevent caching of "" stale "" content type ids ( see django.contrib.contenttypes.management.update_contenttypes for where this gets called ) ."
insert a contenttype into the cache .
returns the python model class for this type of content .
"returns an object of this type for the keyword arguments given . basically , this is a proxy around this object_type 's get_object ( ) model method . the objectnotexist exception , if thrown , will not be caught , so code that calls this method should catch it ."
returns all objects of this type for the keyword arguments given .
return a list all python packages found within directory ' where '
find all files under ' dir ' and return the list of full filenames ( relative to ' dir ' ) .
"in https://github.com/pypa/setuptools/pull/837 , we discovered python 3.3.0 exposes the extension suffix under the name ' so ' ."
"> > > bytes2human(128991 ) ' 126 k ' > > > bytes2human(100001221 ) ' 95 m ' > > > bytes2human(0 , 2 ) ' 0.00b '"
"i 'd love to use uuid.uuid4 , but this is 20x faster"
` ` encoding ` ` determines the encoding used to interpret any ` ` str ` ` objects decoded by this instance ( utf-8 by default ) . it has no effect when decoding ` ` unicode ` ` objects .
should display table of address references
should display n / a for tag when there are no tag bits
should display n / a for index when there are no index bits
should display n / a for offset when there are no offset bits
should display table for direct - mapped / set associative cache
should correctly display table for fully associative cache
get_addr_refs should return correct reference data
should return string representation of reference
retrieves all indices where hits occur in a list of ref statuses
read_refs_into_cache should work for direct - mapped lru cache
read_refs_into_cache should work for set associative lru cache
read_refs_into_cache should work for fully associative lru cache
read_refs_into_cache should work for fully associative mru cache
should initialize table with required parameters and default values
should initialize table with optional parameters if supplied
should return the correct ascii separator string
should correctly display title
should not display title if not originally supplied
should correctly display table when left - aligned
should correctly display table when center - aligned
should correctly display table when right - aligned
same as : meth:`urllib3.connectionpool . httpconnectionpool.urlopen ` with custom cross - host redirect logic and only sends the request - uri portion of the ` ` url ` ` .
change to root directory of the git repo containing this file
get set of changed locale files
make file at path writeable by the user
make file read only
copy staged changes to other path location
check if the bluetooth controller is available .
scan for bluetooth devices .
scan for bluetooth devices and return a ds4 device if found .
wait for new ds4 devices to appear .
"find the cameras connected to this machine , and return them in order of quality . that means try gphoto2 first , then webcam , then pi camera ."
parse an erratically formatted string . return a list of icalendar . calendar entries .
"take a list of icalendar . calendar entries ; format it as a list of events in html , returned as a string . writes to icalendar format as an intermediary because that 's the easiest way to get icalendar . calendar to parse its date"
card separation is
initialize update object
list of available updates
update the device
parse json data
initialize an update object
initialize result . to be used as a result indicator
: param repo_name : name of a repository that contains branches of interest : type repo_name : str
: param url : url for the protection endpoint of a branch that should be marked as protected : type url : str
save function as at command .
% s format_string -- format and print a string .
% s -- capitalize the string .
% s n -- drop n elements from list / string .
% s pattern -- return none if arg is not equal to pattern .
% s -- filter results by value has length
% s -- extract the first element / character of a list / string
% s n -- get the n - th element / character from list / string .
% s separator -- concatenate a list / string with intervening occurrences of separator
% s -- same as join but separator set as ' '
% s regexp -- replace in a string / list regexp to '' .
% s -- get last element / character of incoming list / string .
% s -- return length of list / string .
% s -- make the string is lowercase
% s function -- apply the following function to each element / character in list / string .
% s -- remove ansi colors from string .
% s pattern -- return none if arg is equal to pattern .
% s regexp -- filter results by regexp . leave ungrepped
% s from to -- replace in a string / list from to to .
% s -- reverse list / string .
% s pattern -- return the string with trailing pattern removed .
% s regexp -- filter results by regexp
% s -- sort list / string .
% s separator -- return a list of the substrings of the string splited by separator
% s -- same as split by splited a string by whitespace characters
% s pattern -- return the string with leading and trailing pattern removed .
% s -- same as strip but trims a whitespaces .
% s -- extract the elements after the head of a list
% s n -- take n elements from list / string .
% s -- make the string is uppercase .
"helper function to parse user search query . : param query : the search query . : return : ( list of tags , rating )"
combine a rating string and multiple tag lists into a single search string . : param rating : the rating . : param join_str : the character to join the list . : param tags : the lists of tags . : return : a single search string .
"process a list of tags to separate them into two lists . : param site : the site of the tags : param tags : the list of tags . : param data_manager : the datamanager object . : return : two lists of tags . the first one are the list of tags that are in the db , the second one are the list of tags that are n't in the db ."
"parse the post list to return the file url and its tags . : param post_list : the post list . : param url_formatter : a callable to get the file url . : param tag_key : the key to get the tag string . : return : a tuple of ( file url , list of tags )"
generate tags to retry the search if no results were found . : param site : the site name . : param safe_queries : the search tags that are in the db . : param unsafe_queries : the search tags that are not in the db . : param data_manager : the datamanager object . : return : a list of tags that are either in the db or matched with one in the db .
"get function call parameters for a site . : param site : the site name . : param api_key : the danbooru api key , not required for other sites . : param user : the danbooru username , not required for other sites . : return : ( request url , file url formatter , key for the tag string )"
: return : true if there 's nothing playing and nothing in queue .
"try to get a member from the context . : param ctx : the context . : param ex : the exception to be raised if member can not be found . : return : the member . : raises : ex , see : param ex"
"extract all leading mentions from a message . : param msg : the message . : return : a tuple of ( list of ids , the leftover message ) > > > s = ' < @1212 > asd < @45642 > ' > > > leading_mentions(s ) ( [ 1212 ] , ' asd < @45642 > ' ) > > > s1 = ' asd < @!454545 > asd ' > > > leading_mentions(s1 ) ( [ ] , ' asd < @!454545 > asd ' ) > > > s2 = ' < @45><@!245><@8787 > dsads<@154545 > ' > > > leading_mentions(s2 ) ( [ 45 , 245 , 8787 ] , ' dsads<@154545 > ' )"
"get leading mentions as members from a message . : param ctx : the discord context . : param msg : the message . : return : a tuple of ( a list of mentioned members , leftover message )"
find a member by full name with discriminator . : param bot : the bot . : param name : the full name . : return : the member if found .
check if the system is linux . : return : true if the system is linux .
check if the system is macos . : return : true if the system is macos .
get memory usage by this process in mib. : return : the memory usage in mib.
get total system memory in mib. : return : total system memory in mib
fallback function to get system name . : return : system name from /etc / issue if the file exists else system release
get the current system name . : return : the current system name .
"initialises this mjpgstreamer against the given ` img_path , and ip : port combination , then starts the server as a daemon thread . args : img_path : the path to obtain jpeg imagery from ip : ip to bind the server to port : port to bind the server to"
generator that yields the second newest file by modified time in the given ` path ` . the second newest file is yielded so that files in the process of being written are not used before they are complete ; this is generally not an issue that the second newest file faces .
generates jpeg bytes from any image file in the given path based on the second newest file modified in the given ` path ` .
create a mjpgstreamhandler with the ` img_path ` set inside of it .
initialization steps for new object .
load the configuration file and return its contents in lines .
parse the configuration file and return a dictionary of values .
initilization process for newly instantiated classes .
save an instance of a bayesloop study class to file .
load an instance of a bayesloop study class that was saved using the bayesloop.save ( ) function .
parse uniformly args and kwargs from a templatetag
hook for overriding in subclasses .
"modification of adaboostclassifier , has modified reweighting procedure ( as described in article ' new approaches for boosting to uniformity ' ) . in the simplest case ( voting='mean ' ) we use the mean of neighbours ' predictions . : param uniform_variables : list of variables along which uniformity is desired ( i.e. [ ' mass ' ] ) : param base_estimator : any sklearn classifier which support weights ( i.e. decisiontreeclassifier ( ) ) : param n_estimators : number of base classifiers to be trained : param learning_rate : float , the ' size of step ' : param n_neighbours : number of neighbours to use : param uniform_label : : param train_variables : variables to use in training ( usually these should not include ones from uniform_variables ) : param ( str|callable ) voting : string , describes how we use predictions of neighbour classifiers . possible values are : ' mean ' , ' median ' , ' random - percentile ' , ' random - mean ' , ' matrix ' ( in the ' matrix ' case one should also provide a matrix to fit method . matrix is generalization of )"
builds the corresponding url to an external resource given a valid xref identifier . valid xref identifiers are defined in the do_xref.config file that should be found in the same directory as this module .
provide a simple widget for a boolean option key
provide a single widget to change a numeric key
create a range widget for key types like ( tt )
create a widget for choosing between a list of selections
append a new named section for multiple entries with ` heading `
append an entry to a named section .
reset whole view and keys to their defaults
built all entries and sections
called once the user enteres a new search query .
called once the view is visible . delay save of settings .
called once the view gets out of sight . revert or apply .
callback for the apply button .
callback for the reset button .
called when a key in gsettings changes .
called on ctrl - enter
configures the logging module for running tests . this automatically binds the helpers in lib.logutils and captures output into a specified file . supplying none to the parameters will result in defaults .
generates a flattened iterator of all registered tests from the supplied test suite . use it for pretty - printing / logging only .
generates and returns an argparse . argumentparser instance for use with parsing test - related options .
main method . discovers and runs tests in the ' tests ' subdirectory .
"returns a complete buffered line , if one exists , and removes it from the buffer . if a complete line does not exist , this returns none , and no modifications are made to the buffer ."
dummy wrapper around the logger log statement . this method exists to provide a better funcname in the log record .
receives messages and logs them using the test runner log level .
receives the ' close ' event . this writes out any pending buffered data and then calls the parent ' close ' method .
"starts the worker thread , running an infinite loop waiting for jobs ."
joins the underlying thread for this worker .
clears the locally held reference to the task pool and thread handle .
"retrieves the currently held thread handle , if any ."
sets the thread handle for the worker .
retrieves the parent task pool .
"retrieves the name from the thread handle , if available ."
sets the name of the held thread handle .
converts a .mat file to the appropriate json format
handy for json serialization
"return fms git repo path , if any"
true if fms dir is a git repo
use git rev - parse to get given commit hash
return git status output
true if git repo is clean
isnonevalidation should log due to smiles parse error .
an empty smiles produces a mol with not atoms .
"fragmentvalidation should identify 1,2 - dichloroethane ."
"fragmentvalidation should identify 1,2 - dimethoxyethane ."
neutralvalidation should identify net overall charge .
isotopevalidation should identify atoms with isotope labels .
utility function that returns the charge parent smiles for given a smiles string .
test neutralization of ionized acids and bases .
test preservation of zwitterion .
choline should be left with a positive charge .
this should have the hydrogen removed to give deanol as a charge parent .
sodium benzoate to benzoic acid .
benzoate ion to benzoic acid .
charges in histidine should be neutralized .
no organic fragments .
no organic fragments .
larger inorganic fragment should be chosen .
smaller organic fragment should be chosen over larger inorganic fragment .
test table salt .
test reionizer moves proton to weaker acid .
test charged carbon does n't get recognised as alpha - carbon - hydrogen - keto .
reionization should not infinitely loop forever on these molecules .
test forced charge correction maintaining overall neutral charge .
test forced charge correction with no corresponding proton for neutralization .
custom resonanceenumerate options allow unconstrained charges .
shift worms values by an approximation of the removed background . i used the top95 of the unmasked area . i am assuming region of the background is kept .
reformat image for the model .
calculate the probability of worm using the class_model and save into table_to_save . table_to_save must be passed by reference
use a pre - trained nn to identify blobs that correspond to worms or worm aggregates
"opencv function to return a skeletonized version of img , a mat object"
modified version of getroimask optimized to highlight the food patch
get the best the best fit to a circle using the hough transform .
estimate the food contour from a binary mask . 1 ) get the best the best fit to a circle using the hough transform . 2 ) transform the mask into polar coordinates centered in the fitted circle . 3 ) get the closest point to the circle using 2*n_bins angles . 4 ) smooth using lowess fitting ( good to ignore outliers ) to estimate the food contour . 5 ) transform back into cartesian coordinates .
identify the contour of a food patch . i tested this for the worm rig . it assumes the food has a semi - circular shape . the food lawn is very thin so the challenge was to estimate the contour of a very dim area .
detect which is the target web application back - end database management system .
class constructor .
render an edge description suitable for use in a gml file using the set internal attributes .
render an edge suitable for use in a pydot graph using the set internal attributes .
render an edge description suitable for use in a gml file using the set internal attributes .
render an edge update description suitable for use in a gml file using the set internal attributes .
"create an orphan field at specified address : field_cls(fieldset , * args , * * kw )"
replaces union all select with union select
this function calls a class to extract information from the given dbms banner based upon the data in xml file
replaces apostrophe character with its illegal double unicode counterpart
"replaces instances like ' concat(a , b ) ' with ' concat_ws(mid(char(0 ) , 0 , 0 ) , a , b ) '"
connect an event handler to an event . append it to handlers list .
raiser an event : call each handler for this event_name .
"given a pydbg instantiation that at the current time is assumed to have "" crashed "" ( access violation for example ) record various details such as the disassemly around the violating address , the id of the offending thread , the call stack and the seh unwind . store the recorded data in an internal dictionary , binning them by the exception address ."
"for the supplied crash , generate and return a report containing the disassemly around the violating address , the id of the offending thread , the call stack and the seh unwind . if not crash is specified , then call through to last_crash_synopsis ( ) which returns the same information for the last recorded crash ."
dump the entire object structure to disk .
load the entire object structure from disk .
"for the last recorded crash , generate and return a report containing the disassemly around the violating address , the id of the offending thread , the call stack and the seh unwind ."
default profile settings
mark current profile as active
find available tox profiles
new tox instance
load all plugins in plugins folder
new incoming custom lossless packet ( callback )
new incoming custom lossy packet ( callback )
friend with specified number is online
returns list of all plugins
return window or none for specified plugin
enable / disable plugin : param key : plugin short name
new command for plugin
return list of items for menu
"app is closing , stop all plugins"
show tray notification and activate window icon note : different behaviour on different os : param title : name of user who sent message or file : param text : text of message or file info : param tray : ref to tray icon : param window : main window
plays sound notification : param t : type of notification
a basic linux manifest test to ensure that windows specific values are n't used .
generate the list of images which match the provided scale factors .
generates a -webkit - image - set for the provided list of images .
regex replace function which replaces url ( ) with -webkit - image - set .
regex replace function which inserts -webkit - image - set rules .
regex replace function which adds a content style to an < img > .
helper function that adds references to external images available in any of scale_factors in css backgrounds .
regex replace function which removes images for scale factors not in scale_factors .
helper function which removes images in image sets not in the list of supported scale_factors .
helper function that adds references to external images available in other scale_factors and removes images from image - sets in unsupported scale_factors .
returns inlined text of the html document .
returns inlined text of the html document .
returns a set of all filenames inlined by this file .
returns this document translated .
parses and inlines the represented file .
tests a bug where & nbsp ; would not be escaped correctly .
run this test with the given options .
get the page set this test will run on .
"_ _ eq _ _ , _ _ ne _ _ functionality of comparator classes ."
verify _ _ eq _ _ functionality for ignore .
verify listregex match functionality .
test basic equality cases .
test listcontains with strict = true .
test listcontains with strict = false .
the call is not mocked .
replacing mocks for args - only calls .
replacing strict kwargs mock with another strict mock .
replacing strict kwargs mock with nonstrict mock .
matching of arguments containing lists .
strict lookup fails due to extra kwarg .
""" nonstrict lookup passes with extra kwarg ."
deep matching of ignore objects .
regex matching .
lookup matches mutilple results .
test default result matching .
example hook for testing .
return value of hook is used as the final result .
verify default hooks are used .
fill in the profile in question .
creates the argparse parser .
run the copy using a temp file .
load csv |table_file| into a table . return table .
return a creds object from given credentials .
main function .
return the spreadsheetrow corresponding to package=|package| .
upload |_csv_table| to the given google spreadsheet .
upload all rows in table that need to be changed in spreadsheet .
delete all rows from spreadsheet that not found in table .
read a deps file and return all the sections .
stringify a deps dictionary in a pretty way .
stringify an object in a pretty way .
replace all instances of our git server with a git_url var .
"given all the sections in a deps file , write it to disk ."
implements the var syntax .
parses command line arguments .
verifies the sanity of the command arguments .
sets the basic logging configuration .
runs the unit tests .
javascript snippet for finding an element with a given text on a page .
closes all tcp sockets held open by the browser .
a write_test_result should call port.diff_image with tolerance=0 in case of failurereftestmismatch .
simulates a remotesh invocation .
test normal functionality .
test failure in remote cmd .
test failure in ssh commad .
test the case of successful reboot .
test case of reboot pending .
test case of connection down .
test case of bad error code returned .
access to chrome://oobe / login page which is neither a tab nor an extension .
"custom_categories is an optional string containing a list of comma separated categories that will be traced instead of the default category set . example : use "" webkit , cc , disabled - by - default - cc.debug "" to trace only those three event categories ."
returns a user - friendly name for the process of the given |cmd_line| .
runs the specific task on the url given .
initialize the cnstestbase with socket_timeout = 60 secs .
launches html test which plays each video and records seek stats .
creates the argparse parser .
"returns the name of the package , omitting the version ."
maps index to a color .
gets the closure of the reverse dependencies of a node .
creates the version map for the input data .
gets the set of divergent packages .
"if all pages fail , no summary is printed ."
clears the browser 's disk and memory cache .
wrap value from client side for chromedriver side .
unwrap value from chromedriver side for client side .
quits the browser and ends the session .
used with filterfn to isolate patches to chromite .
used with filterfn to isolate patches to the manifest .
used with filterfn to isolate patches based on a specific upstream .
returns true if the pool has no patches .
returns a new pool with only patches that match constraints .
returns a new pool with only patches that match constraints .
return a patch pool with only patches to the manifest .
return a patch pool with only patches based on a particular branch .
disable actual uploading .
fill in good values for username and host .
"test normal stats creation , exercising default functionality ."
test normal safe stats creation .
safe stats creation handles exceptions properly .
going for code coverage .
verifies we do n't propagate a given exception during upload .
we do n't propagate timeouts during upload .
we do n't propagate any environment errors during upload .
we propagate keyboardinterrupts .
we timeout when the upload takes too long .
test that we do n't print anything when there are no errors .
""" test exception supression ."
test we propagate some exceptions .
creates a file name with whitespaces and comma in it .
discover all modules in |start_dir| which match |pattern| .
discover all classes in |start_dir| which subclass |base_class| .
use the django builtin static file resolver to return an absolute path usable as css url ( ) argument . sass equivalent of the ' static ' template tag .
generate a list of include paths that libsass should use to find files mentioned in @import lines .
"perform sass.compile , but with the appropriate include_paths for django added"
this method must be otower 💂 verwritten .
"emit this signal on behalf of ` sender ` , passing on kwargs ."
our default is to read ( pollin ) the specified ' io ' file descriptor .
"try to read our i / o for ' timeout ' milliseconds , return none otherwise . this makes calling and reading i / o non blocking !"
we need to poll stdin to receive i3bar messages .
get the full text for the module as well as the partial text if the module is a composite . partial text is the text for just the single section of a composite .
dispatch on_click config parameters to either : - our own methods for special py3status commands ( listed below ) - the i3 - msg program which is part of i3wm
execute the given i3 message and log its output .
"process the event for the named module . events may have been declared in i3status.conf , modules may have on_click ( ) functions . there is a default middle click event etc ."
takes an event dict . logs the event if needed and cleans up the dict such as setting the index needed for composits .
"wait for an i3bar json event , then find the right module to dispatch the message to based on the ' name ' and ' instance ' of the event ."
"returns the interface 's ipv4 address if device exists and has a valid ip address . otherwise , returns an empty string"
build and return our command parser
run a remote command . this is called via the py3status - command utility .
find the module(s ) given the name(s )
refresh the module(s )
send a click event to the module(s )
check the given command and send to the correct dispatcher
remove the socket as it is no longer needed .
main thread listen to socket and send any commands to the commandrunner .
initializes a localvolume .
"since this type is immutable , we do n't need to deepcopy it ."
mark the data invalidated . clients will refetch the volume .
returns a future that maps the result of ` future ` by ` func ` .
calls ` func ( ) ` from a new thread .
"stop the server , invalidating any viewer urls ."
register ` callback ` to run in the server event loop thread .
testing stardog check .
convert package name + resource into a fully qualified resource name
"pkg / typename - > typename , typename - > typename"
"pkg / typename - > pkg , typename - > none"
"split a name into its package and resource name parts , e.g. ' std_msgs / string - > std_msgs , string '"
"check if name is a legal ros name for filesystem resources ( alphabetical character followed by alphanumeric , underscore , or forward slashes ) . this constraint is currently not being enforced , but may start getting enforced in later versions of ros ."
"validates that name is a legal resource base name . a base name has no package context , e.g. "" string "" ."
"drive a left circuit , 50 m on a side ."
drive to home .
setup rc override control .
drive a mission from a file .
drive apmrover2 in sitl .
string converter that human - readable byte size to a number .
: raises parametererror :
: param str readable_size : human readable size ( bytes ) . e.g. 256 m : raises valueerror :
test that multinomial regression with two categories is the same as logistic regression
this test verifies that numerically computing the conjugate is essentially the same as using the smooth_conjugate of the atom
return doc_templater class generator for klasses with objective docs
jags version as a tuple of ints .
return modules directory .
set modules directory .
return a list of loaded modules .
load a module .
unload a module .
create new model instance .
divides iterations into roughly constant time sub - iterations . time necessary to complete a single iteration is estimated as elapsed time divided by all already completed iterations .
"function to insert an html element into another html fragment example : html = ' < p > paragraph1</p><p > paragraph2 ... </p > ' element = ' < a href=""/read - more/"">read more</a > ' --- > ' < p > paragraph1</p><p > paragraph2 ... <a href=""/read - more/"">read more</a></p > '"
"insert an inline "" read more "" link into the last element of the summary : param instance : : return :"
create temporary output and cache folders
remove output and cache folders
test generation of site with the plugin .
test generation of site with the plugin .
get all commits including path without following renames
test generation of site with a generic tag that reads in a config file .
"process the metadata dict , lowercasing the keys and textilizing the value of the ' summary ' key ( if present ) . keys that share the same lowercased form will be overridden in some arbitrary order ."
parse content and metadata of textile files .
convert rgb matplotlib colormap .
colormap periodic / circular data ( phase ) .
zebra palette colormap with nbands broad bands and nentries rows in the color map .
colormap for positive / negative data with gray scale only original from cushman - roisin book cd - rom .
ahvrr colormap used by noaa coastwatch .
parses the api responses for the : py : meth:`route53.connection . route53connection.create_hosted_zone ` method .
: param route53connection connection : the connection instance being used to send the change request . : param str hosted_zone_id : the id of the hosted zone this change set pertains to .
adds a change to this change set .
parses the api responses for the : py : meth:`route53.connection . route53connection.get_hosted_zone_by_id ` method .
cat_thresh parsing threshold for categorical attrs num_thresh parsing threshold for numerical attributes
given data in a list of lists format this returns a list of attribute types
internal method to determine whether data is numerical
internal method to determine whether data is categorical defaults to number of distinct values is n / logn
de - duplicate environment vars and sort them alphabetically .
respond to incoming requests .
validates that incoming requests genuinely originated from twilio
respond and greet the caller by name .
respond to incoming phone calls with a menu of options
respond to incoming calls with a mms message .
respond and greet the caller by name .
define a handler for when the fax is initially sent .
define a handler for when the fax finished sending to us .
send a dynamic reply to an incoming text message
respond to incoming phone calls and mention the caller 's city
respond to incoming calls with a mms message .
respond to incoming phone calls with a menu of options
processes results from the < gather > prompt in /voice
memoization decorator for a function taking one or more arguments .
preprocesses the given image for training .
preprocesses the given image for evaluation .
preprocesses the given image .
crops the given image using the provided offsets and sizes .
crops the given list of images .
performs central crops of the given image list .
subtracts the given means from each image channel .
computes new shape with the smallest side equal to ` smallest_side ` .
resize images preserving the original aspect ratio .
preprocesses the given image for training .
preprocesses the given image for evaluation .
preprocesses the given image .
"returns a network_fn such as ` logits , end_points = network_fn(images ) ` ."
generates cropped_image using a one of the bboxes randomly distorted .
distort one image for training a network .
prepare one image for evaluation .
pre - process one image for training or evaluation .
wrapper around qtgui . qfiledialog.getexistingdirectory static method compatible with pyqt > = v4.4 ( api # 1 and # 2 ) and pyside > = v1.0
"wrapper around qtgui . qfiledialog.getopenfilename static method returns a tuple ( filename , selectedfilter ) -- when dialog box is canceled , returns a tuple of empty strings compatible with pyqt > = v4.4 ( api # 1 and # 2 ) and pyside > = v1.0"
"wrapper around qtgui . qfiledialog.getopenfilenames static method returns a tuple ( filenames , selectedfilter ) -- when dialog box is canceled , returns a tuple ( empty list , empty string ) compatible with pyqt > = v4.4 ( api # 1 and # 2 ) and pyside > = v1.0"
"wrapper around qtgui . qfiledialog.getsavefilename static method returns a tuple ( filename , selectedfilter ) -- when dialog box is canceled , returns a tuple of empty strings compatible with pyqt > = v4.4 ( api # 1 and # 2 ) and pyside > = v1.0"
opens an astviewer window
sets up the main menu .
creates the ui widgets .
cleanup resources .
clears the widgets
opens a python file . show the open file dialog if file_name is none .
opens a file dialog and returns the file name selected by the user
updates the tree and editor widgets .
opens a file and sets self._file_name and self._source code if successful
highlights the node if it has line : col information .
reads the persistent program settings .
writes the view settings to the persistent store
function for testing .
shows the about message window .
called when the window is closed .
closes all windows .
cachehitresponse : drop when served from the cache
testselfansweredtcp : drop after exceeding qps
teeaction : ecs
teeaction : no ecs
finds the frequency of given frequency .
finds the frequency of given parse result frequency .
finds the frequency of given word frequency .
finds the count of distinct items for ngram_type .
finds the count of distinct words . @type unigram_collection : collection @rtype : int
finds the count of distinct parse results . @type unigram_collection : collection @rtype : int
runs the prosail model with the given parameters and returns a wavelength - reflectance array .
return an iterable with theme instances
"done_reding does not mean that the iterator 's buffer is empty . iterator might have done reading from underlying source , but the read chunks might still be available for serving through .next ( ) method ."
"done_reding does not mean that the iterator 's buffer is empty . iterator might have done reading from underlying source , but the read chunks might still be available for serving through .next ( ) method ."
returns int .
called just after the project has been created
called prior to project deletion
start the timer .
clear the timer .
get the measured time elapsed since this timer was started .
convert an requested period to an actual elapsed period of the timer .
convert an actual elapsed period to a period reported by the timer .
@param frequency : clock frequency in hz . @param freqerror : maximum frequency error in parts per million ( ppm ) . the frequency error is assumed to be normally distributed with freqerror corresponding to 3 standard deviations . @param rng : l{np.random . randomstate } from which to draw frequency error .
create virtual timer .
create timer multiplexer .
timer event handler .
load motion capture data from an asf and amc file pair .
consruct a new asfbone .
construct a new asfroot .
get a from the model tree by name .
initialise capture .
load a capture from a file .
save this capture to a file .
list of the devices in this capture .
get a device from the capture by identifier .
initialise captured device .
add data for a sensor on this device .
list of the sensor identifiers on this sensor unit .
get data for a given sensor identifier .
construct environment model .
"writetext(t termbox , x integer , x integer , fg termbox . color , fg termbox . color ) - > none execute a series of change_cell 's in a sequential manner such as to write a line of text"
getcharrange ( ) - > str get a string of the characters that are valid to enter in search mode
filenameclean(filename str ) - > str convert a raw filename to a simplified one that can be searched for
"selectfilesonsearchbuffer(files list[str ] , searchbuffer str ) - > list[str ] return a list of selected files by comparing simplified filenames with the search buffer"
"getfilecolors(mode enum , selected int , thisfile string , filelist list[str ] ) - > ( termbox . color , termbox . color ) takes a bunch of things and returns the color that the given file should be when displayed"
"showthisfile(string , enum , integer ) - > bool returns whether or not the given file should be actually displayed"
"writepath(filename str , path str ) - > none write a string ( usually the path that the calling shell should cd to ) to a file"
"selectedvalueformode(mode enum ) - > list / int return the correct default value for ' selected ' , which can either be a list or an int"
"drawfilelist(t termbox , ystart integer , yend integer , xend integer , mode enum , selected int / list ) - > none draw the list of selected files onto the screen"
"switchmode(prevmode enum , selected int / list ) - > ( enum , int / list , str ) switch the mode to either search or normal and do associated setup for each mode"
"takeactiononpath(f str , path str ) - > ( enum , int / list , str ) do something with a filename that the user selected"
"runcommandonfile(path str , command str ) - > [ does n't return ] close lightning , write the current path , and execute the command"
slicer(num int ) - > f(int ) returns a function that returns the first num characters of the given string
make an authorization for an order . this payment will then be captured when the order is set marked ' shipped ' .
process the transaction and return a processorresult :
"given a prior authorization , capture remaining amount not yet captured ."
release a previously authorized payment .
this is mainly helpful for debugging purposes
a basic description that will be displayed to the user when selecting their shipping options
complex calculations can be done here as long as the return value is a dollar figure
"describes the actual delivery service ( mail , fedex , dhl , ups , etc )"
can be a plain string or complex calcuation returning an actual date
"can do complex validation about whether or not this option is valid . for example , may check to see if the recipient is in an allowed country or location ."
returns the version as a human - format string .
render the url for a google checkout image .
add a subscription and return the results in the requested template .
remove a subscription and return the results in the requested template .
add a subscription and return the results in the requested template .
add a subscription and return the results in the requested template .
"any preprocessing steps should go here for instance , copying the shipping and billing areas"
calculate the tax and return it
delete the named urlpattern .
remove any urls whose names are already in use .
"delete the old urlpattern , and add a new one ."
look up the bestselling products and return in a list
test for audiomd.to_dict ( ) .
find a validator for digital object from given ` fileinfo ` record . : returns : validator class
return validation result
str immutable types call _ _ new _ _ ( ) to instantiate new classes .
return directory object to subdirectory ` < self>/<directory >
return original class attribute ethods or self.subdir(attr ) if attribute does not exist .
"parse command line arguments and run application . : arguments : commandline parameters . : returns : 0 if all ok , otherwise bagiterror(or other exception ) is risen"
check mime type determined by libmagic
test pdf 1.7 ok case
test pdf 1.7 invalid case
test pdf 1.7 wrong version case
"when using a deployment shell , do n't print the returned result to stdout . for example , when the result is superfluous to be printed , because the action itself contains already print statements , while the result can be useful for the caller ."
"if the node has not yet been separated in serveral parallel , isolated nodes per host . do n't do it yet for this function . when anothor action of the same host without this decorator is called , the node will be split ."
"when using role isolation , and several hosts are available , run on only one role . useful for instance , for a database client . it does not make sense to run the interactive client on every host which has database access ."
"give this node action an alias . it will also be accessable using that name in the deployment shell . this is useful , when you want to have special characters which are not allowed in python function names , like dots , in the name of an action ."
set the group for this node .
"test lif spiking network : simulate_brunel_network(short pulse , 1ms , default values )"
returns an oriented elliptic gaussian cloud of 2d points
run one batch of oja 's learning over a cloud of datapoints .
plots the datapoints and the time series of the weights args : data_cloud ( numpy.ndarray ): n by 2 data weights_course ( numpy.ndarray ): n by 2 weights
generates a point cloud and runs oja 's learning rule once . optionally plots the result .
test exponential - integrate - and - fire model
create cross connections .
destroy cross connections .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
initialize zerocross class
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
mandatory method for environment specific switch classes .
verify that client config can be created and reports can be removed .
verify that post command is true .
verify that operation with queue is working .
verify that operation with cmdproc is work .
initialize ipmitool class .
get all available sensor data repository entries .
get all available sensor states for sensor .
method for generating event for sensor with sensor state .
method for clear system event log .
method for check if ipmi is supported by device .
lacp class initialization .
"start / stop / restart protocol , start / stop sending pdu , send marker request , update link parameters after the link has been modified ."
command to retrieve lacp statistics .
create / modify / delete / enable / disable a lacp link .
clean all tcl variables and lacp_dict .
initialize vethcross class .
get port name .
create connections .
destroy connections .
returns set of commands to create / destroy connection between 2 linux network namespaces .
returns set of commands to create / destroy connection between default nns and custom nns .
returns set of commands to create connection between 2 default nns .
create single connection .
destroy single connection .
create single connection .
initialize switchrr class .
parse additional cli logging options .
create a directory .
return loggeradapter for module level logging .
return loggerwrapper for pipe logging .
initialize noerrargumentparser class .
add arguments and save regexps of valid for the instance options in valid_args_cre_list .
filter out invalid options and parse only predefined ones for the instance .
initialize classlogger class .
this method is called from class .
configure and return loggeradapter instance .
return logeradapter instance for module level loging .
setup the object with a logger and a loglevel and start the thread .
return the write file descriptor of the pipe .
"this is the method executed by the thread , it simply read from the pipe ( using a file - like wrapper ) and write the text to log ."
utility method to send the message to the logger with the correct loglevel .
initialize qtrun class .
loading ixncfg file .
execute qt and wait for result .
initialize remotemultihosttg class .
get ports with speed from tg instances .
return ports related to specific tg .
return port 's sequence number in list of ports .
start tg instances .
shutdown tg instances .
start tg instances or get running ones .
stop or release tg instances .
cleanup tg instances .
check tg instances .
perform any necessary operations to leave environment in normal state .
collect sniffed data from all tg instances .
simulate port link connecting ( set it to admin up etc ) .
simulate port link disconnecting ( set it to admin down etc ) .
stop and remove all streams .
set traffic stream with specified parameters on specified tg port .
sends the stream created by ' set_stream ' method .
enable and start streams from the list simultaneously .
disable streams from the list .
starts sniffing on specified interfaces .
clearing statistics on tg ports .
read statistics - framesreceived .
read statistics - filtered frames received .
read statistics - uds3 - capture trigger ( uds3 ) - count of non - filtered received packets ( valid and invalid ) .
clear statistics .
read statistics - framessent .
get port tx rate .
get port rx rate .
get ports rx rate for specific qos .
get qos packets count .
set qos stats type .
set flow control .
get mtu value in host os .
set mtu value in host os .
args : ui_instance(uionpssshell ): ui_onpss_shell instance switch_instance(switchgeneral ): specific switch instance
args : prog(str ): command to search for in the patch
"search for switch drivers and set the name , kernel_module and script accordingly ."
reload the switch driver using the manual reload script .
check is switch driver service is running .
stop the switch driver using the script .
kill the switch driver process .
check if the switch driver process itself is running .
modprobe the switch driver kernel module .
construct clusters uri with optional filters .
construct cluster uri .
makes get /clusters request and returns clustercollection .
makes get /cluster request and returns clusterentity .
makes post /cluster request and returns clusteridentity .
makes patch /cluster request and returns clusteridentity
makes delete /cluster request and returns response object
"> > > coerce(""nan "" ) nan > > > coerce(""nan "" ) nan > > > coerce(""unkn "" ) > > > coerce(""u "" ) > > > coerce(""1 "" ) 1.0 > > > 0.039 < coerce(""4.0000000000e-02 "" ) < 0.041 true > > > 0.039 < coerce(4.0000000000e-02 ) < 0.041 true"
"> > > lines = [ ' 920804700 : nan ' , ... ' 920805000 : 4.0000000000e-02 ' , ... ' 920805300 : 2.0000000000e-02 ' , ... ' 920805600 : 0.0000000000e+00 ' , ... ' 920805900 : 0.0000000000e+00 ' , ... ' 920806200 : 3.3333333333e-02 ' , ... ' 920806500 : 3.3333333333e-02 ' , ... ' 920806800 : 3.3333333333e-02 ' , ... ' 920807100 : 2.0000000000e-02 ' , ... ' 920807400 : 2.0000000000e-02 ' , ... ' 920807700 : 2.0000000000e-02 ' , ... ' 920808000 : 1.3333333333e-02 ' , ... ' 920808300 : 1.6666666667e-02 ' , ... ' 920808600 : 6.6666666667e-03 ' , ... ' 920808900 : 3.3333333333e-03 ' , ... ' 920809200 : nan ' ] > > > g = iterparse(lines ) > > > g.next ( ) ( 920804700 , nan ) > > > g.next ( ) ( 920805000 , 0.04 ) > > > len(list(g ) ) = = len(lines ) - 2 true"
"> > > class testclass(object ): ... pass > > > testclass = testclass ( ) > > > testclass.a = 1 > > > testclass.b = "" 2 "" > > > testclass.c = 3 > > > testclass.d = true > > > buildparameters(testclass , [ "" a "" , "" b "" ] ) [ ' --a ' , u'1 ' , ' --b ' , u'2 ' ]"
register a connection function with a scheme . each connection function must take standard connection arguments and return a dbapi connection object and the module used to connect .
"connect to the given db uri in the format ` ` driver://user : pass@host : port / database_name?param = value ` ` , returning a db - api connection object and the paramstyle used by the db - api module ."
examples : :
examples : :
removes expired tokens from db
for devel purposes we need also index.html of frontend to be executed
"get configuration from settings , format it and return"
"execute a command , redirecting the output to the log ."
"get a specific directory , using some xdg base , with sensible default ."
"get the base fades directory , from xdg or kinda hardcoded ."
"get the config fades directory , from xdg or kinda hardcoded ."
return the interpreter 's full path using pythonx.y format .
return a ' sanitized ' interpreter and indicates if it is the current one .
return latest version of a package .
return a list of dependencies to upgrade .
hit pypi with a http head to check if pkg_name exists .
check if the indicated dependencies actually exists in pypi .
send the cmd info and collected stdout to logger .
retrieves package version from the file .
run parent initialization and then fix the scripts var .
"run parent install , and then save the man file ."
alter the installation path .
create a virtualenv using the virtualenv lib . fades : more>1.6
wait at most a second for the lockchecker to end .
"if post data do n't contain parameter ' quantity ' , then one unit of a requested item should be added ( the quantity defaults to 1 ) ."
"if post data do n't contain parameter ' pk ' , no exception should be raised and the response is expected to contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value is negative , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value is zero , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value ca n't be converted to an integer , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data do n't contain parameter ' pk ' , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data do n't contain parameter ' pk ' , no exception should be raised and the response is expected to contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value is negative , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value is zero , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
"if post data contain parameter ' quantity ' and the associated value ca n't be converted to an integer , then the corresponding exception is expected to be handled by the view , and the response should contain the relevant error message ."
represents a column containing number of positions this is auto - detected via ' poscount ' string search
this function adds one or more joins attaching required aligned corpora to a partial sql query ( query without where and following parts ) .
arguments : conf -- a dictionary containing imported xml configuration of the plugin
arguments : conf -- a dictionary containing ' settings ' module compatible configuration of the plug - in
returns thread - local connection
return a new instance of the plug - in with the same connection parameters .
puts a value into a hash table stored under the passed key
returns a complete hash object (= python dict ) stored under the passed key . if the provided key is not present then an empty dict is returned .
loads data from key->value storage
saves ' data ' with ' key ' .
deletes data with passed access key
tests whether the ' key ' exists in the storage
set auto expiration timeout in seconds .
"increments the value of ' key ' by ' amount ' . if no key exists , the value will be initialized as ' amount '"
set key to value within hash ' name ' for each corresponding key and value from the ' mapping ' dict .
arguments : conf -- a dictionary containing imported xml configuration of the plugin
arguments : conf -- a dictionary containing ' settings ' module compatible configuration of the plug - in
return a new instance of the plug - in with the same connection parameters .
returns a stored list . if there is a non - list value stored with the passed key then typeerror is raised .
add a value at the end of a list
removes and returns the first element of the list stored at key .
returns length of a list . if there is a non - list value stored with the passed key then typeerror is raised .
sets the list element at index to value
trims the list from the beginning to keep_left - 1 and from keep_right to the end . the function does not return anything .
gets a value from a hash table stored under the passed key
puts a value into a hash table stored under the passed key
removes a field from a hash item
returns a complete hash object (= python dict ) stored under the passed key . if the provided key is not present then an empty dict is returned .
gets a value stored with passed key and returns its json decoded form .
saves ' data ' with ' key ' .
set auto expiration timeout in seconds .
removes a value specified by a key
tests whether there is a value with the specified key
"an atomic operation "" set if not exists "" ."
an atomic operation which obtains current key first and then sets a new value under that key
"increments the value of ' key ' by ' amount ' . if no key exists , the value will be initialized as ' amount '"
"set key to value within hash ' name ' for each corresponding key and value from the ' mapping ' dict . before setting , the values are json - serialized"
returns a pbkdf2_hex hash of the passed data with default parameters
returns a pbkdf2_hex hash of the passed data with specified parameters
"splits a string expected to have an "" algorithm$salt : iterations$hashed_pwd "" format and returns a dictionary of the values . for legacy pwd hashes , a dictionary with a single value ( i.e. { ' data ' : legacyhash } ) is returned ."
this function must be always implemented . kontext uses it to create an instance of your authentication object . the settings module is passed as a parameter .
arguments : session -- werkzeug session instance
updates user 's password . there is no need to hash / encrypt the password - function does it automatically .
tests whether the current user 's name belongs to the ' administrators ' group
"tests whether the password candidate matches required password properties ( like minimal length , presence of special characters etc . )"
searches for user 's data by his username . we assume that username is unique .
arguments : data -- a dictionary where values are either lists or single values bib_id -- unique attribute used as a bibliography key bib_label -- attribute used to display bibliography entries autocomplete_attr -- attribute queried in auto - complete mode empty_val_placeholder -- value used instead of an empty value
exports data into a sql where expression
"transform : [ corpora][conc_calc_backend conf= "" ... "" ] ... into : [ global][calc_backend conf= "" ... "" ] ..."
add global / action_path_prefix add global / static_files_prefix
add corpora / freqs_cache_ttl add corpora / freqs_cache_min_lines add corpora / colls_cache_dir add corpora / colls_cache_ttl add corpora / colls_cache_min_lines
configures the package . you can call this only once ( once the application starts ) . it loads all supported languages and creates respective formatter objects .
per - request activation of a specific formatting
imports a string from manatee to kontext
exports a string from kontext to manatee
"converts a number ( float , int ) to a string with respect to configured formatting attached to current language ."
creates new sorted list from passed list ( or any iterable data ) according to the passed locale .
"returns number formatting related configuration defined in respective formats.json file . both , a single value and all the values can be retrieved ."
returns a time formatting string ( as used by time.strftime ) according to the currently selected formats.json .
returns a date formatting string ( as used by time.strftime ) according to the currently selected formats.json .
returns combined formatting for date and time : [ date format string][separator][time format string ] according to the currently selected formats.json
escapes a cql attribute value to protect it against regexp evaluation
converts underscore - separated identifier into a camel - case one ( e.g. foo_and_bar will become fooandbar )
a helper function to retrieve values from corpus registry file using proper encoding conversion .
"formats a number according to the current session locale . by default , two decimal places are displayed in case of float numbers . this can be modified ad - hoc using ' mask ' parameter ."
loads users from the users.sample.json file
"test the auxiliary method to add a user to the mocked redis db , both using the old and the new hashing"
"test loading users from the sample file to the mocked redis db , jodoe 's i d in the sample file is 1"
"hash a password using the default values , then split the returned hash string and check whether correct information is present"
"hash a password using the specified values , then split the returned hash string and check whether correct information is present"
"try to split the legacy hash , it must contain the ' data ' value only"
"load users from the sample file , try to find user ' jodoe '"
"load users from sample file , try to authenticate user ' jodoe ' using his sample password , then try to authenticate as a non - existing user , which should return anonymous user"
"save user ' mary ' with her password hashed using the legacy algorithm ( hashlib.md5 ) , try to authenticate her , update her password using the new default method , check whether the new hash has proper format , try to authenticate using the new password"
monitor the keyboard 's events .
begin listening for output from the stenotype machine .
stop listening for output from the stenotype machine .
called when a key is pressed .
called when a key is released .
check that array correctly represents an outcome for survival analysis .
check that all arrays have consistent first dimensions .
alternative to : func:`pandas.concat ` that preserves categorical variables .
compute negative partial log - likelihood
compute gradient and hessian matrix with respect to ` w ` .
minimize negative partial log - likelihood for provided data .
predict risk scores .
predict cumulative hazard function .
predict survival function .
compute baseline cumulative hazard function .
perform z - normalization on each numeric column of the given table .
encode categorical columns with ` m ` categories into ` m-1 ` columns according to the one - hot scheme .
encode categorical columns to numeric by converting each category to an integer value .
fit base estimators .
perform prediction .
perform prediction .
perform prediction .
print out a formatted file as expected by qualtrics import .
re - scrapes jira into states.json
"given a ticket 's state dictionary , returns how much engineering time was spent on it . engineering states determined by edx_engineering_states list ."
"given a ticket 's state dictionary , returns how much time it spent in the given ` state ` ."
converts timedelta strings back into timedeltas . these were explicitly serialized as ' { 0.days}:{0.seconds}'.format(tdelta )
read in and parse states.json
"iterates over tickets , collecting lists of how much time was spent in various states ."
returns the average time spent over the number of tickets .
standard deviation of the list .
"returns a percentile function for the given numeric qper qper : float in range of [ 0,100 ] . percentile to compute which must be between 0 and 100 inclusive ."
pretty print the given time
"given a list of times and a list of stats functions , prints out all the stats over the list ( optionally in a pretty format )"
"a docstring for main , really ?"
returns the number of cpus in the system
exec commands in parallel in multiple process ( as much as we have cpu )
"args : receiver ( list[graphicobject ] ): the collection of objects to move . no objects in this collection should be parents of each other , or weird behavior will occur . dx ( unit ): the x - axis delta dy ( unit ): the y - axis delta"
unit : the x - axis delta
unit : the y - axis delta
"args : start ( point or tuple init args ): the position of the start - pedal mark relative to start_parent . start_parent ( graphicobject ): an object either in a staff or a staff itself . this object will become the line 's parent . end ( point ): the position of the release - pedal mark relative to end_parent ( if provided ) . end_parent ( graphicobject ): an object either in a staff or a staff itself . the root staff of this * must * be the same as the root staff of ` start_parent ` . if omitted , the stop point is relative to the start point ."
initialize a qpagelayout from a paper object
"args : end_x ( unit ): the x - axis position of the endpoint end_parent ( graphicobject or none ): the parent of the endpoint . ` end_pos ` will be relative to this object . if none , this defaults to the spanner ."
unit : the x position of the endpoint
unit : the y position of the endpoint .
point : the position of the endpoint
args : document ( document ):
open a window showing a preview of the document .
render the document to a pdf file .
render a section of self.scene to an image .
destroy the window and all global interface - level data .
register a font file with the graphics engine .
remove all fonts registered with ` register_font ( ) ` .
tests that the endpoint_dictionary gets the result
tests getting the links for a class with only no_pks apimethods
tests getting the links for a class with only no_pks apimethods
tests calling the all_options route and constructing all of the links .
": param unicode name : : param dict property_map : a map of the parent 's property name to the corresponding related fields properties . for example , it may be called "" child "" on the parent but it corresponds to the i d field on the related field . : param unicode relation : the name of the resource class that this relation is a type of . it uses a string so that you do not have to worry about the order of how relations were defined . it looks up the actual type from the resourcemetaclass . : param bool embedded : indicates whether the related resource should be embedded in the parent resource when returned . otherwise , a more basic representation will be used ( e.g. a link or i d ) : param bool required : an indicator for whether the relation must be constructed . : param bool no_pks : a flag that indicates that the resources created do not need pks ( for example a next link in retrievelist mixin ) : param list[unicode]|tuple[unicode ] query_args : a list of strings that should be passed to the query_args parameter for resource construction . : param bool templated : if templated is true , then the resource does not need to have all pks . however , embedded is negated if templated = true to prevent infinite loops . : param bool remove_properties : if true , then the properties in the child relationship will be removed . otherwise , the properties will simply be copied to the relationship"
the resourcebase subclass that describes the related object if no _ relation property is available on the instance it returns none . raises a key error when the relation keyword argument passed on construction is not available in the self._resource_meta_class.registered_names_map dictionary ( by default the self._resource_meta_class is the resourcemetaclass ) .
takes the properties from the parent and and maps them to the named properties for the parent resource to its relationships
helper method for construct_resource . : param resourcebase resource : the resource to evaluate . : return : a boolean indicating whether returning none is valid . : rtype : bool
removes the properties that are supposed to be on the child resource and not on the parent resource . it copies the properties argument before it removes the copied values . it does not have side effects in other words .
takes a dictionary of the values of the parent resources properties . it then maps those properties to the named properties of the related resource and creates a dictionary of the related resources property values . raises a keyerror if the parent does not contain keys that matches every key in the self.property_map
"sets the query_args to the values of the property_map remove_properties = false , and no_pks = true then calls super"
simple sets the resource on the instance .
"this property is the fully qualified and formatted response . for example , you might return a hypermedia formatted response body such as the siren hypermedia protocol or hal . this must be overridden by any subclass . additionally , it is a property and must be decorated as such ."
headers that should be added to response . for example it might be the content - type etc ... this must be overridden by any subclass since it raises a notimplementederror . it can also be overridden as a class attribute if it will not be dynamic .
does exactly what it says it does . uses ` ` join_url_parts ` ` with the ` ` self.base_url ` ` and ` ` resource_url ` ` argument together .
takes an exception and appropriately formats the response . by default it just returns a json dump of the status code and the exception message . any exception that does not have a status_code attribute will have a status_code of 500 .
"takes a request and appropriately reformats the request . for example , jsonapi requires a specific request format that must be transformed to work with ripozo . for this base implementation it simply returns the request without any additional formating ."
: return : returns the status code of the resource if it is available . if it is not it assumes a 200 . : rtype : int
ensures the class property is available and appropriate
ensures that the properties attribute is available and is a dictionary
tests whether the entities are available and valid
tests whether the links attribute is available and if there is a self referential link
tests whether an empty body is returned when the status_code is 204
tests getting the links attribute for
tests a list entity entity
tests that an empty list is returned if the fields can not be found .
tests that url params are not a part of the fields returned .
dumb test for format_request
ports to expose to the outside world .
ports needed for communication within the network . this is usually used for internal ipc .
ports necessary to get things working .
helper method to generate and copy over the configuration .
generate a compute - specific configuration . this configuration lives in its own directory that gets copied in each container .
generagte a storage - specific configuration . this configuration lives in its own directory that gets copied in each container .
generate a connector specific configuration .
helper method to generate some environment variables .
generate some environment variables for the connectors . these variables help the connectors query the backend .
create a new initializer param user the user login for the git repo
generate a new hostname
start the service on the containers .
generate a new configuration .
ports needed for communication within the network . this is usually used for internal ipc .
ports necessary to get things working .
generate a new configuration param num number of instances that need to be configured param image image type of the instances
generate the mongodb configuration file .
apply the configuration to the instances
generates and returns the command line to run maverick.
checks if ti is in use . returns true or flase .
parses maverick 's parameter file and returns the results in a dict .
"implements a failsafe for discrepancies with multiple alpha values . returns the following dict : { parameter : { k : param_value } , parameter : { k : param_value } } if the paramterer values are a single value , false is returned : { paramter : false , parameter : { k : param_value } }"
write a bestk result based on ti or structure results .
"grabs the split outputs from maverick and merges them in a single directory . also uses the data from these files to generate an "" outputevidencenormalized.csv "" file ."
performs ti normalization as in the original implementation from maverick. this is essentially a port from the c++ code written by bob verity .
perform a q1 - q2 analysis .
"parameters ---------- mobiles : tuple(atomgroup , atomgroup ) two contacting groups that change over time refs : tuple(atomgroup , atomgroup ) two contacting atomgroups in their reference conformation . this can also be a list of tuples containing different atom groups radius : float , optional ( 4.5 angstroms ) radius within which contacts exist in refgroup method : string | callable ( optional ) can either be one of ` ` [ ' hard_cut ' , ' soft_cut ' ] ` ` or a callable with call signature ` ` func(r , r0 , * * kwargs ) ` ` ( the "" contacts api "" ) . kwargs : dict , optional dictionary of additional kwargs passed to ` method ` . check respective functions for reasonable values ."
create an article for testing with default values
create a category for testing with default values
return a django queryset representation of an instance
give the test user the given permission
log in the client for the current test
create user for testing
logout the current client
create slugs for existing articles .
return the appropriate response for the state of the transaction .
display the directpayment for entering payment information .
try to validate and then process the directpayment form .
first step of expresscheckout . redirect the request to paypal using the data returned from setexpresscheckout .
second step of expresscheckout . display an order confirmation form which contains hidden fields with the token / payerid from paypal .
third and final step of expresscheckout . request has pressed the confirmation but and we can send the final confirmation to paypal using the data from the post'ed form .
paypal ipn endpoint ( notify_url ) . used by both paypal payments pro and payments standard to confirm transactions . http://tinyurl.com/d9vu9d
"standard implementation of a view that processes pdt and then renders a template for more advanced uses , create your own view and call process_pdt ."
payment data transfer implementation : https://developer.paypal.com/webapps/developer/docs/classic/products/payment-data-transfer/
"parse svg path definition ( i.e. "" d "" attribute of < path > elements ) and call a ' pen ' object 's moveto , lineto , curveto , qcurveto and closepath methods ."
descriptive text for use in displays .
gets the time - sorted list of access log for the given user .
gets the last access log for the user .
gets a list of time - sorted lists of access logs for each time period .
gets the access log rates .
descriptive text for use in displays .
"return a dict , for conversion to json ."
appends kml nodes describing all mission configurations .
appends kml nodes describing this mission configurations .
simple login test .
bad login raises exception
test connection timeout
create a logged in client .
test getting missions .
test sending some telemetry .
test sending some ( incorrect ) telemetry .
test getting obstacles .
test odlc workflow .
creates a dummy config for testing .
tests a non - integer mission id in request .
tests a mission id for a mission that does n't exist .
tests getting the mission for a specified id .
tests when there are no active missions .
tests when too many active missions .
tests getting the single active mission .
tests requests that have not yet been authenticated .
post not allowed
no missions results in empty list .
response json is properly formatted for non - superuser .
response json is properly formatted for superuser .
mission id response json is properly formatted for non - superuser .
mission id response json is properly formatted for superuser .
create an interoperror .
tests the unicode method executes .
aerialposition distances are within threshold ( ft ) .
evaluates the distance_to calc with the given input list .
tests distance calc for same position .
tests distance calc for competition amounts .
tests the duplicate function with unequal positions .
tests the duplicate function with unequal positions .
converts a mavlink packet lat / lon degree format to decimal degrees .
converts a mavlink packet millimeter format to decimal feet .
converts a mavlink packet heading format to decimal degrees .
receives packets over the device and forwards telemetry via the client .
sets up the tests .
setup a single active mission to test live kml with .
tests the generate kml method .
tests the generate kml method .
tests the generate kml method .
tests the generate kml method .
tests the generate kml method .
tests the generate kml method .
tests the generate kml method .
toplevel : header declaration_list
toplevel : declaration_list
declaration_list : declaration
declaration_list : declaration_list declaration
declaration : message | include | type | typedef | using
declaration : namespace id lbrace declaration_list rbrace
declaration : header
using : using qualified_id semi
header : sharp header pathspec
include : sharp include pathspec
typedef : typedef qualified_id id semi
type : type qualified_id semi
pathspec : filepath_q | filepath_a
message : message_type id lbrace rbrace
message : message_type id lbrace message_body rbrace
message : message_type id colon qualified_id lbrace message_body rbrace
message_body : message_element
message_body : message_body message_element
message_element : annotated_field | message_setting | group | enum
annotated_field : field
annotated_field : required field
annotated_field : deprecated field
message_setting : setting eq expression semi
field : bitset
group : group_type id lbrace group_body rbrace
group_body : annotated_field
group_body : group_body annotated_field
bitset : bitset_type lbrace bitset_body rbrace
bitset_body : field
bitset_body : bitset_body field
field : simple_type id semi
field : simple_type id eq expression semi
field : simple_type lbracket rbracket id semi
simple_type : bool_type | int_type | float_type | string_type | csp_type | qualified_type
qualified_type : qualified_id
enum : enum lbrace enum_body rbrace
enum_body : enum_body comma enum_value
enum_body : enum_value
enum_value : id eq iconst
enum_value : id
expression : sconst | fconst | iconst
qualified_id : id | id qual qualified_id
initialize options and set their defaults .
add options to the test runner ( tox ) .
invoke the test runner ( tox ) .
get full text and/or abstract for paper and upload to s3 .
get extractions from one of the examples in ` cag_examples ` .
make graphs from all the examples in cag_examples .
return a request message for a given text .
read a given pmc article .
read a given text phrase .
handle replies with reading results .
"terminates / cancels all running , runnable , and starting jobs ."
tag a single ec2 instance .
function run when indra is used in an ec2 instance to apply tags .
get the command appropriate for running something on batch .
returns a list of dicts with jobname and jobid for each job with the given status .
gets the cloudwatch log associated with the given job .
download a log given the log 's group and stream name .
write logs for all jobs with given the status to files .
reads in geneways data and returns a list of statements .
process a cx json file into statements .
process an ndex network into statements .
process a cx json object into statements .
extracts causal relationships between two nouns / terms ( as opposed to events )
extracts relationships involving one term / noun inhibiting another term / noun
extracts relationships with one term influencing another term .
extract the evidence for an event .
"return ` true ` if user is a collaborator with the corresponding permission on this board , ` false ` otherwise ."
"returns ` true ` if the user is a board collaborator with write permissions trying to create . returns ` true ` if user is the account owner . returns ` false ` if user is not authenticated and method is not safe . returns ` true if user is not authenticated and view action is ` list ` and ` board ` query parameter is set , ` false ` if it 's not set ."
"return ` true ` if user is a collaborator with the corresponding permission on this board , ` false ` otherwise ."
tests that serializer.data does n't return any data .
tests serializer 's expected validation errors .
tests that serializer should return object if valid .
tests that serializer should return object for card stack if valid .
tests that serializer.data does n't return any data .
tests serializer 's expected validation errors .
tests that serializer should return object if valid .
tests that serializer 's ` .validate_cards ` only validates if card is not stack and resets cards field to empty list .
tests that serializer 's ` .validate_cards ` validates that each card can be accessed by the user .
tests that serializer 's ` .validate_cards ` validates each type of the cards attached to it .
tests that serializer.data does n't return any data .
tests serializer 's expected validation errors .
tests that serializer should return object if valid .
tests that validate_signup_domain returns none for valid values .
tests that validate_signup_domain raises validationerror if validate_domain_name raises validationerror .
tests that validate_signup_domain raises validationerror for blacklisted signup domains .
returns a suitable description of this field for south .
from : https://djangosnippets.org/snippets/2124/
tests that post request with valid data to endpoint returns expected data .
tests that post request with invalid data to endpoint returns expected error .
tests that post request with valid data to endpoint returns expected data .
tests that post request with valid data to endpoint returns expected data .
tests that post request with invalid data to endpoint returns expected error .
tests that post request with invalid data to endpoint returns expected error .
set modified_by before deleting card .
test simulationresult.dataframe ( )
test on demand observable evaluation
run network generation on all example models
generator that yields the model objects for all example models
tests that network generation runs without error for the given model
gets the currently active path to an external executable
sets the full path to an external executable
identify if this is an anaconda environment
get the binary path from python build time ( for anaconda )
generate the potterswheel code for the odes of the pysb model associated with the exporter .
main strategy logic ( the meat of the strategy )
calculates percentage change between n last elements close : price numpy.ndarray timeperiod : size to check
main strategy logic ( the meat of the strategy )
"trains input data by automatic_search ( ga ) or with given models : param blueprint : multi - currency features csv file ( for example generated by blueprint module ) : param automatic_search : automatically find the best models : param models : list of models to be used . if automatic_search is true , models will be included into model search : param minimum_score : minimum_score the model needs to have so that it is returned : return : list of best models with their score"
function that trains given dataset for a specific pair
loads blueprint csv file and returns paired groups ( grouped by pair )
"sets base price , which is compared to trailing - stop : param price :"
: param price : numpy array of price values : return : returns true if stop - loss met conditions
saves the given transactions to the configured db .
retrieve transactions for producing text file
get currency symbol from locale
implementation of coreutils touch http://stackoverflow.com/a/1160227
this will create the entire directory path for the config file
"because of http://stackoverflow.com/questions/12397681 , parser.add_argument(type= or action= ) on a file can not be used"
create a vector @param metadata features
a = ax+by+cz b = mx+ny+oz a.b = a*m + b*n + c*o
costheta = ( v1.v2 ) / ( |v1| |v2| ) cos 0 = 1 implies identical documents
dist = ( ( x1 - x2)^2 + ( y1 - y2)^2 + ( z1 - z2)^2)^(0.5 )
create a vector @param metadata features
mni2tal for converting from ch2 / mni space to tal - very approximate .
get antspy test data filename
uses the weingarten map to estimate image mean or gaussian curvature
get string representation of a py::capsule ( aka pointer )
needs to be better validated .
get a binary mask image from the given image after thresholding
impute missing values on a numpy ndarray in a column - wise manner .
use a label image to crop a smaller antsimage from within a larger antsimage
create a proper antsimage sub - image by indexing the image with indices . this is similar to but different from array sub - setting in that the resulting sub - image can be decropped back into its place without having to store its original index locations explicitly .
the inverse function for ` ants.crop_image `
"denoise an image using a spatially adaptive filter originally described in j. v. manjon , p. coupe , luis marti - bonmati , d. l. collins , and m. robles . adaptive non - local means denoising of mr images with spatially varying noise levels , journal of magnetic resonance imaging , 31:192 - 203 , june 2010 ."
parses a datetime as a utc iso8601 date
formats a datetime as a utc iso8601 date or returns none if value is none
"for the purposes of testing , all calls to requests.request go through here before json bodies are encoded . it 's easier to mock this and verify request data before it 's encoded ."
sets the created_at and updated_at fields . this should be something a subclass of property that takes care of this during the save cycle .
creates a voucher for an email address .
returns voucher where email address matches and is not claimed . we use a where query here since we do n't enforce uniqueness on email address . just returns 1st .
returns voucher by key . we use a where query here since we do n't enforce uniqueness on key . just returns 1st .
returns all vouchers sent out by user .
return s3 authenticated url sans network access or phatty dependencies like boto .
return s3 authenticated url sans network access or phatty dependencies like boto .
expects a datetime in utc .
"takes a local path with a file , and writes the thumbntail to the destination which is a cstringio.stringio instance . used by user.set_profile_image ( )"
"dumb routine to test input string ` s ` for words or combinations of words . used in conjunction with saving post title , description as a stop - gap mechanism to prevent spammers from self - promotion ."
sets the created_at and updated_at fields . this should be something a subclass of property that takes care of this during the save cycle .
"generate a code based on the app_id , time , and redirect_url set expires_at to be 30 seconds from now ."
path : /incoming
"add a comment , which will create a conversation for the commenter ( user2 ) and sharedfile owner ( admin ) . when user2 tries to mute admin 's conversation , it should fail and admin 's conversation state will remain unchanged . when muting own converastion , "" muted "" flag should change to true ."
create a user sourcefile and sharedfile to work with .
verifies the owner is correctly returned
"if an image exists , it should return the correct path ."
"if an image exists , it should return the correct thumbnail path"
simply returns the correct path for the shake
display name or title is returned if set .
tests that a user can and can not update a certain shake
creates shakes with valid and invalid titles
creates shakes with valid and invalid names
tests whether subscribers returned are the subscribers to a particular shake .
tests both the pagination of a shake 's shared files and the count
verifies adding a new manager works
tests whether a user has the ability to edit a shake
utility to create a stub sharedfile for the user .
"saving a file should redirect to the new file url , unless json=1 is passed in . in which case response should contain original share_key , new_share_key and count ."
bob should be able to save admin 's original file . the parent_id should point to admin 's file and so should original_id .
"when bob saves admin 's original file , an entry gets created in shakesharedfile ."
"when bob saves admin 's original file , an entry gets created post with bob 's user i d."
"when bob saves admin 's original file , a entry gets created in notification table with following attributes :"
"saving sharedfile should transfer over the title , description and source fields ."
parse data into emojichar
lists all possible codepoint variations for given emoji .
returns rendered char for emoji
lists all possible * rendered * codepoint variations for given emoji . this is useful when trying to find this particular emoji in a string by looking for any variation .
` true ` if emoji is coded on two or more bytes
"this metaclass makes a class an owner for some domain objects . the _ _ ownedtype _ _ attribute of the class must be a string . for each type , the following methods will be added to the class ( here assuming a type of ' foo ' ):"
attempt to parse a message as a gntp message
shortcut function for writing gntp headers
parse the first line of a gntp message to get security and other info values
set a password for a gntp message
helper function to decode hex string to ` proper ` hex string
validate gntp message against stored password
verify required headers
generate info line for gntp message
helper function to parse blocks of gntp headers into a dictionary
add binary resource
decode gntp message
encode a generic gntp message
validate required headers and validate notification headers
decode existing gntp registration message
add new notification to registration message
encode a gntp registration message
decode existing gntp notification message
load the printer settings from the user settings .
save the printer settings to the user settings .
return an in - memory wxschedulerprint ( ) object for adding schedules and print on current wxdc
"this code draw a wxscheduler scaled to fit page using date , format and schedules passed by the user . note there is no difference on manage scheduler and schedules beetwen gui and printing framework"
"update the position of the cursor , taking colspan into account ."
return the default flags for placing a list of controls .
return a merged list of flags by overriding the default flags with flags passed by the caller .
"add a number of controls to the page . all controls are placed on one row , and together they form one entry . e.g. a label , a text field and an explanatory label . the default flags for placing the controls can be overridden by providing a keyword parameter ' flags ' . flags should be a list of flags ( wx . align_left and the like ) . the list may contain none for controls that should be placed using the default flag . if the flags list is shorter than the number of controls it is extended with as much ' none 's as needed . so , addentry(alabel , atextctrl , flags=[none , wx . align_left ] ) will place the label with the default flag and will place the textctrl left aligned ."
"more pythonic way to get a specific page , also useful for iterating over all pages , e.g : for page in notebook : ..."
can be overridden in a subclass to do something useful .
override addpage to allow for simply specifying the bitmap name .
location to pop up the menu .
return whether this control has the focus .
"note that windows xp and vista limit the text shown in the tool tip to 64 characters , so we can not show everything we would like to and have to make choices ."
"this implements a substitute for the forkpty system call . this should be more portable than the pty.fork ( ) function . specifically , this should work on solaris ."
"this makes the pseudo - terminal the controlling tty . this should be more portable than the pty.fork ( ) function . specifically , this should work on solaris ."
returns a generator which outputs the frame contents as blocks of binary data .
handles requests from bicingbot users .
sets the bicingbot webhook in its telegram bot
creates a complete schema of the database
creates the first schema of the database
update the schema of the database adding settings table .
convenience function for odeint ( ) .
"integrate the initial value problem ( dy , yinit ) ."
return harmonic oscillator with actuator built in .
return anharmonic oscillator with actuator built in .
return lorenz attractor with actuator built in .
return lorenz attractor with actuator built in .
return van der pol oscillator with actuator built in .
return fitzhugh - nagumo oscillator with actuator built in .
return hindmarsh - rose oscillator with actuator built in .
generate a coupling matrix for global coupling .
generate a coupling matrix for pairwise coupling .
generate a coupling matrix for circular array coupling .
generate a coupling matrix for a 2d grid of n*m oscillators .
generate a coupling matrix from the dorogovtsev - goltsev - mendes graph .
factory for mutuniform
factory for mutnodereplacement
factory for mutinsert
factory for mutshrink
factory for cxonepoint
factory for cxonepointleafbiased
: param atree : : type atree : ` glyph.gp.individual . andimtree ` : param mut1d : any mutation operator worklng for ` glyph.gp.individual . aexpressiontree ` : param rng : ( seeded ) random number generator : return : mutated offspring
: param atree : : type atree : ` glyph.gp.individual . andimtree ` : param btree : : type btree : ` glyph.gp.individual . andimtree ` : param cx1d : any crossover operator working for ` glyph.gp.individual . aexpressiontree ` : param rng : ( seeded ) random number generator : return : two mated offsprings
entry point of application .
human readable representation of the individual .
setup dynamic system .
combine several measurement functions into one .
return a one for each different constant in the primitive set .
apply constant optimization
replace occurences of np.nan in x.
flatten a tuple of tuples .
return argument count of func .
add annoations to func .
check func 's annotation dictionary for return type tuple .
wrap func 's return value into a tuple if it is not one already .
store an instance of parallel_factory .
update the fitness of each individual in population that has an invalid fitness .
modify pickling behavior for the class .
modify unpickling behavior for the class .
default implementation .
assign a fitness value ( as returned by self.measure ( ) ) to idividual .
return a fitness value for individual .
retrieves all ordered samples for a participant .
"retrieves the biobank id , collected time , and test for a percentage of ordered samples . used in fake data generation ."
run migrations in ' offline ' mode .
run migrations in ' online ' mode .
loads a physicalmeasurement fhir resource returns it as parsed json .
loads a physicalmeasurement fhir resource and adds an amendment extension .
returns an readable stream for the biobank samples csv .
loads a consent questionnaireresponse and adds > = 1 consent pdf extensions .
recursively find questions in all_question_codes and populate a dict of question code to linkid .
"verify that questionnaires exist for all the modules in all_module_codes , and construct a map from questionnaire id and version to { question_code : linkid } for all question codes found in the questionnaire in all_question_codes ."
convert xml derived dict to tf . example proto .
"yields successive batches from an iterable , as lists ."
yields the items of an iterable repeatedly .
numpy array protocol ; returns iterator values as an ndarray .
"returns iterator values as an ndarray if it exists , else none ."
"create , configure and return the routes mapper"
cache decorator utilizing beaker . caches action or other function that returns a pickle - able object as a result .
get a cache namespace and key used by the beaker_cache decorator .
inspects function for name of args
"given a dict of files , where the key is a filename in filestotest , the value is the destination in the new projects dir . emptyfiles is a list of files that should be created and empty ."
this method has a docstring
this method has a docstring
proxy a request to a cdn
finish the request
serve the build directory with a webserver .
constructor of reporter .
invoked when reporting is started .
invoked when reporting is done .
do backtrace multiple times .
render label as image .
"read the music file at the given path , in chunks of the given size ."
split the given frequency range in ' column ' number of ranges .
return the power array index corresponding to a particular frequency .
calculate frequency response for each channel
ptm of rotation of theta degrees along the x axis
ptm of rotation of theta degrees along the x axis
ptm of rotation of theta degrees along the x axis
calculates the average process fidelity between two pauli transfer matrices args : ptm_0 ( array ) : n*n array specifying the first pauli transfer matrix ptm_1 ( array ) : n*n array specifying the second pauli transfer matrix d ( int ) : dimension of the hilbert space returns : f ( float ) : process fidelity
calculates the average average gate fidelity between two pauli transfer matrices args : ptm_0 ( array ) : n*n array specifying the first pauli transfer matrix ptm_1 ( array ) : n*n array specifying the second pauli transfer matrix d ( int ) : dimension of the hilbert space returns : f_gate ( float ): average gate fidelity
"class is instantiated with the hydrogen data path file and measured expectation values . the expectation values are in the following order ii , iz , zi , zz , xx , yy"
parses a dictionary
parses a list of ints
parses a list of floats
parses a list of lists of ints
parses a list of lists of floats
parses one or more arguments with the installed parser . args : arguments : a single argument or a dict of arguments ( typically a dict of default values ) ; a single argument is converted internally into a dict containing one item .
override to support full csv syntax .
override to support full csv syntax .
< summary > adds and configure a car for the simulation</summary >
< summary > initialize the simulation</summary >
< summary > update car locations</summary >
add the specified number of invites to current allocated total .
add invites for all users .
ensure user has a minimum number of invites .
ensure all users have a minimum number of invites .
"returns number of unsent allocated invites , or -1 for infinite ."
return true if an invite can be sent .
show usage of the bot .
get user id .
add a new whatsapp contact to the database .
bind a contact to a group .
unbind a contact from his group .
blacklist a whatsapp phone .
list stored contacts .
remove a whatsapp contact from the database .
send a message to a contact through whatsapp .
unblacklist a whatsapp phone .
send a message received in a bound group to the correspondending contact through whatsapp .
"# 用开盘价来选要交易的合约代码 long_short_opt = long_short_enter.apply(func_select_instrument_by_signal , axis=1 , args=('sz50 ' , open , df_info , 3 , 1 ) ) long_short_opt.set_index(['index_datetime ' ] , inplace = true )"
遍历文件夹，得到合约的数据开始时间与结束时间 兼容文件夹下都是同一合约，分钟数据 兼容文件夹下都是同产品，日数据 : param root_path : : return :
遍历文件夹，得到合约的数据开始时间与结束时间 兼容文件夹下都是同一合约，分钟数据 兼容文件夹下都是同产品，日数据 : param root_path : : return :
"for the server , broadcasts the given data packet to all connected clients . for clients , sends the datagram to the server ."
"for the server , broadcasts the given data packet to all connected clients . for clients , sends the datagram to the server ."
compute the numerical approximation of a definite integral
"calculate integer or float factorial ( for gamma function , step=2 )"
calculate gamma function value for a fraction ( numerator & denominator )
fetches some resourcegroups : param uid : : param name : : param limit : : param offset : : param search : performs a fulltext search : return :
assigns an amqp broker to a resource group : param amqp_id : : param resourcegroup_id : e : return :
does not create any joinery geometry
d ------------------e / c -- i------------------>j \ b ------------------a reverse will reverse order of points depicted above
returns a unitized vector perpendicular to the vector formed from pnti to pntj ^ | i------- > j
"finds three points , a , b , c making up a half - circle arc . returns in order [ a , c , b ] oriented on the vector . assumes vector lies in xy plane c / i--- b ------------------->j \ a"
compute the remaning space that will result from segmenting the given curve with self.spacing chunks .
"gets the vector that is aligned with curve , and who s length is half of extra_space"
| | | | | | | | i------------------------->j ' comb ' is centered on line . returns ordered base points and offset points to form a ' comb '
practice function for traversing mesh breadth - first
"creates and island , which is a special mesh for representing an unfolded section of a mesh"
does not use cut list ; unfolds until all faces have been touched
"the process must be started with an island that has one edge , its from face , and the two verts for that face and edge . this function adds those verts note that the verts are added in reverse order ; this is consistent with the assumption of breadth_first_layout ."
for layout to not accidently infinite loop the startmeshloc must be on cut or naked edge
traverse all faces of mesh breadth first and create an island ( does not check if edges are cut or fold ) need to figure out how to setup island so ready to do this function ...
output dsmr data to console .
"applies each distributions ' boundary conditions to the given list of parameters , returning a new list with the conditions applied ."
evalualate joint distribution for parameters .
rejection samples the parameter space .
calculates time series of psd variability
find the psd variation value at a particular time
performs q - transform on each tile for each q - plane and selects tile with the maximum energy . q - transform can then be interpolated to a desired frequency and time resolution .
iterable constructor of qtile tuples
fractional mismatch between neighbouring tiles
iterate over the q values
iterate over the frequencies of this ' qplane '
calculate the energy ' timeseries ' for the given fseries
"returns the length in time of the template , based on the masses , pn order , and low - frequency cut - off ."
"return the amplitude portion of the taylorf2 approximant , used to precondition the strain data . the result is cached , and so should not be modified only read ."
return the distance at a given snr ( default=8 ) of the spa taylorf2 template .
calculate the spa tmplt phase
generate a minimal taylorf2 approximant with optimations for the sin / cos
return the start and end time arrays from a segment file .
return an index array into times that lie within the durations defined by start end arrays
return an index array into times that like outside the durations defined by start end arrays
return the list of segments that match the segment name
return the list of indices that should be vetoed by the segments in the list of veto_files .
return the list of indices that are outside the segments in the list of segment files .
returns a dict with the comment column as the value for each segment
calculate search efficiency in the given ndbins .
calculate search sensitive volume by integrating efficiency in distance bins
return the distance and standard deviation upper and lower bounds
compute sensitive volume and standard error via direct monte carlo integral
compute the sensitive volume using a distance binned efficiency estimate
compute the sensitive volume using sum over spherical shells .
parses the given ` gate_opt ` into something understandable by ` strain.gate_data ` .
parses the --gate option into something understandable by ` strain.gate_data ` .
parses the --psd - gate option into something understandable by ` strain.gate_data ` .
applies the given dictionary of gates to the given dictionary of strain .
applies the given dictionary of gates to the given dictionary of strain in the frequency domain .
adds the options needed to apply gates to data .
yield n successive chunks from l.
get base schema for python type .
"parse endpoint into ( blueprint , endpoint ) . blueprint can be : const:`none `"
normalized indent of docstring .
merge plain objects without mutation .
compose functions .
dump swagger dict to swagger json spec
convert object schema to parameters .
realign spikes to their peaks using bandwidth - limited resampling
locate the peaks in an array of spikes .
resample a signal using discrete fourier transform . the signal is transformed in the fourier domain and then padded or truncated to the correct sampling frequency . this should be equivalent to a sinc resampling .
add builders and construction variables for gnulink to an environment .
add builders and construction variables for the os/2 to an environment .
add builders and construction variables for ar to an environment .
add builders and construction variables for icl to an environment .
add builders and construction variables for applelink to an environment .
run any registered exit functions
add builders and construction variables for g++ to an environment .
abstract class inherited by all rte models .
abstract class inherited by all models .
implementation of a compositional extension of the translating embeddings model [ 1 ] .
: return : ( batch_size ) tensor containing the scores associated by the models to the walks .
implementation of a compositional extension of the bilinear - diagonal model [ 1 ]
: return : ( batch_size ) tensor containing the scores associated by the models to the walks .
implementation of a compositional extension of the bilinear model [ 1 ]
: return : ( batch_size ) tensor containing the scores associated by the models to the walks .
implementation of a compositional extension of the complex model [ 1 ]
: return : ( batch_size ) tensor containing the scores associated by the models to the walks .
"implementation of the er - mlp model described in [ 1 , 2 ]"
: return : ( batch_size ) tensor containing the scores associated by the models to the walks .
"normal_attention for attention strategy 2 : param tensor_base : rank 3 [ bs , sl , vec ] : param tensor_to_attend : rank 3 [ bs , ql , vec ] : param mask_for_tensor_base : [ bs , ql ] : param mask_for_tensor_to_attend : [ bs , sl ] : param similarity_method : ' inner ' ' tri_linear ' ' map_linear ' : param hn : some method need : param use_pooling : true or false : param pooling_method : ' max ' or ' mean ' : param reverse : if use strategy 3 : param scope : : return : use_pooling==true : [ bs , sl , hn ] else [ bs , hn ]"
"attention strategy 4 : self * self = > attention self : param rep_tensor : rank is three [ bs , sl , hn ] : param mask : [ bs , sl ] tf.bool : param scope : param simplify : : return : attended tensor [ bs , sl , hn ]"
"self soft choose attention with : param rep_tensor : rank must be 3 [ bs , sl , hn ] : param rep_mask : [ bs , sl ] : param hn : : param keep_prob : : param is_train : : param scope : : param simplify : return :"
": param target : [ ... , j , d ] dtype = float # ( b , sn , sl , ql , d ) : param logits : [ ... , j ] , dtype = float : param mask : [ ... , j ] , dtype = bool : param scope : : return : [ ... , d ] , dtype = float"
create a new id / name dict with swapped entries .
unswap names according to initial state and swap data .
load data from provided file paths and returns unswapped names .
configure cli args and unswap data .
similar to bisect.insort_right but for reverse sorted lists
create hash for indexing
returns true if entry is not valid any longer
reset the time to live
invalidates the cache entry
add sharding information for a group
create hash for indexing
create hash for indexing
remove cache entry for group
remove cache entry for shard
cache information about a shard
cache information about a group
search cache for a shard based on database and table
search cache for a group based on its name
convenience function to go through document word - by - word .
minimal convenience class for pystruct learning .
index page .
list of all people .
page with details for a specific person .
list of all movies .
page with details for a specific movie .
capture comment and redirect to movie page .
generate a dictionary of connection data for an optional uri plus additional connection settings .
"a small function to print to stderr , used for error and logging messages"
"return firmware version as integer tuple ( major , minor , build ) or ( false , false , false ) if something goes wrong"
"we test if an uhsdr with extended api is connected by using an identification api call not present on a ft817 or older uhsdr / mchf firmwares returns : true if a suitable trx is connected , false otherwise"
read the configuration from trx into a data dictionary
write the configuration in passed data dictionary to trx
check bits mixed with non - bits
check bit groups that span multiple bytes
check that an un - serializable table entry raises a valueerror
: param source : source bytes or file - like object : type source : io . bytesio or bytes or bytearray
read n bytes
read a single boolean value
"read one byte , return as an integer"
read an unsigned 16 - bit integer
read an unsigned 32 - bit integer
read an unsigned 64 - bit integer
read float value .
read a short string that 's stored in up to 255 bytes
read a string that 's up to 2**32 bytes
"read an amqp table , and return as a python dictionary"
"read and amqp timestamp , which is a 64 - bit integer representing seconds since the unix epoch in 1 - second resolution"
"note : dest must also implement ` getvalue ( ) ` , such as : class:`io . bytesio `"
pass through if possible to any file - like destinations
pass through if possible to any file - like destinations
get what 's been encoded so far if we 're working with a bytesio
write a boolean value
write an integer as an unsigned 8 - bit value
write an integer as an unsigned 16 - bit value
write an integer as an unsigned2 32 - bit value
write an integer as an unsigned 64 - bit value
write a string up to 255 bytes long ( after any encoding )
write a string up to 2**32 bytes long after encoding
"write out a python dictionary made of up string keys , and values that are strings , signed integers , decimal , datetime.datetime , or sub - dictionaries following the same constraints"
write out a python datetime.datetime object as a 64 - bit integer representing seconds since the unix epoch
"make sure we 've broken various references when closing channels and connections , to help with gc"
make sure connection is still alive after a channel exception
make sure is_alive ( ) returns false after a connection exception
"make sure we 've broken various references when closing channels and connections , to help with gc"
make sure the connection gets gc'ed when there is no more references to it
make sure to get interruptederror if a read was interrupted
"make an instance of a client , login , and return it ."
"returns ( s1 and s2 have the same value for entry_name ? , message ) ."
returns true if the given string is in google music i d form .
returns true is the given dict is a gm song dict .
returns true if the given list is made up of all strings in gm i d form .
"returns true if the given list is made up of all ( i d , i d ) pairs ."
"return a valid json string , given a jsarray string ."
return text representation of user
list all participants in current ( or specified ) conversation you can also use . for current conversation . includes g+ accounts and emails . usage : /bot user_list [ conversation_name ] [ user_name ]
find users known to bot by their name usage : /bot user_find [ user_name ]
show or change bot configuration usage : /bot config [ get|set ] [ key ] [ subkey ] [ ... ] [ value ]
reload bot configuration from file
display a flatpage and parse dynamic content if available
return the timetag for today
"parses the vvo - online api return string . api returns in format [ [ "" line "" , "" to "" , "" minutes "" ] , [ _ _ ] , [ _ _ ] ] , where "" _ _ "" are up to nine more elements ."
a decorator used to disable functions ( routes ) if a certain feature is not provided by the user class .
generate a url to the request 's current endpoint with the same view arguments .
register func as specific handler 's callable in a dict logging config .
return a list of keys that have changed .
handles errors by flashing an according message : param e : the error : return : a flask response with the according http error code
handles global database errors like :
handles global ldapcommunicationerror exceptions .
login page for users
convert a number from kib to gib
show a user 's traffic on a static site just as in the usersuite .
display version information from local repo
initialize a bare git repository with one commit .
clone a bare repository into { path}/{name } and return the path .
test that ` self.workdir ` only contains the bare repo directory
test that a clone from the bare repo contains the correct files
test the repo is bare
test the repo only has a ` master ` ref
test only a ` master ` exists to which the head points to .
some random balance
"static method for flask - login user_loader , used before _ every _ request ."
checks the memcheck suppressions files for bad data .
list firewall rules visible for the project .
create firewall rule .
creates firewall policy .
creates a firewall .
fast version of non local mean denoising of 3 dimensional data see [ 1 ] _
chambolles tv regularized denoising
chambolles tv regularized denoising
affine transform data with matrix mat
translates 3d data by given amount
rotates data around axis by a given angle
same arguments as ocldevice.__init _ _ e.g. id_platform = 0 id_device = 1 ....
debug via running shell ; need to run py.test with -s
custom_config_content : string
: param query : which query we need to execute to a given connector : param attempts : number of times that query should be executed : param mean_lower_than : total mean should be lower than this value : return : true / raise exception
instantiating the facade automatically handles authentication and connections to all relevant apis ( logic for this would go in the api wrapper classes in a real implementation .
provides the user of the dashboard a simple interface to aggregate performance data from all campaign teams .
once again provides a simple interface to perform the complex task of updating a campaign team 's budget . we assume that the user will specify a ' weight ' that may affect the budget allocation .
private method that the user need not deal with directly .
private method that the user need not deal with directly .
perform setup for the logger . run before any logging.log thingy is called .
return number but limit it to the inclusive given value range
pattern is broken between two blocks .
return a method that takes one argument ( a unit ) and formats a short string to be used as the output for the unit_remove command .
initailize copy command .
returns a method that can be used to format the unit key of a openstack image for display purposes .
initialize remove command .
returns a method that can be used to format the unit key for display purposes .
initialize upload command .
"we only support one content type , so this always returns that ."
generates the unit key and metadata .
"return an md5 sum for a given filename . openstack also uses md5 sums for images , which is why we use it here as well ."
return filesize for a given filename .
send email .
"builds a module , along with optional tests . it makes assumptions , but most can be overridden by passing in args ."
write complexdata to pathname as xml .
add a line item record to this costs object .
"pass in a list of tuples where each tuple represents one filter . the first element of the tuple is the name of the column to filter on and the second value is a regular expression which each value in that column will be compared against . if the regular expression matches the value in that column , that lineitem will be included in the new costs object returned ."
get the html
"returns the triangle of minimum area enclosing a convex polygon . runs in theta(n ) time for convex polygons , or o(n*log(n ) ) for concave polygons as convex hull must be computed ."
fit the model .
"make predictions : given a sequence of interactions , predict the next item in the sequence ."
test the functioning of the module by reading n numbers from serial . the code will use : serial_in = 18 serial_clk = 19 serial_load= 20
"initialize the module . input : * serial_in = gpio pin for the input data bit , connect to the q output of the chip . * serial_clk = gpio pin for the clock , connect to clk of the chip . * selial_load= gpio pin for the load signal ( cs_bar like behavior ) , connect to load of the chip . * serial_n = number of bits to read , default=8"
delete and cleanup .
load the parallel data into the shifter by toggling serial_load low
shift the data into the shifter and return the obtained value . the bits are expected to come as most significant bit ( msb ) first to least significant bit ( lsb ) last . output : out - the data shifted in returned as integer .
how many physical hosts are there ?
"using argparse in a mpi setting either quit cleanly on error of parsing , or return args . this is a collective call"
"remove unreable files and directories from the input path collection , skipped include two type of elements : unwanted directories if removedir is true or unaccessible files / directories"
"verify and return target destination case 1 : source : multiple files destination is an existing directory copytype : files2dir case 2 : source : a file destination can either be : a file does n't exist but writable a file exists then file2file case 3 : source : a directory destination : a directory does n't exist , but writable then dir2dir"
get instance of the oauth client for this provider .
return additional redirect parameters for this provider .
return the callback url for this provider .
build redirect url for a given provider .
return callback url if different than the current url .
return url to redirect authenticated users .
return url to redirect on login failure .
message user and redirect on error .
"tests that a layouterror is raised if the onoverflow attribute for a keepinframe tag is set to "" error "" and the content does not fit in the frame ."
parse script arguments
remove all files and directories created within the tempdir
filter out our self.data to reflect only what we need / want in different functions
read all dictionaries present .
eve / character_name_single.xml
processing logic - extended from baseprocessor
grabs list of raw files ready to be processed
archives and queues up processed files for the inserter
parse a hue name into a float from 0 to 100 .
default function to determine whether to show the toolbar on a given page .
content of the panel when it 's displayed in full screen .
create model . : return :
: return :
annotates given sbml document using the annotations file .
annotate a given sbml file with the provided annotations .
creates unique hash i d for sbase in model .
creates a unique meta i d.
create identifiers.org resource from given collection and entity .
checks if the annotation is valid .
annotates the model with the given annotations .
create dictionary of ids for given model for lookup .
finds the model ids based on the regular expression pattern .
get list of sbml elements from given ids .
annotate given elements with annotation .
adds rdf information to given element .
lookup of sbmlqualifier for given qualifier string .
read annotations from csv in annotation data structure .
read annotations from xlsx file . xlsx is converted to csv file and than parsed with csv reader .
test equation . ba : a_ext = > a ; ( scale_f*(vmax_ba / km_a)*(a_ext - a))/(1 dimensionless + a_ext / km_a + a / km_a ) ;
returns server metadata .
evaluates whether ` request_perm ` is granted by ` effective_perm ` .
gets a list of resources for which the auth token is granted .
checks if the token has a permission .
gets a list of quotas for the given organization .
gets one quota for the given organization .
"checks if ` organization ` has the quota set for ` resource ` , and if ` used ` is not none , also checks if the quota value is higher than ` used ` ."
alias for the associated instance of |lnk| .
alias for the associated instance of |nhru| .
invoke a simple cli analyser or generator .
get a reference to a logger object . set some initial dictionaries .
construct a dictionary of urls that privet clients provide .
save a copy of the raw_image as soon as possible .
make sure we rotate both images .
get the serialized data from the : class:`serializer ` .
a class decorator enabling the instances of the class to be used as a ` ` services``-provider in ` jsonrpc objects ` _ and ` bsonrpc objects ` _ .
a method decorator announcing the method to be exposed as a request handler .
a method decorator announcing the method to be exposed as a notification handler .
a method decorator announcing the method to be exposed as a request handler .
a method decorator announcing the method to be exposed as a notification handler .
returns a template mapping ( dict ) for the following cases : - default params like ' { { package - version } } ' and ' { { artifact - dir } } ' - sha256 params like ' { { sha256 : artifact.zip } } ' ( requires user - provided paths to artifact files ) - custom environment params like ' template_some_param ' which maps to ' { { some - param } } '
builds a universe zip and returns its location on disk
display download link
replace inline attribute field to selectbox with choices
show inlines only in saved models
run action with selected settings
run action with selected settings
page views during last days .
page views during last days .
date of the day as yyyymmdd format .
days ago as yyyymmdd format .
basic average function .
"runs osc prdiff , returning captured stdout as a string ."
implementation of dpkg 's version comparison algorithm
adds package query to dict if it is of the correct architecture and is newer ( has a greater version ) than the currently assigned package .
returns a packagequeryresult instance
initialize a package dir
initialize a package dir with size_limit parameter
initialize a package dir with meta paramter
initialize a package dir ( dir already exists )
initialize a package dir ( dir+storedir already exists )
initialize a package dir ( dir is a file )
run sc2 to play a game or a replay .
"decode bytes . return a ( text , encoding ) tuple ."
read file from disk .
write file to disk .
write file to disk .
back reference to the editor .
true when some changes are not yet written to file .
read file i / o backend .
reload file again from storage .
write file to i / o backend .
return name as displayed .
buffer text changed .
return true when this i / o implementation is able to handle this ` location ` .
"return whether this location exists in this storage .. ( if not , this is a new file . )"
"read file for storage . returns ( text , encoding tuple . ) can raise ioerror ."
write file to storage . can raise ioerror .
enables the lyrics mania plugin that fetches track lyrics from lyricsmania.com
sets up the settings manager . expects a location to a file where settings will be stored . also sets up periodic saves to disk .
save every 30 seconds
copies one all of the settings contained in this instance to another
creates a copy of this settings object
set an option ( in ` ` section / key ` ` syntax ) to the specified value
"get the value of an option ( in ` ` section / key ` ` syntax ) , returning * default * if the key does not exist yet"
returns information about the existence of a particular option
"removes an option ( in ` ` section / key ` ` syntax ) , thus will not be saved anymore"
"sets the option directly to the value , only for use in copying settings ."
turns a value of some type into a string so it can be a configuration value .
convert setting strings back to normal values .
"save options after a delay , waiting for multiple saves to accumulate"
save the settings to disk
called when the plugin is disabled
mainwindow - info - area - widget provider api method
make sure we do n't accidentally set bpm on things
recalculates the bpm each time an event occurs
remove old taps so the bpm value converges faster
make sure we do n't accidentally set bpm on things
updates the current ui display
periodically updates the displayed list of events
: type uri : bytes : rtype : bytes
: type uri : bytes : type data : bytes
": param data : mood data , or none to not show any : type data : bytes|none : return : whether the mood data is successfully set : rtype : bool"
": param pos : seek position , between 0 and 1 inclusive , or none to hide : type pos : float|none"
set the text in the middle of the moodbar .
"add a color layer to the whole moodbar , or none to disable ."
handler for the ' draw ' signal .
factory function that should handle most cases for menus
"the factory function is called when the menu is shown , and should return a menu item . if it returns none , the item is not shown ."
"shortcut for providers.register ( ) , allows registration for use with a providermenu"
shortcut for providers.unregister ( )
": param parent : the parent for this menu : param context_func : a function for context retrieval : param inherit_context : if a submenu , inherit context function from parent menu"
retrieves the menu context which can contain various data
adds a menu item and triggers reordering
provide a simple mechanism to add menu items without a lot of hassle
removes a menu item
removes all menu items and submenus to prevent references sticking around due to saved contexts
reorders all menu items
regenerates the menu by retrieving the context and calling the factory method of all menu items
pops out the menu ( only if there are items to show )
enables the plugin
disables the desktop cover plugin
migrates gravity setting from the old integer values to the new string values
updates the cover image and triggers cross - fading
updates the position based on gravity and offsets
override for fade - in
override for fade - out
increases opacity until completely opaque
decreases opacity until transparent
fades between two cover images
"takes care of drawing the window transparently , if possible"
updates the colormap
updates the cover image and shows the window
hides the window at the end of playback
updates the cover image after cover selection
hides the window after cover removal
updates the appearance
sets up the message
checks api key and secret for validity and opens the uri for access permission
initiates the check for validity
initializes the manager
loads the plugin list
hides the messagebar if requested
enables or disables the selected plugin
reloads a plugin from scratch
shows a dialog allowing the user to choose a plugin to install from the filesystem
called when a row is selected
called when the checkbox is toggled
returns an atom of the given code by searching ' contains ' recursively .
allows closing only if the queue is empty
computes the median of a pareto distribution .
generates a plot of the exponential cdf .
reads the babyboom data .
plot cdf of interarrival time on log and linear scales .
generates a plot of the pareto cdf .
generates a plot of the cdf of height in pareto world .
generates a plot of the normal cdf .
plot the cdf of birthweights with a normal model .
generates a sample normal probability plot .
generates a normal probability plot of birth weights .
return the usage description of the test script .
get a list of all the files with a given extenstion in the directory .
visits all the blocks from a location forwards and returns path taken given a list of answers .
returns a list of the block ids visited based on answers provided : return : list of block location dicts
returns a list of the block ids visited based on answers provided : return : list of block location dicts
returns the next ' location ' to visit given a set of user answers if summary or sectionsummary is available then next location will be those . : param current_location : : return : the next location as a dict
check only the section you are on and that all blocks in that section are complete if the section has a summary section then pass that back as the next location the sectionsummary block itself does not need to be completed : param current_block_id : i d of block you 're routing from : param routing_path : routing path : return : location or none
returns the previous ' location ' to visit given a set of user answers : param current_location : : return : the previous location as a dict : return :
format a datetime string .
"this function format_conditional_date accepts two dates , a user submitted date and a metadata date"
patches the content_security_policy to add the request - specific nonce value
sends a message to rabbit mq and returns a true or false depending on if it was successful : param message : the message to send to the rabbit mq queue : param queue : the name of the queue : return : a boolean value indicating if it was successful
"create the json answer format for down stream processing : param metadata : metadata for the questionnaire : param schema : questionnaireschema class with populated schema json : param answer_store : the users answers : param routing_path : the path followed by the user when answering the questionnaire : param flushed : true when system submits the users answers , false when user submits there own answers : return : a json object in the following format : { ' tx_id ' : ' 0f534ffc-9442 - 414c - b39f - a756b4adc6cb ' , ' type ' : ' uk.gov.ons.edc.eq : surveyresponse ' , ' version ' : ' 0.0.1 ' , ' origin ' : ' uk.gov.ons.edc.eq ' , ' survey_id ' : ' 021 ' , ' flushed ' : true|false ' collection ' : { ' exercise_sid ' : ' hfjdskf ' , ' instrument_id ' : ' yui789 ' , ' period ' : ' 2016 - 02 - 01 ' } , ' submitted_at ' : ' 2016 - 03 - 07t15:28:05z ' , ' metadata ' : { ' user_id ' : ' 789473423 ' , ' ru_ref ' : ' 432423423423 ' } , ' data ' : { } }"
"create the json answer format for down stream processing : param metadata : metadata for the questionnaire : param feedback_json : the feedback json : param survey_id : the string representing the survey i d : return : a json object in the following format : { ' tx_id ' : ' 0f534ffc-9442 - 414c - b39f - a756b4adc6cb ' , ' type ' : ' uk.gov.ons.edc.eq : feedback ' , ' version ' : ' 0.0.1 ' , ' origin ' : ' uk.gov.ons.edc.eq ' , ' survey_id ' : ' 021 ' , ' collection ' : { ' exercise_sid ' : ' hfjdskf ' , ' instrument_id ' : ' yui789 ' , ' period ' : ' 201602 ' } , ' submitted_at ' : ' 2016 - 03 - 07t15:28:05z ' , ' metadata ' : { ' user_id ' : ' 789473423 ' , ' ru_ref ' : ' 432423423423 ' } , ' data ' : { } }"
returns true if the given block should be checked for completeness
waterbutler.core.mime_types contains content type overrides .
mime_types should not override file extension not in the dict
returns a dict of primitives suitable for serializing into json .
"returns a dict of primitives suitable for serializing into a json - api -compliant response . sets the ` i d ` and ` type ` attributes required by json - api , and stores the metadata under the ` attributes ` key . a ` links ` object provides a dict of actions and the urls where those actions can be performed ."
returns a dict of action names and the endpoints where those actions are performed .
utility method for constructing the base url for actions .
does this object describe a folder ?
does this object describe a file ?
the provider from which this resource originated .
` file ` or ` folder `
"the user - facing name of the entity , excluding parent folder(s ) . : :"
"the canonical string representation of a waterbutler file or folder . for providers that track entities with unique ids , this will be the id . for providers that do not , this will usually be the full unix - style path of the file or folder ."
the unix - style path of the file relative the the root of the provider . encoded entities should be decoded .
a dict of optional metadata from the provider . non - mandatory metadata should be stored in this property .
returns a dict representing the file 's metadata suitable to be serialized into json .
adds the ` download ` link to the json - api repsonse ` links ` field .
file objects have ` kind = = ' file ' `
mime - type of the file ( if available )
"date the file was last modified , as reported by the provider , in the format used by the provider ."
"date the file was last modified , as reported by the provider , converted to utc , in format ( yyyy - mm - ddthh : mm : ss+00:00 ) ."
"date the file was created , as reported by the provider , converted to utc , in format ( yyyy - mm - ddthh : mm : ss+00:00 ) ."
size of the file in bytes .
the json api serialization of revision metadata from waterbutler .
"date the revision was last modified , as reported by the provider , converted to utc , in format ( yyyy - mm - ddthh : mm : ss+00:00 ) ."
"returns a dict representing the folder 's metadata suitable to be serialized into json . if the ` children ` property has not been set , it will be excluded from the dict ."
"return a json - api compliant serializable dict , suitable for the wb v1 api . sets the ` size ` attribute to ` none ` , as folders do no have a size ."
adds the ` new_folder ` link to the json - api repsonse ` links ` field .
( optional ) a list of child entities of the folder . each entity should be either a file or folder metadata object . will be ` none ` if the presence of children is unknown .
assigns the given list to the children property . the affirmative absence of child entities should be indicated by passing an empty list .
folder metadata objects have ` kind = = ' folder ' `
fixme : an etag ?
function : get_kpap(dn ) --------------------- returns the geophysical indices for datetime object dn
"function : get_apmsis(dn ) --------------------- returns an array of calculated ap indices suitable for msis . msis requires an array of ap values , described in nrlmsise00.f . this python function formulates the various ap values for msis . from the fortran subroutine , we see that"
creates all necessary widgets .
layouts the widgets into a gridlayout
makes everything pretty and set double validators for the line edits .
connecting actions to slots .
returns the intensity cutoff selected in the dialog .
returns the minimum d - spacing selected in the dialog .
overwriting the dialog exec _ function to center the widget in the parent window before execution .
adds an overlay to the list of overlays : param x : x - values : param y : y - values : param name : name of overlay to be used for displaying etc .
"adds a pattern as overlay to the list of overlays , does not use its original scaling parameters"
"reads a 2 - column ( x , y ) text file and adds it as overlay to the list of overlays : param filename : path of the file to be loaded"
removes an overlay from the list of overlays : param ind : index of the overlay
: param ind : overlay ind : return : returns overlay if existent or none if it does not exist
sets the scaling of the specified overlay : param ind : index of the overlay : param scaling : new scaling value
returns the scaling of the specified overlay : param ind : index of the overlay : return : scaling value
sets the offset of the specified overlay : param ind : index of the overlay : param offset : new offset value
return the offset of the specified overlay : param ind : index of the overlay : return : overlay value
please refer to backend_service 's conversation_controller.upload_file for supported image formats .
uses otsu ' adaptive thresholding to convert the image to black / white pixels based on its immediate surroundings
"sort corners : top - left , bot - left , bot - right , top - right"
"using euclidean distance , calculate the height and width of the final rendered image"
generates a report for a prediction based on ml input : param conversation : the current conversation : param ml_prediction : a dictionary of outcomes for the conversation received from ml_service : param similar_precedents : a list of dicts containing precedents similar to the current case : param probabilities_dict : a dict of probabilities for every outcome classifier : return : a dict of a report detailing the prediction made by the ml_service
: return : dict of outcomes with relevant facts from the ml endpoint
: return : dict of antifacts from the ml endpoint .
: return : dict of antifacts from the ml endpoint .
submits list of resolved facts to ml endpoint . should only be done once all facts have been asked and resolved . : param conversation : the current conversation : return : outcomes vector from ml service
"given the ml service response and a claim category , will extract the non zero predictions and the essential outcomes for that claim category . : param claim_category : the current conversation 's claim category as a string : param ml_response : the response dict received from ml service : return : dict of relevant outcomes for the claim category returned by ml service"
"generates fact dictionary for ml service . maps values for unasked facts based on asked facts , or provides default mappings . : param conversation : the current conversation : return : fact dictionary with mapped facts and resolved facts"
executes machine learning with command line example usage : 1 ) python3 main.py -pre 10000 2 ) python3 main.py -post 3 ) python3 main.py -train : param command_list : command line arguments : return : none
"filters keys of each element of iterable $ .(a , b ) returns all objects from array that have at least one of the keys : [ 1,""aa"",{""a"":2,""c"":3},{""c"":3},{""a"":1,""b"":2}].(a , b ) - > [ { "" a"":2},{""a"":1,""b"":2 } ]"
returns the current line number in our program .
example output : :
uses http proxy if available
send a json message directly to the websocket . see ` rtm documentation < https://api.slack.com/rtm ` for allowed types .
sends a message to a given channel .
"returns data if available , otherwise '' . newlines indicate multiple messages"
join a channel by name .
call the slack web api as documented here : https://api.slack.com/web
pretty print json document with indentation .
get the authorization code from the event .
get the oauth token and team data from slack .
store the team information to the database .
slackbot installer .
convert fixture into * behave * examples : param fixture : a dictionary in the following form : :
: param py : python format or not
"format table to * behave * example : param table : ` ( caption , rows ) ` , each item in ` rows ` is ` ( col1 , col2 , ... ) ` : return"
number of links in the group .
deference a reference object .
x.__getitem__(y ) < = = > x[y ]
recursively visit all names in the group and subgroups .
recursively visit all objects in this group and subgroups .
attrs attribute .
return the object pointed to by a given address .
close the file .
read from a hdf5 dataset directly into a numpy array .
return a context manager which returns data as a particular type .
return the size of the first axis .
shape attribute .
number of dimensions .
dtype attribute .
alias for dataset [ ( ) ] .
size attribute .
chunks attribute .
compression attribute .
compression_opts attribute .
scaleoffset attribute .
shuffle attribute .
fletcher32 attribute .
fillvalue attribute .
dims attribute .
пример скрипта обновления . добываем события любым способом и кормим в analyze_events .
台詞を入力として候補をスコア降順に返す : type words : unicode : rtype : list[dict ]
parametrized constructor for the kvm model
representation function represent a kvm model by its ' test_id ' field .
parametrized constructor for the maintenancemode model
representation function represent a maintenancemode model by its platform and status field .
give a good spelling of the input word : param word : str : return str : word
create folder of new environment project
set parameters of new environment project
update layers_count for database model .
remove a layer 's harvest job so that it may be re - imported later .
importlayers management command should properly overwrite .
import_qgis_styles management commands should run properly .
returned all files related with this layer .
returned qgis layer path prefix .
returned qgis layer name associated with this layer .
returned qgis project path related with this layer .
returned the location of tile cache for this layer .
returned the location of qml path for this layer ( if any ) .
delete all files related to this object from disk .
get associated resource base .
convert to this model from getcapabilities style tag .
returned the location of tile cache for this layer style .
get associated resource base .
returned qgis map name associated with this layer .
returned qgis map path prefix .
returned qgis project path related with this map .
returned the location of tile cache for this layer .
check that applied settings configured correctly .
test that qgis server url is reachable .
test that siteurl is properly configured and reachable .
test that ogc_server settings were properly wrapped .
tests the activity functionality when a layer is saved .
workaround inspired by https://github.com/mozilla/addons-server/pull/4875/files#diff-0223c02758be2ac7967ea22c6fa4b361r96
http - less csw
return true if the list of names contains a bad one
replaces a string that matches the regex with the replacement .
returns files that end with the given extension from a list of file names .
returns the files sans anything in a _ _ macosx directory
provide hint on the type of file being handled in the upload session .
get a list of spatialfiles for the provided file
perform sanity checks on uploaded zip file
encrypt the content of ' src ' file with the certifacts in ' certs ' into ' dst '
decrypt the content of ' src ' with the private key in ' pfxfile ' . the ' pfxfile ' is open using the ' password '
generate a sha256 / rsa key pair . a self - signed certificate with ' common_name ' is stored as ' outname'.cer . the private key is stored in ' outname'.pfx protected with ' pfxpassword '
called when breakpoint is hit
` ` size ` ` : the size of the memory breakpoint .
extracts the functions parameters in an : class:`ordereddict `
"setup a breakpoint at the return address of the function , this breakpoint will call : func:`ret_trigger `"
called at the return of the function if : func:`break_on_ret ` was called
"we want to know if an item is modified that is stored in this dict . if the element is a list or dict , we wrap it in a proxylist or proxydict , and if it is modified execute a callback that updates this instance . if it is a zenpyobject , then the callback updates the parent object ."
"we want to know if an item is modified that is stored in this list . if the element is a list or dict , we wrap it in a proxylist or proxydict , and if it is modified execute a callback that updates this instance . if it is a zenpyobject , then the callback updates the parent object ."
subclasses should do whatever processing is necessary and return a list of the results .
handle retrieving and processing the next page of results .
add attributes such as count / end_time that can be present
retrieve the next page of results .
"when slicing , remove the per_page and page parameters and pass to requests in the params dict"
check users params
scan action of module
is module finished ?
prepare generator for work
list of cms from db
list of uniq cms paths
return id of hash by path from cms_paths_hashes table
return a cms list by hashes ids
get all paths of current cms
( 3.8 )
"( 3.13 ) : param remove_cols : number of list , start from 0 . or feature name match ` features_name ` : return :"
find out encoding .
get one page suppling ' wait ' time .
get multiple pages .
exciter model .
loads event data .
instrument a binary and a default input file
dynamically allocates a new section of memory in the new binary
sets bytes at a given location
sets bytes in a given location based on stdin
issue an optionally - permanent redirect to another location .
serve the specified file as a chunked response .
make sure the given absolute path does not point above the htroot .
serve a request which points to a directory .
serve a request which points to a file .
serve a page for a given http error .
return a server - making callable to create a cherrypy wsgi server .
return a unittest . testsuite with regression tests for the files in data_dir .
extension of expected filename .
"try to convert the source , an .md ( markdown ) file , to an .rst ( restructuredtext ) file at the destination . if the destination is n't provided , it defaults to be the same as the source path except for the filename extension . if the destination file already exists , it will be overwritten . in the event of an error , the destination file will be left untouched ."
"call the conversion routine on readme.md to generate readme.rst . why do all this ? because pypi requires restructuredtext , but markdown is friendlier to work with and is nicer for github ."
resolves a iiif identifier to the resource 's path on disk .
register filter and global in jinja environment instance
split a path into segments and perform a sanity check . if it detects ' .. ' in the path it will raise a ` templatenotfound ` error .
create a parser for xml data .
parse an xsd path
validate an xml element
"returns aggregated archival info for a dataset , given the archivals for its resources ( returned by get_for_package ) ."
"returns the archival for the given resource , or if it doens't exist , returns none ."
returns the archivals for the given package . may not be any if the package has no resources or has not been archived . it checks the resources are not deleted .
checks if this method is enabled for an event and its business lines in the user preferences
"renders a notification template ( subject , description , short description ) for a given instance which fired an event"
choose the first matching template in a template list
retrieve user configuration for this method as a dict
checks if this method is configured for a given user
returns this method configuration form
return path to cdp browser .
call a particular cdp method such as runtime.evaluate
find an unused port and claim it through lock file
return the current javascript console log
returns an iterator that produces log messages one by one .
parse representations to int
builds the image model subgraph and generates image embeddings .
sets up the global step tensor .
this function create a random sparse index matrix with a given shape . it is useful to create negative triplets .
determine pair - wise independent variants .
compute minor allele frequencies .
principal component analysis .
constructor args : pos : position chrom : chromosome
"split into windows args : method : method used to slit the windows : ' slidingwindow ' : uses a sliding window ' genewindow ' : uses windows centered on genes size : window size used in slidingwindow method step : moving step used in slidingwindow method annotation_file : file containing the annotation file for genewindow method minsnps : only windows with nsnps>=minsnps are considered maxsnps : only windows with nsnps>=maxsnps are considered cache : if results need to be cashed out_dir : folder used for caching fname : name of the hdf5 file used for caching rewrite : if true , rewrite the existing cache hdf5 file"
split into windows using a slide criterion args : size : window size step : moving step ( default : 0.5*size ) minsnps : only windows with nsnps>=minsnps are considered maxsnps : only windows with nsnps>=maxsnps are considered
split into windows based on genes
use private argparse apis to get the usage string without the ' usage : ' prefix .
test values after saving and loading of .dense format .
test the type after saving and loading of .dense format .
test values after saving and loading of .sparse format .
4 test the type after saving and loading of .sparset1 format .
test values after saving and loading of .dense format .
test the type after saving and loading of .dense format .
test values after saving and loading of .sparse format .
4 test the type after saving and loading of .sparset1 format .
test values after saving and loading of .sparse format .
4 test the type after saving and loading of .sparset1 format .
test values after saving and loading of .sparse format .
4 test the type after saving and loading of .sparset1 format .
"compatibility only , do n't use . same as losewriteconnection ."
"compatibility only , do n't use . call pauseproducing ."
"compatibility only , do n't use . call resumeproducing ."
serialize an object graph into a sequence of bytes . returns a deferred that fires with the sequence of bytes .
unserialize a sequence of bytes back into an object graph .
devuelve la lista de estilos ( returns the list of styles )
devuelve un estilo dado su dirname ( returns a style given its dirname )
borra un estilo ( deletes a style )
añade un estilo ( adds a style )
registra un escuchador interesado en ser informado de los cambios producidos en stylestore ( registers a listener interested in being informed of the changes in stylestore )
carga los estilos desde el directorio de estilos definido en config ( loads the styles from the directory defined in config )
make a win32 event object for a socket .
add a new win32 event to the event loop .
remove an event .
add a socket filedescriptor for notification of data available to read .
add a socket filedescriptor for notification of data available to write .
remove a selectable for notification of data available to read .
remove a selectable for notification of data available to write .
"remove all selectables , and return a list of them ."
spawn a process .
implement the specific resource finding mechanism for this idevice :
"like getresourcesfield ( ) , a general helper to allow nodes to search through all of their fields without having to know the specifics of each idevice type ."
takes a beautifulsoup fragment ( i ) and bursts its contents to import this idevice from a commoncartridge export
upgrades the node from version 0 ( exe version 0.4 ) to 1 . adds icon
upgrades the node from version 1 ( not released ) to 2 use new field classes
"upgrades the node from 2 ( v0.5 ) to 3 ( v0.6 ) . old packages will loose their icons , but they will load ."
upgrades v0.6 to v0.7 .
upgrades v0.6 to v0.7 .
upgrades to v0.12
attach the idevice to the textareafield for tinymce image embedding :
"when no label was given , docstring is given preference compared to action ."
"when a label was given , it is given preference compared to docstring ."
"make and return a new block . if height or width is specified , they may be of any css - supported measurement format , such as ' 200px ' or ' 50 % ' ."
implement the specific resource finding mechanism for this idevice :
upgrades the node from version 0 to 1 .
"upgrades the node from 1 ( v0.5 ) to 2 ( v0.6 ) . old packages will loose their icons , but they will load ."
upgrades v0.6 to v0.7 .
upgrades to exe v0.10
upgrades to exe v0.10
"upgrades to somewhere before version 0.25 ( post - v0.24 ) taking the old unicode string fields , and converting them into image - enabled textareafields :"
delete icon from system resources
upgrades the node from version 0 to 1 .
"upgrades the node from 1 ( v0.5 ) to 2 ( v0.6 ) . old packages will loose their icons , but they will load ."
"upgrades to somewhere before version 0.25 ( post - v0.24 ) taking the old unicode string fields , and converting them into image - enabled textareafields :"
register this block with the blockfactory
process the request arguments from the web server to see if any apply to this block
returns an xhtml string with the form element for editing this block
returns an xhtml string for previewing this block
returns an xhtml string for viewing this block
implement the specific resource finding mechanism for this idevice :
"like getresourcesfield ( ) , a general helper to allow nodes to search through all of its fields without having to know the specifics of each idevice type ."
takes a beautifulsoup fragment ( i ) and bursts its contents to import this idevice from a commoncartridge export
upgrades exe to v0.10
upgrades to v0.12
add _ urlinstruc
process arguments from the webserver . return any which apply to this element .
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
returns an xhtml string with the form element for editing this field
returns an xhtml string with the form element for previewing this field
creates a package
get package using the name
add a package
save all the packages in the package store out to disk
"load a package from disk , add it to the store and return it"
creates a new package from template
initialize a new block object
process the request arguments from the web server
returns an xhtml string with the form element for editing this block
returns an xhtml string for previewing this block
returns an xhtml string for viewing this block
register with the idevicestore
"the user twiddled a control onscreen , causing this event"
"the user hit a button onscreen , causing this event"
save the model object to persistent storage
when the model updates the view should too
when the model updates the view should too
create a workflow and store in the database .
set the configuration for workflow with id workflow_id .
get a workflow with id workflow_id
return all of the existing workflows
inline function calls ( to enable distributed pass analysis )
convert dataframe calls
convert io calls
parallelize for distributed - memory
convert hiframes after typing
apply copy propagate in filter node
reflection matrix for reflecting through a plane through the origin specified by its normal
converts a complex array to a multidimensional float array .
"converts a multidimensional float array to a complex array . input must be a float type , since there is no integer complex type ."
finds the point in the plane that lies at the intersection of the line from a1 to a2 and the line from b1 to b2 .
creates and initializes a record array with specified defaults instead of whatever garbage happened to already be there .
"transposes an array of shape n x 2 into a wide 2d array , using the first column as an index . blanks in the array are filled in with the argument filler ( by default -1 )"
take a bunch of arrays of the same first dimension and combine them into a record array
renumbers an index of a subarray given by the boolean array inarray . ( this will probably make more sense if you look at the doctest . )
"the scalar triple product of 3 vectors a dot b cross c = determinant of [ a b c ] a , b , and c must have last dimension = 3"
normalizes vectors in n - space . the zero vector remains the zero vector .
spherical linear interpolation .
linear interpolation .
normalized linear interpolation .
distance between points in euclidean space .
"area of euclidean triangle given by a , b , and c."
"returns the bearing ( angle ) between points . by default , the bearing is calculated with respect to the + y direction ."
"central angle between vectors with respect to 0 . if vectors have norm 1 , this is the spherical distance between them ."
"for use with the naive slerp methods . takes the central angle between each of the points in pts . if they are close , returns the central angle . if not , raises an error ."
"solid angle of a triangle with respect to 0 . if vectors have norm 1 , this is the spherical area . note there are two solid angles defined by three points : this will always return the smaller of the two . ( the other is 4*pi minus what this function returns . )"
"returns the bearing ( angle ) between points . by default , the bearing is calculated with respect to the north pole . can also be considered as the angle adjacent to origin in the triangle formed by origin , destination , and pole ."
"gives a base shape centered on [ 0,0,1 ] ."
cheezy function to get the factors of a small number other than 1 and itself
produces a bunch of svg files and a csv file for use with pattypan
closes the infobar .
opens a directory browser .
returns the chosen directory .
returns whether or not the text is invalid .
test getalltes method
test getallduplication method
test getnonredondantduplications method
test getallalignments method
"name : elliptical_slice purpose : markov chain update for a distribution with a gaussian "" prior "" factored out input : initial_theta - initial vector prior - cholesky decomposition of the covariance matrix ( like what numpy.linalg.cholesky returns ) , or a sample from the prior lnpdf - function evaluating the log of the pdf to be sampled pdf_params= parameters to pass to the pdf cur_lnpdf= value of lnpdf at initial_theta ( optional ) angle_range= default 0 : explore whole ellipse with break point at first rejection . set in ( 0,2*pi ] to explore a bracket of the specified width centred uniformly at random . output : new_theta , new_lnpdf history : originally written in matlab by iain murray ( http://homepages.inf.ed.ac.uk/imurray2/pub/10ess/elliptical_slice.m ) 2012 - 02 - 24 - written - bovy ( ias )"
collect form errors and return the error messages as a list .
changes all strings to unicode and encodes as utf-8 so we can save texts with special characters to json without the escape sequences http://stackoverflow.com/q/18337407
"takes in filepath to json file , reads it and returns a python object"
takes in filepath and data object saves data to json in filepath
get random user agent string
get headers object with random user agent
start print_signals and yield dumb - init process and print_signals pid .
return a list of direct child pids for the given pid .
return a list of all descendant pids for the given pid .
return whether a process is running with the given pid .
"return a process ' state , such as "" stopped "" or "" running "" ."
"sleep until fn succeeds , or we time out ."
"kill a process , ignoring "" no such process "" errors ."
"rel : a relevance grade ( positive integer ) qid : a query id ( positive integer ) features : a dict of { feature : value } , where ` feature ` is a positive integer ."
read a document in the line format : < line > .=. < target > qid:<qid > < feature>:<value > < feature>:<value > ... < feature>:<value > # < info > < target > .=. < positive integer > < qid > .=. < positive integer > < feature > .=. < positive integer > < value > .=. < float > < info > .=. < string >
documents : list of document ids rels : dict indicating the relevance grade of a document id cutoff : cutoff rank
gets the latest timestamped backup file name with the given database type extension .
validate the consistency of a configuration object for the specific model
set the initial model configuration
check the consistency of initial status : param valid_status : valid node configurations
execute a bunch of model iterations
"describes the current model parameters ( nodes , edges , status )"
reset the simulation setting the actual status to the initial configuration .
specify the statuses allowed by the model and their numeric code
execute a single model iteration
evaluate similarity among statuses
compute the point - to - point variations for each status w.r.t . the previous system configuration
build node status and node delta trends from model iteration bunch
": param models : a list of model object : param trends : a list of computed simulation trends : param statuses : the model statuses for which make the plot . default [ "" infected "" ] ."
: param plot : the bokeh plot to add to the grid
: param ncols : number of grid columns : return : a bokeh figure image
构造函数，通过视图类型，当前日期，星期开始时间计算视图的开始时间和结束时间 和python 传统计算方式不同，此处weekstartday是一个星期从哪一天开始，1代表星期一，0代表星期天
return the status_person_id i d and the date of the given status
update the payments set on task_id
return the taskmentions available for the task related forms
return the tva objects available for this form
return the product objects available for this form
return the workunit objects available for the given form
return the paymentconditions objects available for the given form
used to fit colander 's invalid exception api
return an hexadecimal version of the rgb tuple for css rendering
return a random color
pop all directories informations included in a filename used to avoid problems with ie who 's sending absolute filepaths
returns the url for the preview
"tries to get a element given by name , or default when it does n't exists"
retrieves the file contents of a given file
writes file datas to a file
pass file datas through filters
return the destination file path
saves the file contents to a file
return the max allowed filesize configured in autonomie
return the file upload field description
validates the file 's size
return the form schema for template upload
pass file datas through filters
add views for payments configuration
build a deferred for company selection widget
return a schema node for company selection
ensure we do n't query customers from other companies
return a customer selection node
return the current company i d allows company i d access through request 's context
return a query
disable the current company
enable a company
return a dict representation
"get all tasks for this company , as a list"
: param int nb_per_page : how many to return : param int page_nb : pagination index
return the estimations of the current company
return the invoices of the current company
return the cancelinvoices of the current company
return true if this company owns invoices
return the real customers ( with invoices )
return invoices waiting for more than 45 days
return current company 's customer codes and names
return current company 's project codes and names
return the next estimation index
return the next invoice index
return the next cancelinvoice index
retrieve the annual turnover for the current company
build a header image containing text
returns a white layer that will be our image background
"complete the image to get at last my proportions , not more"
return true if the expenses were already configured
return a form to select the period of the expense sheet
list of years an expensesheet has been retrieved for
return expenses stored by year and users for display purpose
view that lists the expensesheets related to the current company
"return a payment form name , add the form to the page popups as well"
"extract the current company i d from the request , if there is one"
retrieve the companies the current user has access to
retrieve the current company object
build the usermenu
build the admin menu
add the company choose menu
"return the user menu ( my account , holidays ... )"
top menu panel
a panel to render the navigation inside the administration interface
pyramid 's inclusion mechanism
usefull shortcut to add an item to the menu
add an element to the menu
insert an element at the begining of the menu
return the period configured in the current request
return the expense sheet for the given 4 - uple
return a new expense sheet for the given 4 - uple
fire an expensestatuschanged event
"button for "" go back to project "" link"
add buttons in the request actionmenu attribute
return an excel filename based on the request context
add module 's related routes
declare all the routes and views related to this module
find an existing expense sheet
create a new expense sheet instance
find an existing expense sheet
create the payment
shorten the civilite string
return a validator for the expensetype
validate the amount to keep the sum under the total
return a schema for expense add
"if s is an executable path , return the output of check_output applied to it . if it 's a path , but not executable , return the contents of the file . if it 's not a path , return the string ."
add a new batch of predictions .
load all the predictions added with the ' add ' member function into the appropriate fields of this object . this should be called only with a reasonable number of predictions .
return true iff we have the data and the flags needed to do an accuracy assessment .
return indexes of in correct alignments in order from highest to lowest predicted pcor
return a dataframe summarizing information about
write a roc table with # correct/ # incorrect stratified by predicted mapq .
write a roc table with # correct/ # incorrect stratified by predicted mapq .
write a roc table with # correct/ # incorrect stratified by predicted mapq .
"close prediction file handle . if we have the information and flags needed for accuracy assessment , then do that too ."
return user details from weibo . api url is : https://api.weibo.com/2/users/show.json/?uid=<uid>&access_token=<token >
saves current social - auth status to session .
"adds parameters to url , parameter will be repeated if already present"
"given the hostname and an untrusted url to redirect to , this method tests it to make sure it is n't garbage / harmful and returns it , else returns none , similar as how 's it done on django.contrib.auth.views ."
"converts to lowercase , removes non - word characters ( alphanumerics and underscores ) and converts spaces to hyphens . also strips leading and trailing whitespace ."
return the first item in the list for what func returns true
like urlparse.parse_qs but transform list values to single items
return access_token stored in extra_data or none
return provider session live seconds . returns a timedelta ready to use with session.set_expiry ( ) .
disconnect the social account for the given user
return true / false if a user instance exists with the given arguments . arguments are directly passed to filter ( ) manager method .
create a user with given username and ( optional ) email
return all the usersocialauth instances for given user
return user details from douban
return user data provided
return user details from douban
return user data provided
"returns a : class:`channel ` with the given id . if not found , returns none ."
"returns a : class:`member ` with the given id . if not found , returns none ."
gets the @everyone role that all members have by default .
gets the default : class:`channel ` for the server .
returns the url version of the server 's icon . returns an empty string if it has no icon .
returns the url version of the server 's invite splash . returns an empty string if it has no splash .
returns the true member count regardless of it being loaded fully or not .
returns the server 's creation time in utc .
returns the server 's roles in the order of the hierarchy .
returns the first member found that matches the name provided .
a function that tries to turn the value into enum ` ` cls ` ` .
按 i d 查询用户
按 username 查询用户
按 email 查询用户
查询活动详情 get /api / activity/<int : activity_id >
"like list.index , but gives the index of the * last * occurrence ."
"given the list of arguments to be passed on to the planner components , split it into a prefix of filenames and a suffix of options . returns a pair ( filenames , options ) ."
"partition args.planner_args , the list of arguments for the planner components , into args.filenames , args.translate_options , arge.preprocess_options and args.search_options . modifies args directly and removes the original args.planner_args list ."
guess which planner components to run based on the specified filenames and set args.components accordingly . currently implements some simple heuristics :
"set args.components to the planner components to be run and set args.translate_inputs , args.preprocess_input and args.search_input to the correct input filenames ."
"show explicit help for remaining args instead of "" ... "" ."
test that delete - effects are applied before add - effects
"name : the name of the predicate . signature : a list of tuples ( name , [ types ] ) to represent a list of parameters and their type(s ) ."
addlist : set of predicates that have to be true after the action dellist : set of predicates that have to be false after the action
"name : the name identifying the action signature : a list of tuples ( name , [ types ] ) to represent a list of parameters an their type(s ) . precondition : a list of predicates that have to be true before the action can be applied effect : an effect instance specifying the postcondition of the action"
name : the name of the domain types : a dict of typename->type instances in the domain predicates : a list of predicates in the domain actions : a list of actions in the domain constants : a dict of name->type pairs of the constants in the domain
name : the name of the problem domain : the domain in which the problem has to be solved objects : a dict name->type of objects that are used in the problem init : a list of predicates describing the initial state goal : a list of predicates describing the goal state
writes a registery script to update the path variable into the sync registry
reads csv in unicode
creates a csv table with aligned columns
tests that .com urls are accepted
"return [ ( url , label , selected ) , ... ]"
"return [ ( url , label , selected ) , ... ]"
delete gallery and all pictures belonging to it .
remove picture from the gallery and delete the image file on server .
set picture as the galleries primary picture .
add a picture to the gallery .
create a new gallery .
return an iterable of functions .
calculate the maximum width of container names so we can make the log prefixes line up like so :
return a generator that prints a warning about logs and waits for container to exit .
consume the queue by reading lines off of it and yielding them .
returns the path to the default aws credentials file . this is where the temporary access keys will be stored unless otherwised specified by the user . : return : the path to the default credentials file
returns the path to the default aws credentials file . this is where the temporary access keys will be stored unless otherwised specified by the user . : return : the path to the default credentials file
parses the command line options . : return : an options object
sets up logging based on some command line options . : param options : options parsed from the command line
generates a configuration file for subsequent runs to consume .
creates a config object and overrides any values provided on the command line . : param options : parsed command line options : return : the config object
creates an authenticator object based on what credential information was passed as arguments . : param options : pasred command line options : return : an authenticator object
generates a set of aws iam credentials for each available role for the principal . : param options : the parsed command line arguments : param config : the kerb configuration : param authenticator : the authenticator object used to handle adfs authentication
"application entrypoint . parses the command line options , sets up the configuration for the token generation , and then starts generating token(s ) for the given options . : return :"
returns differentially methylated probes among sample 1 and 2 : param samples1 : list of sample 1 : param samples2 : list of sample 2 : return : a list of probes ids
helper function to list all names passed to a variable .
helper function to write all the members of var_dict to the makefile .
add the local_path line to the makefile .
add the clear_vars line to the makefile .
add a line to include stlport .
"given all the variables , write the final make file ."
create a new varsdictdata .
tests create_filepath_url ( ) .
tests copy_contents ( ) .
"args : diff_base_url : base url indicating where diff images can be loaded from descriptions : a ( string , string ) tuple describing the two image sets . if not specified , default_descriptions will be used ."
adds an imagepair ; this may be repeated any number of times .
overrides the default settings for one of the extracolumn headers .
returns the columnheaderfactory object for a particular extracolumn .
ensure this column_id / value pair is part of the extracolumns summary .
records one column_id / value extracolumns pair found within an imagepair .
returns all column headers as a dictionary .
returns a dictionary describing this package of imagepairs .
berechnet das gewichtete mittel über das attribut attr für die fragebogenliste fb_list .
berechne die checksumme eines ean barcodes
prüfe die checksumme eines ean barcodes
es sollen rechte wiederhergestellt werden die vorher nicht abgegebn wurden
a double smooth normalization of a spectrum
normalize multiple spectra using the same configuration this is specially designed for thekeenan
"parameters ---------- pixel_disp : np.ndarray dispersion array wave_arm : int the arm length in terms of pixels frac : float the reserved fraction , between 0.00 and 1.00"
normalize multiple spectra using the same configuration
"the function ` ` random_booster ` ` uses random thresholds and indices to train a classifier . it performs ` ` t ` ` rounds of boosted decision stumps to classify the data ` ` x ` ` , which is an m - by - n matrix of m training examples of dimension n."
the function ` ` plt_errors_over_time ` ` plots train and test error from boosting . it plots the training and testing error of a decision - stump based boosting algorithm over iterations of the boosting algorithm .
"this function returns a discretized value ( a number ) for a continuous state vector . currently x is divided into 3 "" boxes "" , x_dot into 3 , theta into 6 and theta_dot into 3 . a finer discretization produces a larger state space , but allows a better policy ."
parse arguments and return an arguments object
"merge command line arguments , config files , and default configs"
"fetch environment variables , returning a default if not found"
create configuration has from command line arguments
ensure all arguments provided correspond to a file
ensure file exists at the provided path
ensure all arguments correspond to directories
ensure directory exists at the provided path
load configuration from yaml file
validate configuration dict keys are supported
produce a ball of walkers around an initial parameter value .
testing delete an icmp entry
testing delete a tcp entry
testing delete an udp entry
initialize the driver
delete conntrack entries specified by list of rules
delete all conntrack entries within namespace
parse entry from text to python tuple
delete all conntrack entries
list and parse all conntrack entries
delete selected entries
finds pixels with maximum value within a region of interest
use the user settings to define the number of workers that are being used
check if the wallet is enabled .
create a journal object from the standard fatebook
"test impact cast , impact revert and total allowed impact"
"init function , reads the config containing server list args : input_file - a yaml file containing a key nodes containing the server list logger_config - configuration for logger return : none raise : none"
return the list of all the nodes args : none return : list of all the nodes raise : none
return a random nodes from the full list args : none return : a random node raise : none
read the items from the key nodes in the topology config and add it to the attribute resolved_topology args : none return : none raise : none
computes the log_likelihood of the data
computes the maximum likelihood covariance estimator
"parameters ---------- store_precision : bool specify if the estimated precision is stored assume_centered : boolean if true , data are not centered before computation . useful when working with data whose mean is almost , but not exactly zero . if false , data are centered before computation ."
saves the covariance and precision estimates
fits the maximum likelihood estimator covariance model according to the given training data and parameters .
computes the log - likelihood of a gaussian data set with ` self.covariance _ ` as an estimator of its covariance matrix .
computes the mean squared error between two covariance estimators . ( in the sense of the frobenius norm )
computes the mahalanobis distances of given observations .
test meanshift algorithm
constructs a new estimator with the same parameters .
pretty print the dictionary ' params '
returns the final estimator if there is any .
returns true if the given estimator is ( probably ) a classifier .
get parameter names for the estimator
get parameters for the estimator
set the parameters of the estimator .
returns the mean accuracy on the given test data and labels .
returns the coefficient of determination r^2 of the prediction .
"fit to data , then transform it"
centers and norms x * * in place * *
test gram schmidt orthonormalization
test the fastica algorithm on very simple data .
test the fastica algorithm on very simple data .
attempts to retrieve a reliable function code hash .
windows can not encode some characters in filenames
"return the function import path ( as a list of module names ) , and a name for the function ."
"filters the given args and kwargs using a list of arguments to ignore , and a function specification ."
test bayesianridge on diabetes
test bayesianridge on toy
test bayesianregression ard classifier
tests covariance module on a simple dataset .
tests ledoitwolf module on a simple dataset .
tests oas module on a simple dataset .
ward clustering based on a feature matrix .
warning : modifies connectivity in place
function cutting the ward tree for a given number of clusters .
fit the hierarchical clustering on the data
fit the hierarchical clustering on the data
calculates the parameters for a perfect hash . the result is returned as a hashinfo tuple which has the following fields :
returns a list of rows that are stored as a priority queue to be used with heapq functions .
"takes a priority queue as generated by place_items_in_square ( ) . arranges the items from its conceptual square to one list . returns both the resultant vector , plus the displacement vector , to be used in the final output hash function ."
finds the first index that the row 's items can fit .
checks if all the occupied columns in the row fit in the indices given by free columns .
prints a row queue as its conceptual square array .
returns the list without all the nones at the right end .
creates a perfect hash function from the given keys . for a description of the keyword arguments see : py : func:`hash_parameters ` .
creates a dictionary - like mapping class that uses perfect hashing . ` ` name ` ` is the proper class name of the returned class . see ` ` hash_parameters ( ) ` ` for documentation on all arguments after ` ` name ` ` .
samples a value using the explicit p
"computes the joint p(q , y )"
is this input event a keypress ?
"format a list of ( key , value ) tuples ."
"part : _ c_ontent , _ h_eaders+content , _ u_rl scope : _ a_ll , re_q_uest , re_s_ponse"
"save either the request or the response body to disk . part can either be "" q "" ( request ) , "" s "" ( response ) or none ( ask user if necessary ) ."
"dumps(object , encoding = none ) - > string"
"dump(object , file , encoding = none )"
"dump value as a tnetstring , to a deque instance , last chunks first ."
generate fragments of value dumped as a tnetstring .
"loads(string , encoding = none ) - > object"
"load(file , encoding = none ) - > object"
"pop(string , encoding = none ) - > ( object , remain )"
@type client_conn : bool | none | libmproxy.proxy.connection . clientconnection @type server_conn : bool | none | libmproxy.proxy.connection . serverconnection @type req : bool | none | libmproxy.protocol.http . httprequest @type resp : bool | none | libmproxy.protocol.http . httpresponse @type err : bool | none | libmproxy.protocol.primitives . error @return : bool | none | libmproxy.protocol.http . httpflow
@return : libmproxy.proxy.connection . clientconnection
@return : libmproxy.proxy.connection . serverconnection
@return : libmproxy.protocol.primitives . error
check if the status has changed . alter dates accordingly .
only render this content block for users in this segment .
display who 's currently logged in
a helper for raising remote exceptions
training the model
private method to generate a sentence . the sentence will have at maximun 140 characters ( a tweet ) . we use the list of all noums from the vocav to eliminate all unk tokens that may occur .
"given the words in the string "" starting text "" this method generates "" number_of_tweets "" tweets . it also appends at the end of the sentence the hashtags that may occur in the list "" hashtag_list "" ."
function to run all the tests from a class of tests .
function to sample an index from a probability array
gives you the date in form : day - month - year
function to create an unique label using the date and time .
function that returns a list of all the people on twitter that i really want to follow . you can follow them two ! ! !
function initialize one matrix of weights and one bias vector .
function that applies a affine transformation in the input tensor using the variables from the dict layer .
"this function uses the model to generate a sentence starting with the token(s ) "" starting_text "" . the generated sentence has at most "" stop_length "" tokens . if you use the list "" stop_tokens "" , the sentence will end at any word of that list ."
convenience function . similar to generate_text
"genereate sentences in the command line until the user type "" * end * """
constructor : param bar_length : length of the bar in characters
update_progress ( ) : displays or updates a std out progress bar
"evaluate detection results . args : eval_dir : directory to write evaluation logs global_step : step of the checkpoint all_boxes : all_boxes[cls][image ] = n x 5 arrays of [ xmin , ymin , xmax , ymax , score ] returns : aps : array of average precisions . names : class names corresponding to each ap"
verifies the symlink is created and links properly .
verifies the shortcut is created and links properly .
verifies the expected output files from a test run .
verifies the expected output files from a test run .
verifies the expected output files from a test run .
verifies the expected output files from a test run .
verifies the summary file includes the failure record for teardown_class .
checks if the iperf result has valid throughput data .
returns : the raw json output from iperf .
average receiving rate in mb / s over the entire run .
average receiving rate in mb / s over the entire run . this data may not exist if iperf was interrupted .
average sending rate in mb / s over the entire run . this data may not exist if iperf was interrupted .
starts iperf server on specified port .
retrieve a dataset from the packet database and store it . an id number is returned which can be used to reference this dataset in the future
"translate an id to a string from the anomaly causes table . if a hostname is passed , use that hostname from now on ( and reset the caches )"
"translate an id to a string from the anomaly states table . if a hostname is passed , use that hostname from now on ( and reset the caches )"
retrieve the user - labeled anomaly data
"write a new anomaly to the anomaly database . as of this writing , this code not been tested against the essence api so this function is a placeholder"
run a test and look for anomalies
: param str|unicode|list[str|unicode ] static_dir : check for static files in the specified directory .
allows mapping mountpoint to a static directory ( or file ) .
adds statics expiration rule based on a criterion .
use the uwsgi caching subsystem to store mappings from uri to filesystem paths .
"convert the provided red , green , blue color to a 24 - bit color value . each color component should be a value 0 - 255 where 0 is the lowest intensity and 255 is the highest intensity ."
return the 24 - bit rgb color value at the provided position or slice of positions .
set the 24 - bit rgb color value at the provided position or slice of positions .
"class to represent a neopixel / ws281x led display . num should be the number of pixels in the display , and pin should be the gpio pin connected to the display signal line ( must be a pwm pin like 18 ! ) . optional parameters are freq , the frequency of the display signal in hertz ( default 800khz ) , dma , the dma channel to use ( default 10 ) , invert , a boolean specifying if the signal line should be inverted ( default false ) , and channel , the pwm channel to use ( defaults to 0 ) ."
"initialize library , must be called once before other functions are called ."
update the display with the data from the led buffer .
set led at position n to the provided 24 - bit color value ( in rgb order ) .
"set led at position n to the provided red , green , and blue color . each color component should be a value from 0 to 255 ( where 0 is the lowest intensity and 255 is the highest intensity ) ."
scale each led in the buffer by the provided brightness . a brightness of 0 is the darkest and 255 is the brightest .
get the brightness value for each led in the buffer . a brightness of 0 is the darkest and 255 is the brightest .
return an object which allows access to the led display data as if it were a sequence of 24 - bit rgb values .
return the number of pixels in the display .
get the 24 - bit rgb color value for the led at position n.
"polar dimensional basis function based on laguerre polynomials of characteristic size beta phs : additional phase factor , used in the fourier transform"
generate the n x k matrix of basis functions(k ) for each pixel(n ) beta : characteristic size of the shaeplets nmax : maximum decomposition order r : radius matrix of n pixels th : theta matrix of n pixels
return arrays of shape ' size ' with radius and theta values centered on xc rot : radians in which to rotate the shapelet
create a new input widget .
open a message and inform the host file that it 's been incremented .
write message to file .
set value associated with key .
get available keys in message .
return size of message in bytes .
dump message 's binary content .
get value of a given key as its native or specified type .
release message handle and inform host file of release .
possibility to manually close message .
check whether a key is present in message .
return key count .
return value associated with key as its native type .
return list of tuples of all key / value pairs .
"returns true , if the file exists . returns false , if the file does not exist . returns none , if another error occurred ."
return domain of ` host ` .
run script .
sets various configurations for seaborn from the settings or arguments .
helper function to plot a density estimate of some distribution .
helper function to plot a simple time series on an axis .
sort of a circular plot function so that we can store all vizualization related utilities in this package rather than in the results package .
"takes an environment and an actor service , and streams data to it ."
creates messages based on the data volume and sends to the service .
perform simulation - specific process setup .
a side process that records the state of the cluster at every step .
returns the percent of nodes that are utilized
returns the percent of nodes that are utilized
returns the number of messages that are backlogged in the queue .
constructs the load balancing script for the simulation .
get taxonomic scientific name for taxonomy i d
get lineage for a taxonomic i d
get a lineage name for a taxonomic i d
check if a taxid has a parent in its lineage
get table name
check if the table has an index ( other than primary key )
returns the correct database driver
get a database connection setting
set a configuration value
read configuration file with database settings
load configuration file
set database connection settings and info as config
fallback response .
fetch request .
read toml conf file for latter use .
": param conf : dict , 包含 redis 的 host , port , db"
"初始化连接 redis 数据库 , 确保 redis 连接成功 : return : none"
"加载 lua 脚本 , 生成对应的 sha , 保存在类属性中 : param lua_script_file : lua file path : return : none"
将传入的参数传入 lua 脚本进行处理，默认第一个值为 key : param kwargs : 位置参数 : return : lua 脚本返回值
"remove and return the first item of the list ` ` data_queue ` ` if ` ` data_queue ` ` is an empty list , block indefinitely"
return the length of the list ` ` data_queue ` `
push the data onto the head of the list ` ` data_queue ` `
delete all keys in the current database
returns a list of keys matching ` ` pattern ` `
"初始化连接 influxdb 数据库 , 确保 influxdb 连接成功 : return : none"
"write to multiple time series names : param json_body : list of dictionaries , each dictionary represents a point , the list of points to be written in the database : param time_precision : database time precision , default is second : param database : str , the database to write the points to . defaults to the client ’s current database : param retention_policy : str , the retention policy for the points . defaults to none : return : bool"
"change the client ’s database . : param database : str , database name : return : none"
"send a query to influxdb : param query : str , sql - like query statement : return : always return a list"
"守护线程 : param args : args[0 ] : dict , key : thread_name , value : thread_instance args[1 ] : function , 重新生成类实例的方法 args[2 ] : dict , 线程间通信的 queue 集合 args[3 ] : 运行时的 maintainer 的唯一实例 : param args : : return : none"
"raises the exception , performs cleanup if needed"
"组成一个 元素为 tuple 的列表，tuple的值为 { 文件路径 , 文件的最后修改时间 } ， 根据这个列表生成一个唯一 sha 值 : return : sha 值"
递归遍历工作目录，获取目录下的配置文件、python 文件、lua 文件列表 : param l : : param filelist : : return : list
registers the surrogateescape error handler on python 2 ( only )
"like builtin super ( ) , but capable of magic ."
from the py3 bytes docstring :
returns a newstr ( i.e. unicode subclass )
b.splitlines([keepends ] ) - > list of lines
"s.rindex(sub [ , start [ , end ] ] ) - > int"
returns index of sub in bytes . raises valueerror if byte is not in bytes and typeerror if ca n't be converted bytes or its length is not 1 .
a trick to cause the ` ` hasattr ` ` builtin - fn to return false for the ' encode ' method on py2 .
"strip trailing bytes contained in the argument . if the argument is omitted , strip trailing ascii whitespace ."
"strip leading and trailing bytes contained in the argument . if the argument is omitted , strip trailing ascii whitespace ."
b.lower ( ) - > copy of b
b.upper ( ) - > copy of b
"b.maketrans(frm , to ) - > translation table"
gets valid user credentials from storage .
fetches the friends from g+ using the information on django - social - auth models user is an instance of usersocialauth . notice that g+ contact api should be enabled in google cloud console and social auth scope has been set this way in settings.py
fetches friend email 's from g+
prepare the social friend model
"checks if there is socialfrind model record for the user if not attempt to create one if all fail , redirects to the next page"
"return information for the volume containing the given path . this is going to be a pair containing ( file system , file system flags ) ."
"given a tuple consisting of a path to an uncompressed archive , credential directory , and desired output path , resign accordingly ."
"given a path to an app , a mapping of credential directories to desired output paths , optional info.plist properties to overwrite ,"
"given an isign.archive object , a mapping of credential directories to desired output paths , optional info.plist properties to overwrite ,"
"convenience method , if we just want the data"
"the slots have negative offsets , because they start from the ' top ' . so to get the actual index , we add it to the length of the slots ."
"some dylibs have all 5 slots , even though technically they only need the first 2 . if this dylib only has 2 slots , some of the calculated indices for slots will be negative . this means we do n't do those slots when resigning ( for dylibs , they do n't add any security anyway )"
do the actual signing . create the structre and then update all the byte offsets
parse architectures and associated codesig
do we have the fields we expect ?
"does "" user.__str _ _ ( ) "" work as expected ?"
"do "" user.get_full_name ( ) "" & "" get_short_name ( ) "" work as expected ?"
assert email is case - insensitive .
assert ` password_reset_email_context ` returns the correct data .
do we have the fields we expect ?
assert ` text_email_template ` and ` html_template_name ` can be customised .
passwords should be tough .
"returns a response , using the ` response_class ` for this view , with a template rendered with the given context ."
: param params : request . get or request . post or some dict like object contains your basic query string : return : a django queryset object so that you can do much more filter or pagination
list active breakpoints / hooks
lists the methods of a class
convert any representation of ` level ` to an int appropriately .
attach file handler to rash logger .
configure your shell .
"detect "" terminal "" you are using ."
does the heavy - lifting involved in saving . updates or inserts the data for a single table .
checks if the database count matches the es count
looks for discrepancies between postgres and elastic search numbers re - indexes time periods that differ in count
get all the dates between the start_date and the end_date
first convert start_date and end_date to have the day of week we require . then get all the dates of the specified day of week between the start_date and end_date .
return the current fiscal year . each fiscal year starts on october 1
"given a range of dates , get unique fiscal years"
"given a month column string , return the date of a day ( monday by default ) of that week an example of a month column string : september 2015 , week 1"
"get a row of the exporter table , return the date of a day ( monday by default ) of that week , the fiscal year , and the url of the xml file to keep the format consistent , if the record is from previous fiscal years , none is returned"
a generator to parse all the rows
"given date range , constructs urls of corresponded xml files ."
"ingest as the given user , with the given transformer"
verify a der signature
"verify that ` handle_result ` can modify the return values of the worker , such that other dependencies see the updated values ."
"this fixture fixes the order of the ` container_factory ` , ` runner_factory ` and ` rabbit_config ` fixtures to get the fastest possible teardown of tests that use them ."
return a boolean whether the lock is available for claiming
claim the lock ( lock must be available )
schedule c{callback } to be invoked every time this lock is released . returns a l{subscription } .
release the lock
"fire when the lock * might * be available . the caller will need to check with isavailable ( ) when the deferred fires . this loose form is used to avoid deadlocks . if we were interested in a stronger form , this would be named ' waituntilavailable ' , and the deferred would fire after the lock had been claimed ."
serves a number of services for a contextual block . the caller can specify a number of service classes then serve them either stopping ( default ) or killing them on exiting the contextual block .
add a service class to the runner . there can only be one service class for a given service name . service classes must be registered before calling start ( )
start all the registered services .
stop all running containers concurrently . the method blocks until all containers have stopped .
kill all running containers concurrently . the method will block until all containers have stopped .
wait for all running containers to stop .
evaluate expressions in ` text `
parse a python statement and analyze the symbols used . the result will be used to determine what variables a step depends upon .
evaluate an expression with sos dict .
execute a statement .
test target r_library
testing depending on r_library
test re - execution of steps with r_library
create temporary files
test action bash
test action run
test action csh
test action tcsh
test action zsh
test args option of scripts
wraps subprocess.check_output and logs errors to boinc
"creates and stages input files based on a list of ( name , contents ) in input_files , and calls bin / create_work with extra args specified by create_work_args"
add boinc 's bin / create_work arguments to a python argparse parser exclude can be a list of args not to add
read create_work_args from python argparse args
internal method for converting bcd formatted number to decimal
internal method for converting decimal formatted number to bcd
internal method for setting the value of a single bit within a byte
set the date and time on the rtc date must be in iso 8601 format - yyyy - mm - ddthh : mm : ss
read the date and time from the rtc in iso 8601 format - yyyy - mm - ddthh : mm : ss
enable the output pin
disable the output pin
"set the frequency of the output pin square - wave options are : 1 = 1hz , 2 = 4.096khz , 3 = 8.192khz , 4 = 32.768khz"
"write to the memory on the ds1307 the ds1307 contains 56 - byte , battery - backed ram with unlimited writes variables are : address : 0x08 to 0x3f valuearray : byte array containing data to be written to memory"
"read from the memory on the ds1307 the ds1307 contains 56 - byte , battery - backed ram with unlimited writes variables are : address : 0x08 to 0x3f length : up to 32 bytes . length can not exceed the avaiable address space ."
parse command line arguments
parse bed file for mapping contigs to concatenated ref
make gff3 record output
make gff3 output of blast hits for jbrowse display
read xml file to yield single record
"creates a new health object for the given node . databases for health statistics will be created in the ' data_dir ' . the databases use the "" whisper "" database format from graphite , so they automatically handle long - term storage with decreasing resolution . once the databases are created they never grow or shrink , regardless of the amount of data stored ."
captures stats of the local system and writes them into the series database . : return : none
"lookup a metric name and resolve it to a metric database . : param name : the metric name to resolve . : return : a data point if it was resolvable , or none"
request the minimum value from the given metric . : param dp : the metric to check for minimum value . : param from_time : the earliest time in the series . : param until_time : the latest time in the series ( optional ) . if omitted this defaults to now . : return : the minimum value from the series requested .
request the maximum value from the given metric . : param dp : the metric to check for maximum value . : param from_time : the earliest time in the series . : param until_time : the latest time in the series ( optional ) . if omitted this defaults to now . : return : the maximum value from the series requested .
request the average value for the given metric . : param dp : the metric to use to compute the average value . : param from_time : the earliest time in the series . : param until_time : the latest time in the series ( optional ) . if omitted this defaults to now . : return : the average value from the series requested .
"checks to see if the given metric has been healthy over the last ' seconds ' seconds . if ' has_alert ' is true then the metric must be lower than ' low_water ' , otherwise it must be lower than ' high_water ' . returns true if it 's healthy , false if it 's not ."
"checks to see if memory is in a healthy state . this is a convenience for is_healthy(""mem.percent "" )"
"checks to see if swap is in a healthy state . this is a convenience for is_healthy(""swp.percent "" )"
get watchdog pid via ` ` netstat ` ` .
start watchdog to build the sphinx docs .
stop sphinx watchdog
scales floats so that their tiles will have the given widths
manipulates floats so that their tiles are logarithmic sizes small to large
manipulates floats so that their tiles are logarithmic sizes large to small
manipulate floats so that you get diagonal stripes for tiles - does pairwise subtraction . returns a different sized list than the original .
manipulate floats so that you get backwards diagonal stripes for tiles - does pairwise addition . returns a different sized list than the original .
for two dimensions only
for two dimensions only
returns tiles scaled by widths
returns tiles which vary in size logarithmically from small to large
returns tiles which vary in size exponentially from large to small
"returns tiles in the shape of stripes ( scaled by widths ) , a set for each dimension in floats"
returns tiles in the shape of diagonal stripes
returns tiles in the shape of backward diagonal stripes
returns tiles in the shape of diamonds
"does appropriate manipulations to get special shaped or sized tiles . tileshapes are ' square ' - square or rectangular tiles ( the default ) , ' stripe ' - stripes for each dimension , and ' diagonal ' - diagonal stripes for each pair of dimensions ' backdiagonal ' diagonal stripes the other way ' alldiagonal ' - diagonal stripes for all dimensions at once ' allbackdiagonal ' - diagonal stripes the other way for all dimensions at once ' diamond ' - diagonal stripes and back diagonal stripes are applied tilesizes are ' uniform ' - all tiles are the same size ( the default ) , ' log ' - tile sizes vary logarithmically from small to large , and ' exp ' - tile sizes vary exponentially from large to small scaling is handled first if tilewidths is set - there should be a width for every element of the float vector . if you do n't wish to apply scaling to the floats , tilewidths may be set to none , or to a vector of 1 's the same length as floats . memctable , numtilings and ints are the same as for the regular tiles routine . note that you may get back more tiles than numtilings - for stripes or diagonal stripes you may get a larger number of tiles back ."
set up each test .
test deletion for anonymous users .
test deletion for account of volunteer .
test deletion for account of organization .
test deletion for account of admin .
set up each test .
string reprezentation of an organization object .
test list 's fields of organization rest api endpoint .
set up each test .
test organizations list length for admin user .
set up each test .
test organizations list length for user with organization .
set up each test .
test organizations list length for regular user .
test organizations list length for anonymous user .
initializes this file object with an file equivalent from the underlying sql - based interface for avspoof database .
convert a timedelta to seconds with the microseconds as fraction
formats timedelta / datetime / seconds
convert the given input to an integer or return default
convert the given ` input _ ` to an integer or return default
"convert objects to unicode , if needed decodes string with the given encoding and errors settings ."
"convert objects to string , encodes to the given encoding"
"scale a number down to a suitable size , based on powers of 1024 ."
triggers a notification with the given text .
"hides the current notification , if any existing ."
"returns a control , that will change the notification to a single line view , if it is grabbed ."
"returns a control , that will change the notification to use the whole display , if it is grabbed ."
expects a dialog from live to appear soon . the dialog will be shown on the controller with the given message regardless of wether a dialog actually appears . this dialog can be cancelled .
"add and remove listeners for visible drum pads , including mute and solo state"
update hardware leds for drum pads
override when you give it a select button
override when you give it a quantize button
"if takeover_drums , the matrix buttons will be controlled from the script . otherwise they send midi notes to the track associated to this drum group ."
creates and returns the guitarwing script
"hkmeans : clusters the data by using multiple runs of kmeans to recursively partition the dataset . the number of resulting clusters is given by ( branch_size-1)*num_branches+1 . this method can be significantly faster when the number of desired clusters is quite large ( e.g. a hundred or more ) . higher branch sizes are slower but may give better results . if dtype is none ( the default ) , the array returned is the same type as pts . otherwise , the returned array is of type dtype ."
"kmeans : ( self , pts , num_clusters , max_iterations = none , dtype = none , * * kwargs ) runs kmeans on pts with num_clusters centroids . returns a numpy array of size num_clusters x dim . if max_iterations is not none , the algorithm terminates after the given number of iterations regardless of convergence . the default is to run until convergence . if dtype is none ( the default ) , the array returned is the same type as pts . otherwise , the returned array is of type dtype ."
commandline : python -m vtool.tests.test_pyflann --test - test_pyflann_add_point
commandline : python -m vtool.tests.test_pyflann --test - test_pyflann_searches
commandline : python -m vtool.tests.test_pyflann --test - test_pyflann_tune
commandline : python -m vtool.tests.test_pyflann --test - test_pyflann_io
"clean the mask ( num_erode , num_dilate ) = ( 1 , 1 ) ( w , h ) = ( 10 , 10 )"
"args : img ( ndarray[uint8_t , ndim=2 ] ): image data"
referencs : http://docs.opencv.org/trunk/doc/py_tutorials/py_imgproc/py_grabcut/py_grabcut.html
checks whether the response object is a html page or a likely downloadable file . intended to detect error pages or prompts such as kaggle 's competition rules acceptance prompt .
nonblocking ( timeout=0 )
"timeout : after port open , the input buffer must be empty"
timeout : each sent character should return ( binary test ) . this is also a test for the binary capability of a port .
timeout : test the timeout / immediate return . partial results should be returned .
blocking ( timeout=1 )
"no timeout : after port open , the input buffer must be empty ( read ) . a character is sent after some time to terminate the test ( sendevent ) ."
"no timeout : after port open , the input buffer must be empty ( in_waiting )"
no timeout : each sent character should return ( binary test ) . this is also a test for the binary capability of a port .
test rts / cts
test dtr / dsr
test write ( ) timeout .
simple test of line reader class
simple test of line reader class
hook to extend argparse parser with custom arguments
create the filter using argparse ` ` args ` `
"filter a site , return not none if the site should be filtered"
"return the name to put in the vcf header , default is ` ` name ` ` + ` ` threshold ` `"
"rudimentale controllo , vede se i primi 3 byte sono gdc"
load alignment from genedoc file
list all available active products
cart detail view
cart update view
initialises internal variables . used internally .
registers it 's own iq handlers in your application dispatcher instance . used internally .
unregisters browser 's iq handlers from your application dispatcher instance . used internally .
"returns dictionary and key or none , none none - root node ( w/o "" node "" attribute ) /a / b / c - node /a / b/ - branch set returns '' or none as the key get returns '' or none as the key or none as the dict . used internally ."
this is the main method that you will use in this class . it is used to register supplied disco handler ( or dictionary with static info ) as handler of some disco tree branch . if you do not specify the node this handler will be used for all queried nodes . if you do not specify the jid this handler will be used for all queried jids .
returns the previously registered disco handler that is resonsible for this node / jid combination . used internally .
unregisters disco handler that is resonsible for this node / jid combination . when handler is unregistered the branch is handled in the same way that it 's parent branch from this moment .
servers disco iq request from the remote client . automatically determines the best handler to use and calls it to handle the request . used internally .
execute cli command
: type capacity : int : type dataprofile : enumstoragepooldataprofile : type metadataprofile : enumstoragepoolmetadataprofile : type mountpoint : str : type name : str : type status : enumstoragepoolstatus : type totalcapacity : int : rtype : storagepool
"generate rfc3339 time format input : d = date type local_tz = use local time zone if true , otherwise mark as utc"
"input : date : date type local_tz : if true , use system timezone , otherwise return 0"
input : date : date type local_tz : bool
called from nbdservers in case of ardb server failures
: type clustertype : enumclustercreateclustertype : type datashards : int : type drivetype : enumclustercreatedrivetype : type label : str : type metadrivetype : enumclustercreatemetadrivetype : type nodes : list[str ] : type parityshards : int : type servers : int : type serverspermetadrive : int : type zerostorclientid : str : type zerostornamespace : str : type zerostororganization : str : type zerostorsecret : str : rtype : clustercreate
: type i d : str : type url : str : rtype : graph
set authorization header value
: type i d : str : type loglevels : list[int ] : type maxrestart : int : type maxtime : int : type queue : str : type recurringperiod : int : type statsinterval : int : type tags : str : rtype : job
: type filesystems : list[str ] : type flist : str : type hostnetworking : bool : type hostname : str : type initprocesses : list[coresystem ] : type name : str : type nics : list[containernic ] : type ports : list[str ] : type storage : str : rtype : createcontainer
convert from datetime format to timestamp format input : time in datetime format output : time in timestamp format
convert from timestamp format to datetime format input : time in timestamp format output : time in datetime format
return an instance of ` val ` that is of type ` datatype ` . keep track of exceptions so we can produce meaningful error messages .
serialize to json : rtype : str
return a dict representation of the event and its sub - objects ` convert_datetime ` controls whether datetime objects are converted to strings or not : rtype : dict
return the handler for the object type
return the serialized ( flattened ) value from the registered handler for the type
return the deserialized ( restored ) value from the registered handler for the type
can not restore here because we do n't know what type of enum it is
: type devicename : str : type status : enumstoragepooldevicestatus : type uuid : str : rtype : storagepooldevice
: type dashboard : str : type name : str : type slug : str : type url : str : rtype : dashboardlistitem
: type blocksize : int : type i d : str : type readonly : bool : type size : int : type status : enumvdiskstatus : type templatevdisk : str : type type : enumvdisktype : type vdiskstorage : str : rtype : vdisk
create a race : param length : length in meters : param description : description of the race : param pet_category_name : pet category name : param normal_scale : normal scale used to calc numpy.random.normal : return :
save a normal to c * : param normals : : param loc : : param scale : : param size : : return :
save the racer to c * : param racer_id : : return :
save racedata to c * : param racer : : param race_sample : : return :
save raceresult to c * : param race : : param racers : : return :
update race obj with winner : return :
calculate finish time of a racer : param previous_distance : : param distance_this_sample : : param number_of_seconds : : param race_length : : return :
run a race ! : return :
status of an app
loads saved settings from pickled file - language and screen size dimensions and mode
save settings to file
gets a component as though the vector were a list .
sets a component as though the vector were a list .
return the result of multiplying this vector with a scalar or a vector - list object .
"takes a number from 1 - 99 and returns it back in a word form , ie : 63 returns ' sixty three ' ."
"takes 2 variables : h - hour , m - minute , returns time as a string , ie . five to seven - for 6:55"
used in touch typing program
used in touch typing program to build a list of words to retype
"config : instance_type : ec2 instance type ebs_size : ebs storage size in gb ebs_type : ebs storage type ( available values : gp2 , io1 , st1 , sc1 , standard ( default : io1 ) ebs_iops : ebs storage iops s3_access_arn : iam instance profile for s3 access ami_id : id of ami used for the instance - it should have docker daemon and cwl - runner ( either toil or cwltools ) installed password : password for ssh connection for user ec2 - user ebs_optimized : use this flag if the instance type is ebs - optimized ( default : ebs - optimized ) shutdown_min : number of minutes before shutdown after the jobs are finished . ( default now ) copy_to_s3 : upload or copy the json file to s3 bucket json_bucket launch_instance : launch instance based on the json file log_bucket : bucket for collecting logs ( started , postrun , success , error , log )"
"parse csv that contains match results . format is as follows : match_id , red1 , red2 , red3 , blue1 , blue2 , blue3 , red score , blue score"
"takes a url , and turns it into a partial media object dict"
build a media dict from the given url and media type this will parse the foreign key from the url and add other data about the media type
"uses foreign_key_patterns to extract the media foreign key from the given url each index in the dict contains a list of valid patterns - tuples of ( regex string , group # )"
"input : the html from the thread page ex : https://www.chiefdelphi.com/media/photos/38464 ,"
"check for etag , then fall back to if - modified - since"
"takes a list of sync - enabled offseasons from first and sorts them returns a tuple of events ( linked to tba , candidates to link , new )"
"given an "" old "" and a "" new "" award object , replace the fields in the "" old "" award that are present in the "" new "" award , but keep fields from the "" old "" award that are null in the "" new "" award ."
"does n't actually return match objects . instead , returns dict where the key is the event_short and the value is a list of strings in the following csv format : match_id , red1 , red2 , red3 , blue1 , blue2 , blue3 , red score , blue score"
"takes a url , and turns it into a webcast dict ( as defined in models.event )"
"parse json that contains a list of awards where each award is a dict of : name_str : string of award name . ex : "" tournament winner "" or "" dean 's list finalist "" team_key : string in the format "" frcxxx "" for the team that won the award . can be null . awardee : string corresponding to the name of an individual that won the award . can be null ."
returns a node filter that is the composition of all filter functions passed as arguments . filters will be applied in the order they appear .
returns a node filter that only let nodes whose type is in the allowed_types list to pass through .
"returns a new filter that lets throught all nodes normally filtered out by node_filter , and filters out the one normally passed ."
"a filter that lets all nodes through , except attributes with a default value and attribute groups containing only such attributes ."
"a filter that lets all nodes through , except required attributes missing a value ."
"a filter that only let through obj and groups containing attributes with missing values , as well as those attributes ."
"a filter that only lets through required attribute nodes , aka those attributes without a default value in lio configuration policy ."
instantiate an rtsroot object . basically checks for configfs setup and base kernel modules ( tcm )
to run command easier
check if container exists
create a container ( without all options ) default template : ubuntu
clone a container ( without all options )
check info from lxc - info
list containers directory
"list all containers with status ( running , frozen or stopped ) in a dict same as lxc - list or lxc - ls --fancy ( 0.9 )"
starts a container
stops a container
freezes a container
unfreezes a container
destroys a container
returns the output of lxc - checkconfig ( colors cleared )
compute the total score for a player 's game of bowling .
calculates the nth fibonacci number
prevent non - admins from acessing the page : return : 403 - forbidden page
list all departments : return : admin / departments / departments.html with list of departments
add a department to the database : return :
edit a department : param i d : the i d of the department : return : a template
delete a department from the database : param i d : the i d 's department : return : redirection to template
list all roles : return : list of roles
add a role to the database : return :
edit a role
delete a role from the database
list all employees
assign a department and a role to an employee
: param encoded_data : the encoded version of the original matrix . size ( # samples x encoding length ) this is the output of lcms_autoencoder.py 's autoencoder
there was an issue with user first / last name fields being duplicated
there was an issue with user first / last name fields being duplicated
delete all map feature data
addresses # 1717 on github
addresses # 1716 on github
addresses # 1715 on github
address # 1375 and # 1027 on github
"this method returns the method for the passed action type , none otherwise ."
"this method returns all the object for the passed action type , otherwise none ."
returns the ' build ' action for this scheme .
returns the ' test ' action for this scheme .
returns the ' launch ' action for this scheme .
returns the ' profile ' action for this scheme .
returns the ' analyze ' action for this scheme .
returns the ' archive ' action for this scheme .
pass the path to the ' .xcodeproj ' file to initialize the xcodeproj object .
"returns the parsed object from the project file for matching identifier , if no matching object is found it will return none ."
this method returns a list of ' xcodeproj ' objects that represents any referenced xcodeproj files in this project .
this method is for returning a list of paths to referenced project files in this xcodeproj file .
this method will return a list of build targets that are associated with this xcodeproj .
this class the main functionality of interfacing with rgb - d video files . whether for record or for reading from the corresponding files
sets the pointer of the reader to the indicated frame number
generates a mesh topology adequate for a given depth resolution
"define a set of variables which remain unchanged for a stream of data , e.g. the depth topology"
this function takes the rgbdcontainer object and makes it look like a 3d mesh
this function generates another mesh ( not depthmesh ) by cropping the organized set of veftices ( a depth roi )
main cli entrypoint .
default schema .
"creates the grammar for an alphanumeric ( a ) field , accepting only the specified number of characters ."
checks that the string is not empty .
"creates the grammar for a numeric ( n ) field , accepting only the specified number of characters ."
transforms the received parsed value into an integer .
"creates the grammar for a numeric ( n ) field , accepting only the specified number of characters ."
transforms a string into a float .
checks that the number parsed from the string is above a minimum .
"creates the grammar for a boolean ( b ) field , accepting only ' y ' or ' n '"
transforms a string into a boolean value .
"creates the grammar for a flag ( f ) field , accepting only ' y ' , ' n ' or ' u ' ."
"creates the grammar for a date ( d ) field , accepting only numbers in a certain pattern ."
"creates the grammar for a time or duration ( t ) field , accepting only numbers in a certain pattern ."
"creates the grammar for a lookup ( l ) field , accepting only values from a list ."
creates the grammar for a blank field .
tests that the default field name is correct for optional fields .
tests that the given field name is set correctly for optional fields .
tests that the field name does not change for creating a new one
tests that the numeric float field accepts values of the correct number of characters .
tests that the numeric float field accepts values starting with zeros .
tests that the numeric float field accepts values ending with zeros .
tests that the numeric float field accepts values ending with zeros .
tests that the numeric float field accepts values of the correct number of characters .
tests that the numeric float field accepts values starting with zeros .
tests that the numeric float field accepts values ending with zeros .
tests that the numeric float field accepts values ending with zeros .
tests that an exception is thrown when the columns are set as negative .
tests that an exception is thrown when the columns are set as negative .
tests that an exception is thrown when the columns are set as zero .
tests that an exception is thrown when the columns are set as zero .
tests that an exception is thrown when the positive values size is set as negative .
tests that an exception is thrown when the positive values size is set as negative .
tests that an exception is thrown when the field is empty and it should n't be .
tests that an exception is thrown when the field is smaller than expected .
tests that an exception is thrown when the field contains letters .
tests that nwn grammar decodes correctly formatted record prefixes .
tests that a exception is thrown when the the works number is zero .
tests that an exception is thrown when the field is empty and it should n't be .
tests that an exception is thrown when the field is empty and it should n't be .
tests that an exception is thrown when the field is empty and it should n't be .
tests that an exception is thrown when the field is empty and it should n't be .
tests that nwn grammar decodes correctly formatted record prefixes .
tests that nwn grammar decodes correctly formatted record prefixes .
tests that writer grammar decodes correctly formatted record prefixes .
tests that writer grammar decodes correctly formatted record prefixes .
tests that writer grammar decodes correctly formatted record prefixes .
constructs a cwrfile .
the file 's metadata tag .
the file 's transmission .
constructs a filetag .
the year in which the file has been created . this is a numeric value .
file sequence number . this is a numeric value .
the file sender id . this is an alphanumeric code .
the file receiver id . this is an alphanumeric code .
the cwr standard specification used to code the file . this is a comma separated numeric value .
tests that ipa grammar decodes correctly formatted record prefixes .
tests that ipa grammar decodes correctly formatted record prefixes .
tests an average code .
tests the highest possible value .
tests the lowest possible value .
tests that an exception is thrown when no numbers are set .
tests that an exception is thrown when only 10 numbers and no header are received .
tests that an exception is thrown when 11 numbers are received .
tests that an exception is thrown when the string is empty
tests that an exception is thrown when the string is empty
tests that an exception is thrown when the string is too short
tests that an exception is thrown when the string is too short
"this function is run inside the weirdo casapy ipython environment ! a strange set of modules is available , and the ` pwkit.environments.casa.scripting ` system sets up a very particular environment to allow encapsulated scripting ."
"` extrapos ` is basically a hack for multi - step processing . we have some flux measurements that are computed from luminosities and distances . the flux value is therefore an unwrapped uval , which does n't retain memory of any positivity constraint it may have had . therefore , if we write out such a value using this routine , we may get something like ` fx : u = 1pm1 ` , and the next time it 's read in we 'll get negative fluxes . fields listed in ` extrapos ` will have a "" p "" constraint added if they are imprecise and their typetag is just "" f "" or "" u "" ."
entry point for pyreqs
"install the package via pip , pin the package only to requirements file . use option to decide which file the package will be pinned to ."
uninstall the package and remove it from requirements file .
returns true if needs c wrapper around cblas for calling from fortran .
"calculate a 8 - bit checksum of the key fields of a message , so we can detect incompatible xml changes"
merge enums between xml files
check for duplicate message ids
count total number of msgs
like mkdir -p
generate a testsuite value for a mavfield
set a testsuite value for a mavfield
dkronjob : test getting invalid field
dkronjob : test setting invalid field
dkronjob : test setting invalid field
dkronjob : test saving job
dkronjob : test executions
dkronjob : test run
dkronjob : test delete
render the markdown content to html .
row[0 ] - i d ; row[1 ] - description ;
create a list item .
set the correct type and contents .
create a nested list element .
create the deeper list
add a list item
add a deeper list item
get the resulting list
decide whether the pending list must be generated before the given item
applies only if the list is finished with next item .
insert a fake item
add the item to pending and return an empty item
append to the list in the postprocessor
get the resulting html
escape all lines in an array according to the output options .
escape a line with replacements from elyxer.a map
escape all unicode characters to html entities .
search for all embedded containers of a given type
search for all containers of a type and remove them
search for elements of a given type and process them
search for all embedded containers and process them
perform a recursive search in the container .
extract all text from elyxer.allowed containers .
group some adjoining elements into a group
remove a container but leave its contents
show in a tree
"get the value of a parameter , if present ."
get the value of a comma - separated parameter as a list .
check if the parent 's output is empty .
get a description
show warning if version < 276
replace special chars from elyxer.the contents .
replace all special chars from elyxer.a line
return all text .
return a printable representation .
complete the tagged text and return it
complete the tagged text with a constant
return a printable representation .
"create the toc entry for a container , consisting of a single link ."
create a toc entry for header and footer ( 0 depth ) .
create the link that will make the whole toc entry .
decide if the link is an anchor based on a set of labels .
return a printable representation .
open the indenting div a few times .
close the indenting div a few times .
create the indented entry .
return a printable documentation .
place the entry in a tree of entries .
find the stem where our next element will be inserted .
convert a container into an indented toc entry .
indent a toc entry .
convert a container to a toc entry .
read the whole file
read the whole file with the given encoding
get reader and writer for a file name
swap the temp file for the original
get the unicode representation
include the provided child document
process a regular include : standard child document .
convert an included document .
read a verbatim document .
read a document as a listing .
read the contents of a complete file .
return a printable description .
parse the array
parse a whole row
create the cell that corresponds to the given index .
"parse all rows , finish when no more row ends"
"iterate over all rows , end when no more row ends"
add an empty row .
add a row to the contents and to the list of rows .
parse the array
parse the different alignments
"parse the matrix , set alignments to ' c ' ."
parse the cases
parse the whole environment .
parse the begin command
find the command bit corresponding to the \begin{piece }
see if the formula is inlined
get the formula type from the first line .
parse the formula until the end
parse the formula contents
parse a formula in one line
parse a formula in multiple lines
see if the formula is inlined
parse the formula until the end
set the proper size with width and height .
set max width and/or height .
read some size parameters off a container .
"read a size parameter off a container , and set it if present ."
"set the value of a parameter name , only if it 's valid ."
check if the height parameter is valid ; otherwise erase it .
do the full processing on a parameter .
extract the first number in the given text .
"check image dimensions , set them if possible ."
scale the value according to the image scale and return it as unicode .
"remove percent width if present , to set it at the figure level ."
add the proper style attribute to the output tag .
get the style for a single parameter .
test the null session handler that stores no data .
test the default in - memory session store .
test freezing and thawing variables .
"test the bug _ _ lastmatch _ _ return u""undefined "" is solved"
initialize the redis session driver .
translate a username into a key for redis .
custom helper method to retrieve a user 's data from redis .
the built - in rivescript interactive mode .
recursively scan a topic and return a list of all triggers .
"given one topic , get the list of all included / inherited topics ."
"will return true if json.result = = "" success "" . if json.result was not found , and need_success is set to true , a illegalresponseexception is raised . if json.result was not found , and need_success is set to false , it will return the original json ."
checks that the download was successful .
: type json : dictobject
return ` true ` if the all the fields of the message in ` self ` are equivalent to the fields in ` other ` .
"a single line representation of the ' file ' , ' line ' , and ' function ' keys in the ` details ` dictionary ."
take the given message object and hand it to all the primary factors(creator ) with a msghook callable .
creates a new argument parser .
called with ` ` python -m ophis.tests ` ` : run main test suite .
main entry point for your project .
overrides the qdialog done method to first store which choice the user selected
"random domain name prefix , with adjusted probability for the first two characters ."
> > > reverse_name('ns57.1and1.com ' ) ' com.1and1.ns57 '
> > > import adns > > > status_name(adns.status.nxdomain ) ' nxdomain '
> > > ip_to_int(none ) 0 > > > ip_to_int('0.0.0.0 ' ) 0 > > > ip_to_int('1.2.3.4 ' ) 16909060
> > > int_to_ip(none ) '' > > > int_to_ip(0 ) '' > > > int_to_ip(-1 ) ' -1 ' > > > int_to_ip(16909060 ) ' 1.2.3.4 '
preload memcache with some json requests .
generate initial condition with power - spectrum p and post - filtering f ( either gaussian smoothing or transfer function )
"compute density of partices on the force mesh . the partices are simply deposited into integer bins , using the searchsorted routine"
compute velocity potential from initial density
compute zeldovich displacement from initial density
deploy particles to compute densities . we interpolate a refined lagrangian mesh and deposit those particles .
compute the gravitational acceleration from the density .
"leap - frog algorithm , kick - drift - kick"
continue sending data over the connected tcp socket
computes the state variable tendencies in time for implicit processes .
prepare arguments and call the rrtgm_lw driver to calculate radiative fluxes and heating rates
"add rrtmg_lw fortran source if fortran 90 compiler available , if no compiler is found do not try to build the extension ."
property of aplusbt parameter a.
property of aplusbt parameter b.
"compute energy flux convergences to get heating rates in : math:`w / m^2 ` ,"
property of aplusbt_co2 parameter co2 .
computes energy flux convergences to get heating rates in : math:`w / m^2 ` .
derivative w.r.t diagonal of self covariance matrix
return the names of hyperparameters to make identification easier
return the number of hyperparameters this cf holds .
get covariance matrix k with given hyperparameters and inputs x = x1 and x\`*`=x2 .
get diagonal of the ( squared ) covariance matrix .
"the derivatives of the covariance matrix for each hyperparameter , respectively ."
"the partial derivative of the covariance matrix with respect to x , given hyperparameters ` theta ` ."
class representing a single analytical parameter ( pollutant ) .
creates a string representation of the parameter and units .
defines the season from a given date .
makes a pandas . timestamp from separate date / time columns
returns the water year of a given date
calculate position of each symbol
"make skeleton , annotate x , y position of each symbol"
"render skeleton , store in database"
try to guess a reasonable block length to use for block - wise iteration over ` data ` .
create an array mapping variant alleles into a different allele index system .
locate variants with no shared alleles between two populations .
locate alleles that are found only in a single population .
validate if something appears to be a mac .
init the instance .
check the definition .
compare date .
report an issue .
copy / inherit from another entity .
check the assignment definition .
create an object .
get a tuple key if not set .
report on new entries as found .
main entry .
strip whitespace from username
make sure the worldmap username maps to an actual user object
limit worldmap user drop down to only the selected choice
predicts and averages tha probabilities for a input image
computes the top-1 accuracy for k patches
computes the top - k accuracy for k patches
predict the classes and the probabilities of an input image
internal . handles signals from the os .
internal . gets the size of a file .
internal . gets a bytearray from hex data .
internal . get an integer in format for wav file header .
internal . create a wav file header .
internal . update the wav header
internal . update the wav file header with the size of the data .
internal . thread method .
internal . open the serial port and capture audio data into a temp file .
start recording on the pi - toppulse microphone .
returns recording state of the pi - toppulse microphone .
stops recording audio
saves recorded audio to a file .
"set the appropriate i2c bits to enable 16,000hz recording on the microphone"
"set the appropriate i2c bits to enable 22,050hz recording on the microphone"
set bitrate to device default
set bitrate to double that of device default by scaling the signal
get a reader of images loading them from a list of pahts .
load and prepare image the same way as caffe scripts .
rescale and/or crop the image based on the rescale configuration .
initialize the representation runner .
checks whether there are unexpected or missing fields
return a function that will act as the body for the ` ` tf.while_loop ` ` call .
populate the feed dictionary for the decoder object
lp term from eq . 14
simple highway layer
decode the cervellotic header of the sm file .
read an sm data file .
construct the catalog interface class
retrieves the strip footprint wkt string given a cat id .
retrieves the strip footprint wkt string given a cat id .
retrieves the strip catalog metadata given a cat id .
use the google geocoder to get latitude and longitude for an address string
perform a catalog search over an address string
"perform a catalog search over a specific point , specified by lat , lng"
find and return the s3 data location given a catalog_id .
perform a catalog search
return the most recent image
if the file is different to updated then copy updated into the file else leave alone so cvs and make do n't treat it as modified .
generate ' outpath ' from ' inpath ' .
regenerate the given file .
check message wrapped by _ ( )
"ensure lifetime in secs and value is supported , based on policy ."
ensure ike policy is v1 for current rest api .
ensure the mtu value is supported .
ensure there is one gateway ip specified for the router used .
ensure that an ip address is specified for peer id .
ensure ipsec policy encap mode is tunnel for current rest api .
ensure ike policy auth algorithm is supported .
ensure ipsec policy auth algorithm is supported .
validate ipsec site connection for cisco csr .
returns the vpnservices on the host .
update status of vpnservices .
obtain the ipv4 and/or ipv6 gw ip for the router .
get the gateway ip(s ) and save for later use .
"use service 's external ip , based on peer ip version ."
convert vpnservice information for vpn agent .
"drop the old databases , in preparation for running a test ."
"create a database . if it already exists , an exception of type weedb . databaseexistserror will be raised ."
"return a connection to a database . if the database does not exist , an exception of type weedb . nodatabaseerror will be raised ."
"drop ( delete ) a database . if the database does not exist , the exception weedb . nodatabaseerror will be raised ."
superclass should raise exception of type weedb . operationalerror if the database does not exist .
returns an appropriate database cursor .
"execute a sql statement . this version does not return a cursor , so it can only be used for statements that do not return a result set ."
returns a list of the tables in the database . returns an empty list if the database has no tables in it .
"generator function that returns a summary of the table 's schema . it returns a 6 - way tuple : ( number , column_name , column_type , can_be_null , default_value , is_primary )"
returns a list of the column names in the specified table . implementers should raise an exception of type weedb . programmingerror if the table does not exist .
"return a database specific operational variable . generally , things like pragmas , or optimization - related variables ."
"a test client , called multiple times , should not attempt to close the server again ."
should return dataframe with complete window
should return last activity
should return empty
should return first activity
should return average speed weighted by distance
should return all - false boolean index if all activities have the feature
should return all - true boolean index if no activities have the feature
should return all - true boolean index except for first activity that has the feature
should compute moving average for given feature retaining existing features and observations
should not add new column if one or more moving averages were computed for the given feature
should create new column with name [ original_feature_name]_[window_size ] as name
should compute moving averages for given feature and window
convenience function for selecting ( and plotting ) windows .
the optional ` ` weight_function ` ` parameter can be used to customize the weight of the window . its single parameter is an instance of the window . the following example will create a window function that does exactly the same as the default weighting function .
load a dictionary coming from a json file and parse it to window object .
returns the window in a representation suitable for inclusion as a json file .
"from a list of indices , return the ones inside this window excluding the borders .."
absolute time of the left border of this window .
relative time of the left border in seconds to the first sample in the array .
absolute time of the right border of this window .
relative time of the right border in seconds to the first sample in the array .
the weight of the window used for the weighted interval scheduling . either calls a potentially passed window weight function or defaults to the window length in number of minimum periods times the cross correlation coefficient .
"for every interval j , compute the rightmost mutually compatible interval i , where i < j i is a sorted list of interval objects ( sorted by finish time )"
"use dynamic algorithm to schedule weighted intervals sorting is o(n log n ) , finding p[1 .. n ] is o(n log n ) , finding opt[1 .. n ] is o(n ) , selecting is o(n ) whole operation is dominated by o(n log n )"
"ensure that the linear function index of the cluster functions is sane . that is , all indexes are simply 0 , 1 , 2 ... n"
remove all basis functions with no eci value and reindex the basis in a sequential order . new field is entered to remember what the old index used to be
initialize with basis.json or similar
raise error informing that the requested species is not part of the allowed set .
checks if the formula 's cluster has at least one instance of the given site
checks if the formula 's cluster has multiple instances of the given site
returns true if the basis functions in the formula all correspond to one of the specified species
"return the indexes for all the basis functions that are made up exclusively from basis functions corresponding to the specified species . use this function to extract a subset of basis functions , such as a binary subspace from a ternary ."
"map the indexes of shared clusters from the given detector to self . unlike detect_clusters , this routine allows specifying what fields should be compared to determine what a shared cluster is , allowing for example the comparison of the basis function formula , which would distinguish basis functions instead of just clusters . it also allows passing a function that triggers an error for certain types of clusters when they can not be mapped . for example , the expectation can be to always expect a mapping ( returns true ) , never expect a mapping ( returns false ) , or expect only for active basis functions ( returns true of the cluster function has an "" eci "" entry """
"map the indexes of shared clusters from the given detector to self . as a default , the expectation is that every single cluster of the given detector should map somewhere on self ."
return list of species that make up the basis
"return list of all species , including background"
return list of indexes corresponding to non - zero eci values : returns : list of int
"first detect where the clusters of the given detector lie in self , then from that set of basis functions , return only those that contain the same species as the basis set of the given detector ."
"map the indexes from the given detector onto self , but return only the ones that have an active eci"
"map the indexes from the given detector onto self , but return only the ones that do not have an active eci"
extract the eci values from the json format into a vector of mostly zeros with the appropriate values in the right positions
return copy of the basis json used at construction : returns : json
"go through the given eci values and add entries into the basis json object . the eci values must have an index associated with each value , which corresponds to the linear function index . any preexisting eci values will be removed ."
iterate over the cluster functions that contain the specified species
iterate over the cluster functions returns ------- todo
"this method loads data from sparse mtx file format ( ' csr ' preferably . see python sci.sparse matrix format , also referred to as matrix market read and write methods ) . label files should contain a column of these labels , e.g. see the contents of a three labels file : 1.23 -102.45 2.2998438943 loading uniquely test labels is allowed ( training labels are optional ) . in pattern_recognition mode no training labels are required . none is returned out for corresponding shogun label object . feature list returned : [ features_tr , features_ts , labels_tr , labels_ts ] returned data is float type ( dtype='float64 ' ) . this is the minimum data length allowed by shogun given the sparse distance functions does not allow other ones , e.g. short ( float32 ) ."
returns a named tuple of type partitionssummary .
get and parse arguments .
get and parse arguments .
write a debug log file command-yyyymmdd-hhmmss.ffffff.log .
return the logs generated up to this point .
log exceptions instead of printing a traceback to stderr .
return an error message and write a log file if logging was not enabled .
configure the root logger and a logfile handler .
get the log level from the cli arguments .
handle exit signals and write out a log file .
format the log record with timestamps and level based colors .
test that a single command is successfully generated .
test that class commands are generated correctly .
test that class commands inheriting from object are generated .
test that module commands are generated and called correctly .
test that a multiple commands are successfully generated .
test that the help subcommand responds as expected .
test creating a command that overwrites the primary command .
test that custom primary commands support dispatch .
test that custom primary commands support dispatch .
test that a simple primary command is attached to the default doc .
test that a command with a subcommand of the same name does not fail .
verify that usage strings are dedented correctly .
verify that multiline usage strings are parsed correctly .
verify that positional argument parameters work as expected .
verify that unused keyword argument parameters work as expected .
": param name : 系列名称，用于 tooltip 的显示，legend 的图例筛选 。 : param x_axis : x 坐标轴数据 。 : param y_axis : y 坐标轴数据。数据中，每一行是一个『数据项』，每一列属于一个『维度 』 。 数据项具体为 [ open , close , lowest , highest ] （ 即：[开盘值 , 收盘值 , 最低值 , 最高值 ] ） 。 : param kwargs :"
: param name : 系列名称，用于 tooltip 的显示，legend 的图例筛选 。 : param attr : 属性名称 。 : param value : 属性所对应的值 。 : param kwargs :
": param name : 系列名称，用于 tooltip 的显示，legend 的图例筛选 。 : param nodes : 关系图结点，包含的数据项有 name：结点名称（必须有 ！ ） 。 x : 节点的初始 x 值 。 y：节点的初始 y 值 。 value：结点数值 。 category：结点类目 。 symbol：标记图形，有'circle ' , ' rect ' , ' roundrect ' , ' triangle ' , ' diamond ' , ' pin ' , ' arrow'可选 。 symbolsize：标记图形大小 。 : param links : 结点间的关系数据，包含的数据项有 source：边的源节点名称的字符串，也支持使用数字表示源节点的索引（必须有 ！ ） target：边的目标节点名称的字符串，也支持使用数字表示源节点的索引（必须有 ！ ） value：边的数值，可以在力引导布局中用于映射到边的长度 : param categories : 结点分类的类目，结点可以指定分类，也可以不指定 。 如果节点有分类的话可以通过 nodes[i].category 指定每个节点的类目 ， 类目的样式会被应用到节点样式上 : param is_focusnode : 是否在鼠标移到节点上的时候突出显示节点以及节点的边和邻接节点 : param is_roam : 是否开启鼠标缩放和平移漫游 。 如果只想要开启缩放或者平移，可以设置成'scale'或者'move'。设置成 true 为都开启 : param is_rotatelabel : 是否旋转标签 : param graph_layout : 关系图布局，默认为 ' force ' none：不采用任何布局，使用节点中必须提供的 x ， y 作为节点的位置 。 circular：采用环形布局 force：采用力引导布局 : param graph_edge_length : 力布局下边的两个节点之间的距离，这个距离也会受 repulsion 影响 。 支持设置成数组表达边长的范围，此时不同大小的值会线性映射到不同的 长度。值越小则长度越长 。 : param graph_gravity : 节点受到的向中心的引力因子。该值越大节点越往中心点靠拢 。 : param graph_repulsion : 节点之间的斥力因子。默认为 50 支持设置成数组表达斥力的范围，此时不同大小的值会线性映射到不同的斥力 。 值越大则斥力越大 : param graph_edge_symbol : 边两端的标记类型，可以是一个数组分别指定两端，也可以是单个统一指定 。 默认不显示标记，常见的可以设置为箭头，如下：edgesymbol : [ ' circle ' , ' arrow ' ] 。 : param graph_edge_symbolsize : 边两端的标记大小，可以是一个数组分别指定两端，也可以是单个统一指定 。 : param kwargs :"
return a dokuwiki - compatible unix int timestamp for a mediawiki api page / image / revision
convert a canonical mediawiki pagename to a dokuwiki pagename
convert a mediawiki internal anchor heading link to the dokuwiki anchor heading link i d
convert a camelcased string to underscore_delimited ( tweaked from this stackoverflow answer ) http://stackoverflow.com/questions/1175208/elegant-python-function-to-convert-camelcase-to-camel-case
"given ' pages ' as a list of mediawiki pages with revisions attached , export them to dokuwiki pages"
"given ' images ' as a list of mediawiki image metadata api entries , download and write out dokuwiki images . does not bring over revisions ."
convert the supplied mediawiki page to a dokuwiki page
rebuild the wiki - wide changelong from meta/ to meta/_dokuwiki.changes or from media_meta to media_meta/_media.changes
fix permissions under the data directory
invalidate cached pages by updating modification date of a config file
adapted from django 's django.template.defaultfilters.slugify .
make sure that the slug is unique for the given date before the data is actually saved .
: param text : the text which should be scanned : param flags : default regular expression flags
` true ` if the scanner reached the end of text .
apply ` pattern ` on the current position and return the match object . ( does n't touch pos ) . use this for lookahead .
apply a pattern on the current position and check if it patches . does n't touch pos .
"scan the text for the given pattern and update pos / match and related fields . the return value is a boolen that indicates if the pattern matched . the matched value is stored on the instance as ` ` match ` ` , the last value is stored as ` ` last ` ` . ` ` start_pos ` ` is the position of the pointer before the pattern was matched , ` ` pos ` ` is the end position ."
scan exactly one char .
return the \newcommand sequences needed to define the commands used to format text in the verbatim environment . ` ` arg ` ` is ignored .
return only logits . not sigmoid(logits ) .
returns a list of all objects in the database
returns a the object with i d of _ i d
returns a the object with a given uuid
returns an object with a given name
returns object data as dictionary object
main entry point for the application
remove any non - white listed chars from a string
return all objects
return the object whose i d is _ i d
return the object whose uuid is _ uuid
return the object whose name is _ name
converts name from camel case to snake case
replace non printable chars with their hex code : param line : : return : str
return hexdump in html formatted data : param hex_cmd : : return : str
create temporary temp directories : return :
make a directory if it does not already exist
test if the getters return the right value .
common tests for the ms classes .
test the mstrack item when instantiated from a search .
test the msalbum item when instantiated from a search .
test the msalbum item when instantiated from a search .
test the msalbum item when instantiated from a search .
id to extended id method .
form the uri .
run the main script
print the details of a service
returns true if all walls are still standing .
returns the direction to the given cell from the current one . must be one cell away only .
removes the wall between two adjacent cells .
"creates a new maze with the given sizes , with all walls standing ."
"returns the cell at index = ( x , y ) ."
"returns the list of neighboring cells , not counting diagonals . cells on borders or corners may have less than 4 neighbors ."
returns a matrix with a pretty printed visual representation of this maze . example 5x5 :
returns an unicode representation of the maze . size is doubled horizontally to avoid a stretched look . example 5x5 :
knocks down random walls to build a random perfect maze .
returns a new random perfect maze with the given sizes .
returns a random position on the maze .
displays a value on the screen from an x and y maze positions .
"starts an interactive game on this maze , with random starting and goal positions . returns true if the user won , or false if she quit the game by pressing "" q "" ."
clears the screen and refills it with the given text .
"changes only a portion of the display , keeping the rest constant ."
"waits for user keyboard input and returns the character typed , or special key such as "" up "" ."
waits until the user presses one of the keys in ` expected_keys ` and returns it .
"given a map key - > option , waits until the user selects a valid key and then returns the associated option ."
"given a map key - > function , loops receiving user input and invoking the respective functions . unknown keys are ignored ."
checks if a command is on the path and executable
"< purpose > starts subprocess and executes command line audio player , playing audio file at passed path ."
"calls bash command ` stty size ` and returns standard output , i.e. width and height of current terminal ( blocking call ) ."
"calls bash command ` clear ` , clears the current terminal ( blocking call ) ."
"loads text from file , appends each line to an array and returns array ."
< purpose > clears current terminal window and prints passed banner array and optionally passed text . the banner and the text centered horizontally .
generate a key pair according to the demo 's current default key config .
import a public key according to the demo 's current default key config . the keyname does not include ' .pub ' ; it matches that used for the other functions here .
import a private key according to the demo 's current default key config .
returns a random alphanumeric string of length length . not cryptographically reliable .
return reward and reset for next step
updates rotation and impulse direction
updates velocity and returns rects for start / finish positions
"take shortlist , return it sorted : param short_list : : param sorts : list of sorts to perform : return :"
"gets a random guid . note : python 's uuid generation library is used here . basically uuid is the same as guid when represented as a string . : returns : str , the generated random guid . a = generateguid ( ) import uuid print a print uuid . uuid(a).hex"
: param frum : : param schema : : return :
get the current git revision
get revision of a remote branch
"if a string has single or double quotes around it , remove them . make sure the pair of quotes match . if a matching pair of quotes is not found , return the string unchanged ."
computes the sasa in parallel .
sets the current trajectory paths from the main view .
sets the chosen trajectory and topology paths .
clears the whole view and sets it to the initial state .
saves the generated sasa plot over all frames .
exports the computed sasa values of each frame to a text file .
computes the sasa of the given selections .
event listener for progress bar updates .
plots the selected attribute .
saves the current plot .
calculate output .
calculate output .
"calculate and save derivatives . ( i.e. , jacobian )"
matrix - vector product with the jacobian .
calculate output .
"calculate and save derivatives . ( i.e. , jacobian )"
matrix - vector product with the jacobian .
calculate output .
"calculate and save derivatives . ( i.e. , jacobian )"
matrix - vector product with the jacobian .
calculate output .
"calculate and save derivatives . ( i.e. , jacobian )"
matrix - vector product with the jacobian .
"retrieve a value from the cache , using the given creation function to generate a new value ."
"retrieve a value from the cache , using the given creation function to generate a new value ."
place a value in the cache .
retrieve a value from the cache .
invalidate a value in the cache .
"invalidate the cached content of the "" body "" method for this template ."
invalidate the cached content of a particular ` ` < % def > ` ` within this template .
invalidate a nested ` ` < % def > ` ` within this template .
"retrieve a value from the cache , using the given creation function to generate a new value ."
place a value in the cache .
retrieve a value from the cache .
invalidate a value in the cache .
resource is a table name with schema and column name combined as follow : schema.table.column
list available resources
making sure noone messes up dict - like behavior of our collection
evaluates the trained model on the specified dataset
reads tfrecords from a queue and decodes them
creates batches for training and validating the net
add summaries for losses in model .
adds l2 regularization loss to the given list of losses
negative log likelihood
returns dict of tensorflow variables ( variable_name : variable )
returns current time in day_month_hh - mm - ss/ format
returns current time in hh : mm : ss format
returns expired time in hh : mm : ss format calculated relative to start_time
linear storage control law
simple searev storage simulation . ( without saturation support - > raises an error if storage runs out of bounds )
plot a trajectory of the searev+storage system ( 3 panels )
"state transition of the "" searev + storage "" system"
set of admissible control u(x_k ) of an energy storage controls is the stored power p_sto
penalty on the power injected to the grid p_grid = p_prod - p_sto penal = ( p_grid / power_max)**2
"if context.get_system_version().get_version ( ) > = ( 15 , 0 ): message = u""you're using old youtube - plugin calls - please review the log for updated end points starting with isengard "" context.get_ui().show_notification(message , time_milliseconds=15000 )"
provides pagination for a given list of objects . call function for any page needing pagination .
helper to return httpresponse with json type json.dumps the payload given
get query parameters if search is used
adjust cc / cxx / ld flags for out - of - tree use
turn a gn path into a real path
join a list of arguments to be passed to a shell
get normalized headers for the upstream
return request headers that will be sent to upstream .
"create a new : class:`connectionpool ` based on host , port and scheme . this method is used to actually create the connection pools handed out by : meth:`connection_from_url ` and companion methods . it is intended to be overridden for customization ."
"output strings are always byte strings , even using python 3"
make sure the host line is second in the request
try to load copr user configs if any # 1 . copr config file should be located at ` ~/.config / copr ` # or # 2 . user defined should be stored in ` copr_user.conf ` # next to ` releasers.conf `
copy srpm to remote destination and submit it to copr
echo back whatever is received .
reads directory of images in tensorflow args : path : is_directory :
reads args : filename_queue : imshape : normalize : flatten :
reads args :
reads directory of images . args : path : path to the directory
reads args : filename_queue : imshape : normalize : flatten :
convert class labels from scalars to one - hot vectors .
generate an linnfs filesystem image .
generate random number
generate username using loginradius profile data .
check username is also exist and generate unique username .
insert new user to django database .
: param i d : i d of this object : param x : x coordinate : param y : y coordinate : param z : z coordinate : return :
: return : i d of this coordinate
": return : numpy array holding the coordinates [ x , y , z ]"
": param i d : i d of this vertex . the user has to take care , that this i d is unique ! : param x : x coordinate : param y : y coordinate : param z : z coordinate : return :"
"adds an edge to the vertex . this means , that this edge is connected to the vertex . : param edge : edge object : return :"
"adds an quad to the vertex . this means , that this quad is connected to the vertex : param quad : quad object : return :"
: return : set of all edges connected to this vertex
: return : set of all quads connected to this vertex : rtype : petersscheme . edge
: return : number of edges connected to this vertex
: return : number of quads connected to this vertex
": param i d : i d of this vertex . the user has to take care , that this i d is unique ! : param x : x coordinate : param y : y coordinate : param z : z coordinate : param u : u parameter : param v : v parameter : param quad : associated quad : return :"
": return : the dict with both parameters u , v"
: return : parameter u
: return : parameter v
returns the pointer to the patch this finevertex is associated with . : return : returns a quad object
": param localparams : 4 - d matrix of some data ;) e.g. ( 4x4x4x4 ) : return : spits out a 3x3 matrix of the coefficients on the neighbouring ( and central ) vertex points to that in the center of the patch , for a point with the local parameters localparams on the patch ."
": param i : : param j : : return : a matrix with the biquadractic point coefficients of its neighbour vertices for the control point ( i , j ) on the biquadratic patch , in the form of a 3x3 matrix of neighbouring vertex point coefs"
"checks whether the type of the cut value matches the type of the concept being cut , and raises a queryexception if it does n't match"
returns the api type of the given value based on its python type .
"apply a set of filters , which can be given as a set of tuples in the form ( ref , operator , value ) , or as a string in query form . if it is ` ` none ` ` , no filter will be applied ."
test string formating to match api expectations
tests get_market_ticker >
test getting the market orders
test getting the market depth
test get market spread
test getting the market history
test getting the futures market ticker
test getting the future market orders
test getting the futures market depth
test get futures market spread
test getting the futures market history
test getting the futures index
initialize bittrex class
format the pair argument to format understood by remote api .
verify if api responded properly and raise apropriate error .
handles private api methods
returns simple current market status report
get market trade history
return order book for the market
find supported markets on this exchange
return volume of last 24h
return nonce integer
get all balances from your account
get deposit address for < currency >
creates buy order for < pair > at < price > for < quantity >
creates sell order for < pair > at < price > for < quantity >
withdraw < coin > < amount > to < address > with < address_tag > if needed
retrieves withdrawal history .
retreive deposit history .
get open orders for < pair > or all open orders if called without an argument .
retrieve a single order by orderid .
cancel order with < order_id > for < symbol >
cancel all orders for < symbol >
convert iso style date expression to datetime object
expected input is quote - base . normalize the pair inputs and format the pair argument to a format understood by the remote api .
": return : dict['ask ' : float , ' bid ' : float , ' last ' : float ] example : { ' ask ' : float , ' bid ' : float , ' last ' : float }"
": return : list - > dict['timestamp ' : datetime.datetime , ' is_sale ' : bool , ' rate ' : float , ' amount ' : float , ' trade_id ' : any ]"
": return : dict['bids ' : list[price , quantity ] , ' asks ' : list[price , quantity ] ] bids[0 ] should be first next to the spread asks[0 ] should be first next to the spread"
return sum of all bids and asks
returns market spread
test string formating to match api expectations
test string formating to match api expectations
test market buy
test cancel all orders
returns the workflow class to instantiate for the sub workflow
"connect the * following * task to this one . in other words , the given task is added as an output task ."
"returns the list of tasks that were activated in the previous call of execute ( ) . only returns tasks that point towards the destination task , i.e. those which have destination as a descendant ."
returns the list of threads that were activated in the previous call of execute ( ) .
may be called after execute ( ) was already completed to create an additional outbound task .
returns the processparser for the given process id or name . it matches by name first .
add the given bpmn filename to the parser 's set .
add all filenames matching the provided pattern ( e.g. * .bpmn ) to the parser 's set .
add all filenames in the given list to the parser 's set .
add the given lxml representation of the bpmn file to the parser 's set .
"pre - parse the given condition expression , and return the parsed version . the returned version will be passed to the script engine for evaluation ."
pre - parse the documentation node for the given node and return the text .
"parses the required subset of the bpmn files , in order to provide an instance of bpmnprocessspec ( i.e. workflowspec ) for the given process id or name . the name is matched first ."
connect this task spec to the indicated child .
"connect this task spec to the indicated child , if the condition evaluates to true . this should only be called if the task has a connect_if method ( e.g. exclusivegateway ) ."
returns the outgoing sequenceflow targeting the specified task_spec .
returns the outgoing sequenceflow with the specified id .
returns true if the sequenceflow with the specified id is leaving this task .
returns a list of the names of outgoing sequences . some may be none .
returns a list of outgoing sequences . some may be none .
a subclass should override this method if they want to be notified of the receipt of a message when in a waiting state .
called when a task enters the waiting state .
called when a task enters the ready state .
called when a task enters the complete state .
called when a task enters the cancelled state .
called by a task spec when it was added into the workflow .
returns the task with the given name .
checks integrity of workflow and reports any problems with it .
serializes the instance using the provided serializer .
deserializes a workflowspec instance using the provided serializer .
"returns a weak reference to the given method or function . if the callback argument is not none , it is called as soon as the referenced function is garbage deleted ."
"constructor . do not use directly , use : class:`ref ( ) ` instead ."
returns the referenced method / function if it is still alive . returns none otherwise .
"returns true if the referenced function is still alive , false otherwise ."
proxied to the underlying function or method . raises : class:`deadmethodcalled ` if the referenced function is dead .
decode a sentence coupled with label
decode a sentence in the format of < >
decode the whole corpus in the specific format by calling apply_model to fit specific models
template function for apply_model
apply_model function for lstm - crf
apply_model function for lm - lstm - crf
this function visualizes filters in matrix a.
loads the images from the provided file name
add the weights as a matrix of images
parse all arguments .
assert that clients controller list only contains names provided .
"query relation with nrpe subordinate , return the nagios_host_context"
"query relation with nrpe subordinate , return the nagios_hostname"
return the nagios unit name prepended with host_context if needed
add checks for each service in list
copy the nrpe checks into place
add checks for each service in list
parse all arguments .
tests if juju 's add - credentials command works as expected .
adds the supplied credential to juju with ' juju add - credential ' .
gets the stored test credentials .
verify the client can bootstrap with the newly added credentials
verify the credentials entered match the stored credentials .
convenience function to check a pexpect session has properly closed .
adds credentials for aws to test client using real credentials .
adds credentials for gce to test client using real credentials .
adds credentials for rackspace to test client using real credentials .
adds credentials for maas to test client using real credentials .
adds credentials for joyent to test client using real credentials .
adds credentials for azure to test client using real credentials .
parse all arguments .
test if skip_on_missing_file hides the proper exceptions .
test if skip_on_missing_file ignores other types of exceptions .
recursively resolve sym links and return the absolute path to the final destination
resolve the grape installation base direcory
set the grape_home environment variable if not already set
creates the layout .
adds a widget to the container .
handle the events of the contained widgets and propagate the event .
paints the inner widgets .
initializes the instance
"register a widget within the widget manager . the widget will after it has been registered be able to receive various events . if the shortcut is a valid pygame key i d ( of of the k _ * constants ) , then the shortcut will be stored . the shortcut is used for activating a left mouse press on the widget when the given shortcut key is pressed ."
removes the passed widget from the management .
repaints the surface if needed .
handles the passed event . if the event is of any interest to any of the registred widgets the widgets are allowed to act on the event . if any widget handled the event then this method will return 1 to indicate that it should not be processed any further . a value of 0 indicates that the event was not processed .
handles an event when a key was pressed but not yet released . uses the last known position of the mouse to determine which widget has focus .
handles an event when a pressed key released . uses the last known position of the mouse to determine which widget has focus .
handles an event when the mouse pointer was moved within a widget .
handles an event when a mouse key was pressed but not yet released .
handles an event when a pressed mouse button was released .
handles a timer event .
handles a quit event . this is called when the player has done something that should cause the game to quit .
@api { get } /group/:id get info of group @apiname get group information @apigroup group
@api { post } /group create a reading group @apiname create a reading group @apigroup group
@api { post } /group/:id / members add a new member to reading group @apiname add a new member to a reading groups @apigroup group
@api { delete } /group / list/:id / archive archive a group list @apiname archive a group list @apigroup group
@api { delete } /group / list/:id / retrieve retrieve a group list @apiname retrieve a group list @apigroup group
@api { put } /group/:id / lists / retrieve bulk retrieve group lists @apiname bulk retrieve group lists @apigroup list
check if the limit is exempt .
: param app : : class:`sanic . sanic ` instance to rate limit .
decorator to be used for rate limiting individual routes .
decorator to be applied to multiple routes sharing the same rate limit .
decorator to mark a view as exempt from global rate limits .
decorator to mark a function as a filter to be executed to check if the request is exempt from rate limiting .
resets the storage if it supports being reset
"computes the token for a given secret returns the token , and the seconds remaining for that token"
convert dotted quad string to long and check the first octet
called implicitly before a packet is sent to compute and place igmp checksum .
display a summary of the igmp object .
called to explicitely fixup associated ip and ethernet headers
called to explicitely fixup an associated ethernet header
called to explicitely fixup an associated ip header
recursively convert list content into string
recursively convert dict content into string
"convert objectid , datetime , date into string"
"convert any list , dict , iterable and primitives object to string"
find certain path according to currfile
find certain path then load into sys path
convert camelcase style to under_score_case
converts a string argument to a byte string .
converts a string argument to a subclass of basestring .
convert string into objectid
convert string into int
convert string into float
convert value into bool
convert value into string
convert string into utf8 string
url parameter encode
according to request method config to filter all request paremter if value is invalid then set none
responsibility for rest api code msg can override for other style
can override for other style
can override in son class to do some clean work after request
application processor to setup session for every request
"load the session from the store , by the i d from cookie"
"kill the session , make it no longer available"
generate a random i d for session
removes all the expired sessions
encodes session dict as a string
decodes the data to get back the session dict
provide the type of ' key ' which is a member of ' associative_cls ' .
get coverage test to shut up .
count is pretty simple .
produces equivalent lisp output to the ast .
connects a github repository to a sns topic .
instantiates a repositorylistener . additionally : * creates or connects to a aws sqs queue named for the repository * creates or connects to a aws sns topic named for the repository * connects the aws sns topic to the aws sqs queue * configures the github repository to push hooks to the sns topic
checks for messages from the github repository .
converts a repository_name to a valid sns topic name .
registers a callback on a webhook received event .
parser for complete multipart upload response .
parser for copy object response .
parser for list buckets response .
internal function that extracts objects and common prefixes from list_objects responses .
parser for list objects response .
parser for list objects version 2 response .
parser for list multipart uploads response .
parser for list parts response .
parser for new multipart upload response .
parser for location constraint response .
convert iso8601 date string into utc time .
parser for a get_bucket_notification response from s3 .
parser for multi - object delete api response .
initialize s3element from name and xml string data .
similar to elementtree.element.findall ( )
similar to elementtree.element.find ( )
"extract text of a child element . if strict , and child element is not present , raises invalidxmlerror and otherwise returns none ."
"like self.get_child_text ( ) , but also performs urldecode ( ) on the result ."
fetches an ' etag ' child element suitably processed .
fetches an integer type xml child element by name .
parse a time xml child element .
fetch the current node 's text
initializes a new search engine
navigates to the search page with the query
scrolls to the bottom of the page and waits for more results to load . returns the new height
returns a list of the image objects in the google page
performs a google image search
destroys the browser window
converts an arbitary image to a matrix that can be fed into a classifier .
classifying an image
loads image from data uri
create new directory if not exists
list all the files in direction with the given extension only
execute this state
shows the ` n ` top items of a the datastructure .
wrapper around pandas plotting . see pandas documentation .
creates or changes a column . keeps groups in mind .
filter rows to keep .
select a subset of the columns .
renames the dataframe . expects a a dictionary of strings where the keys represent the old names and the values represent the new names .
expects a list of strings and will reset the column names .
drops columns from the frame .
removes all the duplicate rows in the frame . works just like the pandas method .
removes all the duplicate rows in the frame . works just like the pandas method .
sort the data structure based on * args passed in . works just like .sort_values in pandas but keeps groups in mind .
add a group to the datastructure . will have effect on .agg/.sort/.mutate methods . calling .agg after grouping will remove it . otherwise you need to call .ungroup if you want to remove the grouping on the datastructure .
removes any group from the datastructure .
pipe the datastructure through a large function . wrapper of ` .pipe ` in pandas .
aggregates the datastructure . commonly works with .group_by . if no grouping is present it will just aggregate the entire table .
turns a wide dataframe into a long one . removes any grouping .
turns a long dataframe into a wide one . < pre > currently unimplemented!</pre >
"samples ` n_samples ` rows from the datastructure . you can do it with , or without , replacement ."
mimic of pandas head function . selects ` n ` top rows .
mimic of pandas tail function . selects ` n ` bottom rows .
slice away rows of the dataframe based on row number . remember ; these frames start at 0 .
perform a left join with another frame .
perform an inner join with another frame .
runs the search_google command line tool .
: param rna : input sequence ( rna ) . : type rna : str : param run_checks : check inputs / formats ( disabling increases speed ): alphabet check case : type run_checks : bool : returns : coral . rna instance .
reverse transcribe to dna .
translate sequence into a peptide .
converts a given file in a directory to an rst in the same directory .
recursively converts all ipynb files in a directory into rst files in the same directory .
simulate a gibson reaction .
"find the next sequence to fuse , and fuse it ( or raise exception ) ."
"with one sequence left , attempt to fuse it to itself ."
"given two sequences ( seq1 and seq2 ) , report the size of all perfect matches between the 3 ' end of the top strand of seq1 and the 3 ' end of either strand of seq2 . in short , in a gibson reaction , what would bind the desired part of seq1 , given a seq2 ?"
run the rnacofold command and retrieve the result in a dictionary .
run the rnafold command and retrieve the result in a dictionary .
parses a line from stdout using a regex pattern .
a coral wrapper for the mafft command line multiple sequence aligner .
"given the substitutionmatrix input , generate an equivalent matrix that is indexed by the ascii number of each residue ( e.g. a - > 65 ) ."
"locate the index of the largest value in the array . if there are multiple , finds the earliest one in the row - flattened array ."
"calculates the alignment of two sequences . the global method uses a global needleman - wunsh algorithm , local does a a local smith - waterman alignment , global_cfe does a global alignment with cost - free ends and glocal does an alignment which is global only with respect to the shorter sequence , also known as a semi - global alignment . returns the aligned ( sub)sequences as character arrays ."
calculate the alignment score from two aligned sequences .
boilerplate to assert that a pcr reaction matches the expected sequence .
"amplify entire template , no overhangs ."
"amplify part of the template , no overhangs ."
"if primers point away from each other on a linear template , raise eception ."
"amplify a circular template over the origin , no overhangs ."
"amplify entire template , no overhangs ."
test for when the forward primer overlaps the origin ( index 0 ) .
test for when the reverse primer overlaps the origin ( index 0 ) .
test for when both primers overlap the origin ( index 0 ) .
amplification should occur regardless of the order in which primers are specified .
tests case where primers overlap .
tests that primer overhangs are added correctly to the amplicon .
test that a bad primer raises a primingerror .
test that primers that bind the same strand raise an error .
test that ambiguous primer binding sites raises an error .
"returns the command line call string to execute the target algorithm ( here : spear ) . args : runargs : a map of several optional arguments for the execution of the target algorithm . { "" instance "" : < instance > , "" specifics "" : < extra data associated with the instance > , "" cutoff "" : < runtime cutoff > , "" runlength "" : < runlength cutoff > , "" seed "" : < seed > } config : a mapping from parameter name to parameter value returns : a command call list to execute the target algorithm ."
parse a results file to extract the run 's status ( success / crashed / etc ) and other optional results .
used to randomly sample the search space .
used to seed an algorithm with a regular pattern of corners and centres .
initialise the sampler class .
pick the next feature location for the next observation to be taken .
update a job with its observed value .
"assign a pair ( location in parameter space , virtual target ) a job id ."
update a job with its observed value .
verify that we get the right exception when an unsupported auth type is requested .
"verify that a bad password gets the right exception , and that a retry with the right password works ."
verify that multipart auth works .
verify keyboard - interactive auth works .
"verify that a password auth attempt will fallback to "" interactive "" if password auth is n't supported but interactive is ."
verify that utf-8 encoding happens in authentication .
verify that non - utf-8 encoded passwords can be used for broken servers .
"verify that we catch a server disconnecting during auth , and report it as an auth failure ."
verify that authentication times out if server takes to long to respond ( or never responds ) .
set up lefthand client .
checks for incorrect lefthand api being used on backend .
creates a volume .
deletes a volume .
assigns the volume to a server .
unassign the volume from the host .
try to trick the linefeed detector .
verify that write buffering is on .
verify that flush will force a write .
verify that flushing happens automatically on buffer crossing .
verify that read(-1 ) returns everything left in the file .
verify that buffered objects can be written
determines which child directory of ` repo_dir ` is the project template .
"asks the user whether it 's okay to delete the previously - cloned repo . if yes , deletes it . otherwise , cookiecutter exits ."
determines if ` repo_url ` should be treated as a url to a git or hg repo .
check if the version control system for a repo type is installed .
clone a repo to the current directory .
estimate ` nmom ` number of l - moments from a sample ` data ` .
derives a pep386 - compliant version number from version .
auto - discover installed_apps admin.py modules and fail silently when not present . this forces an import on them to register any admin bits they may want .
returns the root endpoint matching the namespace
returns url parts for use in the url regexp for conducting item lookups
returns a detail link based on whether a client can edit or view the objects
initialize the bar plot checker .
ensure that the given expected attribute values are in the right shape .
assert that the plot has the given number of bars .
the centers of the plotted bars .
assert that the given centers are equivalent to the plotted : attr:`~plotchecker . barplotchecker.centers ` .
assert that the given centers are almost equal to the plotted : attr:`~plotchecker . barplotchecker.centers ` .
the heights of the plotted bars .
assert that the given heights are equivalent to the plotted : attr:`~plotchecker . barplotchecker.heights ` .
assert that the given heights are almost equal to the plotted : attr:`~plotchecker . barplotchecker.heights ` .
the widths of the plotted bars .
assert that the given widths are equivalent to the plotted : attr:`~plotchecker . barplotchecker.widths ` .
assert that the given widths are almost equal to the plotted : attr:`~plotchecker . barplotchecker.widths ` .
the y - coordinates of the bottoms of the plotted bars .
assert that the given bottoms are equivalent to the plotted : attr:`~plotchecker . barplotchecker.bottoms ` .
assert that the given bottoms are almost equal to the plotted : attr:`~plotchecker . barplotchecker.bottoms ` .
the colors of the plotted bars .
assert that the given colors are equivalent to the plotted : attr:`~plotchecker . barplotchecker.colors ` .
assert that the given colors are almost equal to the plotted : attr:`~plotchecker . barplotchecker.colors ` .
the edge colors of the plotted bars .
assert that the given edgecolors are equivalent to the plotted : attr:`~plotchecker . barplotchecker.edgecolors ` .
assert that the given edgecolors are almost equal to the plotted : attr:`~plotchecker . barplotchecker.edgecolors ` .
the alpha values of the plotted bars .
assert that the given alphas are equivalent to the plotted : attr:`~plotchecker . barplotchecker.alphas ` .
assert that the given alphas are almost equal to the plotted : attr:`~plotchecker . barplotchecker.alphas ` .
the line widths of the plotted bars .
assert that the given linewidths are equivalent to the plotted : attr:`~plotchecker . barplotchecker.linewidths ` .
assert that the given linewidths are almost equal to the plotted : attr:`~plotchecker . barplotchecker.linewidths ` .
is an error thrown when there is nothing plotted ?
are the number of bars correct ?
are the x and y values correct ?
are the x and y values almost correct ?
are the x and y values correct with align = center ?
are the x and y values almost correct ?
are the widths correct ?
are the widths almost correct ?
are the colors correct ?
are the colors almost correct ?
are the edgecolors correct ?
are the edgecolors almost correct ?
are the alphas correct ?
are the alphas almost correct ?
are the linewidths correct ?
are the linewidths almost correct ?
"execute a command , capture and return its output ."
execute a command and print its output on failure .
read a list of symbols from a list of strings . each string is one symbol .
read a list of symbols in from a file .
write a list of symbols to the file named by out .
updates the cholesky decomposition of a matrix .
updates the solution of a linear system involving a cholesky factor .
constructor takes user session .
return a list of the apps a user is allowed to see in dashboard .
return list of group membership if user is asserted from ldap .
return user first_name .
return user last_name .
construct a list of potential user identifiers to match on .
if an app does n't have the required fields skip it .
constructor takes user session .
load tokens from word vector file .
a multi - processing wrapper for loading squad data file .
flatten each article in training data .
flatten each article in dev data
normalize spaces in a string .
"get exact indices of the answer in the tokens of the passage , according to the start and end position of the answer ."
"build vocabulary sorted by global word frequency , or consider frequencies in questions first , which is controlled by ` args.sort_all ` ."
"perform pca on tsv file with row and column headers . rows are data points , columns are variables ."
"perform pca of a data matrix . rows are data points , columns are variables ."
"e.g. 1000 x 2 u [: , : npc ] * d[:npc ] , to plot etc ."
pretty prints ubjson data using the handy [ ] -notation to represent it in readable form . example : :
"decorator to call a pywebview api , checking for _ webview_ready and raisings appropriate exceptions on failure ."
"create a web view window using a native gui . the execution blocks after this function is invoked , so other program logic must be executed in a separate thread . : param title : window title : param url : url to load : param width : window width . default is 800px : param height : window height . default is 600px : param resizable true if window can be resized , false otherwise . default is true : param fullscreen : true if start in fullscreen mode . default is false : param min_size : a ( width , height ) tuple that specifies a minimum window size . default is 200x100 : param strings : a dictionary with localized strings : param confirm_quit : display a quit confirmation dialog . default is false : param background_color : background color as a hex string that is displayed before the content of webview is loaded . default is white . : param text_select : allow text selection on page . default is false . : return : the uid of the created window ."
"create a file dialog : param dialog_type : dialog type : open file ( open_dialog ) , save file ( save_dialog ) , open folder ( open_folder ) . default is open file . : param directory : initial directory : param allow_multiple : allow multiple selection . default is false . : param save_filename : default filename for save file dialog . : param file_types : allowed file types in open file dialog . should be a tuple of strings in the format : filetypes = ( ' description ( * .extension[;*.extension [ ; ... ] ] ) ' , ... ) : return : a tuple of selected files , none if cancelled ."
load a new url into a previously created webview window . this function must be invoked after webview windows is created with create_window ( ) . otherwise an exception is thrown . : param url : url to load : param uid : uid of the target instance
load a new content into a previously created webview window . this function must be invoked after webview windows is created with create_window ( ) . otherwise an exception is thrown . : param content : content to load . : param base_uri : base uri for resolving links . default is the directory of the application entry point . : param uid : uid of the target instance
sets a new title of the window
get the url currently loaded in the target webview : param uid : uid of the target instance
destroy a web view window : param uid : uid of the target instance
toggle fullscreen mode : param uid : uid of the target instance
evaluate given javascript code and return the result : param script : the javascript code to be evaluated : param uid : uid of the target instance : return : return value of the evaluated code
"check whether a webview with the given uid is up and running : param uid : uid of the target instance : return : true if the window exists , false otherwise"
": param delay : optional timeout : return : true when the last opened window is ready . false if the timeout is reached , when the timeout parameter is provided . until then blocks the calling thread ."
realise nlg element .
realise message specification - this should not happen
realise a list .
return a copy of message with strings .
return a copy of a document with strings .
return a copy of a paragraph with strings .
tries to find the given filename on disk or via pkgutil.get_data .
constructs announce text for ongoing operations on url_to_display .
initializes the callback with backoff .
"tracks byte processing progress , making a callback if necessary ."
initializes the callback handler .
prints an overwriting line to stderr describing the operation progress .
makes fake ebuilds with minimal real content .
mocked out version of portage_util . findoverlays ( ) .
mocked out version of portage_util . findebuildforpackage ( ) .
set up a test environment .
creates and returns a workonhelper object .
assert that the workon / mask files mention the given atoms .
check that we complain if a board has not been previously setup .
check that the symlinks are regenerated when using a new sysroot .
check that we can mark a single atom as being worked on .
check that we can mark a multiple atoms as being worked on .
check that we can mark all possible workon atoms as started .
check that we can start atoms that have only a cros - workon ebuild .
check that starting an atom twice has no effect .
check that we can stop a previously started atom .
check that we can stop multiple previously worked on atoms .
check that we can stop all worked on atoms .
check that we can stop all workon only atoms .
check that we reject requests to work on unknown atoms .
check that we can list all worked on atoms across boards .
check that we can list the atoms we 're currently working on .
check that we can list all possible atoms to work on .
check that we can list all workon only atoms .
test that we can run a command in package source directories .
test that we can list all the cros workon atoms that are installed .
processes a list of markdown documentation files .
calculate the reason for the error from the response content .
constructor for an unexpectedmethoderror .
constructor for an unexpectedmethoderror .
randomnumber returns a random number of length 8*|length_in_bytes| bits
modexp returns n^e mod p
"makecertificate returns a der encoded certificate , signed by privkey ."
"generatecertkeyandocsp returns a ( cert_and_key_pem , ocsp_der ) where : * cert_and_key_pem contains a certificate and private key in pem format with the given subject common name and ocsp url . * ocsp_der contains a der encoded ocsp response or none if ocsp_url is none"
initializes a timelinemodel .
populates the model with a sequence of globalmemorydump objects .
iterate over the memory dump events of this model .
populates the model with the provided trace data .
find the timeline events with the given names .
"on osx , it is possible for a misconfigured keychain to cause the telemetry tests to stall . this method confirms that the keychain is in a sane state that will not cause this behavior . three conditions are checked : - the keychain is unlocked . - the keychain will not auto - lock after a period of time . - the acls are correctly configured on the relevant keychain items ."
adds a browser argument that allows for the collection of keychain metrics . has no effect on non - mac platforms .
adds the number of times that the keychain was accessed to |results| . has no effect on non - mac platforms .
returns a list of devices .
runs an change - point - finding function on part of a data series .
"returns the last "" window "" of points in the data series ."
removes some anomalies and updates the given test entity .
"runs findchangepoints , always setting an absolute change threshold ."
returns the path to the tryjob description .
verify jobs have unique names .
test that a tryjob spec file is created and pushed properly .
verify internal tryjobs are pushed properly .
verify submitting a tryjob from just a chromite checkout works .
called at the beginning of a shard .
called at the end of a shard .
called at the beginning of a slice .
called at the end of a slice .
"anything shared by pref and full will be replaced with spaces in full , and full returned ."
"takes the output of compare_expected , and returns a string description of the differences ."
0 black 1 red 2 green 3 yellow 4 blue 5 magenta ( purple ) 6 cyan 7 white ( gray )
"find all the files under the base path , and put them in ` ` self.data ` `"
"compares a dictionary of ` ` path : content ` ` to the found files . comparison is done by equality , or the ` ` comparison(actual_content , expected_content ) ` ` function given ."
mock out updatestateful .
mock out updaterootfs .
mock out setuprootfsupdate .
mock out setuprootfsupdate .
patches objects .
tests that update methods are called correctly .
tests that update methods are called correctly .
tests that update methods are called correctly .
tests we raise flasherror when payloads are missing .
tests that project sdk flashing invoked as expected .
mock out copyimagetodevice .
mock out installimagetodevice .
mock out chooseremovabledevice .
mock out listallremovabledevices .
mock out getremovabledevicedescription .
create a usb device for passing to flash . flash ( ) .
patches objects .
tests that imaging methods are called correctly .
tests that imaging methods are called correctly .
tests that using an image not having the magic bytes has prompt .
tests that we try to get the image path using xbuddy .
tests that we ask user to confirm if the device is not removable .
tests that we skip the prompt for non - removable with --yes .
tests that we ask user to choose a device if none is given .
test that flash . usbimageroperation is called when log level < = notice .
test that sudoruncommand is called when log level > notice .
test that usbimageroperation._pingdd ( ) sends the correct signal .
check that the expected pid is returned for _ getddpid ( ) .
check that -1 is returned for _ getddpid ( ) if the pids are n't valid .
tests that we can detect a gpt image .
splits a shebang ( # ! ) into command and arguments .
initializes the internal state .
return the file type of the passed file .
return the file path based on the file contents .
returns the file type for elf files .
decodes the file type of the passed file .
"computes all 16 bit optionally locked reg , reg / mem ops ."
set of 3 operand xmm / ymm / memory ops ( memory is a possible source operand ) .
set of 3 operand xmm / memory ops ( memory is a possible source operand ) .
set of all 2 operand xmm / ymm / memory moves .
set of all 2 operand xmm / ymm / memory to xmm / ymm moves .
"2 operand xmm->memory move or 3 operand xmm , memory->xmm move ."
generates the sha-1 based on the content of this zip .
retrieves the swarm_bot code and returns the sha-1 for it .
polls the server and fake execution .
"try to find an installation location for the directx sdk . check for the standard environment variable , and if that does n't exist , try to find via the registry . returns empty string if not found in either location ."
is header named ` ` name ` ` present in headers ?
"returns the header 's value , or none if no such header . if a header appears more than once , all the values of the headers are joined with ' , ' . note that this is consistent /w rfc 2616 section 4.2 which states :"
"removes the named header from the list of headers . returns the value of that header , or none if no header found . if multiple headers are found , only the last one is returned ."
"updates the headers replacing the first occurance of the given name with the value provided ; asserting that no further occurances happen . note that this is _ not _ the same as remove_header and then append , as two distinct operations ( del followed by an append ) are not atomic in a threaded environment . returns the previous header value for the provided name , if any . clearly one should not use this function with ` ` set - cookie ` ` or other names that may have more than one occurance in the headers ."
returns a standard html response page for an http error . * * note :* * deprecated
"returns the status , headers , and body of an error response ."
an application that emits the given error response .
"provides a simple mechanism for starting a transaction based on the factory ; and for either committing or rolling back the transaction depending on the result . it checks for the response 's current status code either through the latest call to start_response ; or through a httpexception 's code . if it is a 100 , 200 , or 300 ; the transaction is committed ; otherwise it is rolled back ."
parse arguments .
run output based tests
"given an extensiontoload instance , returns the corresponding extensionpage instance ."
checks if this extensiontoload instance has been loaded
returns a list of extensions given an extension i d. this is useful for connecting to built - in apps and component extensions .
perform a request until the server reply
wrap the wsgi application to override some path :
run the server
shutdown the server
start a server to serve ` ` application ` ` . return a server instance .
wait until the server is started
extracts from a build.ninja the commands to run gn .
clobber contents of build directory .
make the filename match the pattern expected by nacl_file_host .
copy files from src_dir to dest_dir .
build an architecture specific version for the chrome installer .
package the pnacl component for use within the chrome installer infrastructure . these files need to be named in a special way so that white - listing of files is easy .
"import a module , or import an object from a module ."
"import a module , or import an object from a module ."
import a module .
"imports a module , but catches import errors . only catches errors when that module does n't exist ; if that module itself has an import error it will still get raised . returns none if the module does n't exist ."
add list of packages for upload .
upload prebuilts for non - dev - installer use cases .
upload prebuilts for dev - installer use case .
upload prebuilts .
returns new lrudict with given |keys| added one by one .
asserts order of keys in |lru_dict| is |expected_keys| .
asserts that given |lru_dict| contains same data as |regular_dict| .
instruct _ test_restorer to check registry cleanup at this level of the stack
adds some sample data used in the tests below .
generate css minifier .
validate the trie_diffs adds 16 bit bsr / bsf is added in 32bit mode .
command entry point for the mv command .
shows quick_log_viewer.html .
retrieves logs .
set up the triggering of a test run .
superclass override .
verifies that the profile was correctly extended .
gets urls for the browser to navigate to .
returns a boolean indicating whether profile extension is finished .
a hook for subclasses to perform cleanup after each batch of navigations .
"updates the member self._navigation_tabs to contain self._num_tabs elements , each of which is not crashed . the crashed tabs are intentionally leaked , since telemetry does n't have a good way of killing crashed tabs ."
"removes a tab which is no longer in a useable state from self._navigation_tabs . the tab is not removed from self.browser.tabs , since there is no guarantee that the tab can be safely removed ."
retrives the url of the tab .
waits for the tab to navigate away from its initial url .
waits for the tab to be ready .
performs a batch of tab navigations with minimal delay .
waits for all the batch navigated tabs to finish loading .
"returns an array of urls to navigate to , given a url_iterator ."
"repeatedly fetches a batch of urls , and navigates to those urls . this will run until an empty batch is returned , or shouldexitafterbatchnavigation ( ) returns true ."
stop the server ( called from tester 's thread )
accept another request ( called from tester 's thread )
tests seeking in a filepart .
tests various reaad operations with filepart .
initialize debugcommand .
add parser arguments .
"provided with a list of pids , print out information of the processes ."
start a new process on the target device and attach gdb to it .
start gdb and attach it to the remote running process with |pid| .
process options and set variables .
run cros debug .
returns key for package files in the google storage cloud .
returns key for package archive files in the google storage cloud .
returns the local package file location .
returns the extension of an archive .
returns directory where local package archive files live .
returns the local package archive file location .
returns the local package archive log file location .
returns the local revision file location .
returns the destination directory for a package archive .
returns the package file stored in the destination directory .
generator for local package target packages within a root tar directory .
normalize the path and ensure it starts with os.path.sep .
number of sections in the file
get the section at index # n from the file ( section object or a subclass )
"get a section from the file , by name . return none if no such section exists ."
yield all the sections in the file
number of segments in the file
get the segment at index # n from the file ( segment object )
yield all the segments in the file
"check whether this file appears to have debugging information . we assume that if it has the debug_info section , it has all theother required sections as well ."
return a dwarfinfo object representing the debugging information in this file .
"return the machine architecture , as detected from the elf header . at the moment the only supported architectures are x86 and x64 ."
implement dict - like access to header entries
verify the elf file and identify its class and endianness .
compute the offset of section # n in the file
compute the offset of segment # n in the file
create a segment object of the appropriate type
"find the header of section # n , parse it and return the struct"
"given a section header , find this section 's name in the file 's string table"
create a section object of the appropriate type
create a symboltablesection
"find the header of segment # n , parse it and return the struct"
find the file 's string table section
parses the elf file header and assigns the result to attributes of this object .
read the contents of a dwarf section from the stream and return a debugsectiondescriptor . apply relocations if asked to .
configure additional middlewares for webapp .
calculates a base64 digest of the contents of a seekable stream .
calculates hashes of the contents of a file .
calculates a base64 crc32c checksum of the contents of a seekable stream .
calculates a base64 md5 digest of the contents of a seekable stream .
calculates a base64 md5 digest of the contents of a seekable stream .
returns the base64 - encoded version of the input hex digest value .
returns the hex digest value of the input base64 - encoded hash .
calculates a base64 digest of the contents of a seekable stream .
returns a dict of hash algorithms for validating an uploaded object .
returns a dict of hash algorithms for validating an object .
initializes the wrapper .
""" reads from the wrapped file pointer and calculates hash digests ."
returns the current stream position .
returns true if the stream is seekable .
seeks in the wrapped file pointer and catches up hash digests .
"catches up hashes , but does not return data and uses little memory ."
parses a single test expectation condition .
called on creation . override to set up custom expectations .
defines whether the given expectation applies to the given page .
returns true to add --host - resolver - rules to send requests to replay .
initiates the devtool client backend which allows browser connection through browser ' devtool .
waits for browser to come up .
returns a user - friendly name for the process of the given |cmd_line| .
"read internal version of header file from instr , write exported version to outstr . the transformations are :"
clears the surfaceflinger latency data .
returns collected surfaceflinger frame timing data .
a helper function to make a string to show the position of the given cursor .
get latencyinfo trace events from the process 's trace buffer that are within the timeline_range .
compute input event latencies .
returns true if the process contains at least one benchmarkinstrumentation::*renderingstats event with a frame .
returns the name of the events used to count frame timestamps .
"utility class for extracting rendering statistics from the timeline ( or other loggin facilities ) , and providing them in a common format to classes that compute benchmark metrics from this data ."
returns a chrome user agent based on a user agent type . this is derived from : https://developers.google.com/chrome/mobile/docs/user-agent
"adds support for gpu , device id , and angle conditions ."
return a story set that only has the first story .
access to chrome://oobe / login page .
"returns true if cryptohome has mounted , the browser is responsive to devtools requests , and the oobe has been dismissed ."
helper to do regex matching on a google storage url
add parser arguments .
initializes cros stage .
generate the name as which |image| will be staged onto moblab .
generate the name as which |image| will be staged onto moblab .
download from gs the update payloads we require .
generate the update payloads we require .
generate and transfer to the moblab the test bits we require .
stage the generated payloads and test bits on a moblab device .
stage the generated payloads and test bits into a google storage bucket .
perform the cros stage command .
returns true if this script is running on an sdk builder .
"write and error to stderr , then exit with 1 signaling failure ."
annotate a buildbot build step .
start a process with the provided arguments .
recursively copy a directory using .
remove the provided path .
create the path including all parent directories as needed .
move the path src to dst .
remove the provided file .
upload the given filename to google store .
return a archivedhttpresponse with |status| code and a simple text body .
return a archivedhttpresponse with |data| encoded as json in the body .
initialize customhandlers .
dispatches requests to matching handlers .
parse special generator urls for the embedded response code .
"if sent , saves embedded image to local directory ."
add the ability to change the server mode ( e.g. to record mode ) . args : server_manager : a servermanager . servermanager instance .
parse special urls for the embedded server manager command .
"tests moving two buckets , one with 2 objects and one with 0 objects ."
tests moving a local directory to a bucket .
tests mv with the -i option .
tests mv with the -n option .
checks the ip of the request against the white list .
checks the remote address of the request against the ip whitelist .
runs a split - select command .
returns a config specifying which apk splits are required by the device .
determines which apk splits the device requires .
returns true if the test suite requires mock test server .
returns true if the test suite requires high performance mode .
single test suite attached to a single device .
process the test output .
sets up necessary test enviroment for the test suite .
cleans up the test enviroment for the test suite .
find the absolute path of the git checkout that contains |path| .
locate the pylintrc file that applies to |path| .
return a dictionary mapping pylintrc files to lists of paths .
return the set of python library paths to use .
run the linter with common runcommand args set as higher levels expect .
returns result of running cpplint on |path| .
returns result of running pylint on |path| .
maps a linter method to the list of files to lint .
call |linter| on |path| and take care of coalescing exit codes / output .
tests that we can nest timeout correctly .
tests that we still re - raise an alarm if both are reached .
return a functor that returns given values in sequence with each call .
get number of times func was tried .
get number of seconds that span all func tries .
run through a test for waitforsuccess .
run through a test for waitforreturnvalue .
test success after a few tries .
test timeout after a couple tries .
test success on first try .
test success after a few tries with longer period .
test value found after a few tries .
test value found on first try .
verify side_effect_func works .
verify a long running side effect does n't call time.sleep(<negative > ) .
"if side_effect is called after the timeout , remaining should be zero ."
function arguments take precedence over gn args and default values .
"parse the gn config file from the build directory , if it exists ."
build directory path .
os of the build / test target .
cpu arch of the build / test target .
is debug build ?
should print additional logging information ?
dcheck and mojo_dcheck are fatal even in release builds
is asan build ?
name of the apk file to run
depth first search of all contexts referenced by a token stream .
returns the first statement context .
wraps source code in a goog.scope statement .
"returns the concatenation of the parent 's node first_id and this node 's offset if it has one , otherwise just call the superclass ' implementation"
sets this node 's clique from a tclib . message instance .
applies substitution to this message .
returns a translated version of this message .
we always expand variables on messages .
"returns a ( i d , string ) pair that represents the string i d and the string in the specified encoding , where |encoding| is one of the encoding values accepted by util . encode . this is used to generate the data pack data file ."
"constructs a new message node that is a child of ' parent ' , with the name , desc , meaning and translateable attributes set using the same - named parameters and the text of the message and any placeholders taken from ' message ' , which must be a tclib . message ( ) object ."
generate the dependency dir for the test suite using isolate .
constructs a linkerexceptiontestresult object .
creates a new linkertestrunner .
sets up and runs a test case .
test that a normal runs completes without error .
test that master / slave version mismatch causes failure .
test that an assertion is thrown if master name is not valid .
test that a normal run of the stage does a database insert .
test that handleskip disables cidb and dies when necessary .
test that handleskip passes when db_type is missing .
test that handleskip passes when db_type is specified .
basic sanity check for results stage functionality
check that we do not update the latest markers on failed build .
check that commit queue patches get serialized
send out alerts when streak counter reaches the threshold .
continue sending out alerts when streak counter exceeds the threshold .
test that writebasicmetadata writes expected keys correctly .
test that getchildconfiglistmetadata generates child config metadata .
check that we can run with a release_tag of none .
elf type as determined by elf metadata
clear caches for all filetype functions ( externally they must all be cleared together because they can call each other )
clear cached results from all functions .
force a function call with |args| to return |value| .
clear cached results for one instance ( function ) .
adds data to the mock datastore .
helper function to recursively add sub - tests to a test .
adds rows to a given test .
adds a set of rows given a dict of revisions to properties .
adds a set of rows given an iterable of id numbers .
sets the domain that users who can access internal data belong to .
sets the domain that users who can access internal data belong to .
sets the list of whitelisted ip addresses .
executes all of the tasks on the queue until there are none left .
sets the user in the environment in the current testbed .
sets the user in the environment to have no email and be non - admin .
gets a variable embedded in a script element in a response .
initializes shellcommand .
adds a parser .
processes options and set variables .
generates the correct ssh connect settings based on our state .
asks the user whether it 's ok that a host key has changed .
starts an ssh session or executes a remote command .
runs ` cros shell ` .
prints an error message and exit the program .
"reads all source specified on the command line , including sources included by --root options ."
gets the closure base.js file if present among the sources .
calculates dependencies for a set of top - level files .
sets compiled to true in the closure base.js source .
copies a list of sources to a destination directory .
writes output in the specified format .
writes a stamp file .
writes a depfile .
appends one or more source objects the list if it does n't already exist .
"args : specs : a list of mappings , each consisting of the input prefix and the corresponding output prefix separated by colons ."
rewrites an input path according to the list of rules .
patch imported modules .
test that deploy._emerge is called for each package .
test that deploy._unmerge is called for each package .
test that brillodeployoperation . run ( ) is called for merge .
test that brillodeployoperation . run ( ) is called for unmerge .
test that brillodeployoperation works for merge .
test that brillodeployoperation works for unmerge .
retry calling the decorated function using an exponential backoff .
creates a cpp_type_generator . the given root_namespace should be of the format extensions::api::sub . the generator will generate code suitable for use in the given model 's namespace .
gets the enum value in the given model . property indicating no value has been set .
gets the enum value in the given model . property indicating the last value for the type .
gets the enum value of the given model . property of the given type .
translates a model . property or model . type into its c++ type .
returns the forward declarations for self._default_namespace .
returns the # include lines for self._default_namespace .
finds the model . type with name |qualified_name| . if it 's not from |self._default_namespace| then it needs to be qualified .
follows $ ref link of types to resolve the concrete type a ref refers to .
"returns a dict ordered by namespace name containing a mapping of model . namespace to every _ typedependency for |self._default_namespace| , sorted by the type 's name ."
gets all the type dependencies of a property .
generates the code to display all value - containing properties .
returns a mock fetch object that returns a canned response .
constructs a filehandle pointing to a temporary file .
constructs a filehandle from an absolute file path .
constructs a filehandle object .
returns the path to the pointed - to file relative to the given start path .
validates the format of a fieldtrial configuration .
set up python logging .
returns the console logger or the root logger if not initialized .
returns the annotator logger or the console logger if not initialized .
"flush stdout and print a message to stderr , also log ."
modulate command output level based on logging level .
"capture stdout from a command , while logging its stderr ."
"raises the exception , performs cleanup if needed ."
validates that all allowed patterns of mnemonics are added .
returns crc32w variants .
validates that all crc32w variants are added .
"acquire a lock in a sub - process , but do n't release ."
"acquire a lock in a sub - process , and reacquire it a second time ."
increment a number in a gs file protected by a lock .
test getting a lock .
test aquiring same lock multiple times .
test lock conflict .
test getting a lock when an old timed out one is present .
have lots of processes race to acquire the same lock .
have lots of processes race to double acquire the same lock .
have lots of processes update a gs file proctected by a lock .
ensure that lcok can be obtained and released in dry - run mode .
test aquiring same lock multiple times in dry - run mode .
"wrap the middleware , so that it applies gzipping to a response when it is supported by the browser and the content is of type ` ` text/ * ` ` or ` ` application/ * ` `"
makes a pageset for dromaeo benchmarks .
pad a string for safe http error responses .
a decorator to declare that only the first n arguments may be positional .
parse accept header .
choose most appropriate supported type based on what client accepts .
get package name for a module .
backport of offset.total_seconds ( ) from python 2.7 + .
decode a datetimefield parameter from a string to a python datetime .
parse component of an accept header .
copy the dictionary of values parsed from the header fragment .
determine if the given accept header matches content type .
comparison operator based on sort keys .
rebuilds accept header .
initialize a time zone offset .
get the a timedelta with the time zone 's offset from utc .
get the daylight savings time offset .
registers the expected requests along their reponses .
"returns true iff the import statment is of the form "" from x import y "" ."
the full dotted path of the module .
"the alias , if the module is renamed with "" as "" . none otherwise ."
the name used to reference this import 's module .
puts a test and row in the datastore and returns the entities .
kill all running emulators that look like ones we started .
delete all temporary avds which are created for tests .
returns an available tcp port for the console .
create and launch temporary emulators and wait for them to boot .
launch an existing emulator with name avd_name .
init an emulator .
return our device name .
creates an avd with the given name .
launches the emulator asynchronously . call confirmlaunch ( ) to ensure the emulator is ready for use .
aggressive cleanup of emulator images .
confirm the emulator launched properly .
collect the list of dependencies for the main_files
get architecture and dependency information for given files
finds the set of libraries matching |name| within lib_path
takes pagetestresults to a dict serializable to json .
simplify dependency json .
look up the cpe for a specified portage package .
checks common to both upload and commit .
initializes gccontext .
returns the base google compute engine command .
runs |cmd| .
runs the zone - specific |cmd| .
copies files from |src| to |dest| on |instance| .
copies files from |src| on |instance| to local |dest| .
copies files from |src| to |dest| .
ssh into |instance| . run |cmd| if it is provided .
lists all instances .
lists all disks .
lists all instances .
creates an image from |source_uri| or |disk| .
returns an instance 's ephemeral external ip address .
creates an |instance| .
deletes |instance| .
deletes |image| . user will be prompted to confirm .
deletes |disk| .
prints memory usage by function addresses with resolving symbols .
makes a new tab .
verify we correctly probe each arch
verify the binfmt register string does n't exceed kernel limits
a fake implementation of os.path.expanduser .
create a lineprogram from the given program encoded in a stream
assert that the state attributes specified in kwargs have the given values ( the rest are default ) .
renders the ui with the form .
updates the given anomalyconfig based on query parameters .
"returns a config dict if one could be gotten , or none otherwise ."
command entry point for the cat command .
parses a merged cyglog produced by mergetraces.py .
returns a dict { offset : [ symbolinfo ] } from a library .
finds all symbolinfo at a given offset .
returns the list of object files in a directory .
returns a list of symbolinfo from an iterable of filenames .
returns true if two symbols refer to the same constructor or destructor .
scans object files to create a { symbol : linker section(s ) } map .
warns about duplicate offsets .
outputs the orderfile to output_file .
import |target| and return a reference to it .
creates a new storyset .
true iff stories are allowed to have different storystate classes .
the base directory to resolve archive_data_file .
lazily constructs wpr_archive_info if it 's not set and returns it .
removes a story .
returns the string name of this storyset . note that this should be a classmethod so the benchmark_runner script can match the story class with its name specified in the run command : ' run < user story test name > < user story class name > '
return a string explaining in human - understandable terms what this story represents . note that this should be a classmethod so the benchmark_runner script can display stories ' names along with their descriptions in the list command .
convenient function to retrieve wpr archive file path .
"wraps an operation to be done against the page . if an error has occurred in an earlier step , skips this entirely ."
returns the expectations that apply to this test .
"does operations before the page is navigated . do not override this method . override willnavigatetopageinner , below ."
"does operations right after the page is navigated and after all waiting for completion has occurred . do not override this method . override didnavigatetopageinner , below ."
"validates and measures the page , taking into account test expectations . do not override this method . override validateandmeasurepageinner , below ."
"runs navigation steps , taking into account test expectations . do not override this method . override runnavigatestepsinner , below ."
runs the default set of navigation steps inherited from page . page .
"runs page interactions , taking into account test expectations . do not override this method . override runpageinteractionsinner , below ."
adds sample data and sets the list of test suites .
search a directory for logcat files .
test that finalize is still able to create a pexe w/ -no - strip - syms .
root : root module
root : root import
root : root definition
import : import string_literal semi
module : attribute_section module identifier_wrapped semi
definition : struct | union | interface | enum | const
attribute_section : lbracket attribute_list rbracket
attribute_list : nonempty_attribute_list
nonempty_attribute_list : attribute
nonempty_attribute_list : nonempty_attribute_list comma attribute
attribute : name equals evaled_literal | name equals name
evaled_literal : literal
struct : attribute_section struct name lbrace struct_body rbrace semi
struct_body : struct_body const | struct_body enum | struct_body struct_field
struct_field : attribute_section typename name ordinal default semi
union : attribute_section union name lbrace union_body rbrace semi
union_body : union_body union_field
union_field : attribute_section typename name ordinal semi
default : equals constant
interface : attribute_section interface name lbrace interface_body rbrace semi
interface_body : interface_body const | interface_body enum | interface_body method
response : response lparen parameter_list rparen
method : attribute_section name ordinal lparen parameter_list rparen response semi
parameter_list : nonempty_parameter_list
nonempty_parameter_list : parameter
nonempty_parameter_list : nonempty_parameter_list comma parameter
parameter : attribute_section typename name ordinal
typename : nonnullable_typename qstn | nonnullable_typename
nonnullable_typename : basictypename | array | fixed_array | associative_array | interfacerequest
basictypename : identifier | handletype
handletype : handle | handle langle name rangle
array : array langle typename rangle
fixed_array : array langle typename comma int_const_dec rangle
associative_array : map langle identifier comma typename rangle
interfacerequest : identifier amp
ordinal : ordinal
enum : attribute_section enum name lbrace nonempty_enum_value_list rbrace semi | attribute_section enum name lbrace nonempty_enum_value_list comma rbrace semi
nonempty_enum_value_list : enum_value
nonempty_enum_value_list : nonempty_enum_value_list comma enum_value
enum_value : attribute_section name | attribute_section name equals int | attribute_section name equals identifier_wrapped
const : const typename name equals constant semi
constant : literal | identifier_wrapped
identifier_wrapped : identifier
identifier : name | name dot identifier
literal : int | float | true | false | default | string_literal
int : int_const | plus int_const | minus int_const
int_const : int_const_dec | int_const_hex
float : float_const | plus float_const | minus float_const
set up the test framework .
set up the context cache .
fetches cached test suite data .
updates test suite data for either internal or external users .
returns a dictionary with information about top - level tests .
fetches just the keys for non - deprecated top - level test entities .
returns an initial suite dict with names mapped to masters .
makes a dictionary listing masters and bots for some set of tests .
makes a dict of test suite names to lists of monitored sub - tests .
"fetches tests with a projection query for the "" monitored "" property ."
"gets the part of the test path after the suite , for the given test key ."
gets a dict of test suite names to descriptions .
refreshes the cached test suites list .
refreshes the cached test suites list .
validates that all allowed patterns of mnemonics are added .
intercepts a response with a particular status code and returns the content from a specified url instead .
paste deploy entry point to create a error document wrapper .
deprectated ; use statusbasedforward instead .
test writeconfigfile with chromium checkout and no revision .
test writeconfigfile with chromium checkout and no revision .
test writeconfigfile with chrome checkout and no revision .
test writeconfigfile with chromium checkout at a given git revision .
test writeconfigfile with chrome checkout at a given git revision .
test writeconfigfile with chrome checkout at a given release tag .
test writeconfigfile with chromium checkout at a given release tag .
test writeconfigfile with chrome checkout at a given release tag .
test buildspecusesdepsgit at release thresholds .
test writeconfigfile with chrome checkout with a gclient template .
scan the directory containing the dll |dll_name| to find the next index to use for the profile data files .
run the pgosweep utility to gather the profile data of a given process .
collect the profile data for the current processes .
removes devtools clients that are no longer connectable .
number of color channels in the image .
width of the image .
height of the image .
flat rgb pixel array of the image .
"returns a rgbacolor for the pixel at ( x , y ) ."
write an image to a png file .
create an image from an array of rgb pixels .
create an image from raw png data .
create an image from a png file .
create an image from raw png data encoded in base64 .
"determines whether two images are identical within a given tolerance . setting likely_equal to false enables short - circuit equality testing , which is about 2 - 3x slower for equal images , but can be image height times faster if the images are not equal ."
returns a new image that represents the difference between this image and another image .
finds the minimum box surrounding all occurrences of bgr |color| .
crops the current image down to the specified box .
computes a histogram of the pixel colors in this image . args : ignore_color : an rgbacolor to exclude from the bucket counts . tolerance : a tolerance for the ignore_color .
"convert an integer into its binary representation in a bytes object . width is the amount of bits to generate . if width is larger than the actual amount of bits required to represent number in binary , sign - extension is used . if it 's smaller , the representation is trimmed to width bits . each "" bit "" is either ' \x00 ' or ' \x01 ' . the msbit is first ."
"logical opposite of int_to_bin . both ' 0 ' and ' \x00 ' are considered zero , and both ' 1 ' and ' \x01 ' are considered one . set sign to true to interpret the number as a 2 - s complement signed integer ."
"bits is a b '' object containing a binary representation . assuming each bytesize bits constitute a bytes , perform a endianness byte swap . example :"
create a binary representation of the given b '' object . assume 8 - bit ascii . example :
locical opposite of decode_bin .
test a simple case .
test a case with arguments .
test a case finished with a newline char .
test a case with several spaces in the line .
thes invalid cases .
"tests special files , such as symlinks , directories and named pipes ."
test shebangs ( # ! ) file decoding based on the executed path .
test decoding various pem files .
test decoding elf files .
test decoding compressed files .
test for various binary file formats .
"returns the path to the build directory , relative to the checkout root ."
sets up any environment variables needed to build with the specified build system .
performs any platform - specific setup .
runs a make command with the given targets .
runs a ninja command with the given targets .
runs a command to build the given targets with visual studio .
makes a copy of the current environment variables .
sets up the android build environment .
performs setup for building with target build system .
constructs and returns a builder object .
runs a command to build chrome .
builds chromium_builder_perf target using options passed into the script .
returns a list of build targets .
builds the android content shell and other necessary tools .
returns a list of build targets .
returns true if name1 or name2 are split method forms of the other .
"count the number of misordered symbols , and log them ."
provides a context where stats are uploaded in the background .
initialize the record .
retrieves a dictionary representing the fields that are set .
"construct a stats object , catching any exceptions ."
return true if upload conditions are met .
upload |stats| to |url| .
updates the selected bots internal_only_property .
kicks off update tasks for individual bots and their tests .
start updating internal_only for the given bot and associated data .
updates the given test and associated row entities .
gets a cookie object ( which is a dictionary - like object ) from the request environment ; caches this value in case get_cookies is called again for the same request .
return a * plain * dictionary of cookies as found in the request .
"parses a query string into a list like ` ` [ ( name , value ) ] ` ` . caches this value in case parse_querystring is called again for the same request ."
"parses a query string like parse_querystring , but returns a multidict"
"parses the request , returning a multidict of form variables ."
reconstructs the url from the wsgi environment .
"resolve the given relative url as being relative to the location represented by the environment . this can be used for redirecting to a relative path . note : if url is already absolute , this function will ( intentionally ) have no effect on it ."
"splits off the first segment of the path . returns ( first_part , rest_of_path ) . first_part can be none ( if path_info is empty ) , '' ( if path_info is ' / ' ) , or a name without any / 's . rest_of_path can be '' or a string starting with /."
"' pops ' off the next segment of path_info , pushing it onto script_name , and returning that segment ."
"parse the headers in the environment ( like ` ` http_host ` ` ) and yield a sequence of those ( header_name , value ) tuples ."
monkey patch for fieldstorage.__repr _ _
the browser in which this tab resides .
"returns the url of the tab , as reported by devtools ."
a dictionary populated with measured dom statistics .
brings this tab to the foreground asynchronously .
closes this tab .
true if the browser instance is capable of capturing screenshots .
capture a screenshot of the tab 's contents .
true if the browser instance is capable of capturing video .
synchronously highlights entire tab contents with the given rgbacolor .
clears a highlight of the given bitmap . rgbacolor .
starts capturing video of the tab 's contents .
stops recording video of the tab 's contents .
returns the value of the cookie by the given |name| .
forces a garbage collection .
"clears the browser 's networking related disk , memory and other caches ."
prints an exception in a more useful format than the default .
check that native libs have a common directory and return the directory .
returns the parsed command line arguments in |argv| .
update and unlock topology based on cidb - backed keyval store .
validate that trie_diffs adds 16 bit shld / shrd in 32bit mode .
"dummy password hash , where user password is just reverse"
perform two - stage authentication to verify login
get the list of packages and licenses in a chromeos license file .
compare the package list in 2 dictionaries and output the differences .
compare the license list in 2 sets and output the differences .
check that local binhosts are fetched correctly .
check that remote binhosts are fetched correctly .
check that urls are generated correctly for remote binhosts .
check that urls are generated correctly when uri is defined .
"send an authenticated request to the api . : param method : ' get ' , ' put ' , ' post ' , etc . : param path : the part after "" /api / apollo/ "" , or if it starts with a slash , the whole path after the hostname : param headers : anything besides authorization that may be necessary : param fields : to include in the request , for requests that are not post or head , these will be encoded on the url : param body : for submitting with the request . body type should be string , bytes , list , or dict . for the latter two , they will be encoded as json and the content - type header set to "" application / json "" . : param validate : a function taking one parameter , the response , which can be inspected . the function returns true if the response is valid , false otherwise . : return : response if response.status is in the 200s , fusionerror containing the response otherwise"
initializes credentials flow by way of client.flow_from_clientsecrets and provies the user with a link to follow in a web - browser in order to authrize the appication 's ability to access the users files .
opens pickledcredsfile that contains all of the parameters needed to instantiate a credentials object from the oauth2client.client
fetches correct flow_to_use and builds accordingly .
utilizes the service account credential flow to instantiate an authorized credentials object for calling the google api
get authentication token
"get authentication token it 's the same as the get request , but supports authenticating via saml - response in the body"
verify that the user is allowed to access requested resource .
true if no users other than the admin user exists . : return :
base : site2 is connected_to site1 site2=====>site1
site0 relationships : i | base | modification | comment ------------------------------------------------- 0 . | site1 | site6 | new site ( and removed site1 ) 1 . | site2 | site4 | moved site ( and removed site2 ) 2 . | site3 | site2b | new site 3 . | site4 | site3 | moved site 4 . | site5 | - | remove site5
tests a creation of a deployment from scratch .
run migration command .
downgrade database schema .
upgrade database schema .
get current database schema revision .
parse command line arguments .
configure logging based on command line argument .
parse the plugin spec to a dict of filters for the sql query
get the status of running system services
services the status of which we keep track of .
filter events by timestamp range .
filter events by deployment .
filter events by message pattern .
include only desired fields .
make sure snapshots events appear when using the ' cfy events list ' command
"it might take longer for events to show up in the db than it takes for execution status to return , this method waits until a specific event is listed in the db , and wil fail in case of a time out ."
configure database timezone .
update postgres timezone and create a deployment .
make sure events timestamp field is in utc .
make sure events reported_timestamp field is in utc .
base : site2 is connected_to site1 site2=====>site1
site0 relationships : i | base | modification | comment ------------------------------------------------- 0 . | site1 | site6 | new site ( and removed site1 ) 1 . | site2 | site4 | moved site ( and removed site2 ) 2 . | site3 | site2b | new site 3 . | site4 | site3 | moved site 4 . | site5 | - | remove site5
tests a creatiom of deployment from scratch .
get deployment by i d
create a deployment
delete deployment by i d
get deployment outputs
get / returns a 404 .
builds the rpm
run this script inside a vagrant box where ` mock ` is installed and configured
return a dictionary of macros from ` version_info `
apply the defines to the spec file . we do n't use ` --define ` because ` mock ` 's ` --rpmbuild - opts ` does n't apply to ` --buildsrpm `
run command on vagrant box
get the list of dependencies
check for and install any internal dependencies .
extract lines which contain urls from the spec.dependencies file
allow network access during the build and set the % dist macro ( we have to download packages from pypi )
check the modified time and ask the server if the file has changed
extract rpm ` source * : ` definitions from the spec file so we can download them
"coordinates are flipped from the input format to the ( x , y ) convention here"
hook to do things before the element is rendered . default behavior is to do nothing .
hook to do things after the element is rendered . default behavior is to do nothing
"update with any whitespace we might have missed , and advance position to after the token"
returns true if we 're in a state where a # starts a comment .
returns true if we 're in a state where a { starts python mode .
download a story from a given url
register a footnote and return a link to that footnote
take a string and return a valid filename constructed from the string . uses a whitelist approach : any characters not present in valid_chars are removed . also spaces are replaced with underscores .
add all of the data points for a node
top level interface to create a socket and connect it to the redis daemon .
loop in and read in all the data until we have received it all .
"initialize the simulations database module . this needs to be called before any other function of this module can be used , but after : func:`db.init ` ."
returns a list of all identifiers for which simulation results exist in the database .
add ( or update ) a data point to the database . : param simulation . datapoint point : datapoint instance . .
return a : class:`simulation . datapoint ` object for the given parameters .
test if the minimum distance computation works .
calculate the minimum distance of : attr:`code ` via integer programming .
a callback function for gurobi that is able to terminate the mip solver if a solution which is better than the sent codeword has been found .
calculate the minimum distance of : attr:`code ` via integer programming .
tests : func:`orthogonalcomplement ` by
: param key : name of distributed lock : type key : str : param dbconn : pymongo client connection to mongodb : type dbconn : pymongo db connection : param dbname : name of database ( defaults to ' mongoelector ' ) : type dbname : str : param dbname : name of collection ( defaults to ' mongolocker ' ) : type dbname : str : param ttl : lock will expire ( ttl seconds ) after acquired unless renewed or released : type ttl : int : param timeparanoid : sanity check to ensure local server time matches mongodb server time ( utc ) : type timeparanoid : bool
determine if a retry is appropriate
verify database server 's time matches local machine time
"attempts to acquire the lock , will block and retry indefinitely by default . can be configured not to block , or to have a timeout . you can also force the acquisition if you have a really good reason to do so ."
"returns current status of the lock , but does not indicate if the current instance has ownership or not . ( for that , use ' self.owned ( ) ' ) this is a ' look before you leap ' option . for example , it can be used to ensure that some process is owns the lock and is doing the associated work . obviously this method does not guarantee that the current instance will be successful in obtaining the lock on a subsequent acquire ."
determines if self is the owner of the lock object . this verifies the instance uuid matches the uuid of the lock record in the db .
"returns the current ( valid ) lock object from the database , regardless of which instance it is owned by ."
releases lock if owned by the current instance .
renews lock expiration timestamp
converts datetime objects to iso - compatible strings during json serialization . converts decimal objects to floats during json serialization .
"handle get requests , either for a single resource or a collection ."
handle a get request for a single model instance .
handle a get request for a full collection ( when no i d was provided ) .
handle a post request by adding a new model instance .
handle a put request by editing an existing model .
respond to delete requests by deleting the model and returning its json representation .
serialize a queryset into a json object that can be consumed by backbone.js .
"convert json output to an httpresponse object , with the correct mimetype ."
return an httpresponse indicating that input validation failed .
a ndb tasklet that does urlfetch .
same tasklet but with decorator .
wrapper for callback to hand over custom data
"sends a message to the managers , as defined by the managers setting ."
first the distribution using the given observations .
checks if mass and stats are available from rpy2 .
returns the pdf of the distribution .
returns the cdf of the distribution .
returns the sf of the distribution .
registers aligner under given name .
returns all registered aligners .
external dependencies required by aligner .
checks if all required external dependencies are in ` ` $ path ` ` .
configures an argument parser for the indexer .
parses arguments from argparse into a dict .
constructs an indexer instance from given arguments .
identifies insertions from given reads .
example kws for tophat2_align .
tests example call .
tests example call .
tests example call with paired - end data .
tests example call with extra arguments .
main function .
parses command line arguments .
wrapper function for check_call .
"yield dicts that correspond to aggregates of the flow records given by the sequence of flowrecords in ` all_records ` . skips incomplete records . this will consume the ` all_records ` iterator , and requires enough memory to be able to read it entirely . ` key_fields ` optionally contains the fields over which to aggregate . by default it 's the typical flow 5 - tuple ."
dispatches reqs that fire off automatically when the minion starts
finds appropriate reactions to a pub message and dispatches them
dispatches reactions in response to typical functions
dispatches a reaction to a find_job call
dispatches a reaction to a running call
run the unit tests .
inside recursion . : param forest : an acyclic hypergraph . : param topsort : a partial ordering of the nodes in the forest . : param omega : a function that computes the weight of an edge ( defaults to the edge 's own log probability ) : return : a dictionary mapping a symbol to its inside weight .
override to add javascript only when adding an object .
decorator for tasks that activates the language passed to it .
remove various accumulating data from the core app .
add clients_url and faq_url to the context if clients_page / faq_page settings are defined .
return database name if it exists or raise exception .
convert nodal displacements to polar form .
get coordinates of nodes in scaled deformed configuration .
return a list of spoke tensions .
"return a list of rim stresses , specified by comp . '"
plot the exaggerated deformed wheel shape .
plot the spoke tensions on a polar plot .
"the validationreport should contain an id of the root node that was validated in the graph . for example , if the input was the url of an assertion , that url ( the assertion['id ' ] would appear ."
"the validationreport reports which version of the open badges spec the validationsubject was found to be in . prop : "" openbadgesversion """
"the validationreport contains the properties of messages , warningcount , errorcount , valid : return :"
partition generator for stratified cross validation for classification problems .
partition generator for random sub - sampling validation for classification problems .
partition generator for leave - one - out cross validation for classification problems .
partition generator for stratified cross validation for regression problems .
partition generator for random sub - sampling validation for regression problems .
construct a new configuration panel for a replay signal source .
initialize the sample rate and poll size controls .
construct a new source for replaying eeg saved to file .
set things up for starting the source .
poll for new data . this method sleeps in order to ensure that self.pollsize observations are generated at a realistic rate .
initialize configuration values .
initialize a new bmuplot widgets for eeg and marker .
draw the bmu plot .
returns the path values associated with |variable| and relative to the |cmake_path| directory .
"reads the |input| template , parses variable substitution sections and writes |output| ."
read the |source| gypi file and extract the variables section .
"constructor . defines the "" --what "" option of a script ."
called by coverage to initialize the plugins here .
trace only files named xyz.py
claim that * /*xyz.py was actually sourced from /src/*abc.zz
"map the line number x to x05,x06,x07 ."
enable deprecationwarnings during all tests .
first of the chain of functions for testing ` short_stack ` .
second of the chain of functions for testing ` short_stack ` .
third of the chain of functions for testing ` short_stack ` .
"runs some code with ` debug ` option , returns the debug output ."
"a no - op function to stub out run , copy , etc , when only cleaning ."
copy a directory .
run a list of commands .
compare files matching ` file_pattern ` in ` dir1 ` and ` dir2 ` .
check that the file contains all of a list of strings .
check that the file contains at least one of a list of strings .
check that the file contains none of a list of strings .
clean ` cleandir ` by removing it and all its children completely .
skip the current test .
filter the list of ` files ` to only those that match ` file_pattern ` .
scrub uninteresting data from the payload in ` strdata ` .
command - line access to farm tests .
create a test case from a run.py file .
"test set up , run by the test runner before _ _ call _ _ ."
"test tear down , run by the test runner after _ _ call _ _ ."
"here to make unittest . testcase happy , but will never be invoked ."
execute the test from the run.py file .
"run as a full test case , with setup and teardown ."
make the url people should start at for this version of coverage.py .
replace a code object 's line number information to claim that every byte of the bytecode is a new source line . returns a new code object . also recurses to hack the line numbers in nested code objects .
requests for non - existent articles should get 404
message handler which counts hits against all arbitration ids
"adds a can message handler which should add found data to found_arb_ids . prints all of these afterwards , sorted by the number of hits ."
argument parser for the listener module .
listener module main wrapper .
"update gemini to the latest release , along with associated data files ."
update test directory to be in sync with a tagged installed version or development .
link tools installed via conda into the tool directory .
perform a soft link of the original file into the final location .
return a map of sample name to reported sex
return the starting and ending variant i d for a given chromosome
test to see if the number and type of genotype calls on the x chromosome make sense given the sex of the individual that is stated in the samples table ( ped ) .
"attempt to add new , user - defined columns to the variants table . warn if the column already exists ."
generalized annotation of variants with a new column .
"populate a new , user - defined column in the variants table with a boolean indicating whether or not overlaps were detected between the variant and the annotation file ."
"populate a new , user - defined column in the variants table with a integer indicating the count of overlaps between the variant and the annotation file ."
"populate a new , user - defined column in the variants table based on the value(s ) from a specific column . in the annotation file ."
prune the current run of genotypes .
sweep through the genotypes for each sample in search of rohs .
pause program execution until delay ( in seconds ) has expired .
"since baserunservercommand is only run once , we need to call model valdidation here to ensure it is run every time the code changes ."
returns a service object for use with drive api queries based on the contents of ~/.credentials/
get a dictionary of filenames : file_ids from the authenticated drive account . can filter with search string . returns / searches through most recent 250 files by default .
is python running in interactive
gets valid user credentials from storage .
gets comments from the api for the file_ids .
"strips whitespace for all individual strings in a list parameters : input_list , a list of strings returns : output_list , a list of strings"
"helper function to parse a single code and quoted text to support the hierarchical index . used by json_to_df ( ) , not usually called directly by users ."
converts a dictionary of json responses from the api to a pandas dataframe with a hierarchical index .
process dataframes to return of lists of codes by level
counts the number of unique concatenations of codes in levels .
a convience method for executing all the commands .
gather the required variables for the install .
build kubernetes from a github repository using the makefile .
install kubernetes binary files from the output directory .
retry decorator original from http://wiki.python.org/moin/pythondecoratorlibrary#retry
this function returns the predicted integer . the imput is the pixel values from the imageprepare ( ) function .
this function returns the pixel values . the imput is a png file location .
main function .
return a list of properties to be removed from the event
create a new graphalgorithm
create a sub graph of all the matching vertices and their edges
search for occurrences of a template graph in the graph
return the subgraph induced on nodes in entities .
generate connected components as subgraphs .
generate all simple paths in the graph g from source to target .
generate graph using the query
decides which action to run on given event
adds new vertex to the entity graph
updates the vertex in the entity graph
deletes the vertex from the entity graph
removes the deleted vertex from the entity graph
updates vertices neighbor connections
updates the neighbor vertex and adds the connection edges
"deletes the "" vertex "" old connections"
"finds "" vertex "" valid and old connections"
a builder to create a vertex
a builder to create an edge
checks if the contents of data[key ] matches the given regex
train the model
return the probability of a given list of wixarika morphemes
returns the most probable segmentation option of a list
train the model
return the probability of a given list of wixarika morphemes
returns the most probable segmentation option of a list
the mandatory cobbler module registration hook .
module identification function
save a collection item to database
delete a collection item from database
save a collection to database
load a collection from database
return a distro forged from item_dict
remove element named ' name ' from the collection
return a package forged from item_dict
remove element named ' name ' from the collection
genders file is over - written when manage_genders is set in /var / lib / cobbler / settings .
return a file forged from item_dict
remove element named ' name ' from the collection
"draw the gis coastline data from the state of hawaii to draw the land boundaries . this does not include rivers , etc . , only the coastline ."
compute freezing temperature of sea water
compute velocity of sound
compute depth from pressure and latitude
need explicit string cast to avoid quotes .
"before encryption , need to prepare values ."
configure the mesos metrics collector options : host : ip of target mesos host port : port of target mesos host trackingname : vanity host name to use for master tracking separator : separator character for mesos metric names configfile : metric configuration file
saves the message for the recipient and looks in the form instance for other possible recipients . prevents duplication by excludin the original recipient from the list of optional recipients .
"sends an email update when needed . we will send for each user only one update email each time , with all the the user update info . updates will be sent in periods ."
"given an array of arrays of objects , each object having field with a date to be checked , returns if it 's needed to send an email ."
parses the incoming bytestream as json and returns the resulting data .
finds the expected install path for the so / dll .
get a single primary ip address . this will not return all ips in the interface . see http://stackoverflow.com/a/28950776/671626 : return : integer with the ip of the user .
ingress needs to be restarted for old paths to be removed at startup . : param minikube : executable minikube installed beforehand .
loads a ingress yaml file into a python object .
loads a replication controller yaml file into a python object .
starts the cluster unless it has been already started by the user . : param minikube : executable minikube installed beforehand .
creates a docker client using the python sdk . : param raw_env_settings : string that is returned by the ' minikube docker - env ' command . : return :
check if the vm driver is enabled or not . this is important to see where the environment variables live . : param raw_env_settings : string that is returned by the ' minikube docker - env ' command . : return : boolean value indicating if enabled or not .
finds environment settings and builds docker images for each directory . : param minikube : executable command to run in terminal .
disables all the components running in the cluster and starts them again with fresh updated state . : param game_creator_yaml : replication controller yaml settings file . : param ingress_yaml : ingress yaml settings file .
the entry point to the minikube class . sends calls appropriately to set up minikube .
a csrf cookie token is required in order to not get a 403 forbidden response by the post to the inputs . : return : string representing the token .
a integration test utility to create a browser session request for a single test . : return : a session object for requests .
attempts to send a get to the url . server is already up as the test should be calling the ` is_server_healthy ( ) ` function before calling this .
attempts to send a post to the url . server is already up as the test should be calling the ` is_server_healthy ( ) ` function before calling this .
"function will only return true when the param url returns a 2xx code . after 45 seconds , the check assumes a timeout . : param url : http url for the address to poll . : return : boolean value to indicate result ."
a private wrapper function for all the utilities that will log a user in with the correct credentials and take care of all csrf token exchange .
"sends an appropriate post request to create a game with a given name , using default settings provided ."
mock that returns decidedly un - random alphanumeric bytes
extract the persistent pinnings from a cookie .
return the union of the preexisting pinned set -- socked away on the request -- with any newly set pins .
pin db sets according to data in an incoming cookie .
set outgoing cookie to persist preexisting and new pinnings .
@brief get number of recorded frames
@brief initialize recording by adapting the video to the first frame input .
"@brief start video recording creates a folder for the video , called by the same video filename , and creates a subfolder for storing each frame ."
@brief write frame in thread for smoother program flow .
@brief write new frame to output video
@stop video recording
@brief give all setups to the unit test .
@brief give all tear down steps . is runned even if the test failed .
@brief get configured settings with correct input images / videos
@brief test unit for the image link
"send the request via udp , with retries using exponential backoff"
send the request packet via tcp
"send the request packet via tcp , using select"
send the request packet using dns over tls
"axfr uses tcp , and is answered by a sequence of response messages ."
parse config file and find source dir in it
return the list of files to be decompiled
return successive entries from an iterable as long as the predicate evaluates to true for each entry .
"yield iterables for successive slices of ` iterable ` , each containing up to ` size ` items , with the last being less than ` size ` if there are not sufficient items in ` iterable ` . pass over the input iterable once only . yield iterables , not lists ."
"given an iterable i , apply f over it to extract a value from each element and yield successive iterables where the result of f for all elements is the same ."
5.7 crc checksum using teh polynomial given in the datasheet
this function reads the first two bytes of data and returns the temperature in c by using the following function : t = = 46.82 + ( 172.72 * ( st/2 ^ 16 ) ) where st is the value from the sensor
this function reads the first two bytes of data and returns the relative humidity in percent by using the following function : rh = -6 + ( 125 * ( srh / 2 ^16 ) ) where srh is the value read from the sensor
resets the sht12 .
reads the temperature from the sensor . this call blocks for 250ms to allow the sensor to return the data .
reads the humidity from the sensor . this call blocks for 250ms to allow the sensor to return the data
add an ` mac access authentication ` _ signature to headers .
"add a ` bearer token ` _ to the request uri . not recommended , use only if client ca n't use authorization header or body ."
add a ` bearer token ` _ to the request uri . recommended method of passing bearer tokens .
add a ` bearer token ` _ to the request body .
return true or false depending on whether the ` ` path ` ` should be ignored ( if it matches any pattern in ` ` ignore_patterns ` ` ) .
recursively walk the storage directories yielding the paths of all files that should be copied .
checks if the staticfiles settings have sane values .
ensures we have a connection to the email server . returns whether or not a new connection was required ( true or false ) .
closes the connection to the email server .
sends one or more emailmessage objects and returns the number of email messages sent .
a helper method that does the actual sending .
turn all nested sequences to tuples in given sequence .
converts all keys in dictionary to str type .
checks if the path should be handled . ignores the path if :
returns the relative path to the media file on disk for the given url .
actually serves the request path .
looks for files in the extra locations as defined in ` ` static_root ` ` .
looks for files under $ splunk_home / share / splunk / search_mrsparkle / exposed
"constructs a new node . if no connector is given , the default will be used ."
"this is called to create a new instance of this class when we need new nodes ( or subclasses ) in the internal code in this class . normally , it just shadows _ _ init _ _ ( ) . however , subclasses with an _ _ init _ _ signature that is not an extension of node.__init _ _ might need to implement this method to allow a node to create a new instance of them ( if they have any extra setting up to do ) ."
utility method used by copy.deepcopy ( ) .
the size of a node if the number of children it has .
for truth value testing .
returns true is ' other ' is a direct child of this instance .
"adds a new node to the tree . if the conn_type is the same as the root 's current connector type , the node is added to the first level . otherwise , the whole tree is pushed down one level and a new root connector is created , connecting the existing tree and the new node ."
negate the sense of the root connector . this reorganises the children so that the current node has a single child : a negated node containing all the previous children . this slightly odd construction makes adding new children behave more intuitively .
sets up internal state so that new nodes are added to a subtree of the current node . the conn_type specifies how the sub - tree is joined to the existing children .
closes off the most recently unmatched start_subtree ( ) call .
helper function to return a url pattern for serving files in debug mode .
create a new httptlsconnection .
"an instrumented template render method , providing a signal that can be intercepted by the test system client"
perform any global pre - test setup . this involves :
perform any global post - test teardown . this involves :
returns an object containing the state of the warnings module
restores the state of the warnings module when passed an object that was returned by get_warnings_state ( )
changes django to only find templates from within a dictionary ( where each key is the template name and each value is the corresponding template content to return ) .
restores the original template loaders after : meth:`setup_test_template_loader ` has been run .
"tries to do a ' xml - comparison ' of want and got . plain string comparison does n't always work because , for example , attribute ordering should not be important . comment nodes are not considered in the comparison ."
strip quotes of doctests output values :
a minimal generic sitemap can be rendered
"given a datasource , generates a dictionary that may be used for invoking the layermapping utility ."
given a data source ( either a string or a datasource object ) and a string model name this function will generate a geodjango model .
helper routine for ` ogrinspect ` that generates geodjango models corresponding to the given data source . see the ` ogrinspect ` docstring for more details .
ensure that we can make a token and that it is valid
ensure that the token generated for a user created in the same request will work correctly .
"ensure we can use the token after n days , but no greater ."
"make sure we do n't allow overly long dates , causing a potential dos."
"a flatpage can be served through a view , even when the middleware is in use"
"a non - existent flatpage raises 404 when served through a view , even when the middleware is in use"
a flatpage served through a view can require authentication
a flatpage can be served by the fallback middlware
a non - existent flatpage raises a 404 when served by the fallback middlware
a flatpage served by the middleware can require authentication
a flatpage with special chars in the url can be served by the fallback middleware
a flatpage can be served through a view and should add a slash
a non - existent flatpage raises 404 when served through a view and should not add a slash
a flatpage can be served by the fallback middlware and should add a slash
a non - existent flatpage raises a 404 when served by the fallback middlware and should not add a slash
a flatpage with special chars in the url can be served by the fallback middleware and should add a slash
a flatpage at / should not cause a redirect loop when append_slash is set
"helper function that returns a dictionary of all fields in the given model . if self.field_filter is set , it only includes the fields that match the filter ."
check that login_required is assignable to callable objects .
check that login_required is assignable to normal views .
check that login_required works on a simple view wrapped in a login_required decorator .
check that login_required works on a simple view wrapped in a login_required decorator with a login_url set .
ensures that displaying content types in admin ( or anywhere ) does n't break on leftover content type records in the db for which no model is defined anymore .
redirect messages to the dummy outbox
"if the request method is head and either the ip is internal or the user is a logged - in staff member , quickly return with an x - header indicating the view function . this is used by the documentation module to lookup the view function for an arbitrary page ."
"returns ` true ` if the ` localeregexurlresolver ` is used at root level of the urlpatterns , else it returns ` false ` ."
testing envelope initilization .
testing envelope properties .
testing envelope equivalence .
testing envelope expand_to_include -- point as two parameters .
testing envelope expand_to_include -- point as a single 2 - tuple parameter .
testing envelope expand_to_include -- extent as 4 parameters .
testing envelope expand_to_include -- extent as a single 4 - tuple parameter .
testing envelope expand_to_include with envelope as parameter .
testing envelope expand_to_include with point as parameter .
displays the login form and handles the login action .
logs out the user and displays ' you are logged out ' message .
removes the current session data from the database and regenerates the key .
returns true if the given session_key already exists .
creates a new session instance . guaranteed to create a new object with a unique key and will have saved the result once ( with empty data ) before the method returns .
"saves the session data . if ' must_create ' is true , a new session object is created ( otherwise a createerror exception is raised ) . otherwise , save ( ) can update an existing object with the same key ."
"deletes the session data under this key . if the key is none , the current session key value is used ."
loads the session data and returns a dictionary .
remove expired sessions from the session store .
helper function to parse the backend configuration that does n't use the uri notation .
function to load a cache backend dynamically . this is flexible by design to allow different use cases :
public interface to the flat page view .
add a global application argument .
set global defaults .
decorator to create a command line subcommand for a function .
decorator to specify a command line argument for a subcommand .
decorator to specify defaults for a subcommand .
run the application .
"this function takes a gdal spatialreference system and adds its information to the ` spatial_ref_sys ` table of the spatial backend . doing this enables database - level spatial transformations for the backend . thus , this utility is useful for adding spatial reference systems not included by default with the backend -- for example , the so - called "" google maps mercator projection "" is excluded in postgis 1.3 and below , and the following adds it to the ` spatial_ref_sys ` table :"
add various fields used by the splunk django bindings .
convert a cmp= function into a key= function
return a suite of all tests cases contained in testcaseclass
return a suite of all tests cases contained in the given module
return a suite of all tests cases given a string specifier .
return a suite of all tests cases found using the given sequence of string specifiers . see ' loadtestsfromname ( ) ' .
return a sorted sequence of method names found within testcaseclass
"find and return all test modules from the specified start directory , recursing into subdirectories to find them . only test files that match the pattern will be loaded . ( using shell style pattern matching . )"
used by discovery . yields test suites it loads .
serve static files below a given point in the directory structure .
figures out the correct ogr type based upon the input .
returns the value of the name property .
"does an equivalence test on the ogr type with the given other ogrgeomtype , the short - hand string , or the integer ."
returns a short - hand string form of the ogr geometry type .
returns the django geometryfield for this ogr type .
"gets a number ( as a number or string ) , and returns it as a string , using formats defined as arguments :"
returns the name of the metadata column used to store the the feature table name .
returns the name of the metadata column used to store the the feature geometry column .
callback for ` make_option ` for the ` ogrinspect ` ` layer_key ` keyword option which may be an integer or a string .
callback for ` make_option ` for ` ogrinspect ` keywords that require a string list . if the string is ' true'/'true ' then the option value will be a boolean instead .
returns the http request 's path_info as a unicode string .
"returns the equivalent of the http request 's script_name environment variable . if apache mod_rewrite has been used , returns what would have been the script name prior to any rewriting ( so it 's the script name as seen from the client 's perspective ) , unless the force_script_name setting is set ( to anything ) ."
populate middleware lists from settings . middleware_classes .
returns an httpresponse object for the given httprequest
processing for any otherwise uncaught exceptions ( those that will generate http 500 responses ) . can be overridden by subclasses who want customised 500 handling .
"applies each of the functions in self.response_fixes to the request and response , modifying the response in the process . returns the new response ."
testing ` count ` aggregate with ` .values ( ) ` . see # 15305 .
function implements a linear feedback shift register taps : list of polynomial exponents for non - zero terms other than 1 and n buf : list of buffer initialisation values as 1 's and 0 's or booleans
generate a maximal length sequence 2^n - 1 bits long
"get the load average for a unix - like system . for more details , "" man proc "" and "" man uptime """
make the client go go go
wrap it all up together
make the client go go go
wrap it all up together
test case for https://github.com/graphite-project/carbon/pull/120
persist datapoints in the database for metric .
"return true if the given metric path exists , false otherwise ."
create an entry in the database for metric using options .
lookup metric metadata .
modify metric metadata .
"return filesystem path for metric , defaults to none ."
validate that the database can handle the given archivelist .
"saves the json object [ obj ] to [ fn ] , creating all necessary directories in the process . if [ dirs ] is given , the function is executed for every root directory in the array ."
return default platform specific shared objects folder .
"get list of applications , containing one or more .sol files , sorted by domain ."
read and return shared object .
return files that match to file extension(s ) .
return each sub - directory .
ensure that any system entities fail by default
ensure that any xml params that are decdoed into system entities fail .
any dtd urls must fail by default .
converts an arbitrary object c{obj } to a c{list } .
converts an arbitrary object c{obj } to a c{dict } .
converts an arbitrary object c{obj } to a c{set } .
converts an arbitrary object c{obj } to a c{tuple } .
converts an arbitrary object c{obj } to a string .
converts an arbitrary object c{obj } to a byte string .
called when an instance of u{decimal . decimal < http:// docs.python.org/library/decimal.html#decimal-objects > } is about to be encoded to an amf stream .
"args : lattice : lattice parameters in the form of [ [ a_x , a_y , a_z ] , [ b_x , b_y , b_z ] , [ c_x , c_y , c_z ] ] returns : metric tensor : [ [ a.a , a.b , a.c ] , [ b.a , b.b , b.c ] , [ c.a , c.b , c.c ] ]"
import a csv file containing countries .
should not be able to update with an anonymous user .
you should be able to update with an anonymous user .
should not allow another user to change a school 's data
this should allow a superuser to change school data .
anonymous users can not delete a school .
advisors can delete their school .
a user can not delete another user 's school .
a superuser can delete a school .
it should reject an anonymous user .
it should reject a request from an unauthorized user .
it should reject a request from a superuser .
"field is used to represent an intermediary field , e.g. assignment , to check the delegate against ."
"it should correctly authenticate and return a user , or return an error message ."
it should correctly change a user 's password or raise an error .
it should correctly reset a user 's password or raise an error .
it should correctly reset a delegate 's password or raise an error .
a general purpose interpolation routine for transforming between two different latitude - pressure level grids .
"compute changes in toa flux using radiative kernels . inputs are xarray dataset handles for model climatology files , and another dataset for the kernels ."
compute climate feedbacks with respect to local surface temperature using radiative kernels . inputs are netcdf4 dataset handles for model climatology files .
compute climate feedbacks with respect to global mean surface temperature using radiative kernels . inputs are netcdf4 dataset handles for model climatology files .
set value in the dictionary
get value from the dictionary
simulate the dijkstra algorithm in a graph
: type producer : kafka.producer . producer : type topic : str or unicode
overriden method to process the item
: param settings : the current scrapy settings : type settings : scrapy.settings . settings
define the variables required to declare a new video .
downloads the file of the url defined within the class instance .
implementation of actually download process
a cleaner representation of the class instance .
define the variables required to declare a new video .
sanitizes filenames for many operating systems .
"takes the size of file or folder in bytes and returns size formatted in kb , mb , gb , tb or pb ."
this function - when passed as ` on_progress ` to ` video.download ` - prints out the current download progress .
"tb , if given , is the original traceback ( so that it can be printed out ) . if expected is set , this is a normal error message and most likely not a bug in youtube - dl ."
helper for quickly adding a streamhandler to the logger . useful for debugging .
"make a request using : meth:`urlopen ` with the ` ` fields ` ` encoded in the body . this is useful for request methods like post , put , patch , etc ."
adds hierarchical monitoring links of the form < domain>/<host>/<guest >
the docker image name for the building container
the docker image name for the building container
the magic command line option to separate in a docker run the outside and inside commands
this script folder extraction
the build folder where travis builds in ( or all setup.py --all builds )
run a docker image
run the build docker image
run the build docker image
main function supporting all commands
main logic to call functions
destroy a server and it 's storages .
destroy a tag ( only works if the tag is not in use ) .
"makes a fault - and - striae plot ( a.k.a . "" ball of string "" ) for normal faults with the given strikes , dips , and rakes ."
"makes a tangent lineation plot for normal faults with the given strikes , dips , and rakes ."
read data from a text file on disk .
initialize a job .
check if job is high priority .
define if one job is higher priority than the other .
define if these are the same type of jobs .
create an object holding the built - in flags of a compiler .
the built - in defines provided by the compiler .
the list of built - in include paths used by the compiler .
the list of built - in flags .
the detected compiler .
the detected standard to use .
the detected target language .
try to guess the language based on the compiler .
singleton class wrapper .
clear all existing caches .
test retrieval of built ins when we are uncertain about the language .
test retrieval of flags for a c compiler .
test retrieval of flags for a c++ compiler .
test retrieval of flags for an objective - c compiler .
test retrieval of flags for an objective - c++ compiler .
test initialization .
test appending single values to unique list .
test clearing the list .
test iterating over values .
test merging with other iterable .
initialize default flags storage .
get flags for a view path [ abstract ] .
parse the flags from given chunks produced by separating string .
get cached path for file path .
find current path in a search scope .
function to connect to peeringdb and fetch results for a given asn
"ensure args and kwargs passed , are passed onto _ insert_tasks as expected ."
"ensure if ` duplicatetasknameerror ` raised , that each task is retried ."
"ensure if ` duplicatetasknameerror ` raised , that each task is retried , and count is correct if some tasks could be re - inserted ."
ensure only tasks that were not enqueued on the initial bulkadd ( ) are re - inserted .
setup the environment for a furious context .
cleanup our environment modifications .
ensure clear_context successfully clears attributes set during initialization from the local context .
initialize the list of stats .
initialize a : class:`discretelatentmodel `
natural parameters of the components as a matrix .
sufficient statistics of the latent model .
per components expected log - likelihood .
natural gradient update .
sum of kl divergence between posteriors / priors .
called after each update of the parameters .
compute the posterior distribution of the latent variables .
generator that yields all valid itemsets of size two where each combo is as a stripe .
"just like a list , except the append method adds the new value to the list only if it is larger than the smallest value ( or if the size of the list is less than max_size ) . if each element of the list is an int or float , uses that value for comparison . if the first element is a list or tuple , uses the first element of the list or tuple for the comparison ."
"just like a list , except the append method adds the new value to the list only if it is larger than the smallest value ( or if the size of the list is less than max_size ) ."
album art can be fetched with tinytag
` ` true ` ` if the database is unversioned or if its version is less then the maximum defined .
` true ` if any missing updates require user consent .
return an iterable of string prompts for updates that require user consent .
update database schema to the highest possible version .
delete all content from the database along with supporting structures .
"create a new , empty counter object . and if given , count elements from an input iterable . or , initialize the count from another mapping of elements to their counts ."
"list the n most common elements and their counts from the most common to the least . if n is none , then list all element counts ."
iterator over elements repeating each as many times as its count .
like dict.update ( ) but add counts instead of replacing them .
like dict.copy ( ) but returns a counter instance instead of a dict .
like dict.__delitem _ _ ( ) but does not raise keyerror for missing values .
add counts from two counters .
"subtract count , but keep only results with positive counts ."
union is the maximum of value in either of the input counters .
intersection is the minimum of corresponding counts .
"migrate if necessary , exit(1 ) on error"
"migrate into different dir and then swap it in , to mitigate mishaps"
decode old albumart base64 encoding ; copied code from pathprovider
if no permission raise httpresponseexception
returns the keyword arguments for instantiating the form .
gets the current anti - aliasing mode for map graphics .
sets the anti - aliasing mode for map graphics .
gets a boolean indicating whether or not displaying related information in identify results is enabled .
gets a boolean value indicating whether or not dynamic layer order and symbology are enabled .
gets a boolean value indicating whether or not dynamic layer order and symbology are enabled .
gets the properties for the feature server ( feature access in web ui ) extension .
gets the name of the folder that the service will reside in .
sets the name of the folder that the service will reside in .
gets the properties for the kml server extension .
gets the properties for the mobile ( mobile data access in the ui ) server extension .
gets the properties for the network analysis server extension
gets the name of the service .
sets the name of the service ( can not be an empty value ) .
gets a boolean indicating whether or not the server locks the database schema .
sets a boolean indicating whether or not the server locks the database schema .
gets the properties for the schematics server extension .
gets the current anti - aliasing mode for map text .
sets the anti - aliasing mode for map graphics .
gets the properties for the wcs server extension .
gets the properties for the wfs server extension .
gets the properties for the wms server extension .
sets the value for properties that are dependent on both the folder name and the service name .
gets or sets a list of capabilities ( as defined by the self . capabilities enumerator ) that are enabled for this extension .
gets or sets the wfs namespace prefix that is used by the wfs getfeaturerequest request .
gets or sets a the axis order for the wfs service when using the 1.0 api .
gets or sets a the axis order for the wfs service when using the 1.1 api .
no capabilities are supported for wfsserverextension . returns none .
gets or sets instructions for appropriately contacting the organization and/or named person responsible for the service .
gets or sets a value indicating whether or not layer names are inherited .
gets or sets the wfs namespace prefix that is used by the wfs getfeaturerequest request .
gets or sets a url to the provider 's website .
"gets or sets the service type for the service , e.g. ' wfs ' ."
"gets or sets the service type version for the service , e.g. ' 1.1.0 ' ."
"by default , a running pipegraph chatters to localhost:5005 via tcp ( use utils / log_listener.py to listen ) . if you want it to log to another port , use this function before createing the graph ."
check if a file exists and its size is > 0
makes certain there is only one object with this class & .name .
detects the number of cpus on a system . cribbed from pp .
"args : init_func ( s -- > { 0,1 } ) init_func ( s -- > { 0,1 } ) policy ( s -- > a )"
summary : executes the option until termination .
summary : executes the option until termination .
args : action ( str )
"args : mdp ( mdp ) delta ( float ): after an iteration if vi , if no change more than @\delta has occurred , terminates . max_iterations ( int ): hard limit for number of iterations . sample_rate ( int ): determines how many samples from @mdp to take to estimate t(s ' | s , a ) . horizon ( int ): number of steps before terminating ."
args : s ( state )
args : s ( state ) a ( str ): action
"summary : starting with @self.start_state , determines all reachable states and stores them in self.states ."
summary : runs valueiteration and fills in the self.value_func .
args : state ( state ) horizon ( int )
args : state ( state )
args : state ( state )
args : state ( state )
args : state ( state )
"args : subagentclass ( simple_rl . agentclass ) actions ( list of str ) agent_params ( dict ): a dictionary with key = param_name , val = param_value , to be given to the constructor for the instance of @subagentclass . state_abstr ( stateabstraction ) state_abstr ( actionabstraction ) name_ext ( str )"
args : ground_state ( state ) reward ( float )
args : mdp ( mdp ) state_abstr ( stateabstraction ) action_abstr ( actionabstraction ) step_cost ( float ): cost for a step in the lower mdp . sample_rate ( int ): sample rate for computing the abstract r and t.
args : mdp_distr ( mdpdistribution ) state_abstr ( stateabstraction ) action_abstr ( actionabstraction )
args : mdp ( mdp ) state_abstr_stack ( stateabstractionstack ) action_abstr_stack ( actionabstractionstack ) step_cost ( float ): cost for a step in the lower mdp . sample_rate ( int ): sample rate for computing the abstract r and t.
args : mdp_distr ( mdpdistribution ) state_abstr ( stateabstraction ) action_abstr ( actionabstraction )
returns a normal : class:`tsocket ` instance .
returns a normal : class:`tframedtransport ` instance wrapping ` tsocket ` .
a convenience function for creating an ssl socket factory .
a convenience function for creating a sasl transport factory .
decorator to require an order - preserving partitioner
"decorator for : class:`~slimta.edge.smtp . smtpvalidators ` methods that are given a |reply| object . it will check the current smtp session 's connecting ip address against the dnsbl provided at domain name ` ` address ` ` . if the ip matches , set the reply and do not call the validator method ."
"checks this dnsbl for the given ip address . this method does not check the answer , only that the response was not ` ` nxdomain ` ` ."
"gets the txt record for the ip address on this dnsbl . this is usually a reason for why the ip address matched . as such , this function should only be called after : meth:`.get ( ) ` returns ` ` true ` ` ."
adds a dnsbl domain name to the list of dnsbls to check .
queries all dnsbls in the group for matches .
gets the reasons for each matching dnsbl for the ip address .
"this method may be over - ridden by sub - classes if you need to control how the relay error is generated . by default , the error raised is a : class:`~slimta.relay . transientrelayerror ` unless the process output begins with a ` ` 5.x.x ` ` enhanced status code . this behavior attempts to mimic the postfix pipe _ daemon ."
"creates a : class:`ptrlookup ` object based on the ip address of the socket 's remote address , using : py : meth:`~socket.socket.getpeername ` ."
"creates a : class:`ptrlookup ` object based on the ip address of the socket 's local address , using : py : meth:`~socket.socket.getsockname ` ."
starts the ptr lookup thread .
"attempts to get the results of the ptr lookup . if the results are not available , ` ` none ` ` is returned instead ."
run the domain and iterate over the result .
action : collect all elements into list .
action : find maximal elements in the pipeline .
action : group elements by keys
action : group elements by keys and return elements and counts
action : apply a function to reduce stream to a single value ( left fold )
transformation : take a first n elements from the pipeline .
action : take the first element from the pipeline
run the pipeline
transformation : filter elements from the pipeline
transformation : map function on each elements in the pipeline
accept a name or actual class object for a class in the current module . return a class object .
return a membership object for the user whose credentials were used to connect .
replace the first entries in a deque of strings with a single string of up to size bytes .
returns true if the socket has been closed .
read a number of bytes .
write the given data to this socket .
remove deactivated handlers from the chain
returns a callable object that will restore the current ` stackcontext ` when executed .
run a coroutine ` ` func ` ` in the given ` stackcontext ` .
initialze the predictions and indexes
run partial prediction by executing one cascade stage
run prediction using the cascade .
learn one ranker with sgd and l1 regularization .
train a cascade over a partition of disjoint feature sets .
train a cascade accoring to the algorithm in wang et al . ( 2011 )
run prediction with a saved cascade
runs some basic verification before calling super(qdialog).accept ( ) .
called when a recent item is selected
allow the user to create a new project
allow the user to browse for a project directory and load .
"ingests a json file specified by path , containing project_name : project_directory mappings and returns dict of valid projects ( conducting path checking and conversion to pathlib . path ) parameters ---------- path : path path object referencing json object containing mappings of recent projects - > project directories"
"take a dictionary of recent projects ( project_name : project_dir ) and write it out to a json formatted file specified by path parameters ---------- recent_files : dict[str , path ]"
interpolate i.e. up sample a give 1d vector by interpolation factor
"finds the time shift or delay between two signals if s1 is advanced to s2 , then the delay is positive ."
"synchronize and join a gravity and gps dataframe ( df ) into a single time shifted df . time lag / shift is found using the find_time_delay function , which cross correlates the gravity channel with eotvos corrections . the dfs ( gravity and gps ) are then upsampled to a 1ms period using cubic interpolation . the gravity dataframe is then shifted by the time shift factor returned by find_time_delay at ms precision . we then join the gps df on the gravity df using a left join resulting in a single df with gravity and gps data at 1ms frequency . finally the joined df is downsampled back to the original frequency 1/10hz"
"returns a series of ( x , y ) points from an svg fragment"
"returns the ( x , y ) center point of a drawingview object"
"returns the ( x , y ) dimensions of a page"
capture stdout to a file if provided
generate roles_data.yaml from imputed roles
node registration or update
node registration or update
provide baremetal nodes
introspect baremetal nodes
introspect all manageable nodes
provide all manageable nodes
configure node boot options .
configure all manageable nodes .
create raid configuration on nodes .
discover nodes .
clean baremetal nodes
clean all manageable nodes
sort oslo config options by name
test handling a processingerror exception in a mapper .
test handling a processingerror exception in a mapper .
asserts that a non - critical error is routed to the error stream .
"put records at the input , then read them from the output ."
put and read a record from the input stream .
put records in the input kinesis stream .
retrieve records from the output kinesis stream .
empty the bucket associated to the test deployment .
@param resolver : a schema object name resolver . @type resolver : l{resolver . resolver }
build a an object for the specified typename as defined in the schema
process the specified type then process its children
add required attributes
get whether or not to skip the specified child
get the ordering
"cast the i{untyped } list items found in content i{value } . each items contained in the list is checked for xsd type information . items ( values ) that are i{untyped } , are replaced with suds objects and type i{metadata } is added . @param content : the content holding the collection . @type content : l{content } @return : self @rtype : l{encoded }"
"get a list of links to be displayed in main navigation bar . : return : list(string , string ) - a list of ( name , url)-tuples"
get an url to the start page of the dashboard . : return : string - url to startpage
test for redirect to sso login page
sending an email after successfull register
"creates a list of email addresses in "" prename lastname < email@example.net > "" format . this should be suitable for mass subscription and similar purposes ."
"exports certain staff data in ods format , containing the necessary information for the name tag production application . the produced ods file is the input for the name tag java aplication ."
exports an overview of the staff containing contact data and field of duty .
display a matrix to show persons with associated jobs .
display a matrix to show helpers with associated helper jobs .
display a matrix to show orga with associated orga jobs .
exports group names with associated tutors in ods format . the produced ods file serves as an input for the name tag java aplication .
create the mass_mail tuple for one person
send fillform informations to the user
generates a pdf file with orga certificates for selected staff people and sends it to the browser
test the registration for students
test the success view without a registration
add a forcing term to the model . typically used as a decorator :
"set a right - hand side term for the equation . default is [ 0,0 ] , override this method when subclassing ."
"calculate the dynamics for the u , v and phi equations ."
exit : quits the setup .
list : lists the dropbox usernames .
del username : resets the dropbox for username .
add username : starts the setup for username .
this function is to be called by external script for executing shell commands
load library files as modules and save each of them as attributes
style the given string with ascii escapes .
return true if the patch is compatible .
save the current config to path .
load the config from path
list all mounts
return the current process i d.
return the parents process i d.
send signal sig to the process pid . constants for the specific signals available on the host platform are defined in the signal module
directory changes in script via callable interface should not affect parent shell but is persistent for any following calls from the same parent shell .
"translate a sequence of arguments into a command line string , using the same rules as the ms c runtime :"
"main function for the communicatior , loops here"
callback functions for the library call when receiving nack
send message and retry sending if it gets nacked
calibrate raw cassini iss images using isis .
perform either normal spiceinit or one for ringdata .
check label for target and fix if necessary .
will raise because no config is found at patched path .
add a function or class to the _ _ all _ _ .
take a scalar or list and make it a list
"read a json file in . if no file is found and default value is set , return that instead . otherwise error"
"read a config file . this method optionally supports yaml , if the dependency was already installed . o.w. json plz"
load a module that is in the python path with a canonical name
create a user - defined model
when we use ` functools.partial ` the ` _ _ name _ _ ` is not defined which breaks our export function so we use update wrapper to give it a ` _ _ name _ _ ` .
create a user - defined trainer
loads a user - defined model
model name file helper to abstract different dl platforms ( fws )
lookup a sentence by i d and return words
get a sparse index ( dictionary of top values ) .
prune all elements in a large probability distribution below the top k.
"convert a ` b ` sparse array to a dense one , to expand labels"
"convert a ` bxt ` sparse array to a dense one , to expand labels"
turn a sequence of iob chunks into single tokens .
function returns unicode representation of a category
function returns unicode representation of a note
create a build environment .
install package using pip .
list active breakpoints / hooks
lists the methods of a class
suspends threads in the process
"extended euclidean algorithm , from https://rosettacode.org/wiki/modular_inverse#python"
"modular multiplicative inverse , from https://rosettacode.org/wiki/modular_inverse#python"
set the id of the plugin
register the plugin using an instance and the class object
unregister the plugin using an instance and the class object
get the type of the module
drill a gcode linear move file or text .
drill a gcode linear move text .
get the repository constructor .
get the centroid of a polygon .
drill a gcode linear move file .
display the drill dialog .
thread layer constructor .
get the string representation of this thread layer .
"set the default settings , execute title & settings filename ."
drill button has been clicked .
parse a gcode line .
add a thread to the output .
add a thread layer if it is none .
parse gcode text and store the drill gcode .
get the drilling center depth .
determine if a point on the thread layer is close .
add a linear move to the loop .
parse gcode initialization and store the parameters .
parse a gcode line .
parse a surrounding loop .
get the repository constructor .
display the file or directory dialog .
"set the default settings , execute title & settings filename ."
get the triangle mesh for the slc file .
get little endian float given a file .
get little endian float given a file .
process the vertice points for a given boundary .
read the slc header .
display the inset dialog .
read in the sampling table section . it contains a table length ( byte ) and the table entries .
get the string representation of this sample table entry .
add empty lists .
get the string representation of this carving .
get the corner maximum of the vertices .
get the corner minimum of the vertices .
get the carved svg text .
get the layer thickness .
get the rotated boundary layers .
process a contour layer at a time until the top of the part .
read slc and store the layers .
read in the sampling table section . it contains a table length ( byte ) and the table entries .
"set the bridge layer thickness . if the infill is not in the direction of the bridge , the bridge layer thickness should be given as none or not set at all ."
set the layer thickness .
set the import radius .
set the is correct mesh flag .
feed the file or text .
feed a gcode linear move text .
get the repository constructor .
feed a gcode linear move file .
display the feed dialog .
"set the default settings , execute title & settings filename ."
feed button has been clicked .
parse gcode text and store the feed gcode .
get gcode line with feed rate .
parse gcode initialization and store the parameters .
parse a gcode line and add it to the feed skein .
get the tool specified by the relevant settings
multiply the fill file or text .
multiply the fill text .
get the repository constructor .
multiply a gcode linear move file .
display the multiply dialog .
"set the default settings , execute title & settings filename ."
multiply button has been clicked .
add moved element to the output .
add multiplied layer to the output .
parse gcode initialization and store the parameters .
parse gcode text and store the multiply gcode .
get the moved location and set the old location .
parse gcode initialization and store the parameters .
parse a gcode line and add it to the multiply skein .
set maximum and minimum corners and z.
"returns all discounts available to this user for the given categories and products . the discounts also list the available quantity for this user , not including products that are pending purchase ."
returns : sequence[discountforproduct | discountforcategory ] : all clauses that passed the filter function .
annotates the queryset with a usage count for that discount claus by the given user .
run before all tests
test creating a new color scheme
test getting color scheme name
test getting colors without passing a base color
test getting colors with a base color
test getting colors when specifying a scheme
test cloning a color scheme
tests for user color schemes
test retrieving recent colors
set properties for a renderer for testing with _ checkproperties
test properties of renderer against expected
test getters and setters
test cloning renderer
test saving and recreating from xml
test renderer conversion
test rendering with expression variables in marker
called by setup : run before each test .
called by teardown : run after each test .
"compare i d , name and geometry"
delete all features from the given layer
"layer factory ( return the backend layer ) , provider specific"
"layer factory ( return the online layer ) , provider specific"
"find the feature and return it , raise exception if not found"
preliminary checks for each test
delete a single feature
delete a multiple features
insert multiple features
setup the involved layers and relations for a n : m relation : return :
test copy and move features
test widget with no layer
"handle data preparation for v.net.distance : * integrate point layers into network vector map . * make v.net.distance use those layers . * delete the threshold parameter . * if where statement , connect to the db"
test widget getters / setters
test widget handling of null values
test clearing widget
test that signals are correctly emitted when clearing
prints algorithm parameters with their types . also provides information about options if any .
"executes an algorithm dialog for the specified algorithm , prepopulated with a given set of parameters ."
creates a default processing context
"loads a layer / table into the current project , given its file ."
returns true if output is set to be skipped signal
gdal provider does n't support non file based outputs
will return a mock qgisinterface object with some methods implemented in a generic way .
trys to find where the file is relative to the qgis source code directory . if it is already placed in the processing or qgis testdata directory it will return an appropriate schema and relative filepath
parse alg string to grab parameters value . can handle quotes and comma .
extracts the algorithm id and input parameter list from a processing runalg command
test that rendering a simple line symbol with offset
test retrieving unique values using base class method
test retrieving min values using base class method
test retrieving min values using base class method
test materializing layers
interprets a parameter as an ogr compatible source and layer name : param executing :
test setting anchor point for widget
test that moving or resizing the anchor widget updates the floating widget position
test resizing parent widget correctly repositions floating widget
test that floating widget will be placed inside parent when possible
test mainpanel methods
test adding panels to stack
test accepting current panel
test accepting all panels
test clearing stack
test that taking the main panel accepts all open child panels
test zonal stats
test ` with edit(layer ): ` code
run before all tests
test adding geonode wms related connection settings to a uri
test adding geonode wfs related connection settings to a uri
verify if we have the right parameters
run before all tests
run after all tests
test that on - the - fly re - opening in update / read - only mode works
check writing integer64 fields to an mapinfo tabfile ( which does not support that type ) .
test fetching ellipsoid parameters
fake httplib implementation
returns a started ` mock.patch ` object for the supplied target .
"determine whether a called attribute name may be considered as an item call . by default , it returns false anyway , disabling that feature ."
return self _ _ call _ _ ( ) method
nicely display self dict 's items as a formatted multiline string array . the optionnal argument ` pattern ` can be used to limit item display to keys whose name starts with it 's value .
"override standard dict ( ) update method , because it seems that using the default one does not use self object 's _ _ setitem _ _ ( ) method . this is problematic for phpsploit session main objects ."
"this function returns a parser . the grammar should be like most full text search engines ( google , tsearch , lucene ) ."
evaluate quoted strings
create a new path object .
open the file with editor setting for edition .
display the file with phpsploit 's browser setting .
read path file contents .
write ` data ` to the file path .
get the list of file path lines .
get minified php code from file .
interpret ` file ` data as a command line sequence .
test whether a path is absolute
test whether a path is absolute
aquí se definen los botones
aquí se ejecuta al seleccionar unos de los botones
log errors caused by updates .
send a message when the command /start is issued .
send a message when the command /help is issued .
handle the inline query .
"blocking function executing a motion : param motion : [ { "" motor_name "" : value_in_degrees } , { } ... ] : param duration : duration in secs"
"given a class that returns a different value each time the property f is called , the memoisation should make the returned value to be the same each time : return :"
"given that two different functions share the same function name , memoisation of these functions should not be influenced by one another . : return :"
"given two instances of the same class , the memoisation should not persist between the two"
used in the inferencewithrestarts class . needs to be in global scope for multiprocessing module to pick it up
"given two equal matrices , ` sympy_expressions_equal ` should correctly identify them as equivalent . given two different matrices , it should correctly call them different"
"given two equivalent expressions , ` sympy_expresions_equal ` should correctly call them equal . given two different expressions , the function should say they are not equal ."
"given a ` sympy . matrix ` , ` to_sympy_matrix ` should return the said matrix ."
"given a list of integers , to_sympy_matrix should be able to convert it to a matrix of these integers : return :"
"given a list of strings , to_sympy_matrix should be able to convert them into a matrix of expressions ."
"given a list of strings , to_sympy_matrix should be able to convert them into a column matrix of expresions"
"makes a counter for central moments ( n_counter ) and a counter for raw moment ( k_counter ) . each is a list of : class:`~means.approximation.ode_problem . moment`s . therefore , each : class:`~means.approximation.ode_problem . moments ` is represented by both a vector of integer and a symbol ."
: param propensities : the rates / propensities of the reactions : param n_counter : a list of : class:`~means.core.descriptors . moment`\s representing central moments : type n_counter : list[:class:`~means.core.descriptors . moment ` ] : param stoichoimetry_matrix : the stoichiometry matrix . explicitly provided by the model : param species : the names of the variables / species
"provides the terms needed for equation 11 ( see ale et al . 2013 ) . this gives the expressions for : math:`\frac{d\beta}{dt } ` in equation 9 , these are the time dependencies of the mixed moments"
"calculates : math:`f():math : ` in eq . 12 ( see ale et al . 2013 ) for a specific reaction , : math:`k ` and : math:`e `"
calculates : math:`<f > ` in eq . 12 ( see ale et al . 2013 ) to calculate : math:`<f > ` for each variable combination .
compute s^e in equation 11 ( see ale et al . 2013 )
get frame from frame.f_trace attribution
check if code has frame.f_trace attribution
"convert arg to time with optional format . return arg , converted time if converted or none , otherwise"
return hash of file in path or none
skip specific files
create a backup trial
restore file with < code_hash > from < trial_id >
restore the main script from < trial >
compare files with existing files return match and dict with the most updated version of files
"find file according to timestamp , code_hash , and number of access"
ignore commands added by add_argument_cmd
add argument to parser available for both ipython magic and cmd
create magic for command
execute the command . override on subclass
get arguments from magic
use jsonpickle to get objects representation store representation in the content database
default serialization for iterables
default serialization for non iterables
"add new music , return music obj"
return music obj
return music set status
update music obj by kwargs
delete music obj
return memory usage in bytes .
return resident memory usage in bytes .
return stack size in bytes .
returns a converted copy of the image
reduce an image to a new_height keeping proportions
we need to use the same ward each time we make a facility
"returns preprocessing_fn(image , height , width , * * kwargs ) ."
apply mirc compatible colors and styles to the given text .
remove all mirc compatible styles and coloring from the given text .
: param test_function : propertytest.uniqueness_statistic or reliability_statistic function which is used to calculate a statistic . : param challenge_count : int number of challenges used . : param measurements : int number of calculations see test_function for more details . : param challenge_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate challenges . : param ins_gen_function : a function : * kwargs - > list of pypuf.simulation.base . simulation this function is used to generate a list of simulation instances which are inspected . : param param_ins_gen : a collections . ordereddict with keyword arguments this keyword arguments are passed to ins_gen_function to generate pypuf.simulation.base . simulation instances and saved into the result log .
runs a property test .
summarize the results of the search process .
"this function can be used to create a list of ltfarrays . : param n : int number of stages of the puf : param k : int number different ltfarrays : param instance_count : int number of simulations to be instantiated . : param transformation : a function : array of int with shape(n , k , n ) , int number of pufs k - > shape(n , k , n ) the function transforms input challenges in order to increase resistance against attacks . : param combiner : a function : array of int with shape(n , k , n ) - > array of in with shape(n ) the functions combines the outputs of k pufs to one bit results , in oder to increase resistance against attacks . : param bias : none , float or a two dimensional array of float with shape ( k , 1 ) this bias value or array of bias values will be appended to the weight_array . use a single value if you want the same bias for all weight_vectors . : param mu : float mean ( “ centre ” ) of the stage weight distribution of the puf instance simulation . : param sigma : float standard deviation of the stage weight distribution of the puf instance simulation . : param weight_random_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate the stage weights for the arbiter puf simulation . : return : list of pypuf.simulation.arbiter_based.ltfarray . ltfarray"
"this function can be used to create a list of noisyltfarray . : param n : int number of stages of the puf : param k : int number different ltfarrays : param instance_count : int number of simulations to be instantiated . : param transformation : a function : array of int with shape(n , k , n ) , int number of pufs k - > shape(n , k , n ) the function transforms input challenges in order to increase resistance against attacks . : param combiner : a function : array of int with shape(n , k , n ) - > array of in with shape(n ) the functions combines the outputs of k pufs to one bit results , in oder to increase resistance against attacks . : param bias : none , float or a two dimensional array of float with shape ( k , 1 ) this bias value or array of bias values will be appended to the weight_array . use a single value if you want the same bias for all weight_vectors . : param mu : float mean ( “ centre ” ) of the stage weight distribution of the puf instance simulation . : param sigma : float standard deviation of the stage weight distribution of the puf instance simulation . : param weight_random_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate the stage weights for the arbiter puf simulation . : param sigma_noise : float standard deviation of the noise distribution . : param noise_random_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate the noise for the arbiter puf simulation . : return : list of pypuf.simulation.arbiter_based.ltfarray . noisyltfarray"
"this function can be used to create a list of simulationmajorityltfarray . : param n : int number of stages of the puf : param k : int number different ltfarrays : param instance_count : int number of simulations to be instantiated . : param transformation : a function : array of int with shape(n , k , n ) , int number of pufs k - > shape(n , k , n ) the function transforms input challenges in order to increase resistance against attacks . : param combiner : a function : array of int with shape(n , k , n ) - > array of in with shape(n ) the functions combines the outputs of k pufs to one bit results , in oder to increase resistance against attacks . : param bias : none , float or a two dimensional array of float with shape ( k , 1 ) this bias value or array of bias values will be appended to the weight_array . use a single value if you want the same bias for all weight_vectors . : param mu : float mean ( “ centre ” ) of the stage weight distribution of the puf instance simulation . : param sigma : float standard deviation of the stage weight distribution of the puf instance simulation . : param weight_random_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate the stage weights for the arbiter puf simulation . : param sigma_noise : float standard deviation of the noise distribution . : param noise_random_seed : int the seed which is used to initialize the pseudo - random number generator which is used to generate the noise for the arbiter puf simulation . : param vote_count : int number of evaluations which are used to choose a response with majority vote . : return : list of pypuf.simulation.arbiter_based.ltfarray . simulationmajorityltfarray"
""" stupid test which gains code coverage"
""" stupid test which gains code coverage"
create address_scope : foo - address - scope with minimum option .
create address_scope : foo - address - scope with minimum option .
create address_scope : foo - address - scope with minimum option .
returns an neutron client .
hook to add global options
create a fake port pair .
create multiple port_pairs .
create a fake port pair group .
create multiple port pair groups .
create a fake flow classifier .
create multiple flow classifiers .
create a fake port chain .
create multiple port chains .
create a fake service graph .
create multiple service graphs .
retrieve data using neutron client for the given tenant .
prepare test environment .
create test flavor with missing parameters .
create test flavor with minimal parameters .
create test flavor including optional parameters .
delete flavor .
list flavors test .
list flavors test with pagination .
list flavors test with sorting by name and i d.
show flavor test .
update flavor test .
associate flavor test .
disassociate flavor test .
"return client class , instance ."
create multiple fake bgp speakers .
create one or multiple fake bgp peers .
register a decorated method so that it can be recognized as a route .
args : client_access_key : a vws client access key . client_secret_key : a vws client secret key .
perform an image recognition query .
helper function for retrieving course data from bucknell servers .
fetches description and other data for an individual section .
helper function that creates a beautiful soup object from the course data and groups sections .
finds a course within a department .
"parses html for an individual section and stores extra sections ( labs , etc ) if it is a main section ."
generates section data for main sections or extra sections .
"identifies the type of each section ( main , lab , etc ) and stores relevant data in the object for further parsing ."
"groups extra sections ( labs , recitations , etc ) to the main sections of the course ."
exports the course object .
"fetches course data table in html , extracts sections , and generates list of courses ."
parse the data for an individual section by treating it like an entire course .
"fetches course data table in html , extracts sections , and generates list of courses ."
signal the task to stop gracefully . wait until it stops and return its process return code
return true if the task is finished
forcefully terminate the task
wait until the task is done and return its process return code
"check the state of local adb server , return a json representing its state"
start the local adb server using the adb tool from the android sdk
kill the local adb server using the adb tool from the android sdk
detect the path to the adb tool from the android sdk
get the information about a touchscreen event trace
record a touchscreen event trace from a given device
replay a touchscreen event trace to multiple devices
list all the devices and their details by communicating with the adb server
"synchronize the touchscreen input events from one device ( master ) to many ( slaves ) , in real - time"
control multiple devices to perform the same operation . possible commands :
take a screenshot from a device and save to the local machine
"run a test plan on multiple devices , store the test result to a folder and optionally report the progress via websocket"
iterates over all the active services in the database and attempt to execute that service 's functionality . the success or failure of the service and any error messages are stored in the database .
"similar to mkdir -p , make a directory ignoring eexist"
configure urllib2 to pass authentication information if provided in the configuration .
test dimensionality reduction using sample data
"calculates the variance for each row of a sparse matrix , using the relationship var = e[x^2 ] - e[x]^2 ."
this function identifies the genes that have the max variance across a number of bins sorted by mean .
returns the data where the expression is normalized so that the total count per cell is equal .
"returns ln(data+1 ) , whether the original data is dense or sparse ."
basically this is to test that the poisson em can correctly separate clusters in simulated data .
returns the zip parameters that best fit a given data set .
performs hard em clustering using the zero - inflated poisson distribution .
test that get request is successful on bulk view .
test that post request with single resource only creates a single resource .
test that post request with multiple resources creates all posted resources .
test that put request updates all submitted resources .
test that put request updates all submitted resources .
test that patch request partially updates all submitted resources .
test that delete is not allowed when results are not filtered .
test that delete removes all filtered resources .
test that options request is successful on bulk view .
test that we are still able to query single resource
test that get returns 200
test that post with single resource returns 201
test that post with multiple resources returns 201
test that put with multiple resources returns 200
test that patch with multiple partial resources returns 200
test that patch with multiple partial resources returns 200
hook to ensure that the bulk destroy should be allowed .
calls xdg - email with the appropriate options
check if we are inside flatpak
in flatpak the only special path visible also from outside is /var / tmp/ to be able to use the files from the host we change the path to the absolute one . this fix in the future may not be necessary because the portals should be able to automatically handle it .
"tries to send the email using firstly the portal , then the xdg - email and as a last attempt the mailto uri"
"creates , encrypts , and send signatures for each uid on the key"
"formats a given fingerprint ( 160bit , so 20 characters ) in the gnupg typical way"
parses information contained in a barcode
"strips a fingerprint of any whitespaces and returns a clean version . it also drops the "" openpgp4fpr : "" prefix from the scanned qr - encoded fingerprints"
if the bluez object is available it means that there is a working bluetooth
initializes the server to serve the data
"this is run in the same thread as the caller . this calls run ( ) in a separate thread . in order to resolve dbus issues , most things are done here . however , you probably need to start dbus.mainloop.glib . dbusgmainloop ( set_as_default = true ) in order for this work ."
an httpd is started and being put to serve_forever . you need to call shutdown ( ) in order to stop serving .
this is being run by thread in a separate thread after you call start ( )
sends shutdown to the underlying httpd
evaluates a file containing a python params dictionary .
creates a new parameter object from the given parameterargument .
return a dict of ` models . field ` instances for named fields .
return utf-8 - encoded bytes of a path to a tmp file .
` openssl.tsafe . connection ` can be instantiated .
debug info contains correct data .
"in default setting , get method is not logged"
get a list of security groups .
allocate a new floating ip address .
associate or disassociate a floating ip address .
get a list of floating ip addresses .
get a list of floating ip pools .
returns the initialized tab group for this view .
adds the ` ` tab_group ` ` variable to the context data .
sends back an ajax - appropriate response for the tab group if needed .
loads the tab group .
a no - op on this class . tables are handled at the tab level .
loads the table data based on a given table_dict and handles them .
log user operation .
log error info when exception occurred .
return operation log format .
get parameters to log in operation_log .
change post data to json string and mask data .
naive case - insensitive search .
tests ability to create and delete a group
tests ability to edit group name and description
create namespace and run checks
delete namespace and run checks
tests the namespace creation and deletion functionality :
this is a basic scenario test :
this is a basic scenario test :
listen for compress events .
provide a basic filter to allow angular template content for angular .
generate a dictionary of template contents for all static html templates .
quick utility to make comparing template output easier .
render a custom template to string .
test if site_branding tag renders the correct setting .
returns an iterable of default classes .
returns a dict of default attributes .
returns a dict containing the final attributes to be rendered .
returns a final css class concatenated string .
returns a flattened string of html attributes .
returns a flattened string of html attributes .
returns a list of class name of html element in string .
get the id of the domain in which the current operation should happen .
register api views to respond to a regex pattern .
lists names of columns that have required fields .
formats the self.filtered_data in a way suitable for a formset .
provide the formset corresponding to this datatable .
"return a row with no data , for adding at the end of the table ."
return the row data for this table broken out by columns .
naive case - insensitive search .
common function for getting the region from endpoint .
merge another quotaset into this one .
test parameter expanding
test grid search
"builds a header chain until it connects . returns true if it has successfully connected , false if verification failed , otherwise the height of the next header needed ."
return an lxml ` ` isoschematron . schematron ( ) ` ` instance using the schematron file at ` ` sct_path ` ` .
"validate a mets file using both an xmlschema ( .xsd ) schema and a schematron schema , the latter of which typically places additional constraints on what a mets file can look like ."
return a ` ` class::lxml.etree . xmlschema ` ` instance given the path to the xmlschema ( .xsd ) file in ` ` xmlschema ` ` and the ` ` class::lxml.etree._elementtree ` ` instance ` ` mets_doc ` ` representing the mets file being parsed . the complication here is that the mets file to be validated via the .xsd file may reference additional schemata via ` ` xsi : schemalocation ` ` attributes . we have to find all of these and import them from within the returned xmlschema .
validate a mets file using a schematron schema . return a boolean indicating validity and a report as an ` ` lxml . elementtree ` ` instance .
return a human - readable string representation of the error report returned by lxml 's schematron validator .
return a human - readable string representation of the error log returned by lxml 's xmlschema validator .
return a human - readable string representation of all of the validation errors .
tests that the assertion creators ` ` has_methods ` ` and ` ` has_class_methods ` ` behave correctly .
test the dependency injection ( di ) infrastructure for metsrw plugins .
get_component_code should return the right code given an existing component name
get_state_machine_code should return the right code given existing component name and statemachine name
get_publisher_details should return the right publisher details given existing component and statemachine codes
: type fund_id : str : type name : str : type description : str : type site : str : type email : str : type logo : iobase : type donatable : bool
could be used as a source for json or any other representation format
starts new worksession for given user . by default we use ` datetime.now ` in the underlying model to save in ` start_time ` field .
"update an activity counter . the intention is to find out how much time was actually spent working on the task , excluding sexting , brewing coffee and jogging ."
ends given worksession for given user . this is the route for correctly finished tasks : given session to be marked as closed and a timestamp of the event to be saved .
deletes current worksession if skipped .
: param task_type_name : current task type name : type task_type_name : str : param answer_model : current answer model : type answer_model : abstractanswer : param user_model : active user model : type user_model : user
"return sorted list of tuples ( user_id , tasks_done )"
find users who contributed the most
returns an array of all previously scanned files
"returns and array of strings from a file , where each line is an item"
shaft torque as a function of rotor angular speed
return connect_model if rotating machine
create model and analysis function
extracts parameters from content and creates template
read and returns sample data to fill form with default sample sequence .
transforms biopython 's blast record into blast object defined in django - blastplus app .
"runs blastplus / tblastn search , collects result and pass as a xml temporary file ."
checks if database is set as annotated .
find time dimension coordinates in an ` xarray . dataarray ` .
"categorise all the non - dimension coordinates of an ` xarray . dataarray ` into those that span only time , those that span only space , and those that span both time and space ."
generate a weights array for a given weighting scheme .
correlation between pcs and a field .
covariance between pcs and a field .
extract the appropriate dimensions from a set of pcs and a field for construction of covariance / correlation map dimensions .
parameters ---------- images : np.array images to extract patch vectors filter_shape : tuple of ints the shape of a filter step_shape : tuple of ints step height / width of a filter
"if int is given , duplicate it and return as a 2 element tuple ."
yields patches with its location indices . kernel visits the image from the left top into right bottom .
parameters ---------- patches : np.ndarray set of patches which represented as a 3d array .
normalize a patch .
normalize patches .
parameters ---------- image_shape : int or sequence of ints input image shape . filter_shape_l1 : int or sequence of ints the shape of the kernel in the first convolution layer . step_shape_l1 : int or sequence of ints the shape of kernel step in the first convolution layer . n_l1_output : l1 in the original paper . the number of outputs obtained from a set of input images . filter_shape_l2 : int or sequence of ints the shape of the kernel in the second convolution layer . step_shape_l2 : int or sequence of ints the shape of kernel step in the second convolution layer . n_l2_output : l2 in the original paper . the number of outputs obtained from each l1 output . block_shape : int or sequence of ints the shape of each block in the pooling layer .
separate a given image into blocks and calculate a histogram in each block .
check that the filter visits all pixels of input images without dropping any information . raise valueerror if the network structure does not satisfy the above constraint .
initialize the albumwidget .
selection mode toggled .
create the liststore model for this widget .
update the album widget .
cancel selection mode callback .
selection mode button clicked callback .
add a song to the item to album list .
player changed callback .
create a mutant with point mutations ( returns a copy - leaves the original unchanged )
create mutation string for storage as metadata .
solvate a molecule in a water box with optional ions
: param mol : : type mol : moldesign.molecules . molecule : return :
"given atoms , atomcontainers , lists of atoms , and lists of atomcontainers , return a flat list of all atoms contained therein ."
returns kinetic energy
makes sure atom names are unique in each residue .
restores chain ids and residue indices ( these are stripped by some methods )
faster method to compute sums of iterables if they 're all in the right units
dot product that respects units
return true if arrays are almost equal up to numerical noise
convert a json description to a quantity . this is the inverse of : meth:`moldesign.units.quantity . mdtquantity.to_json `
return the base unit system of an quantity or arbitrarily - nested iterables of quantities
"facilitates creating an array with units - like numpy.array , but it also checks units for all components of the array ."
turns a list of dimensionless numbers into a numpy array . does not permit object arrays
this is a decorator that lets us associate fixtures with one or more arbitrary types . we 'll later use this type to determine what tests to run on the result
creates a dotdict from a list of items that have a ` ` name ` ` attribute
returns a copy of the core dictionary in its native class
just include all files that wo n't be included as package modules .
give this function unit norm by adjusting its coefficient
overlap of this function with another :
"the l2 - norm of this object , calculated as the square root of its self overlap ."
scalar : : math:`\sqrt{<i|i > } `
scale primitive coefficients to normalize this basis function
calculate orbital overlap with another object
set up active interface internal fields .
already started before the object is created .
stop the active interface .
read an interface from the given configuration object .
write an interface to the given configuration object .
"create an object config instance , using the given arguments to override values in it . an existing config instance can also be specified to base the result from , rather than the test class default ."
"create an object instance , use assertisinstance to ensure it is of the correct type , and return it ."
"get a value from the given object , using the supplied key - value pair ( and internal key if used ) ."
do a dry run of the l3overlay daemon with overlay configurations designed to test each static interface type .
tries to find a tun / tap interface with the given name in the chosen namespace and returns it .
"create a tun / tap interface object , using a given interface name ."
test that ' log_level ' is properly handled by the daemon .
test that ' use_ipsec ' is properly handled by the daemon .
test that ' ipsec_manage ' is properly handled by the daemon .
test that ' ipsec_psk ' is properly handled by the daemon .
test that ' lib_dir ' is properly handled by the daemon .
test that ' fwbuilder_script_dir ' is properly handled by the daemon .
test that ' overlay_conf_dir ' is properly handled by the daemon .
test that ' template_dir ' is properly handled by the daemon .
test that ' pid ' is properly handled by the daemon .
test that ' ipsec_conf ' is properly handled by the daemon .
test that ' ipsec_secrets ' is properly handled by the daemon .
test that ' overlay_conf ' is properly handled by the daemon .
initialise instance .
set up .
tear down .
execute fake cli method .
initialise new lookingglass instance .
initialise new instance .
get the dialect specific syntax for a given method as a lambda .
create the necessary objects .
test getting credentials by name and returning properties .
test getting location by name and returning properties .
test getting router by name and returning properties .
"test getting log entry by ( event , error ) pair ."
test ipprefix type .
the html file contains a block of html that has descriptions of and a link to each zip file . i manually paste the file into the website for users .
uploads a pgn to lichess.org and returns the url to view the analysis .
/ アクセスのテスト .
/alltag アクセスのテスト .
/detail/1 アクセスのテスト .
/detail/2 アクセスのテスト(つくってない記事 ) .
/category / programing アクセスのテスト .
/category / aiueo アクセスのテスト ( 作ってないカテゴリ ) .
/tag / django アクセスのテスト .
/tag / python アクセスのテスト(作ってないタグ ) .
/comment/1 アクセスのテスト .
/comment/2 アクセスのテスト(作ってない記事 ) .
/private アクセスのテスト .
/latest / feed アクセスのテスト .
/sitemap.xml アクセスのテスト .
コマンド定義のための関数。実際の処理はapi.main ( ) .
tests if len ( ) of stl object is number of factes
tests if list(stl ) returns all the facets
test if newly created stl has len ( ) = = 0
tests the output of str
load a dataset in either image space or transport space .
trigger anything that should happen on update of gravitysensor
trigger anything that should happen on update of tiltconfiguration
trigger anything that should happen on update of tiltgravitycalibrationpoint
trigger anything that should happen on update of tilttempcalibrationpoint
a wrapper for views that check specific constance settings . only used for site_is_configured below . the test should be a callable that takes the user object and returns true if the user passes .
"decorator for views that checks that the user is logged in , redirecting to the log - in page if necessary ."
"decorator for views that checks that the user is logged in , redirecting to the log - in page if necessary - but only if require_login_for_dashboard is set true in constance ."
"decorator for views that checks that the user is logged in , redirecting to the log - in page if necessary ."
filter detections using the boxes and classification values .
"filters detections using score threshold , nms and selecting the top - k detections ."
constructs the nms graph .
computes the output shapes given the input shapes .
this is required in keras when there is more than 1 output .
gets the configuration of this layer .
"parse a string into a value , and format a nice valueerror if it fails ."
open a file with flags suitable for csv.reader .
set all layers in a model to non - trainable .
adjust a transformation for a specific image .
apply a transformation to an image .
generate a simple cnn model to target path for further usage
compute the cqt
compute cqt magnitude .
compute the cqt with unwrapped phase
compute the hcqt
rearrange a tensor according to the convolution mode
compute hcqt magnitude .
compute the hcqt with unwrapped phase
transform an audio signal
compute the phase differential along a given axis
construct keras input layers for the given transformer
get the number of frames for a given duration
initializes new color using a boolean true is white and false is black
"converts string "" white "" or "" black "" into corresponding color"
finds out this color is the same as another color .
format ` ` name ` ` + ` ` description ` ` in an unified format that can be used to print beautiful help messages .
args : img ( pil.image ): image to be flipped .
"runs the full dynd test suite , outputing the results of the tests to sys.stdout . parameters ---------- verbosity : int , optional value 0 prints very little , 1 prints a little bit , and 2 prints the test names while testing . xunitfile : string , optional if provided , writes the test results to an xunit style xml file . this is useful for running the tests in a ci server such as jenkins . exit : bool , optional if true , the function will call sys.exit with an error code after the tests are finished ."
"return the external ipv4 address of the current host , otherwise 127.0.0.1"
convert ipv4 string to 32 - bit integer value
covert 32 - bit integer value to ipv4 string
"convert between proquint , integer , hex or ipv4 string representations . tries to guess the representation from input ."
convert 32 - bit integer value into corresponding proquint string identifier .
convert proquint string identifier into corresponding 32 - bit integer value .
return a configuration variable with casting
converts an arbitrary expression to a type that can be used inside sympy .
short version of sympify for internal usage for _ _ add _ _ and _ _ eq _ _ methods where it is ok to allow some things ( like python integers and floats ) in the expression . this excludes things ( like strings ) that are unwise to allow into such an expression .
"use a hack to try keep autosimplification from joining integer or minus sign into an add of a mul ; this modification does n't prevent the 2 - arg mul from becoming an add , however ."
a random realization from the distribution
inverse of the cdf
compute the cdf from the pdf
cumulative density function
expectation of expression over distribution
internal sample method
acquire a readable object for a given package name and identifier . an ioerror will be raised if the resource can not be found .
"create our new "" sin "" function ."
"create our new "" cos "" function ."
"test our easy "" tanh "" function ."
"> > > from sympy import matrixsymbol , q , assuming , refine , det > > > x = matrixsymbol('x ' , 2 , 2 ) > > > det(x ) determinant(x ) > > > with assuming(q.orthogonal(x ) ): ... print(refine(det(x ) ) ) 1"
find the periodic continued fraction expansion of a quadratic irrational .
reduce a continued fraction to a rational or quadratic irrational .
return continued fraction expansion of x as iterator .
return an iterator over the convergents of a continued fraction ( cf ) .
returns a string usable for lambdifying .
test a basic gate .
test the general cgate .
test the representation of the hadamard gate .
test the representation of the x gate .
test the representation of the y gate .
test the representation of the z gate .
test the representation of the s gate .
test the representation of the t gate .
test a compound gate representation .
test the cnot gate .
test gate_sort .
test gate_simp .
test the swap gate .
test single qubit gate commutation relations .
test single qubit gate anticommutation relations .
test commutators of involving cnot gates .
slightly more flexible way to render labels .
autogenerate labels for wires of quantum circuits .
use a lexical closure to make a controlled gate .
combinations with repetition
comptutes a vandermonde matrix of given order and dimension .
generates a polynomial using a vandermonde system
"print a crude ascii art plot of the sympy expression ' expr ' ( which should contain a single symbol , e.g. x or something else ) over the interval [ a , b ] ."
apply a branching rule repeatedly until it has no effect
print the input and output expressions at each rule application
multiplex many branching rules into one
only apply branching rule if condition is true
yield only those results which satisfy the predicate
execute one of the branching rules
compose a sequence of brules so that they apply to the expr sequentially
turn a rule into a branching rule
function for printing of expressions generated in the sympy.physics vector package .
function for displaying expression representation 's with vector printing enabled .
function for displaying expressions generated in the sympy.physics vector package .
function for pretty printing of expressions generated in the sympy.physics vector package .
function for printing latex representation of sympy.physics.vector objects .
"initializes time derivative printing for all sympy objects , i.e. any functions of time will be displayed in a more compact notation . the main benefit of this is for printing of time derivatives ; instead of displaying as ` ` derivative(f(t),t ) ` ` , it will display ` ` f ' ` ` . this is only actually needed for when derivatives are present and are not in a physics.vector . vector or physics.vector . dyadic object . this function is a light wrapper to ` sympy.interactive.init_printing ` . any keyword arguments for it are valid here ."
a factory for ` ` threaded ` ` decorators .
"apply ` ` func ` ` to sub -- elements of an object , including : class:`add ` ."
"apply ` ` func ` ` to sub -- elements of an object , excluding : class:`add ` ."
"after the function finishes , resets the value of mpmath.mp.dps to the value it had before the function was run ."
adds metadata about the depenencies which need to be met for doctesting the docstrings of the decorated objects .
append ` ` obj ` ` 's name to global ` ` _ _ all _ _ ` ` variable ( call site ) .
expand the first add containing a simple kroneckerdelta .
extract a simple kroneckerdelta from the expression .
"returns true if ` ` expr ` ` is an expression that contains a kroneckerdelta that is simple in the index ` ` index ` ` , meaning that this kroneckerdelta is nonzero for a single value of the index ` ` index ` ` ."
returns true if ` ` delta ` ` is a kroneckerdelta and is nonzero for a single value of the index ` ` index ` ` .
evaluate products of kroneckerdelta 's .
rewrite a kroneckerdelta 's indices in its simplest form .
handle products containing a kroneckerdelta .
handle summations containing a kroneckerdelta .
mass of the particle .
point of the particle .
linear momentum of the particle .
angular momentum of the particle about the point .
kinetic energy of the particle
used to set the potential energy of the particle .
the potential energy of the particle .
the position of the state .
the x coordinate of the state
the y coordinate of the state
the z coordinate of the state
the momentum of the state .
returns the frequency of the wave .
returns the time period of the wave .
returns wavelength of the wave . it depends on the medium of the wave .
returns the amplitude of the wave .
returns the phase angle of the wave .
returns the speed of travelling wave . it is medium dependent .
returns angular velocity of the wave .
returns equation of the wave .
string representation of a twave .
addition of two waves will result in their superposition . the type of interference will depend on their phase angles .
loads the latest settings from screenly.conf into memory .
start the stratisd daemon with the simulator .
stop the stratisd simulator and daemon .
a proxy object is returned from a non - existant path .
an invalid path causes an exception to be raised .
tokenizes a text file .
sets the entity owner 's account type .
creates the initial entities that this entityowner needs .
updates the entity with the provided entity data ( or adds a new one if that entity does not exist ) .
removes the entity by i d.
returns the account name and account type .
returns the entity manager of this entityowner .
returns all the entities in this entityowner .
returns the data in database savable format .
returns a boolean indicating if this entity owner needs to be saved on the database .
returns the username of this entityowner .
returns the email of this entityowner .
returns the password of this entityowner .
creates an object file .
creates a new executable file .
runs the provided shell command .
checks the status of quasar .
runs a status check .
temporary utility function .
loads the local scripts .
loads the specified script .
loads this specific script .
loads a set of scripts for a specified application server .
returns the lines with certain constants parsed out .
returns the directory that this file resides in .
returns the raw file name of this c file .
returns the full file path of this c file .
returns the file name of this c file .
runs the specified procedure .
runs the specified procedure .
prompt the user for the procedure to run .
print general information on this project .
generates the scripts .
generates production version of quasar .
loads the quasar asset component which contains all the various assets used .
loads all the quasar client side js component .
loads all the quasar css component .
loads the html component .
initializes a new instance of the class .
initializes a new instance of the class .
the i d property .
the i d property .
the is_first property .
the is_first property .
initializes the current instance of the object .
writes the contents of this object and returns the content as a dict object .
initializes a new instance of the class .
the ver property .
the ver property .
the i d property .
the i d property .
the name property .
the name property .
the duration property .
the duration property .
the success property .
the success property .
the run_location property .
the run_location property .
the message property .
the message property .
the properties property .
the properties property .
the measurements property .
the measurements property .
the ver property .
the ver property .
the role property .
the role property .
the role_instance property .
the role_instance property .
initializes a new instance of the class .
the ver property .
the ver property .
the time property .
the time property .
the sample_rate property .
the sample_rate property .
the seq property .
the seq property .
the ikey property .
the ikey property .
the tags property .
the tags property .
the data property .
the data property .
"split ' name ' field into multiple fields based on regex and field names specified in type_handlers original ' name ' field is replaced with the detection_identity_name field , if returned by regex ."
dlp event with data that can be extracted
threat event with data that can be extracted
"a known type , but information ca n't be extracted ( regex mismatch )"
"ensure the name gets updated from the description , if present"
ensure that nothing gets changed when the type is n't recognised
ensure that entry is skipped if it 's to be ignored .
convert a yy_mm_dd_hh_mm_ss formatted date time string to unix timestamp
"return the full path of firefox sqlite databases , platform independent"
get the file name from a string that might or might not contain the full path
save whatever data the scripts produce to a file ...
send queries to a database and return the results
generate static html with a time code and an appropriate title
get the html table header from a given template file
close html tags
insert a word like a key into a dict and save data like value : param word : insert word param into the sw_dict param like value : param pos : part of speech : param sw_dict : dictionary : param data : insert data param into the sw_dict param like value
"return the sentiment of a given word , part of speech and language : param word : word to analize the sentiment : param pos : part of speech ( n : noun , a : adjetive , v : verb , r = adverb ) : param language : language"
returns a stylesheet object
"when initialized , it copies the class defaults ; then takes a copy of the attributes of the parent if any . all the work is done in init - styles should cost little to use at runtime ."
re - fetches attributes from the parent on demand ; use if you have been hacking the styles . this is used by _ _ init _ _
you can ask a linestyle to set up the canvas for drawing the lines .
determine the amount to charge . this depends on whether the payer agreed to pay fees or not . if they did then we add that to the amount charged . stripe charges 2.2 % + $ 0.30 .
returns the ' name ' table data from the .woff font file at the given * path * .
returns a dictionary containing the english - language name ( string ) data from the woff file at the given * path * .
lb 0 ub |--------------------------- ' ---------------------------| < - - -|---------- ' ' ----------|- - - - >
lb 0 ub |--------------------------- ' ---------------------------| |- - > ---------- ' ' ----------<- - - -|
forces a reaction to have a minimum flux level in the opposite direction of a reference state .
"swaps the cofactors of a reaction . for speed , it can be done inplace which just changes the coefficients . if not done inplace , it will create a new reaction , add it to the model , and knockout the original reaction ."
returns the answers to the lab classes .
gives a latex representation of the assessment .
gives an html representation of the assessment .
returns an pandas empty dataframe object containing rows and columns for marking . this can then be passed to a google doc that is distributed to markers for editing with the mark for each section .
compute the total mark for the assessment .
downloads the basic code representation of a receipt from the given url . : param url : the url as a string . : return : the basic code representation as a string .
"extracts the url hash from the given url . if an anchor part is given , it is used as the hash . : param url : the url to search for the hash . : return : the hash as a base64 url encoded string without padding or none if the hash could not be found ."
this function returns the preferred chunksize that rksv script should use when none was specified . the default is 100000 . the value can be modified via the rksv_dep_chunksize environment variable . : return : an int specifying the default chunksize .
loads an aes-256 key from a cryptographic material container json . : param json : the json data . : return : the key as a byte list or none if there is no key element in the json .
hashes the given data using sha256 . : param data : the data to be hashed as a byte list . : return : the hashed data as a byte list .
encrypts the given data using aes-256 in ctr mode with the given iv and key . can also be used for decryption due to how the ctr mode works . : param iv : the iv as a byte list . : param key : the key as a byte list . : param data : the data to be encrypted as a byte list . : return : the encrypted data as a byte list .
creates a cryptography certificate object from the given pem certificate . : param pem : a certificate as a pem string . : return : a cryptography certificate object .
creates a cryptography public key object from the given pem public key . : param pem : a public key as a pem string . : return : a cryptography public key object .
creates a cryptography private key object from the given pem private key . : param pem : a private key as a pem string . : return : a cryptography private key object .
"converts a cryptography certificate object to a one - line pem string without header and footer ( i.e. the "" ----- ... "" lines ) . : param cert : the certificate object . : return : a string containing the pem certificate ."
"converts a cryptography public key object to a one - line pem string without header and footer ( i.e. the "" ----- ... "" lines ) . : param key : the public key object . : return : a string containing the pem public key ."
adds a certificate header and footer to a pem certificate string . : param cert : the pem certificate string . : return : the pem certificate string with header and footer .
adds a public key header and footer to a pem public key string . : param pubkey : the pem public key string . : return : the pem public key string with header and footer .
"verifies that a certificate has been signed with another . note that this function only verifies the cryptographic signature and is probably wrong and dangerous . do not use it to verify certificates . this function only supports ecdsa and rsa+pkcs1 signatures , all other signature types will fail . : param cert : the certificate whose signature we want to verify as a cryptography certificate object . : param signcert : the certificate that was used to sign the first certificate as a cryptography certificate object . : return : true if the signature is a valid ecdsa signature , false otherwise ."
gets a certificates sha256 fingerprint . : param cert : the certificate as a cryptography certificate object . : return : the fingerprint as a string .
restores the padding to a base64 string without padding . : param data : the base64 encoded string without padding . : return : the base64 encoded string with padding .
generates a new ec key pair usable for jws es256 . : return : the private and public key as objects .
generates a random serial number that can be used for a certificate . : return : the serial as an int .
"creates a certificate for a given public key and signs it with a given certificate and private key . it will reuse the subject of the signing certificate as the subject of the new certificate , only replacing the common name with the one given as parameter , if a signing certificate is specified , otherwise it will just use the given common name as subject and issuer . : param cpub : public key for which to create a certificate . : param ccn : common name for the new certificate . : param cvdays : number of days the new certificate is valid . : param cserial : the serial number for the new certificate as an int . : param spriv : private key for the signing certificate . : param scert : certificate used to sign the new certificate , or none if no certificate is used . : return : the new certificate as an object ."
removes the bom from utf-8 files so that we can live in peace . : param fd : the file descriptor that may or may not have a bom at the start . : return : the position after the bom as reported by fd.tell ( ) .
read a json file that may or may not have a bom .
overrides some methods or whatever class is passed as parameter . this is intended to allow for pickling / unpickling of certificate objects .
overrides some methods or whatever class is passed as parameter . this is intended to allow for pickling / unpickling of public key objects .
capture_output -- deprecated -- this always returns output now
adds an smtp user with credentials :
create a presentation with a page layout called mylayout add a presentation style for the title check that mylayout is listed in styles.xml
"create a text document with a page layout called "" pagelayout "" add a master page check that pagelayout is listed in styles.xml"
"create a text document with a page layout called "" pagelayout "" add a master page add an automatic style for the heading check that pagelayout is listed in styles.xml under automatic - styles check that the heading style is not listed in styles.xml check that the pagelayout is not listed in content.xml"
find the expected fields in the file
find the expected fields and values in the file
update fields in openoffice.org 3.x version of file .
return the polygon points
"the value of the viewbox attribute is a list of four numbers < min - x > , < min - y > , < width > and < height >"
check that a simple load works
"create a document , save it and load it"
test that a line break ( empty ) element show correctly
check that meta : generator is the original one
check that meta : generator is the original one
check that lists are loaded correctly
load a document containing tables
test that styles referenced from master pages are renamed in ooo 2.x documents
check that formula prefixes are preserved
check that formulas are understood when there are no prefixes
check that external entities are not loaded
load a document containing subobjects
load a document containing chinese content
"# if the object exists and has the attribute , set the variable if self.target_object and hasattr(self.target_object , self.var_name ): self.string_data.set(getattr(self.target_object , self.var_name ) ) self.string_entry.config(state = normal ) else : self.string_entry.config(state = disabled )"
convert bytes * b * to a string .
convert * value * to a string .
find the length of the integer part of a number * n * .
filter the dict * d * to remove keys not in * keys * .
return the unique items from iterable * seq * ( in order ) .
strip the ansi escape sequences from a string .
open and read the file * filename * .
test the convert_to_string ( ) function .
test the override_missing_values ( ) function .
test the bytes_to_string ( ) function .
test the align_decimals ( ) function .
test align_decimals ( ) with no results .
test align_decimals ( ) with non - decimals .
test the quote_whitespaces ( ) function .
test the quote_whitespaces ( ) function with no results .
test the quote_whitespaces ( ) function with non - spaces .
test that * style_output ( ) * does not style without styles .
test that * style_output ( ) * does not try to style without pygments .
test that * style_output ( ) * styles output .
test that * style_output ( ) * styles output with newlines in it .
test that * style_output ( ) * styles output with custom token names .
test formatting for an integer datatype .
"test formatting for a decimal(12 , 4 ) datatype ."
test formatting for a real datatype .
test that providing one format string works .
test that numbers are n't formatted without format strings .
test that numbers are n't formatted without column types .
initializes the suggestionlist .
clears all of the variables relating to the state of the quasimode 's generated information .
sets the user text based on the value of text .
sets the stored user text to the value indicated by the current autocompleted suggestion .
"while not good general coding style , this method deliberately encapsulates all the calls necessary to update the internal suggestion list and auto - completion objects , as such calls ( by their nature ) involve a fair amount of string processing and can be performance sensitive ."
"uses the commandmanager to determine if usertext auto - completes to a command name , and what that command name is ."
uses the command manager to determine if there are any inexact but near matches of command names to usertext .
"sets an internal variable telling the class that the suggestion list is "" dirty "" , and should be updated before returning any information ."
"in a pair with getautocompletion ( ) , this method gets the latest suggestion list , making sure that the internal variable is updated ."
"in a pair with getsuggestions ( ) , this method gets the latest auto - completion , making sure that the internal variable is updated ."
determines and returns the description for the currently active command .
"returns the active command , i.e. , the command object that implements the command that is currently indicated to the user , either as the auto - completed command , or as a highlighted element on the suggestion list . if there is no active command , then the function returns none ."
"determines the command name of the "" active "" command , i.e. , the name that is indicated to the user as the command that will be activated on exiting the quasimode ."
"changes which of the suggestions is "" active "" , i.e. , which suggestion will be activated when the user releases the capslock key ."
"sets the active suggestion to 0 , i.e. , the user 's text / auto - completion ."
main keyboard event loop
unlock gdk threading lock
halt thread : restart inner loop and kill outter loop
restart inner loop to use latest options
catch xlib errors
grab a specific key
ungrab a specific key
disable caps lock
enable caps lock
handle gobject timeout
handle callbacks from keylistener
main input events processing loop
stop main loop by exiting from gtk mainloop
helper function to get a keycode from raw key name
sanitize a single character keyval by attempting to convert it
восстанавливает регистр слова ( расположение строчных - заглавных букв ) .
взять данные из data_obj ( наследник datadictsource ) и сохранить из в специфичном для класса формате .
"подсчитать частоту , с которой встречаются различные правила . требуется для предсказателя , чтобы выбирать наиболее распространенные варианты ."
"возвращает ( lemma , paradigm_id , rule ) со всеми вариантами разбора слова ."
проверить словарь на корректность
"сравнить свои данные с данными из другого источника , считая самого себя непогрешимым ."
you can either provid a client_id and client_secret to the constructor or set spotipy_client_id and spotipy_client_secret environment variables
"if a valid access token is in memory , returns it else feches a new token and returns it"
gets client credentials access token
store some values that are n't directly provided by a web api response .
creates a spotifyoauth object
gets a cached auth token
gets the url to use to authorize this app
parse the response code in the given response url
gets the access token for the app given the code
store some values that are n't directly provided by a web api response .
"usage , { % if value|starts_with:""arg "" % }"
this import mnist and saves the data as an object of our dataset class : param concat_val : concatenate training and validation : return :
gets the eval step ` tensor ` value after running ` update_ops ` .
evaluates the model at the given checkpoint path .
parameters : - key
parameters : - key
creates a vm folder in the specified folder .
cleans a folder by selectively destroying any vms and folders it contains .
retrieves an item from a datacenter folder .
finds and returns an specific object in a folder .
traverses a folder path to find a object with a specific name .
enumerates a folder structure and returns the result .
converts a nested structure of folders into a formatted string .
retrieves vms and folders from a folder structure .
moves a list of managed entities into the named folder .
renames a folder .
: param dict infra : full infrastructure configuration : param dict spec : full exercise specification
waits for a single vim . task to finish and returns its result .
gets a human - readable summary of a datastore .
parameter values * are not * stored inside the class
"unlike in c++ , this must * return * a numpy array of parameters ."
"unlike in c++ , this takes a numpy array of parameters as input , and modifies it in - place . the return value is still logh."
gaussian sampling distribution .
try logging in using credentials stored on the disk .
returns the path of files in the sync folder without the leading folder separation character
tries to create local directories
returns the md5 hash of a local file
returns the time of the smartfile servers
"this should be tested more . if the offset calculation is incorrect , unchanged files will be put into sync up / down queues , and since a sync up on a file that has not been changed will cause corruption ."
check if the android sdk has been installed
setup the android sdk and ndk
test if provided build tool name is valid
get the default config name for this platform
"get the toolchain path location for a config , this first checks for a ' cmake - toolchain ' attribute , and if this does not exist , builds a xxx.toolchain.cmake file from the platform name ( only for cross- compiling platforms ) . toolchain files are searched in the following locations : - a fips - files / toolchains subdirectory in the project directory - a fips - files / toolchains subdirectory in all imported projects - finally in the cmake - toolchains subdirectory of the fips directory"
test if at least one matching config exists
"return list of config directories , including all imports"
"return { dir : [ cfgname , ... ] } in fips_dir / configs and proj_dir / fips - files / configs"
load one or more matching configs from fips and current project dir
check if a build tool is installed
check whether an external crossplatform - sdk is installed
"check if provided config is valid , and print errors if not"
[ xos - genx ] generate output from base.xproto
[ xos - genx ] generate output from base.xproto
[ xos - genx ] generate django output from test.xproto
"[ xos - genx ] read multiple models as input , print one file per model"
"[ xos - genx ] read multiple models as input , print separate files based on + + +"
"walk back along the path to the current module , searching for a version file"
test for importing a simple bpmneditor diagram example ( as bpmn 2.0 xml ) into inner representation and generating layout for it
test for importing a simple bpmneditor diagram example ( as bpmn 2.0 xml ) into inner representation and generating layout for it
test for importing a simple bpmneditor diagram example ( as bpmn 2.0 xml ) into inner representation and generating layout for it
"default constructor , initializes object fields with new instances ."
getter for ' default ' field . : return : a value of ' default ' field .
setter for ' default ' field . : param value - a new value of ' default ' field . must be either none ( default is optional according to bpmn 2.0 xml schema ) or string .
"this test will fail , but nobody cares because it passes on travis ."
make sure failing tests pass when running under ci .
make sure failing tests fail when not running under ci .
make sure failing tests pass when running under a custom ci .
the constructor for the archiveinfomsg class .
the main for the archiveinfomsg class
warn about the missing files in an archive
warn about the unexpected files in the archive
report differences between expected files and files in the archive
log the differences between the expected files and the files in the archive
log the uids and gids mismatches
log the unames and gnames mismatches
log the file mode mismatches
log the targe mismatches
log the file type mismatches
log the file mtime mismatches
log the file hash mismatches
the constructor for the placeholder class .
main of the placeholder class
return the path with the biggest integer in the same directory for the placeholder
return the real path afther placeholder replacement
execute callable produces an iterable .
execute this flow . req
returns str(option_string * dropdown value ) e.g. -vvvvv
primary test harness .
tests the happy path through the default run mode of gooey
tests the happy path through the subparser run mode of gooey
verifies that issue # 201 does n't regress and auto_start skips the config screen and hops right into the client 's program
verifies that custom validation routines supplied via gooey_options prevents the user from advancing past the configuration page when they fail
when the auto_start flag = = true gooey should skip the configuration screen
constructor period .
update the dynamic parameter values .
set all the dynamic parameter values to zero .
get inertia ( 3x3 ) matrix .
get mass tensor ( 3x1 ) column vector .
get spatial inertia ( 6x6 ) matrix .
get external force ( 6x1 ) column vector ( linear + angular ) .
get external force ( 3x1 ) column vector ( linear ) .
get external moment ( 3x1 ) column vector ( angular ) .
initialise inertial terms .
initialise mass tensor terms and mass of the link .
initialise rotor inertia and friction parameters .
initialise external force terms .
copies the inertia parameters . used for composed link inertia computation
generates a list of matrices . size of the list is number of links .
generates a list of vectors . size of the list is number of links .
generates a list of vars . size of the list is number of links .
generates a list of vectors for angular velocities . size of the list is number of links + 1 . the zero vector is the base angular velocity
generates a list of vectors for linear velocities . size of the list is number of links + 1 . the zero vector is the base angular velocity
generates lists of vectors for angular and linear accelerations . size of the list is number of links + 1 . the zero vector is the base angular velocity
generates a list of auxiliary u matrices
generates 6 - vector of different v elements ' product combinations
"returns : vertices , normals"
"returns : vertices , indices , normals"
"returns : vertices , indices , normals"
"returns : vertices , indices , normals"
"returns : vertices , indices , normals"
modify the signature in vin 0 of the tx to fail csv prepends -1 csv drop in the scriptsig itself .
modify the nsequence to make it fails once sequence lock rule is activated ( high timespan ) .
modify the nlocktime to make it fails once mtp rule is activated .
` listsinceblock ` did not behave correctly when handed a block that was no longer in the main chain :
one - time creation of app 's objects .
attaches the on_change event to the value property of the widget .
executes whenever the input form changes .
called each time that any watched property changes .
put together a : class:`netloc ` from its constituent parts .
"the username portion of this netloc , or ` ` none ` ` ."
replace or add a username to this netloc .
remove any username ( and password ) from this netloc .
"the password portion of this netloc , or ` ` none ` ` ."
replace or add a password to this netloc .
remove any password from this netloc .
the username and password of this netloc as a 2 - tuple .
replace or add a username and password in one method call .
the hostname portion of this netloc .
replace the hostname on this netloc .
"the port number on this netloc ( as an ` ` int ` ` ) , or ` ` none ` ` ."
replace or add a port number to this netloc .
remove any port number from this netloc .
replace any number of components on this netloc .
add documentation to a function .
"import module , returning the module after the last dot ."
add an item to six.moves .
remove item from six.moves .
return an iterator over the keys of a dictionary .
return an iterator over the values of a dictionary .
"return an iterator over the ( key , value ) pairs of a dictionary ."
create a base class with a metaclass .
获取所有 tag url
获取某 tag 下所有电影的详细 url
"获取某个电影 url 下详细信息，包括 title，year，director , writter , actor , category , district , language , date , time 返回：dict"
获取所有电影的 url 通过tags 来分类获取，由于数据较大，每次只跑一个tag，共35个tag 通过指定 index 可获取对应tag下的电影 url，放到movie_urls{index}.json 文件下（tag之间有重复，等所有爬取完成后再去重 ）
"initialize a rectangular sliding tile puzzle with size1 * size2 tiles . size1 gives the number of rows . the number of columns is given by size2 or size1 if size2 is none . the opptional seed argument is used to seed the random number generator for randomizing the initial puzzle layerout if it is set , so the same puzzle can be generated repeatedly by setting the same seed ."
return the winning color or none if the game is not over .
construct the maze based on the given width and height . all constructed mazes guarantee no loops and end to end visibility .
return the string representation of the maze with the player and finish line . : return :
"check if self is equal to other . : param other : another object : return : true if equality passes , false otherwise"
"return if the maze is solved yet . : return : true if solved , false otherwise"
return a list of valid moves . : return : array of moves .
"given a list of moves , return the string list of moves : param moves : list of move objects ( dict with move tuple ) : return : list of strings representing the moves"
"move the player within the maze . if the movement is invalid , print a message , do nothing . : param direction : string , direction to move in : return : none"
return the raw pythagorean distance from the player position to the goal . : return :
"calculate heuristic for maze completion : param name : ignoring the heuristic , only one heuristic ( pythagorean dist ) . placed for compatibility with existing search methods : return :"
return the string version of self . : return :
return a new object representing self . : return :
check if two puzzles are in the same state .
represent self as an array for web visualization . : return maze as 2d array of integers - 0 : free space - 1 : wall - 2 : player - 3 : goal
absolute exponential autocorrelation model . ( ornstein - uhlenbeck stochastic process ): :
"squared exponential correlation model ( radial basis function ) . ( infinitely differentiable stochastic process , very smooth ): :"
generalized exponential correlation model . ( useful when one does not know the smoothness of the function to be predicted . ): :
spatial independence correlation model ( pure nugget ) . ( useful when one wants to solve an ordinary least squares problem ! ): :
cubic correlation model : :
linear correlation model : :
"runs a single iteration of isotonic regression on the input data , and reports the total time taken ( in seconds ) ."
fit 's using kernel k
fit the model from data in x.
fit the model from data in x and transform x.
transform x back to original space .
return the disk usage in a directory .
convert a memory text to it 's value in kilobytes .
ensure directory d exists ( like mkdir -p on unix ) no guarantee that the directory is writable .
remove all subdirectories in this path .
tokenizer that maps all numeric tokens to a placeholder .
items of a defaultdict(int ) with the highest values .
fit kernel ridge regression model
predict using the kernel ridge model
returns the huber loss and the gradient .
fit the model according to the given training data .
compare analytic and numeric gradient of kernels .
check that parameter vector theta of kernel is set correctly .
auto - correlation and cross - correlation should be consistent .
test that diag method of kernel returns consistent results .
adding kernels and multiplying kernels should be commutative .
anisotropic kernel should be consistent with isotropic kernels .
test stationarity of kernels .
test that sklearn 's clone works correctly on kernels .
test consistency of matern kernel for special values of nu .
check that gp kernels can also be used as pairwise kernels .
check that set_params()/get_params ( ) is consistent with kernel.theta .
the function to predict ( classification will then consist in predicting whether g(x ) < = 0 or not )
test lda on empty document ( all - zero rows ) .
test cython version of dirichlet expectation calculation .
solve the isotonic regression model : :
build the f _ interp1d function .
build the y _ isotonicregression .
"fit the model using x , y as training data ."
pickle - protocol - return state of the estimator .
pickle - protocol - set state of the estimator .
perform affinity propagation clustering of data
"create affinity matrix from negative euclidean distances , then apply affinity propagation clustering ."
predict the closest cluster each sample in x belongs to .
"this mask is safer than safe_mask since it returns an empty array , when a sparse matrix is sliced with a boolean mask with all false , instead of raising an unhelpful error in older versions of scipy ."
return items or rows from x using indices .
resample arrays or sparse matrices in a consistent way
shuffle arrays or sparse matrices in a consistent way
element wise squaring of array - likes and sparse matrices .
generator to create n_packs slices going up to n.
get number of jobs for the computation .
fit the factoranalysis model to x using em
apply dimensionality reduction to x using the model .
compute data covariance with the factoranalysis model .
compute data precision matrix with the factoranalysis model .
compute the log - likelihood of each sample
get oauth credentials by user_id asynchronously
""" get oauth credentials by user_id synchronously"
return user_id part of key
get key by given user i d
returns query for scheduled tasks that are due at given datetime .
adds job to task queue and transactionally updates state to ' queued ' and saves job . does nothing if state is not ' scheduled ' .
schedules all due jobs queried by queue_due(now ) to the send queue .
query all jobs that have a scheduled date for at most delta_minutes ago .
"sends remind mail . if only_if_noreply is true , it is only sent if there was no reply ."
checks if there was a reply and disables job if there was .
checks if there was a reply . it loads the list of message ids in the thread and compares them to the known message ids when the reminder was scheduled . returns first unknown message in thread or none if there was no reply .
thread i d as integer .
"query all jobs that have state scheduled , queued or sent ( but not done ) or are done and have been scheduled for no longer than delta_minutes ago ."
"sends mail in to steps ( sending , and marking as sent ) that both can fail and be retried independently to minimize the effect of failures that lead to double sendings . the mail is guranteed to have been sent when state is sent or done . it is guranteed to have been marked as sent when state equals ' done ' ."
return a fixedoffset instance for the current working timezone and dst conditions .
encode a folder name using imap modified utf-7 encoding .
decode a folder name from imap modified utf-7 encoding to unicode .
extracts public key from x08 pem .
submit a task .
run a task flow worker ( conductor ) .
construct a post request from a picture and its thumbnail .
"encodes fields and files for uploading . fields is a sequence of ( name , value ) elements for regular form fields - or a dictionary . files is a sequence of ( name , filename , value ) elements for data to be uploaded as files . return ( content_type , body ) ready for urllib2.request instance you can optionally pass in a boundary string to use or we 'll let mimetools provide one ."
return none if inventory had no link for our markup .
return the link from inventory based on first package name .
returns the link from sphinx inventory based on a cross reference id specified in absolute dotted path and with a custom pretty text for the url .
"return the link from inventory using short names , by resolving them based on the imports done in the module ."
"a message is sent to stdout when no link could be found for the reference , while returning the reference name without an a link tag . the message contains the full name under which the reference was resolved ."
"ok , maybe argspec 's format is n't the best after all : this takes an argspec and returns ( regulararguments , [ ( kwarg , kwval ) , ( kwarg , kwval ) ] ) ."
"return a nicely - formatted source - like signature , formatted from an argspec ."
start and stop the server on the default port
try to create two instances on the same port
create two instances on different ports and start and stop them
add and remove many files to a server when it is not running
remove a stream that does not exist from server . no exception is raised when we delete streams that does not exist on server .
remove streams from server when it is running . no exception is raised when we delete streams that does not exist on server .
add files to server
it is not allowed to start or stop a server twice in a row
return covered module names as a nested dict .
run cherrypy.response through tidy .
"escape text , replacing space with nbsp and tab with 4 nbsp 's ."
"escape text , replacing newline with html br element ."
get html links to the streaming server 's media . if the streaming server is not running we will return a message ' streaming server is not running ' .
grabbed some of below from wsgiserver.py
run the given wsgi app and set response.body to its output .
generates a mask so that multiple recognitions of can be removed from an iou matrix .
removes rows and columns from a
"provides metrics for the fsns dataset . fm , precision , recall and correctsequences are an implementation of the metrics described in "" end - to - end interpretation of the french street name signs dataset "" [ https://link.springer.com/chapter/10.1007%2f978-3-319-46604-0_30 ] params : gtidtransdict : sample_id to data dictionary . a simple file name to file contents might do . methodidtransdict : sample_id to data dictionary . a simple file name to file contents might do ."
"converts rectagles defined by the top left corner , and the bottom - right corner to a quadrilateral defined by 4 points in clockwise order . if more than 4 columns are passed as input , the will be appended after the 8th column of the returned matrix ."
"converts quadrilaterals to the smallest axis - aligned rectangles defined by the top left and the bottom - right corners . if more than 8 columns are passed as input , the will be appended after the 4th column of the returned matrix ."
base class for db handlers
"check if a config file exists globally , otherwise create it ."
"get value from config or env , if the value is not in the config , prompt the user for it ."
get value from config or env if it exists .
parameters ---------- fpath : str the local file path of the hdf5 store
"make sure the ekf updates after a few imu , mag and baro updates"
"benchmark the time for an ekf update using just imu , mag and baro data"
make sure the ekf with zero inputs has reasonable status
make sure the ekf with zero inputs converges to / stays at zero
convert input to an array of 32 bit floats
updates the sensors with inputs
"provides an initialized ekf , ready to go"
"walk the index gathering inode , dir entry , and file nodes ."
get a list of ubi volume objects from list of blocks
set up routes with a version prefix .
return a copy of ` df ` with the columns renamed as in ` col_map ` . parameters ---------- df : pandas . dataframe
"return a values_map from data in ` df ` and the matching column and arguments names from ` df ` , ` crumb_arg_names ` and ` arg_names ` . parameters ---------- df : pandas . dataframe"
create a generator of crumbs filled with the ` df ` column names and ` crumb ` arguments that match or the ones indicated in ` names_map ` . parameters ---------- df : pandas . dataframe
sort features based on entropy
"recursive minimal entropy discretization ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` inputs : feature : a list or a numpy array of continuous attributes klass : a list , or a numpy array of discrete class labels . atleast : minimum splits . outputs : splits : a list containing suggested spilt locations"
a test function
"discretize a table ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` columns 1 to n-1 represent the independent attributes , column n the dependent ."
command or alias
detect whether the installed version of openpyxl is supported
build an absolute path from * parts * and and return the contents of the resulting file . assume utf-8 encoding .
extract _ _ * meta * _ _ from meta_file .
this initialiser sets up a connection to the specified gaffer server as per gafferconnector . gafferconnector and requires the additional pki object .
construct the credentials class from a pem file . if a password is not supplied and the file is password - protected then the password will be requested .
this method returns a ssl context based on the file that was specified when this object was created .
returns data required for an openid connect id token according to :
"returns data required for an openid connect userinfo response , according to :"
encode the set of claims to the jwt ( json web token ) format according to the openid connect specification :
the nonce in the id token should be the same nonce passed to the initial authorization call .
test if the responses contain the requested claims according to permissions
returns the subdirectory in ` userdata ` which acts as the root of the user - specific filesystem in steam ( aka all user - specific files are stored under this directory )
"returns the user 's config directory . this is normally not very useful , and consumers should look at ` custom_images_directory ` and ` shortcuts_path ` instead ."
"returns the path to the directory in which steam stores all of it 's custom grid images . the images are stored where the name is the app i d of the app whose image they want to override , and the extension is one of four valid extensions ."
"returns the path to the file in which steam stores its shortcuts . this file is a custom file format , so see the ` shortcuts ` module if you would like to read / write to this file ."
"generates the app i d for a given shortcut . steam uses app ids as a unique identifier for games , but since shortcuts do nt have a canonical serverside representation they need to be generated on the fly . the important part about this function is that it will generate the same app i d as steam does for a given shortcut"
"verify that an ioerror is raised , and that the errno and message are as expected"
makes an archive of a repository in the given destdir .
fixes for the following issues on windows - https://bugs.python.org/issue8557 - windows does not parse shebangs
on windows there 's a different directory for the virtualenv
install the pre - commit hooks .
uninstall the pre - commit hooks .
"do coying file . if target was existed then copying to review folder instead . in review folder , last number of filename is increased if file was existed ."
calculate age from self.birthday to date in exif tag
get sub - folder name from the create date in exif tag
"img : numpy array , 1 - mask , 0 - background returns run length as string formated"
"constructor , response_cb receive the response number , the new file selected and a list of the paths on the icon view . picture_path is the path of the current display picture"
builds up the ui
adds an image element in the view having the given view_name
"iteratively finds elements to be added to a view , and adds them"
returns the selected item
clear user avatar
removes all avatars from the cache
remove current selected avatar
remove all avatars from curent tab
"this slot is executed when the user clicks the ' add ' button . it shows up a file chooser , than if the image can be manipulate through toolkit function ( test is performed through picturehandler ) shows an image area selector . then , the image in added to the cache ( through avatarmanager object , and to the views"
this slot is called when the selected image in a view changes . currently it does n't anything useful nor interesting :p
"this method overrides okcanceldialog class ' _ on_accept . if the user clicks ' ok ' , set the selected image ( if any ) as the user 's avatar"
initialize the media call .
invite the peer for a call . @note the other participants need to have been previously set .
accept the call invitation .
reject the call invitation .
signal to the peer that we are waiting for the user approval .
end the call .
close the media session and dispose the call .
ensure handling an empty ver attribute propery .
ensure handling an empty ver attribute propery .
set the roster entries in the < roster > stanza .
return a dictionary of roster entries .
remove all < item > elements from the roster stanza .
accepts an invitation .
add a < nick > element with the given nickname .
return the nickname in the < nick > element .
remove the < nick > element .
return a dict representing the object
creates an event class that has the event list as constants starting with event _ and an uppercase string replacing the spaces with underscores
set the contents of the html body .
return the contents of the html body .
remove the html body contents .
renames a group to the address book .
resizes to new_size the given avatar pix . overrides base 's class abstract method .
saves the image to disk
returns true if the image is an animation
returns the toolkit - dependant object
"builds a picturehandler object from a pix object , whose type is gtk.gdk . pixbuf ."
updates the three submenus whenever contactmenu is shown
return the location of the user 's downloads folder
"run a command in the system and return the output , return none if something fails"
join the list of strings to the home folder
load the information of the theme on path
get the image path or else use the default image
testing using multiple instructions elements in a data form .
testing adding fields to a data form .
testing setting form values
test that setting type to ' submit ' clears extra details
test that setting type to ' cancel ' clears all fields
"return the value of the name config value , if not set then set it to default and return that value"
"load the config file from path , clear old values if clear is set to true"
save to a config file
connect to the server .
pre - process incoming xml stanzas by converting any ` ` ' jabber : client ' ` ` namespaced elements to the component 's default namespace .
"once the streams are established , attempt to handshake with the server to be accepted as a component ."
the handshake has been accepted .
process the session_start event .
process incoming message stanzas .
process the initial command result .
process an error that occurs during command execution .
compare the result of calling tostring against an expected result .
test escaping xml special characters .
test converting an empty element to a string .
test converting an empty element inside another element .
test converting an empty element wrapped with text inside another element .
test converting multiple child elements to a unicode string .
"test using xmlns tostring parameter , which will prevent adding an xmlns attribute to the serialized element if the element 's namespace is the same ."
"test that elements of the form < a > foo < b > bar</b > baz</a > only include "" baz "" once ."
test that stanza objects are serialized properly .
test that serializing xml : lang works .
adds a messenger contact and updates the address book .
handle requesting a specific resource .
augment the default xep-0030 static handler object .
replace the extended identity data for a jid / node combination .
add additional extended identity data for a jid / node combination .
replace the extended identity data for a jid / node combination .
load the config of the session
start the login process
send a common message
send typing notification to contact
request the attention of the contact
invite a contact to a conversation
send a file to the first user of the conversation
try to start a call with the first user of the conversation
return a list containing the contacts in the address book with the block flag set
return a list containing the contacts in the address book with the allow flag set
"return true if the contact has set the reverse flag and not the forward flag ; otherwise false . this means , contacts that are not in your contact list but they do have you"
"return true if the contact has set the forward flag and not the reverse flag ; otherwise false . this means , contacts that are in your contact list but they do n't have you"
return true if the contact has set the forward flag ; otherwise false
disconnects a single endpoint from msn
return the mail url for the service . if mail is n't supported returns none
load an image representing a status and store it on cache
draw random variables from the distribution
draw random variables from the distribution
( generalized ) lomb - scargle periodogram with floating mean
use a bootstrap analysis to compute lomb - scargle significance
compute the aic for a lomb - scargle periodogram
compute the bic for a lomb - scargle periodogram
perform a multiterm periodogram at each omega
utility routine to find the best frequencies
fit multiple fourier terms to the data
"compute the phased fit , and optionally return phased times"
loader for sdss galaxy colors .
it should call shortcut.setup
it should run the script file content on v8
it should propagate v8 exceptions
it should load the lib into the v8 context
draws a representation of the rectangle on the canvas .
draws a representation of the point on the canvas .
draws a representation of the circles on the canvas .
draws the national flag of the czech republic .
draws a representation of the polygon on the canvas .
draws a representation of the triangle on the canvas .
draws a representation of the trapezoidal on the canvas .
returns false if it violates an invariant otherwise true .
converts times to integers .
converts int to time .
returns a new time object that adds a given number of seconds to a time object .
returns a new time object that contains the product of the original time and the number .
returns a time object that represents the average pace(time per mile ) .
serializes an image / label as a tfexample byte string
deserializes a tfexample from a byte string
converts a vector / array into a csv string
converts a csv string to a vector / array
writes mnist image / label vectors into parallelized files on hdfs
reads / verifies previously created output
bottleneck residual unit variant with bn before convolutions .
generator for v2 ( preactivation ) resnet models .
resnet-50 model of [ 1 ] . see resnet_v2 ( ) for arg and return description .
resnet-101 model of [ 1 ] . see resnet_v2 ( ) for arg and return description .
resnet-152 model of [ 1 ] . see resnet_v2 ( ) for arg and return description .
resnet-200 model of [ 2 ] . see resnet_v2 ( ) for arg and return description .
alexnet version 2 .
get the visible width of a unicode string .
align a string with center / rjust / ljust and adds additional padding .
get maximum widths of each column in the table .
get the width and height of the terminal .
set the terminal title .
multipul file select with dialog
create radio button window for option selection
"create list with selectlist , and then return seleced string and index"
get selected check button options
get entries of the list
return available lapack function objects from names .
round floating - point lwork returned by lapack to integer .
"ugly , but people may rely on this . see scipy pull request 123 , specifically the linked ml thread "" width of the gaussian in stats.kde "" . if it is necessary to break this later on , that is to be discussed on ml ."
regression test for # 1181 .
modified weiszfeld step .
spatial median ( l1 median ) .
approximation of the breakdown point .
least squares estimator for theilsenregressor class .
fit linear model .
returns the nth item of a sequence ( eg . list or string )
slices a seuence from n1 to n2
appends a datum to a sequence
pops an item from the end of a sequence
reverses a sequence
return the length of a sequence
"returns # t if the sequence contains a. do not use this for string , use string::contains instead ."
repeats sequence1 i times
creates a list from the top 2 items on the stack
creates a list from the top 3 items on the stack
creates a list from the top i items on the stack not including i
unpacks a sequence
initialises all the parameters of the object .
generates code for all the languages defined in the object .
parses raw http request into separate dictionaries for headers and body and other parameters .
verify that a url ( containing the protocol ) is valid .
verify that a port is valid .
generate url based on the host .
initialize a paypalnvp instance from a httprequest .
flag this instance for investigation .
do a direct payment .
load1=2.470;5.000;10.000;0 ; load5=1.710;4.000;6.000;0 ; load15=1.290;3.000;4.000;0 ;
converts a given array into a max heap : param arr : input array of numbers
"assuming sub trees are already max heaps , converts tree rooted at current indx into a max heap . : param indx : index to check for max heap"
inserts an element in the max heap : param value : value to be inserted in the heap
deletes the value on the specified index node : param indx : index whose node is to be removed : return : value of the node deleted from the heap
extracts the maximum value from the heap : return : extracted max value
show bands as image with option of converting mask to alpha .
recursively create python dict 's to replace the nested xml structure
kickstarts the lti integration flow .
"returns information related to the current user : any linked course , assignment , etc . helps inform the app as to what to do next , for a given state ."
check that the client key is no shorter than lower and no longer than upper . removed bit about safe characters since it does n't allow common special characters like ' _ ' or ' . '
build a message context from a cloudifycontext instance
build a message context from a cloudifyworkflowcontext instance
build a message context from a cloudifyworkflowcontext instance
build a message context from a cloudifyworkflownode instance
instantiate an amqp backed logger based on the provided handler for sending log messages to rabbitmq
send a workflow event to rabbitmq
send a workflow event to rabbitmq
send a workflow node event to rabbitmq
send a plugin event to rabbitmq
send a task event to rabbitmq
see ` ` manager.get_node_instance_ip ` ` ( this method duplicates its logic for the sake of some minor optimizations and so that it can be used in local context ) .
return a celery app
"if the target is the mgmtworker queue , or if no tenants was passed use the default broker url . otherwise , create a tenant - specific one"
remove all cluster settings .
checks whether the page is already cached and returns the cached version if available .
"create or get a single permission based on its application label , its name and codename"
entry point for permission creation . will be called after db synchronisation for every installed app ( see settings . installed_apps )
get the latest release version from readme.md
get the project_number from a doxygen configuration file .
get the version or revision tag from an arbitrary file .
cmsis - core(m ) version
cmsis - core(a ) version
cmsis - dap version
cmsis - driver version
cmsis - dsp version
cmsis - nn version
cmsis - pack version
cmsis - rtos2 version
files referenced by pack description
"returns dict , where key is user uuid , and value is list of roles : staff , support , owner , expert ."
rudimentary parser for the ` requirements.txt ` file we just want to separate regular packages from links to pass them to the ` install_requires ` and ` dependency_links ` params of the ` setup ( ) ` function properly .
"returns slope and y - intercept of weighted linear fit to ( x , y ) data set . inputs : x and y data array and uncertainty array ( unc ) for y data set . outputs : slope and y - intercept of best fit to data and uncertainties of slope & y - intercept ."
setup argument parsing .
run the main application .
generate new secret string .
returns 1024 random bytes of data .
builds random strings based on random data .
returns ` ` str ` ` with a length between 16 and 64 .
returns ` ` str ` ` with a length between 48 and 64 .
returns ` ` str ` ` with a length of 24 or 32 .
simple form : value is a string
value is a mapping : script is a string
value is a mapping : script is a list
value is a mapping : script is a mapping ( invalid )
find_config can find the config in the current directory
find_config cuba can find the config in the parent directory
find_config can find the config way up the directory hierarchy
find_config raises configerror if the config can not be found
load_config raises configerror if the config is empty
load_config raises configerror on unexpected config node
load_config loads a minimal config
load_config loads a config with aliases
load_config refuses spaces in aliases
load_config loads a config using ! from_yaml
load_config loads a config using ! from_yaml with nested keys
load_config raises configerror when ! from_yaml references nonexistant key
load_config raises configerror when ! from_yaml references nonexistant file
load_config raises configerror when ! from_yaml has unicode args
load_config raises configerror when ! from_yaml has missing args
process_command handles no aliases and an empty command
process_command handles no aliases
process_command handles unused aliases
process_command handles aliases with no args
process_command handles aliases with args
process_command handles multiline aliases
process_command raises configerror when args are specified with multiline aliases
aliases can override the image
hooks of mixed forms are valid
"hooks with list not under "" script "" key are invalid"
"hooks with dict , but missing "" script "" are invalid"
find the downward closure of a set of vertices .
complete separations by adding all implicitly - separated vertices .
find edges which can be added to the hierarchy .
give alternate path if one exists .
find a spanning tree for a graph .
find the value of knowing about the existence of an edge .
find all new consistent connecting edges and their evaluations .
create a new gccassembler instance .
"load extra dependencies for the given object file path . the extra dependencies could be loaded from a generated dependency file for that path , or loaded from the emk.scope_cache(path ) ( or some other mechanism ) ."
returns a list of arguments to write secondary dependencies to the given dep_file path .
get the extension of object files built by this assembler .
rule function to assemble a source file into an object file .
calculates beta ( k_parallel to the planes ) as a function of wavelength ( nm ) and incident angle ( rad )
calculates light angular frequency as a function of wavelength ( nm )
"a , b , c , d , coefficients of the unit cell translation operator"
evaluates |0.5(a+d)-1| to study the photonic crystal bands
evaluates the bloch wavevector
evaluates the n - unit - cell translation operator
evaluates the additional operator for the incident medium
evaluates additional operator for the substrate
evaluates additional operator for the substrate
evaluates the reflectance for a symmetric structure
evaluates the reflectance for a general structure in the omega beta space
evaluates the reflectance for a general structure in the lambda theta space
test the function for filtering a list of dicts by ids .
parses the status log of openvpn .
from the blog post linked above .
get the data from our saved predictions or pooled features .
create our lstm
create a deeper lstm
create a wider lstm
create a wider lstm
write your forwards migration here
write your backwards migration here
overrides encoding when charset declaration or charset determination is a subset of a larger charset . created because of issues with chinese websites
"open the html document in a web browser , saving it to a temporary file to open it . note that this does not delete the file after use . this is mainly meant for debugging ."
reload image from disk . this facilitates re - loading of images from disk in case the image content changes .
get a list of all the fonts available on this system .
call rendering process using the ` root ` widget . the screenshot will be done in ` framecount ` frames .
"extend the run of unittest , to check if results directory have been found . if no results directory exists , the test will be ignored ."
"prepare the graphic test , with : - window size fixed to 320x240 - default kivy configuration - without any kivy input"
"internal method to be called when the window have just displayed an image . when an image is showed , we decrement our framecount . if framecount is come to 0 , we are taking the screenshot ."
"when the test is finished , stop the application , and unbind our current flip callback ."
render the new frames and :
create a motionevent instance with x and y of the first position a touch is at .
setting up test .
setting up test .
return a readeable diff report name using 2 reports
return a relative path of b from a.
generate a directory name for a report .
render stats .
create the rest file .
extract stat from the rest index file .
render rst stat .
build gnuplot script
setting up test .
setting up test .
fetch user for a given provider by i d.
tweaked version of check for replaced auth . user
create a random string for generating test data .
create a random email for generating test data .
create a random url for generating test data .
create a test user
create oauth provider .
create a test remote accountaccess
visualize the data
returns whether we are frozen via py2exe . this will affect how we find out where we are located .
"this will get us the program 's directory , even if we are frozen using py2exe"
expand the given build request by combining all property_sets which do n't specify conflicting non - free features .
"return the cross - product of all elements of property_sets , less any that would contain conflicting values for single - valued features ."
returns non - conflicting combinations of property sets .
"returns true if ' v ' is either implicit value , or the part before the first ' - ' symbol is implicit value ."
"takes the command line tokens ( such as taken from argv rule ) and constructs build request from it . returns a list of two lists . first is the set of targets specified in the command line , and second is the set of requested build properties ."
regression test for a boost build bug causing it to not use a generator if it got added after already building a targer of its target type .
regression test for a boost build bug causing it to not use a generator with a source type derived from one of the generator 's sources but created only after already using the generateor .
return true if the variable is odd .
return true if the variable is even .
check if a variable is divisible by a number .
return true if the variable is defined :
like : func:`defined ` but the other way round .
return true if the variable is none .
return true if the variable is lowercased .
return true if the variable is uppercased .
return true if the object is a string .
return true if the object is a mapping ( dict etc . ) .
return true if the variable is a number .
return true if the variable is a sequence . sequences are variables that are iterable .
check if an object points to the same memory address than another object :
check if it 's possible to iterate over an object .
check if the value is escaped .
register features need by this module .
clear the module state . this is mainly for testing purposes . note that this must be called _ after _ resetting the module ' feature ' .
"registers a target type , possibly derived from a ' base - type ' . if ' suffixes ' are provided , they list all the suffixes that mean a file is of ' type ' . also , the first element gives the suffix to be used when constructing and object of ' type ' . type : a string suffixes : none or a sequence of strings base_type : none or a string"
"specifies that targets with suffix from ' suffixes ' have the type ' type ' . if a different type is already specified for any of syffixes , issues an error ."
returns true iff type has been registered .
issues an error if ' type ' is unknown .
sets a scanner class that will be used for this ' type ' .
returns a scanner instance appropriate to ' type ' and ' property_set ' .
returns a base type for the given type or nothing in case the given type is not derived .
"returns type and all of its bases , in the order of their distance from type ."
"returns type and all classes that derive from it , in the order of their distance from type ."
returns true if ' type ' is ' base ' or has ' base ' as its direct or indirect base .
same as is_derived . should be removed .
"sets a target suffix that should be used when generating target of ' type ' with the specified properties . can be called with empty properties if no suffix for ' type ' was specified yet . this does not automatically specify that files ' suffix ' have ' type ' --- two different types can use the same suffix for generating , but only one type should be auto - detected for a file with that suffix . user should explicitly specify which one ."
"change the suffix previously registered for this type / properties combination . if suffix is not yet specified , sets it ."
"returns suffix that should be used when generating target of ' type ' , with the specified properties . if not suffix were specified for ' type ' , returns suffix for base type , if any ."
"returns file type given it 's name . if there are several dots in filename , tries each suffix . e.g. for name of "" file.so.1.2 "" suffixes "" 2 "" , "" 1 "" , and "" so "" will be tried ."
"register the given type on the specified oses , or on remaining oses if os is not specified . this rule is injected into each of the type modules for the sake of convenience ."
"if < location > is not set , sets it based on the project data ."
"given the list of source targets explicitly passed to ' stage ' , returns the list of targets which must be staged ."
use sha1 for more accuracy .
difference of 2 objects
the main diff method
short representation of item if it is too long
start record .
stop record .
play current recording .
location of the recording .
returns ` true`if the wifi is enables else ` false ` .
turn on scanning .
return a dictionary of secified network .
returns a list of all the available wifi .
method to connect to some network .
to disconnect from some network .
this method provides sending messages to recipients .
return true or false depending if there is an object or not .
enable the proximity sensor .
disable the proximity sensor .
is a given sequence of labels impossible ? yes ... suck it eg:- ఏ followed by anything but an ఎ : param chars : : return : boolean true if seq is impossible
"computes ` log(exp(a).sum(axis = axis ) ) ` avoiding numerical issues using the log - sum - exp trick . direct calculation of : math:`\log \sum_i \exp a_i ` can result in underflow or overflow numerical issues . big positive values can cause overflow : math:`\exp a_i = \inf ` , and big negative values can cause underflow : math:`\exp a_i = 0 ` . the latter can eventually cause the sum to go to zero and finally resulting in : math:`\log 0 = -\inf ` . the log - sum - exp trick avoids these issues by using the identity , .. math : : \log \sum_i \exp a_i = \log \sum_i \exp(a_i - c ) + c , ext{using } , \ c = \max a. this avoids overflow , and while underflow can still happen for individual elements it avoids the sum being zero . parameters ---------- a : theano tensor tensor of which we wish to compute the log - sum - exp . axis : int , tuple , list , none axis or axes to sum over ; none ( default ) sums over all axes . sum_op : function summing function to apply ; default is t.sum , but can also be t.mean for log - mean - exp ."
computes ` log(exp(a).mean(axis = axis ) ) ` avoiding numerical issues using the log - sum - exp trick . see also -------- log_sum_exp
make all yaml dictionaries load as ordered dicts .
special dumper wrapper to modify the yaml dumper .
convert yaml timestamp format .
convert specific serialized objects before converting to yaml .
read yaml from a sublime view .
wrapper for yaml dump .
"lookup a trace by session and trace session id , then print it ."
print an already populated cassandra.query . querytrace instance .
convert a timedelta into total microseconds
acceptable contents : list(array ) of data
acceptable contents : list(array ) of data
a test using the pickled whole ast from one of the stencil kernel test cases .
directory where cache files should be put guaranteed to exist
"return path to @filename if it exists anywhere in the data paths , else raise resourcelookuperror ."
"return filename in the xdg data home directory , where the directory is guaranteed to exist"
directory where data is to be saved guaranteed to exist
iterate over all data dirs of @name that exist
"return path to @package/@filename if it exists anywhere in the config paths , else return none"
"iterator to @filename in all config paths , with most important ( takes precendence ) files first"
"return filename in the xdg data home directory , where the directory is guaranteed to exist"
"create dbus connection to gtg @activate : if true , start program if not running"
load task by dbus interface
yield items of @seq with set semantics ; no duplicates
query the firefox places bookmark database
"record that kupferobject @obj was used , with the optional search term @key recording"
"get total score for kupferobject @obj , bonus score is given for @key matches"
get the bonus rank for @obj when used with @for_leaf
register @obj to get a bonus when used with @for_leaf
return if @obj has any positive score in the register
remove all track of affinity for @obj
remove items with chance ( len/25000 )
load learning database
save the learning record
decrement total count and the least mnemonic
return true if groupedleaf has value for @key
get first ( canonical ) value for key
return iterator of all values for @key
check if groupedleaf has non empty value for @key
register that @filepath may appear soon @ctx : the action 's execution context token
"read an entire file into a string , in practice the wrapper node.read ( .. ) should be used instead of this method : :"
compute a hash value for a file by using md5 . this method may be replaced by a faster version if necessary . the following uses the file size and the timestamp value : :
"convert a string , tuple or version number into an integer . the number is supposed to have at most 4 digits : :"
extract the stack to display exceptions
"convert a string argument to a list by splitting on spaces , and pass through a list argument unchanged : :"
parse a string with key = value pairs into a dictionary : :
ensure that a directory exists ( similar to ` ` mkdir -p ` ` ) .
set default attributes on a class instance
convert a string to an identifier suitable for c defines .
"hash lists . for tuples , using hash(tup ) is much more efficient"
replace $ { var } with the value of var taken from a dict or a config set : :
return the binary format based on the unversioned platform name .
"return the unversioned platform name . some python platform names contain versions , that depend on the build environment , e.g. linux2 , freebsd6 , etc . this returns the name without the version number . exceptions are os2 and win32 , which are returned verbatim ."
a function that does nothing
"read property files , used by msvc.py"
decorator : let a function disable the garbage collector during its execution . it is used in the build context when storing / loading the build cache file ( pickle )
"decorator : let a function cache its results , use like this : :"
"yield tuples of ( pid , cpu , mem , ptime , cmd )"
check if skype is running and login to it . return skype proxy object .
@filepath is a filesystem byte string ` str `
return the dbus proxy object for our note application .
find @tag in childs of @node and return text from it . if @tag is not found - return none
"list the data , and return lookup to user"
load_dataset will return some data provided for the competition
"get_data_file returns the file for the dataset , or none if does n't exist"
make sure json library being used does not lose precision converting btc values
return the default location of the diamond data directory
"read the diamond.conf file from dbdir , returns dictionary of settings"
connect to a diamond json - rpc server
define what constitutes an identifying key for a rule type object . the rule 's type as a string concatenated with the rule 's contents was considered to be uniquely identifying . args : none
"parse a string representation and return an equivalent rule . type enumeration value . a string representation is used in the input data files , however the enumeration allows for faster comparisons . this function is a convenience to make it easier to scan the appropriate input files . args : rule_type ( string ): string representation of a type of rule ."
writes a single x vector of features in a one hot inspired representation to the out_features file .
"finds all names in options.attestations file , and goes through each word in the main options.corpus file to create a sparse matrix file to be used with scikit learn ."
calculate the byte wise exclusive of of two : class:`bytes ` objects of the same length .
instantiate rangebasedpagination .
generate data for rendering the current page .
order queryset for pagination .
filter queryset for pagination .
limit queryset for pagination .
"fetch all items from the resulting queryset , and order the list of items in the page , if needed ."
get pagination links for the current page .
get page key for an item in a page .
get paginated link for a page .
get current revision .
restore redis revision from db .
returns a list translated unit uids from ~middle of translated units dataset
returns ` true ` if items in ` left ` list are equal to items in ` right ` list .
convenience function to create and setup fake requests .
returns file store with added translations for untranslated units .
tests that the creation of a virtual folder fails if the provided priority is not greater than zero .
tests that the creation of a virtual folder fails if it does n't have any filter rules .
export whole site
export a project
export a project tp
export a language
export a path
export an unknown path
export a tp
export a tp
returns a formatted string for the non - zero items of a ` changes ` dictionary .
get handler .
returns a single model instance .
retrieve a full collection .
creates a new model instance .
update the current model .
delete the model and return its json representation .
convert a queryset to values for further serialization .
tells if tm is automatically updated from db translations .
search for tm results .
add a unit to the backend
check that the request is an ajax request .
dump requires an output option .
--data output .
--stats output .
set the depth for data .
--data output with tp selection .
--stats output with tp selection
return an absolute path for : param:`filename ` by joining it to ` ` working_dir ` ` .
site wide sync_stores
site wide sync_stores
site wide sync_stores
get the pret mappings from the site config
get the projects mapping from the project.config
get the projects mapping from the project.config
language mappings after project.config and presets are parsed
return a ` language ` for a given code after mapping
returns a pootle code for a given upstream code
returns an upstream code for a given pootle code
missing vfolder argument .
no file on filesystem .
load an empty vfolder.json file
sends sms through sms jazz gateway
the first phase of a gsx search . sets up the gsx connection . @todo : should this be in device.from_gsx ( ) ?
the second phase of a gsx search . there should be an active gsx session open at this stage .
searches our local inventory
searches local service orders
"searches for customers from "" spotlight """
searching for devices from the main navbar
searches for local notes
"searches for anything and redirects to the "" closest "" result view . gsx searches are done separately ."
return text as a barcode .
prepare the view for listing notes / messages .
copy a note with its attachments and labels .
edit a note .
deletes a note
renders the template with this title with the current service order as the context
"toggles a flag of a note ( read / unread , flagged / not , reported / not )"
notes advanced search
submits the po as a gsx stocking order using the default gsx account .
creates a new purchase order
creates an object with the given key and value and puts the object in the specified container
creates an object of the file and stores it into the container as key - value object
"let : math:`g ` be a directed graph , and : math:`v ` be node of : math:`g ` . a node : math:`u ` is * adjacent * to : math:`v ` if : math:`vu ` is an edge ."
"function for finding the edges of the cayley graph . each edge is represented by a tuple , with first entry representing the start node , and second entry representing the end node ."
function for finding the nodes of the cayley graph .
"let : math:`g ` be a directed graph . a * path * on : math:`g ` is a sequence : math:`(v_n)_n ` of nodes of : math:`g ` , such that : math:`v_nv_{n+1 } ` is an edge : math:`\forall n ` ."
the ' reorder ' admin view for this model .
get the numba type of a python value for the given purpose .
generic typeof ( ) implementation .
type various specific python types .
returns the string representation of a given record . this is what is displayed in the results page .
get current absolute position and position change
点击挑战按钮 : return :
章节 by @zxjay
"first look for and initialize apis in the "" api_library "" folder . then prompt the user to log in . next verify that the user 's .yml file is configured for each api . if an api 's required configuration variables are not found , then the api is disabled . next it finds and loads modules in the "" modules "" folder . lastly , it initializes the stt engine ."
returns a list of available user strings
verify that at least 1 user exists
load ( username).yml data into the user
prompts a user to login ( if more than one available )
greet the user
executes a module 's task queue
executes the modules in prioritized order
prompt user to specify which module to use to respond
attempts to match a modules and their tasks
inform the user that an error occurred
"listen for input , match the modules and respond"
"create a bounding box vector object or shapefile from coordinates and coordinate reference system coordinates must be provided in a dictionary containing numerical variables with names ' xmin ' , ' xmax ' , ' ymin ' and ' ymax ' the coordinate reference system can be in either wkt , epsg or proj4 format"
"type can be either "" epsg "" , "" wkt "" , "" proj4 "" or "" osr """
export the geometry of each feature as a wkt string
"to verify that the rest service is working , get the blueprints list ."
get postgresql configuration needed to generate logstash.conf file .
install plugin .
""" install filter plugin needed to encode json data ."
""" install output plugin needed to write to sql databases ."
install driver used by the jdbc plugin to write data to postgresql .
install logstash as a systemd service .
get rabbitmq configuration needed to generate logstash.conf file .
sets an environment variable to a given value ; unsets it when the given value is none .
runs a command ; returns true / false if its exit code is / isn't 0 .
runs gtest_throw_on_failure_test _ and verifies that it does ( or does not ) exit with a non - zero code .
tests the behavior of the default mode .
tests using the gtest_throw_on_failure environment variable .
tests using the --gtest_throw_on_failure flag .
tests that --gtest_throw_on_failure overrides gtest_throw_on_failure .
runs the given command and verifies its exit code and output .
runs gtest_help_test _ with the given flag .
verifies correct behavior when help flag is specified .
verifies correct behavior when no help flag is specified .
"verifies that when no help flag is specified , the tests are run and the help message is not printed ."
verifies that the tests are run and no help message is printed when a flag starting with google test prefix and ' internal _ ' is supplied .
find key item in nested dictionary .
download the specified github repo .
find the version of the repo 's latest published release .
construct a common platform enumeration ( cpe ) for a given software .
display the risk metrics created on the repo to stdout .
check that the data in this : class:`atom ` is valid
the subler argument formatted version of this : class:`atom `
create a subler tagging instance
generate a destination file name for the provided source file . this function will increment a number to append to the file name in order to distinguish it from other copies of the same file name
the current version of your systems sublercli package
a list of tracks found the source file
the metadata currently contained in the source file
atom representations of the metadata currently contained in the source file
atomcollection representation of the metadata currently contained in the source file
"the content rating of the source file . valid us content ratings are : not rated , g , pg , pg-13 , r , nc-17 , tv - y , tv - y7 , tv - g , tv - pg , tv-14 , tv - ma , and unrated . valid uk content ratings are : not rated , u , uc , pg , 12 , 12a , 15 , 18 , r18 , exempt , unrated , and caution . valid german content ratings are fsk 0 , fsk 6 , fsk 12 , fsk 16 , and fsk 18 ."
"we will only update the rating provided if * new_rating * is a valid , subler - supported rating ."
"the type of media encapsulated in the source file . valid values are : music , audiobook , music video , movie , tv show , booklet , or ringtone"
"the explicit rating of the content in the source file . valid explicit ratings are : none , "" clean "" , and "" explicit """
"if we do n't receive a valid explicitness rating , we 'll ignore it"
apply the specified metadata to the source file and output it to the specified destination file
runs tool specified by ` ` tool_id ` ` in history indicated by ` ` history_id ` ` with inputs from ` ` dict ` ` ` ` tool_inputs ` ` .
returns a ( possibly filtered ) list of dictionaries that include information about all repository revisions . the following parameters can be used to filter the list .
read local file contents from file_local_path and upload data to a library .
display information about the user associated with this galaxy connection .
update an existing quota
delete a user .
display information about a user .
undelete a history
get the list of all forms .
create a folder .
create a new api key for a given user .
get the list of all installed sniffers .
get details of a given tool shed repository as it is installed on this galaxy instance .
"returns the ordered list of changeset revision hash strings that are associated with installable revisions . as in the changelog , the list is ordered oldest to newest ."
install dependencies for a given tool via a resolver . this works only for conda currently . this functionality is available since galaxy release_16.10 and is available only to galaxy admins .
"get all tools or filter the specific one(s ) via the provided ` ` name ` ` or ` ` tool_id ` ` . provide only one argument , ` ` name ` ` or ` ` tool_id ` ` , but not both ."
remove a role from the given group .
nature of this action and what is expected will vary based on the the type of workflow step ( the only currently valid action is true / false for pause steps ) .
see the details of a particular workflow invocation step .
returns a list of installed genomes
exports a workflow in json format to a given local path .
"test public interface , which documented in docs / usage - python.md and people can use this attribute in python - code"
return the set of all nodes that can be visited in the graph from start node
return if there is a possible path from start node to end node in the graph
changes all windows / mac line endings in s to unix line endings .
removes google test result report 's header and footer from the output .
removes all file location info from a google test program 's output .
"normalizes the error marker , which is different on windows vs on linux ."
removes memory addresses from the test output .
removes the test names of leaked mock objects from the test output .
returns a list of test names that leak mock objects .
normalizes the output of gmock_output_test _ .
"runs a command in a sub - process , and returns its stdout in a string ."
runs a command and returns its normalized output and a list of leaky tests .
tests act using an lstm for the core .
tests act using an lstm for the core .
custom getter which makes a variable non - trainable .
处理从ricequant下载的分钟线数据 ， 从分钟线数据合成低频数据 2017 - 08 - 11
constructs alexnet .
calculates the minimum size of the input layer .
connects the alexnet module into the graph .
returns integer specifying the minimum width and height for the input .
returns list containing convolutional modules of network .
returns list containing linear modules of network .
process a line and optionally transform it .
abstract method that should be overwritten .
abstract method that should be overwritten .
core functionality of command output processor .
"indicates it text contains sections of interest . : param text : text to inspect ( as string ) . : return : true , if text contains traceback sections . false , otherwise ."
normalizes multi - line text by applying the line processors .
"find the variable in the environment , a .env file , or use a default"
convert a datetime string ( utc ) into a date string in iso format
convert a datetime string ( utc ) into a pretty date string
bootstrap a jailhost that 's been booted into mfsbsd .
a decorator to patch new method into a class .
a decorator to patch datetime.now in target . now .
a decorator to patch random in target . random .
a decorator .
executes all pending deferred tasks .
return first release in which this feature was recognized .
return release in which this feature will become mandatory .
same as a < b.
same as a < = b.
same as a = = b.
same as a ! = b.
same as a > = b.
same as a > b.
same as not a.
"return true if a is true , false otherwise ."
same as a is b.
same as a + b.
same as a & b.
same as a // b.
same as a.__index _ _ ( ) .
same as ~a .
same as a < < b.
same as a % b.
same as a * b.
same as -a .
same as a | b.
same as + a.
same as a * * b.
same as a > > b.
same as a - b.
same as a / b.
same as a ^ b.
"same as a + b , for a and b sequences ."
same as b in a ( note reversed operands ) .
return the number of times b occurs in a.
same as del a[b ] .
same as a[b ] .
return the first index of b in a.
same as a[b ] = c.
same as a + = b.
same as a & = b.
"same as a + = b , for a and b sequences ."
same as a //= b.
same as a < < = b.
same as a % = b.
same as a * = b.
same as a |= b.
same as a * * = b.
same as a > > = b.
same as a -= b.
same as a /= b.
same as a ^= b.
return an estimate of the number of items in obj . this is useful for presizing containers when building from an iterable .
return a list of paths matching a pathname pattern .
return an iterator which yields the paths matching a pathname pattern .
escape all special characters .
update a wrapper function to look like the wrapped function
decorator factory to apply update_wrapper ( ) to a wrapper function
class decorator that fills in missing ordering methods
convert a cmp= function into a key= function
make a cache key from optionally typed positional and keyword arguments
least - recently - used cache decorator .
return current line number and offset .
"getopt(args , options [ , long_options ] ) - > opts , args"
"getopt(args , options [ , long_options ] ) - > opts , args"
free the memory used by the c++ object .
ensures the table exists and has the correct schema .
"returns a set of ( app , name ) of applied migrations ."
records that a migration was applied .
records that a migration was unapplied .
deletes all migration records . useful if you 're testing migrations .
returns a httpresponse whose content is filled with the result of calling django.template.loader.render_to_string ( ) with the passed arguments .
returns a httpresponse whose content is filled with the result of calling django.template.loader.render_to_string ( ) with the passed arguments .
returns an httpresponseredirect to the appropriate url for the arguments passed .
return a queryset or a manager . duck typing in action : any class with a ` get ( ) ` method ( for get_object_or_404 ) or a ` filter ( ) ` method ( for get_list_or_404 ) might do the job .
"uses get ( ) to return an object , or raises a http404 exception if the object does not exist ."
"uses filter ( ) to return a list of objects , or raise a http404 exception if the list is empty ."
return a url appropriate for the arguments passed .
create a package finder appropriate to this list command .
returns ` true ` if the label based on the model 's verbose name is not equal to the default label it would have based on it 's field name .
"given a model class , return the view name to use for url relationships that refer to instances of the model ."
creates a default instance of a basic non - relational field .
creates a default instance of a flat relational field .
parses a string and return a datetime.date .
parses a string and return a datetime.time .
parses a string and return a datetime.datetime .
parses a duration string and returns a datetime.timedelta .
uniformly trim leading / trailing whitespace from docstrings .
"parse out the parts of a docstring . return ( title , body , metadata ) ."
convert the string from rest to an xhtml fragment .
"find named groups in ` pattern ` and replace them with the group name . e.g. , 1 . ^(?p < a>\w+)/b/(\w+)$ = = > ^<a>/b/(\w+)$ 2 . ^(?p < a>\w+)/b/(?p < c>\w+)/$ = = > ^<a>/b/<c>/$"
"find unnamed groups in ` pattern ` and replace them with ' < var > ' . e.g. , 1 . ^(?p < a>\w+)/b/(\w+)$ = = > ^(?p < a>\w+)/b/<var>$ 2 . ^(?p < a>\w+)/b/((x|y)\w+)$ = = > ^(?p < a>\w+)/b/<var>$"
return true if the media type is a valid form media type .
"internal helper method to clone a request , replacing with a different http method . used for checking permissions against other methods ."
returns an object that may be used to stream the request content .
more semantically correct name for request . get .
"returns the user associated with the current request , as authenticated by the authentication classes provided to the request ."
sets the user on the current request . this is necessary to maintain compatibility with django.contrib.auth where the user property is set in the login and logout functions .
"returns any non - user authentication information associated with the request , such as an authentication token ."
"sets any non - user authentication information associated with the request , such as an authentication token ."
"return the instance of the authentication instance class that was used to authenticate the request , or ` none ` ."
parses the request content into ` self.data ` .
"return the content body of the request , as a stream ."
return true if this requests supports parsing form data .
"parse the request content , returning a two - tuple of ( data , files )"
"attempt to authenticate the request using each authentication instance in turn . returns a three - tuple of ( authenticator , user , authtoken ) ."
"set authenticator , user & authtoken representing an unauthenticated request ."
"if an attribute does not exist on this instance , then we also attempt to proxy it to the underlying httprequest object ."
returns ` ` true ` ` if the media type in the first argument < = the media type in the second argument . the media types are strings as described by the http spec .
"returns a list of sets of media type strings , ordered by precedence . precedence is determined by how specific a media type is :"
return true if this mediatype satisfies the given mediatype .
return a precedence level from 0 - 3 for the media type given how specific it is .
"given a path to a handler , return an instance of that handler ."
"if ` ` connection_reset ` ` is ` ` true ` ` , django knows will halt the upload without consuming the rest of the upload . this will cause the browser to show a "" connection reset "" error ."
handle the raw input from the client .
signal that a new file has been started .
receive data from the streamed upload parser . ` ` start ` ` is the position in the file of the chunk .
signal that a file has completed . file size corresponds to the actual size accumulated by all the chunks .
signal that the upload is complete . subclasses should perform cleanup that is necessary for this handler .
create the file object to append to as data is coming in .
use the content_length to signal whether or not this handler should be in use .
add the data to the bytesio file .
return a file object if we 're activated .
short - hand representation because wkb may be very large .
"flush all data from memory into the source file if it exists . the data that needs flushing are geotransforms , coordinate systems , nodata_values and pixel values . this function will be called automatically wherever it is needed ."
returns the name of this raster . corresponds to filename for file - based rasters .
returns the gdal driver used for this raster .
width ( x axis ) in pixels .
height ( y axis ) in pixels .
returns the spatialreference used in this gdalraster .
sets the spatial reference used in this gdalraster . the input can be a spatialreference or any parameter accepted by the spatialreference constructor .
shortcut to access the srid of this gdalraster .
shortcut to set this gdalraster 's srs from an srid .
"returns the geotransform of the data source . returns the default geotransform if it does not exist or has not been set previously . the default is [ 0.0 , 1.0 , 0.0 , 0.0 , 0.0 , -1.0 ] ."
sets the geotransform for the data source .
coordinates of the raster origin .
pixel scale in units of the raster projection .
skew of pixels ( rotation parameters ) .
"returns the extent as a 4 - tuple ( xmin , ymin , xmax , ymax ) ."
returns a warped gdalraster with the given input characteristics .
returns a copy of this raster reprojected into the given srid .
cleans an ipv6 address string .
sanitize ipv4 mapping in an expanded ipv6 address .
unpack an ipv4 address that was mapped in a compressed ipv6 address .
ensure we have a valid ipv6 address .
expand a shortened ipv6 address .
determine if the address is shortened .
creates the sql for this query . returns the sql string and list of parameters . this is overridden from the original query class to handle the additional sql oracle requires to emulate limit and offset .
create a copy of this index .
generate a 32 - bit digest of a set of arguments that can be used to shorten identifying names .
generate a unique name for the index .
"run this to determine if the local machine has win32com , and if it does , include additional tests ."
it should be possible to execute a setup.py with a byte order mark
run the old syncdb - style operation on a list of app_labels .
include a login snippet if rest framework 's login view is in the urlconf .
include a login snippet if rest framework 's login view is in the urlconf .
include a logout snippet if rest framework 's logout view is in the urlconf .
"add a query parameter to the current request url , and return the new url ."
simple filter to return the items of the dict . useful when the dict may have a key ' items ' which is resolved first in django tempalte dot - notation lookup . see issue # 4931 also see : https://stackoverflow.com/questions/15416662/django-template-loop-over-dictionary-items-with-items-as-key
"simple wrapper for smart_urlquote . valueerror(""invalid ipv6 url "" ) can be raised here , see issue # 1386"
converts any urls in text into clickable links .
breaks headers longer than 160 characters ( ~page length ) when possible ( are comma separated )
"given an incoming request , and an outgoing url representation , append the value of any built - in query parameters ."
"if versioning is being used then we pass any ` reverse ` calls through to the versioning scheme instance , so that the resulting url can be modified if needed ."
"same as ` django.urls.reverse ` , but optionally takes a request and returns a fully qualified url , using the request to get the base url ."
gets a single list of messages from all storage backends .
"stores the messages , returning any unstored messages after trying all backends ."
"fetch a given key from the cache . if the key does not exist , the key is added and set to the default value . the default value can also be any callable . if timeout is given , that timeout will be used for the key ; otherwise the default cache timeout will be used ."
"gather details from installed distributions . print distribution name , version , location , and installed files . installed files requires a pip generated ' installed-files.txt ' in the distributions ' .egg - info ' directory ."
print the informations from installed distributions found .
"build modules , packages , and copy data files to build directory"
"generate list of ' ( package , src_dir , build_dir , filenames ) ' tuples"
return filenames for package 's data files in ' src_dir '
copy data files into build directory
check namespace packages ' _ _ init _ _ for declare_namespace
filter filenames for package 's data files in ' src_dir '
"return ` true ` if permission is granted , ` false ` otherwise ."
"return ` true ` if permission is granted , ` false ` otherwise ."
"given a model and an http method , return the list of permission codes that the user is required to have ."
returns the correct stdcall function for certain osr routines on win32 platforms .
returns only the gdal version number information .
returns the full gdal version information .
returns a lazy ' messages ' context variable .
gets a ctypes pointer array ( of length ` n ` ) for geosgeom_t opaque pointer .
"returns a dictionary containing the various version metadata parsed from the geos version string , including the version number , whether the version is a release candidate ( and what number release candidate ) , and the c api version ."
default view used when request fails csrf protection
special case when dimension changed .
"perform the caching that gives this loader its name . often many of the templates attempted will be missing , so memory use is of concern here . to keep it in check , caching behavior is a little complicated when a template is not found . see ticket # 26306 for more details ."
"generate a cache key for the template name , dirs , and skip ."
"returns the given text with ampersands , quotes and angle brackets encoded for use in html ."
hex encodes characters for use in javascript strings .
"similar to escape ( ) , except that it does n't operate on pre - escaped strings ."
"similar to str.format , but passes all arguments through conditional_escape , and calls ' mark_safe ' on the result . this function should be used instead of str.format or % interpolation to build up small html fragments ."
"a wrapper of format_html , for the common case of a group of arguments that need to be formatted using the same format string , and then joined using ' sep ' . ' sep ' is also passed through conditional_escape ."
converts newlines into < p > and < br />s .
internal tag stripping utility used by strip_tags .
returns the given html with all tags stripped .
returns the given html with spaces between tags removed .
quotes a url if it is n't already quoted .
converts any urls in text into clickable links .
avoid text wrapping in the middle of a phrase by adding non - breaking spaces where there previously were normal spaces .
a decorator that defines the _ _ html _ _ method . this helps non - django templates to detect classes whose _ _ str _ _ methods return safetext .
"extract the size number from a "" varchar(11 ) "" type name"
returns a list of table and view names in the current database .
"returns a description of the table , with the db - api cursor.description interface ."
"sqlite will in some cases , e.g. when returning columns from views and subselects , return column names in ' alias . ""column "" ' format instead of simply ' column ' ."
"return a dictionary of { field_name : ( field_name_other_table , other_table ) } representing all relationships to the given table ."
"returns a list of ( column_name , referenced_table_name , referenced_column_name ) for all key columns in given table ."
get the column name of the primary key for the given table .
"retrieves any constraints or keys ( unique , pk , fk , check , index ) across one or more columns ."
helper function to return a url pattern for serving files in debug mode .
"alerts google that the sitemap for the current site has been updated . if sitemap_url is provided , it should be an absolute path to the sitemap for this site -- e.g. , ' /sitemap.xml ' . if sitemap_url is not provided , this function will attempt to deduce it by using urls.reverse ( ) ."
"updates the storage backend ( i.e. , saves the messages ) ."
escape cr and lf characters .
attempt to import a class from a string representation .
pack data into hex string with little endian format .
unpack little endian hexlified binary string into a list .
split a string into two parts at the input index .
extract the srid from a postgis raster string .
convert a postgis hex string into a dictionary .
convert a gdalraster into postgis raster format .
returns the opaque value that was stored .
"returns any and all headers for remembering the value , as a list . value is a standard python type that shall be serializable using json ."
returns any and all headers for forgetting the current requests value .
"return the current user i d , none , or raise an error . raising an error is used when no attempt to verify a ticket has been made yet and signifies that the authentication policy should attempt to call ` ` verify_ticket ` `"
"returns the groups for the current user , as a list . including the current userid in this list is not required , as it will be implicitly added by the authentication policy ."
verify that the principal matches the ticket given .
"add a new ticket for the principal . if there is a failure , due to a missing / non - existent principal , or failure to add ticket for principal , should raise an error"
remove a ticket for the current user . upon success return true
utility function that cleans up the passed in principal this can easily also be extended for example to make sure that certain usernames are automatically off - limits .
we do not allow the unauthenticated userid to be used .
returns the authenticated userid for this request .
a list of effective principals derived from request .
returns a list of headers that are to be set from the source service .
a list of headers which will delete appropriate cookies .
base initialization .
main item resource conversion routine
"gce list requests , global or with zone / region specified ."
"gce get requests , global or zone / region specified ."
gce aggregated list requests for all zones / regions .
gce delete requests .
gce add requests .
filtering result list
returns standard format for given date .
creates fully qualified selflink for an item or collection
run before each test .
show a directory listing .
"generate a list of n random ports near the given port . the first 5 ports will be sequential , and the remaining n-5 will be randomly selected in the range [ port-2*n , port+2*n ] ."
"given an observation array , a label vector , and the location of the centers plot the clusters"
"given an observation array , a label vector ( integer values ) , and gmm mean and covariance parameters , plot the clusters and parameters ."
should be easily clustered with k - means .
returns non - isotropoic data to motivate the use of non - euclidean norms ( as well as the ground truth ) .
season for calls which use season in parameters
team short name for api calls
week number for api calls
api is unavailable
invalid api key
api call get_upcoming_season
api call get_current_week
api call get_schedules_for_season . test response type and items structure
api call get_team_roster_and_depth_charts test response type and items structure
api call players_game_stats_for_season_for_week test response type and items structure
api call get_free_agents test response type and items structure
api call get_current_week
check date value . parse datetime or throw assert exception
get a list of supported devices from ' iw '
convert a ' iw dev scan ' block into a tagged dict
get a list of access points ( as dicts ) for a device
"return a list of reachable access point ssids , sorted by power"
utility function for detexting ambiguous prefixes
just consumes ` disp_params ` which is used by json & matplotlib
"add all ` nx.write_xxx ( ) ` methods plus json & matplotlib funcs , above ."
"construct a * networkx * graph of nodes ( tasks / files / wildcards ) and their dependencies ( file / wildcard , task / setup , calc ) ."
repost if task ' task_names '
append any subtasks of ' task_names '
"appends extension(dot included ) if ` fname ` has'nt got one , or ` stdout ` if was ' - ' ."
gets one post from post_queue and retweets it
removes the extraneous posts from the post_queue
gets the blocked users and adds their ids in the ignore list
searches the twitter for new contests and adds the to the post queue
check if someone mentioned the user and sends a notification usefull because many winners are mentioned in tweets
run the bot as a daemon . this is blocking command
"checks if a post is a retweet and returns original tweet : param post : post to check if its retweeted : return : post : if itsnt retweet it returns the argument , otherwise returns original tweet"
"checks if a post is a quote of the original tweet also the quote maybe is quoting another quote . so we follow quotes until we find the original or if we follow config.max_quote_depth times : param post : the post to check if its a quote : return : if it is nt a quote the argument , otherwise the original tweet"
check if a post is wanted and add 's it in the post queue : param post : the post to insert
inserts a new task in the scheduler . tasks will be called regularly with period delay
inserts a new random task in the scheduler . tasks will be paused for random time from delay - delay_margin to delay+delay_margin
"inserts a task in the sched queue . we do nt enter the task itself , rather the run_task with the index of taskas a parameter . we do it that way so we can reschedule it later : param index : the index of the task"
runs a task and reschedules it again : param index : the index of the task to run
function defined to create customer .
static method defined to get customers by i d.
static method defined to list paystack customers .
static method defined to update paystack customer data by i d.
returns a recursive or a non - recursive directory walker .
walks a directory tree optionally recursively . works exactly like : func:`os.walk ` only adding the ` recursive ` argument .
"enlists all items using their absolute paths in a directory , optionally non - recursively ."
"enlists all the directories using their absolute paths within the specified directory , optionally non - recursively ."
"enlists all the files using their absolute paths within the specified directory , optionally recursively ."
returns the absolute path for the given path and normalizes the path .
returns the real absolute normalized path for the given path .
returns the parent directory path .
"takes a date - time string in standard asn1_print form ( "" mon day 24hour : minute : sec year timezone "" ) and return a python time value in seconds past the epoch ."
extracts the der as a byte sequence out of an ascii pem formatted certificate or key .
takes a certificate in binary der format and returns the pem version of it as a string .
convenience function to lowercase a string .
"determines whether the pathname matches any of the given wildcard patterns , optionally ignoring the case of the pathname and patterns ."
internal function same as : func:`match_path ` but does not check arguments .
matches a pathname against a set of acceptable and ignored patterns .
filters from a set of paths based on acceptable patterns and ignorable patterns .
matches from a set of paths based on acceptable patterns and ignorable patterns .
calculates the greatest common divisor .
least common multiple .
"returns inverse of a mod b , zero if none"
"find and return an unsigned integer i > = 0 such that ` ` number = = 2**i ` ` . if no such integer exists , this function raises valueerror ."
calculates : base**pow mod modulus
determines whether a number is prime .
generates a random prime number .
unused at the moment .
deploy a new instance of the ` dsvault ` contract .
return the current ` authority ` of a ` dsauth`-ed contract .
set the ` authority ` of a ` dsauth`-ed contract .
used as basename for saving parameter files
transform from conic section format to general format .
transform from conic section format to general format .
transform from conic section format to general format .
"transform from conic section format to general format , in integer precision ."
"given a list of timestamps , generate the next ` periods ` of hourly data , via daily averaging ."
"given a list of timestamps , find the number of events by hour on a daily basis ."
generate timeseries of given sampling rate from list of timestamp strings .
generate rolling sum for a timeseries of a given sampling rate from list of timestamp strings .
generate dict of pandas dataframes with multiple time series averaging schemes
string to display to the user
"@param arg : the command argument ( or stdin / stdout / stderr ) to substitute @param direction : direction of the argument : ' in ' , ' out ' , or none"
"pure implementation of counting sort algorithm in python : param collection : some mutable ordered collection with heterogeneous comparable items inside : return : the same collection ordered by ascending examples : > > > counting_sort([0 , 5 , 3 , 2 , 2 ] ) [ 0 , 2 , 2 , 3 , 5 ] > > > counting_sort ( [ ] ) [ ] > > > counting_sort([-2 , -5 , -45 ] ) [ -45 , -5 , -2 ]"
ensure only the selected labels are highlighted .
control the sensitivity of various widgets .
"when a champlainlabel is clicked , select it in the gtkliststore ."
update photos with new locations after photos have been dragged .
scale a champlainlabel by the given factor .
create a new champlainlabel and add it to the map .
return the specific type of cdc processor object given the source_dbtype
register templates .
run a number of prerequisite checks to ensure that dependencies are available on the system - python 3 - lxd
"save a figure from pyplot . parameters ---------- path : string the path ( and filename , without the extension ) to save the figure to . ext : string ( default='png ' ) the file extension . this must be supported by the active matplotlib backend ( see matplotlib.backends module ) . most backends support ' png ' , ' pdf ' , ' ps ' , ' eps ' , and ' svg ' . close : boolean ( default = true ) whether to close the figure after saving . if you want to save the figure multiple times ( e.g. , to multiple formats ) , you should not close it in between saves or you will have to re - plot it . verbose : boolean ( default = true ) whether to print information about when and where the image has been saved ."
fake data generator
fake metric data generator
authenticates a user given email and password .
return a pretty - printed xml string for the element .
add a convolution layer and optionally a batchnorm and relu layer .
add a conv shortcut layer if inplane ! = outplane ; or return the source layer directly .
"add three conv layers , with a>=b<=c filters ."
"add two conv layers , with a<=b filters ."
original resnet with the last batchnorm of each block moved to after the addition layer
"original resnet , where the there is a relue after the addition layer"
resnet with the batchnorm and relu moved to before the conv layer for each block
similar original resnet except that a<=b<=c for the bottleneck block
getattr for a dot separated path
extracts zipkin attributes and configuration from request attributes . see the ` zipkin_span ` context in py - zipkin for more detaied information on all the settings .
"factory for pyramid tween to handle zipkin server logging . note that even if the request is n't sampled , zipkin attributes are generated and pushed into threadlocal storage , so ` create_http_headers_for_new_span ` and ` zipkin_span ` will have access to the proper zipkin state ."
we should be setting the headers and zipkin_trace_id if the request is sampled or if zipkin.always_emit_zipkin_headers is true .
we must ensure zipkin.always_emit_zipkin_headers is true by default for backward compatibility .
log in a user after having been verified .
handle uncaught oauth errors .
token view handles exchange / refresh access tokens .
error view in case of invalid oauth requests .
test to verify that you have been authenticated .
test to verify that you have been authenticated .
test to verify that you have been authenticated .
get api links .
list files in a deposit .
returns logged in user .
return an array with user 's experiments .
get deposit groups .
ldap user by username query .
ldap user by name query .
ldap egroup query .
experiment menu .
annotates a given word for the usersays data field of an intent object .
get url_params and query_params and make db_filters to filter the queryset to the finest . [ 1 ] ~ sign is used to negated / exclude a filter . [ 2 ] when a csv is passed as value to a query params make a filter with ' in ' query .
merges the url_params dict with query_params query dict and returns the merged dict .
returns a dict with db_filters and db_excludes values which can be used to apply on viewsets querysets .
pep8 cell magic
"生成请求参数 , 未urlencode : param model : : param action : : param param : 额外参数 : return :"
返回原生数据 : param model : : param action : : param param : : return :
"根据函数名获得请求url , 并用传入参数发送请求 : param is_parse : 最后是否解析xml , 有些api只返回整数 : return :"
": param username : : param isuid : : return : { ' email ' : '' , ' uid ' : '' , ' username ' : '' } 如果用户不存在返回none"
"用户注册 : param username : : param password : : param email : : param questionid : : param answer : : param regip : : return : 注册成功 : ( userenum . success , 用户id ) 注册失败 : ( userenum , )"
": param username : : param password : : param isuid : : param checkques : : param questionid : : param answer : : return : 成功 : ( userenum . success , result ) 失败 ( userenum , )"
"同步登入 , 确保在后台设置该应用允许同步登入 : param uid : 要同步登入的用户的uid : return : 返回同步登入html代码 , 该代码需要在页面中渲染出来"
检查 email : param email : : return : useremailcheckresult
检查用户名 : param username : : return : usernamecheckresult
"return an affine transformation [ s * r | t ] such that : sum ||s*r*p1,i + t - p2,i||^2 is minimized ."
: type nums : list[int ] : type target : int : rtype : list[int ]
: type p : treenode : type q : treenode : rtype : bool
"returns a tuple of ( pdf_link , summary_text ) ."
find the pagination links on the page and yield them all .
get the download properties .
test _ npi_is_valid returns true if valid int input
test _ npi_is_valid returns true if valid str input
test _ npi_is_valid returns false if invalid int input
test _ npi_is_valid returns false if invalid str input
test _ npi_is_valid fails greacefully if given no / falsey input
test _ npi_constrains_helper no validationerror if valid ref
test _ npi_constrains_helper raise validationerror invalid ref
test _ npi_constrains_helper skips validation if not us
test identification_code created if there is none
test that medical patient type is correctly set on partner
test raises validationerror if male pregnant
test no validationerror if female is pregnant
test compute_age with no special cases
test age properly set if patient deceased
test age equals ' no dob ' if no birthdate_date present
test invalidate patient also invalidates partner
test deceased is true if value set on date_death
test deceased is false if no value set on date_death
it should create the entity if created as a partner .
it should get the default image for entity on create .
it should return the default image for the entity .
it should not perform default image manipulation when testing .
it should not allow birth dates in the future .
"when patients are searched by age , it should return patients with the corresponding birth dates"
should correctly treat patients as being 1 year older on birthday
should return correct result when current date at end of month
build a dictionary structure of an version model instance content . returns : the dictionary content of the version model .
add the extend field to the built dictionary content . returns : the augmented dictionary .
transform the extended dictionary into a pretty json . returns : the pretty json of the extended dictionary .
transform the info dictionary into a pretty json . returns : the pretty json of the info dictionary .
build a dictionary structure of an access model instance content . returns : the dictionary content of the access model .
filter down the access to a specific application . returns : the filtered dictionary of the application access .
build an activity json about the access on the platform . returns : the activity json .
generates a version number using ` git describe ` .
creates output file .
"writes text to the output , performing line endings conversion as needed . note that the changes do n't take effect until you call commit ( ) ."
replaces the value of the given placeholder with its real value . this is useful for parts of the output which are not known at the time they are written because they depend on other parts coming after them .
"generate dot ( graphviz ) for a whole tree not just a node . for example , 3 + 4 * 5 should generate :"
load insee code of every commune in france and generate all the urls to crawl .
"the communes pages urls depends on 5 parameters : - com : the insee code of the commune - dep : the department code on 3 characters - type : type of financial data , bps is for the whole data . - exercise : year of financial data"
parse the response and return an account object
the application launcher .
"assert if transformed variables are in correct range wrange is a list like [ minimum , maximum ]"
function to help debugging the data crunchin ' files .
counts the number of na 's in a specified axis
read x ( features ) table in tsv format ( or compressed ) .
read y ( response ) table in tsv format .
read functional scores table in tsv format .
read feature importance table in tsv format .
save feature importance results to disk
load the parameter for xgboost .
"galerkingausslobatto class : args : t : string for generating the sympy symbol the independent "" time "" variable q_list : list of strings for generating symbols for dof q v_list : list of strings for generating symbols for \dot{q } mod_list : list of values to mod the q values by for periodic variables if not periodic , the value is set to false ( default ) . methods : discretize : creates the variational integrator maps integrate : applies the maps created by discretize"
"generate the nonconservative variational integrator maps by setting the methods _ qi_soln_map , _ q_np1_map , _ pi_np1_map , _ qdot_n_map args : l : sympy expression for the conservative lagrangian . should be in terms of the self.q and self.v variables k : sympy expression for the nonconservative potential . should be in terms of the self.qp/m and self.vp/m variables order : integer order ( r ) of the ggl method ( r+2 is the total order of the method ) method : string ' implicit ' or ' explicit ' evaluation ( default explicit ) verbose : boolean . true to output mapping expressions ( default false ) output : none"
"numerical integration from given initial data args : q0_list : list of initial q values ( floats ) pi0_list : list of initial pi ( nonconservative momentum ) values ( floats ) t : list of t values ( floats ) over which to integrate the system . dt : defaults to the difference between the first two elements of the t array . otherwise the stepsize must be specified as a float . output_v : boolean value , if true , output will be q_list_soln . t , pi_list_soln . t , qdot_list_soln . t defaults to false outputfile : filename for the output file . defaults to false and no file is produced . output is in csv format , with first line the column labels . t_out : sets the output t_array for the output_file . defaults to same as t print_steps : outputs to file every print_steps steps . defaults to 1 . output : q_list_soln . t , pi_list_soln . t the integrated q and pi arrays at each time . unless output_v is true"
` ` statdist ` ` should return the stationary distribution .
"` ` statdist ` ` should work when the graph is not strongly connected , but has a single absorbing class ."
` ` statdist ` ` should fail when the graph is disconnected or has more than one absorbing class .
` ` softmax ` ` should work as expected .
` ` normal_cdf ` ` should return the value of the normal cdf .
` ` normal_pdf ` ` should return the value of the normal pdf .
` ` inv_posdef ` ` should return the correct inverse .
` ` generate_params ` ` should work as expected .
` ` generate_pairwise ` ` should work as expected .
` ` generate_rankings ` ` should work as expected .
` ` compare ` ` should work as expected for choices .
` ` compare ` ` should work as expected for rankings .
` ` probabilities ` ` should work as expected .
typical use case .
the input is longer than 1 hash .
specifying different values for the ` ` length ` ` argument .
passing an ` ` offset ` ` argument to : py : meth:`curl.absorb ` .
passing an ` ` offset ` ` argument to : py : meth:`curl.squeeze ` .
squeezing more than 1 hash from the sponge .
""" normalizes "" a hash , converting it into a sequence of integers ( not trits ! ) suitable for use in signature generation / validation ."
returns whether a sequence of signature fragments is valid .
generates a single key .
generates the key associated with the specified address .
generates and returns one or more keys at the specified index(es ) .
creates a generator that can be used to progressively generate new keys .
advances the generator without creating a key .
prepares the hash sponge for the generator .
returns the number of fragments this generator can create .
returns the next signature fragment .
find addresses matching the command parameters .
"the contructor , context are the parameter given to the html template"
the { quantity } bus stops with most waiting time for a bus
the { quantity } bus stops with most waiting time for a bus
searches the maximum likelihood estimator for the shape parameters of the bum - model given a list of p - values
create result bundle from the image build results in the specified target directory . each result image will contain the specified bundle identifier as part of its filename . uncompressed image files will also become xz compressed and a sha sum will be created from every result image
"read xml description , pass it along to the xslt processor , validate it against the schema and finally pass it to the autogenerated(generateds ) parser ."
return the xml etree parse result for the specified extension namespace
run jing program to validate description against the schema
extract error message form the schematron validation report
apply xslt style sheet rules to the xml data
quote characters which have a special meaning for bash but should be used as normal characters . actually i had planned to use pipes.quote but it does not quote as i had expected it . e.g ' name_wit_a_$ ' does not quote the $ so we do it on our own for the scope of kiwi
quote given input file which has to be of the form key = value to be able to become sourced by the shell
run a function implemented in config / functions.sh
prepare and install a new system for chroot access
create xfs filesystem on block device
vdi disk format post initialization method
create vdi disk format
vmdk disk format post initialization method
create vmdk disk format and machine settings file
store result files of the vmdk format conversion into the provided result instance . this includes the vmdk image file and the vmware settings file
in order to run a vmdk image in vmware products a settings file is needed or the possibility to convert machine settings into an ovf via vmware 's proprietary ovftool
post initialization method
queue a package request
queue a package collection
queue a product request
queue a package exclusion(skip ) request
queue a package exclusion(skip ) request
process package install requests for bootstrap phase ( no chroot )
process package install requests for image phase ( chroot )
process package delete requests ( chroot )
process package update requests ( chroot )
setup package processing only for required packages
setup package processing to also include recommended dependencies
match expression to indicate a package has been installed
match expression to indicate a package has been deleted
check if package database is consistent
"for rpm based package managers , dump and reload the database to match the desired rpm db version"
cleanup request queues
"apt - get package manager template for apt - get called outside of the image , not chrooted"
"apt - get package manager template for apt - get called inside of the image , chrooted"
check if user exists
check if group exists
add group with options
add user with options
modify user with options
setup user home directory
construct a l{fixedoffsettimezone } with a fixed offset .
"construct a l{fixedoffsettimezone } from an offset described by sign ( ' + ' or ' - ' ) , hours , and minutes ."
create a time zone with a fixed offset corresponding to a time stamp in the system 's locally configured time zone .
return this timezone 's offset from utc .
"return a zero c{datetime.timedelta } for the daylight saving time offset , since there is never one ."
return a string describing this timezone .
@param level : a l{loglevel }
get the log level with the given name .
"we want log levels to have defined ordering - the order of definition - but they are n't value constants ( the only value is the name ) . this is arguably a bug in twisted , so this is just a workaround for u{until this is fixed in some way < https://twistedmatrix.com/trac/ticket/6523 > } ."
register to receive data from a producer .
"stop consuming data from a producer , without disconnecting ."
append a c{list } or c{tuple } of bytes to the output buffer .
append some bytes to the output buffer .
@param credentials : something which implements one of the interfaces in self.credentialinterfaces .
@type filename : c{str } @param filename : the name of the file from which to read username and password information .
loads the credentials from the configured file .
this function is deprecated as of twisted 10.2 .
return the service corresponding to a description .
listen on a port corresponding to a description
get a friendly string for the given version object .
@param other : another object . @type other : any
@param package : name of the package that this is a version of . @type package : c{str } @param major : the major version number . @type major : c{int } @param minor : the minor version number . @type minor : c{int } @param micro : the micro version number . @type micro : c{int } @param prerelease : the prerelease number . @type prerelease : c{int }
"return a string in canonical short version format , < major>.<minor>.<micro>[+rsvnver ] ."
"like l{short } , but without the + rsvnver ."
"compare two versions , considering major versions , minor versions , micro versions , then prereleases ."
"given a readable file object which represents a .svn / entries file in format version 4 , return the revision as a string . we do this by reading first xml element in the document that has a ' revision ' attribute ."
"given a readable file object which represents a .svn / entries file in format version 8 , return the revision as a string ."
"figure out the svn revision number based on the existence of < package>/.svn / entries , and its contents . this requires discovering the format version from the ' format ' file and parsing the entries file accordingly ."
install the epoll ( ) reactor .
start or stop a c{loopingcall } based on whether there are readers and writers .
call c{doread } and c{dowrite } on all readers and writers respectively .
add a c{filedescriptor } for notification of data available to read .
add a c{filedescriptor } for notification of data available to write .
remove a c{filedescriptor } from notification of data available to read .
remove a c{filedescriptor } from notification of data available to write .
remove all readers and writers .
return a list of the readers .
return a list of the writers .
checks if the file descriptor is currently being observed for read readiness .
checks if the file descriptor is currently being observed for write readiness .
"initialize epoll object , file descriptor tracking dictionaries , and the base class ."
private method for adding a descriptor from the event loop .
add a filedescriptor for notification of data available to read .
add a filedescriptor for notification of data available to write .
private method for removing a descriptor from the event loop .
remove a selectable for notification of data available to read .
remove a selectable for notification of data available to write .
"remove all selectables , and return a list of them ."
poll the poller for new events .
@param descriptors : the descriptors which will be returned from calls to c{inheriteddescriptors } .
"@param environ : a dictionary - like object to inspect to discover inherited descriptors . by default , c{none } , indicating that the real process environment should be inspected . the default is suitable for typical usage ."
@return : the configured list of descriptors .
return c{arg } . do nothing .
"returns whether or not we should enable the new - style conversion of old - style classes . it inspects the environment for c{twisted_newstyle } , accepting an empty string , c{no } , c{false } , c{false } , and c{0 } as falsey values and everything else as a truthy value ."
"a decorator which conditionally converts old - style classes to new - style classes . if it is python 3 , or if the c{twisted_newstyle } environment variable has a falsey ( c{no } , c{false } , c{false } , or c{0 } ) value in the environment , this decorator is a no - op ."
define how to open item in subclass
hook - you can add here your init code
hook - you can add here your init code
opens info about item according to defined mode
@return : true if can handle item @return : false if can not handle item
"@param coordinator : an l{iexclusiveworker } which will coordinate access to resources on this l{team } ; that is to say , an l{iexclusiveworker } whose c{do } method ensures that its given work will be executed in a mutually exclusive context , not in parallel with other work enqueued by c{do } ( although possibly in parallel with the caller ) ."
gather information on the current status of this l{team } .
increase the the number of idle workers by c{n } .
decrease the number of idle workers by c{n } .
"the implmentation of c{shrink } , performed by the coordinator worker ."
perform some work in a worker created by c{createworker } .
"select a worker to dispatch to , either an idle one or a new one , and perform it ."
called only from coordinator .
stop doing work and shut down all idle workers .
add some data to the response to this request .
the response to this request is finished ; flush all data to the network stream .
"i produce a stream of bytes for the request , by calling request.write ( ) and request.finish ( ) ."
initialize me .
get an entity that was added to me using putentity .
subclass this to generate an entity on demand .
retrieve an entity from me .
store a static reference on ' name ' for ' entity ' .
remove a static reference for ' name ' .
"store an entity for ' name ' , based on the content of ' request ' ."
"remove an entity for ' name ' , based on the content of ' request ' ."
"retrieve a list of all name , entity pairs that i store references to ."
"a list of all name , entity that i can generate on demand ."
"retrieve a list of all name , entity pairs i contain ."
retrieve a list of the names of entities that i store references to .
retrieve a list of the names of entities that i store references to .
retrieve a list of all names for entities that i contain .
a method that determines whether an entity may be added to me with a given name .
a method that determines whether an entity may be added to me .
store an entity if it meets both constraints .
add a layer of ssl to a transport .
"forward any extra attribute access to the original transport object . for example , this exposes c{gethost } , the behavior of which does not change after tls is enabled ."
write some bytes directly to the connection .
write a some bytes directly to the connection .
close the underlying connection .
register a producer with the underlying connection .
unregister a producer with the underlying connection .
@see : l{itlstransport.starttls }
"write some bytes to this connection , passing them through a tls layer if necessary , or discarding them if the connection has already been lost ."
"write some bytes to this connection , scatter / gather - style , passing them through a tls layer if necessary , or discarding them if the connection has already been lost ."
close this connection after writing all pending data .
register a producer .
unregister a producer .
create an inotify instance and return the associated file descriptor .
"add a watch for the given path to the inotify file descriptor , and return the watch descriptor ."
remove the given watch descriptor from the inotify file descriptor .
"initialize the module , checking if the expected apis exist and setting the argtypes and restype for c{inotify_init } , c{inotify_add_watch } , and c{inotify_rm_watch } ."
get a password from the user
ask for a directory to save to .
get a worker 's preference for a given week
initialize the resource
inherit info from parent and return new object
get the url for the resource
raise the proper exception based on the response
perform a read request against the resource
process additional data sent in response
delete the object
change attributes of the item
create an object and return it
"if request was shorter than max request time , delay"
get or create logger ( if it does not exist )
copies a resource file and returns the source path for monitoring
typically used in routes like ` post /widgets `
"typically used in routes like ` get /widgets/12 ` note : sometimes the user is allowed to see a limited version of the requested resource . if that is the case , this method should return true , and ` fields_cant_view ` and ` includes_cant_view ` should be used to control which attributes and relationships are actually visible"
typically used in routes like ` get /widgets `
"typically used in routes like ` patch /widgets/12 ` note : sometimes the user is allowed to edit a limited version of the requested resource . if that is the case , this method should return true , and ` fields_can_edit ` and ` includes_cant_edit ` should be used to control which attributes and relationships are actually editable ."
typically used in routes like ` delete /widgets/12 `
: param model : the model which the user is trying to view attributes of : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which attributes the given user is not allowed to view .
: param model : the model which the user is trying to edit : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which attributes the given user is not allowed to edit .
: param model : the model which the user is trying to edit by creating new relationships : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which relationships the given user is not allowed to create or add to .
: param model : the model which the user is trying to view relationships of : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which relationships the given user is not allowed to view .
: param model : the model which the user is trying to edit : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which relationships the given user is not allowed to edit .
: param model : the model which the user is trying to edit by deleting existing relationships : param user_id : the user on behalf of whom permission is being requested : return : a list of strings indicating which relationships the given user is not allowed to delete or remove from .
"collect , clean , and alphabetize the words in the subtitles"
get language patterns for the given language
graph the stats of the running router
open wireshark with the running device .
only valid if there is no rotation component
"h = spacing_z / spacing_xy nodules = list ( x , y , z , r ) of the nodule , in voxel space specify nth or z. nth : the nth nodule"
take the idlfile and net configuration and create a generator that outputs a jittered version of a random image from the annolist that is mean corrected .
"vec = ( idn , idh , idw ) w_shape = [ n , h , w , c ]"
"input : w : a 4d block tensor of shape ( n , h , w , c ) i : a list of 3 - tuples [ ( x_1 , y_1 , z_1 ) , ( x_2 , y_2 , z_2 ) , ... ] , each having type ( int , float , float )"
"function used for rezooming high level feature maps . uses bilinear interpolation to select all channels at index ( x , y ) for a high level feature map , where x and y are floats ."
"saving an adjusted image should delete "" related "" adjusted images that use areas ."
"deleting an adjusted image should delete "" related "" adjusted images that use areas ."
"create formula . each formula must look like this : ( eqn , pos , path , dsp , count ) for self._convert_concurrently , this is a shorthand with mocking a few values ."
turn a list of formulas as accepted by cachedconverter._convert_concurrently ( ) into a list accepted by cachedconverter._get_formulas_to_convert ( ) .
"call latex to produce a dvi file with the given latex document . temporary files will be removed , even in the case of a latex error . this method raises a subprocesserror with the helpful part of latex 's error output ."
guarded remove of files ( rm -f ) ; no exception is thrown if a file could n't be removed .
"execute cmd ( list of arguments ) as a subprocess . returned is a tuple with stdout and stderr , decoded if not none . if the return value is not equal 0 , a subprocess error is raised . timeouts will happen after 20 seconds ."
"this function calculates the dpi for the resulting image . depending on the font size , a different resolution needs to be used . according to the dvipng manual page , the formula is : < dpi > = < font_px > * 72.27 / 10 [ px * texpt / in / texpt ]"
tex_document should be either a full tex document as a string or a class which implements the _ _ str _ _ method .
set output resolution for formula images .
set whether or not the background of an image is transparent .
check whether a list of rgb colors is correct . it must contain three broken decimals with 0 < = x < = 1 .
set_background_color(rgb_values ) the list rgb_values must contain three broken decimals between 0 and 1 .
set_background_color(rgb_values ) the list rgb_values must contain three broken decimals between 0 and 1 .
set whether latex source document should be kept .
"call latex to produce a dvi file with the given latex document . temporary files will be removed , even in the case of a latex error . this method raises a subprocesserror with the helpful part of latex 's error output ."
create a png file from a given dvi file . the side effect is the png file being written to disk . : param dvi_fn dvi file name : return dimensions for embedding into an html document : raises valueerror raised whenever dvipng output coudln't be parsed
convert the tex document into an image . this calls create_dvi and create_png but will not return anything . thre result should be retrieved using get_positioning_info ( ) .
return positioning information to position created image in the html page .
parse the latex error output and return the relevant part of it .
process string parsing .
process a single file .
process several files .
create objects in the database .
timestamps are not in the correct order ; should warn about this
combine two files with interwoven timestamps
see if a whole horde of weird newlines screws anything up
ensure journals with several days in them continue to work
load a smaller batch from the archive
load the entire archive
load a smaller batch from the archive
try a file that has no datestamp whatsoever
test a file with almost nothing in it
yield individual config data from config_data
test that the config validation works as intended
yield data mocking ' tests ' section in config along with the expected list of cli params
test that we can write the default config to file
tests that the ` flatten_mapping ` function does what it advertises
tests that the ` deepen_mapping ` function does its job
is_logged decorator . put it in route you need to use only for logged user . example : @app.route('/home ' ) @is_logged
catch all 404 erorrs
cancel booked record by user
get login credentials . status_banned = 2 : banned user role_user = 3 : user role
get logged user from db query
generates list of restaurants
show restaurant info page
returns the night - time lights image for a given year .
returns a likely - to - be unique string .
sends a message to the client using the channel api .
crops and formats the image for export .
moves the files with the prefix to the user 's drive folder .
returns the main web page with channel api details included .
processes a get request and returns a json - encodable result .
processes a post request and returns a json - encodable result .
"responds with the result of the handle_function or errors , if any ."
returns the map id of an image for the requested year .
kicks off export of an image for the specified year and region .
"exports an image for the year and region , gives it to the user ."
mark up plain text into fancy html .
"load a class by module and name . params : module : canonical module name , e.g. xx.xxx.xxxx ; name : class name ."
"setdefaultproxy(proxytype , addr [ , port [ , rdns [ , username [ , password ] ] ] ] ) sets a default proxy which all further socksocket objects will use , unless explicitly changed ."
_ _ recvall(bytes ) - > data receive exactly the number of bytes requested from the socket . blocks until the required number of bytes have been received .
"setproxy(proxytype , addr [ , port [ , rdns [ , username [ , password ] ] ] ] ) sets the proxy to be used . proxytype - the type of the proxy to be used . three types are supported : proxy_type_socks4 ( including socks4a ) , proxy_type_socks5 and proxy_type_http addr - the address of the server ( ip or dns ) . port - the port of the server . defaults to 1080 for socks servers and 8080 for http proxy servers . rdns - should dns queries be preformed on the remote side ( rather than the local side ) . the default is true . note : this has no effect with socks4 servers . username - username to authenticate with to the server . the default is no authentication . password - password to authenticate with to the server . only relevant when username is also provided ."
"_ _ negotiatesocks5(self , destaddr , destport ) negotiates a connection through a socks5 server ."
getsockname ( ) - > address info returns the bound ip address and port number at the proxy .
getproxypeername ( ) - > address info returns the ip and port number of the proxy .
getpeername ( ) - > address info returns the ip address and port number of the destination machine ( note : getproxypeername returns the proxy )
"_ _ negotiatesocks4(self , destaddr , destport ) negotiates a connection through a socks4 server ."
"_ _ negotiatehttp(self , destaddr , destport ) negotiates a connection through an http server ."
"connect(self , despair ) connects to the specified destination through a proxy . destpar - a tuple of the ip / dns address and the port number . ( identical to socket 's connect ) . to select the proxy server use setproxy ( ) ."
"check if isinstance(args[0 ] , instance_of ) returns true for * all * members of * args"
return true if at least one of the passed pids is running
"true i d the given pid is running , false otherwise"
"prepare a "" status string "" for this pid"
"creates a list of points for plotting a cube with plot . ( the first 5 points are the bottom square , some sides repeated ) ."
calibration function for the camera ( iphone4 ) used in this example .
compute the harris corner detector response function for each pixel in a graylevel image .
return corners from a harris response image min_dist is the minimum number of pixels separating corners and image boundary .
plots corners found in image .
for each point return pixel values around the point using a neighbourhood of width 2*wid+1 . ( assume points are extracted with min_distance > wid ) .
"for each corner point descriptor in the first image , select its match to second image using normalized cross correlation ."
two - sided symmetric version of match ( ) .
return a new image that appends the two images side - by - side .
"show a figure with lines joining the accepted matches input : im1,im2 ( images as arrays ) , locs1,locs2 ( feature locations ) , matchscores ( as output from ' match ( ) ' ) , show_below ( if images should be shown below matches ) ."
tries to load a private key
": param data : data object ( defaults to reading from csv files ) : type data : sysdata.data.simdata , or anything that inherits from it"
use a different database
"get a data frame of interesting information about instruments , either from a file or cached"
get a data frame of cost data
get instrument price backadjusted
"returns a pd . dataframe with the 6 columns price , carry , price_contract , carry_contract , forward , forward_contract"
get fx data
"calculate the ewmac trading fule forecast , given a price and ewma speeds lfast , lslow and vol_lookback"
"calculate the ewmac trading fule forecast , given a price and ewma speeds lfast , lslow and vol_lookback"
gets daily prices
gets daily prices for use with % volatility this wo n't always be the same as the normal ' price ' which is normally a cumulated total return series
gets daily returns ( not % returns )
gets volatility of daily returns ( not % returns )
get percentage returns normalised by recent vol
get returns normalised by recent vol
"returns a cumulative normalised return . this is like a price , but with equal expected vol used for a few different trading rules"
average normalised returns across an asset class
"price for an asset class , built up from cumulative returns"
: param instrument_code : : return :
create a production system instance
read png images from input directory in batches .
render hdr for viewing exposure estimate - > log2 - > clahe - > remap to l_remap - > gamma correction - > hdr @param e : exposure ( n x m x 3 ) @param l_remap : remap intensity to l_remap in the image adjust step @param saturation : saturation of the color . @param numtiles : number of contextual tiles in the clahe step return contrast reduced image
"log2(e ) . remove 0s . return log2e , has_nonzero"
the main algorithm is clahe : contrast limited adaptive histogram equalization preprocessing : convert rgb to xyz to lab postprocessing : back to rgb
remap i from range_in to range_out @param i : image @param range_in : range of the input image . will be assigned minmax(i ) if none @param range_out : range of the output image @param gamma : factor of the gamma correction
tone mapping based on fast bilateral @param e : exposure @param scale : scale of the contrast reduction @param offset : return hdr image
"return an generator for all styles by name , both builtin and plugin ."
scan the buffer for modelines and return filetype if one is found .
get the certificate at the request_url and return it as a sha256 hash . will get the raw socket from the original response from the server . this socket is then checked if it is an ssl socket and then used to get the hash of the certificate . the certificate hash is then used with ntlmv2 authentication for channel binding tokens support . if the raw object is not a urllib3 httpreponse ( default with requests ) then no certificate will be returned .
create an authentication handler for ntlm over http .
"parameters ---------- n_commands , n_sensors : int the number of commands that the world is expecting and the number of sensors that the world will be providing . these are the only pieces of information becca needs about the world to get started ."
build a set of discretized inputs for the featurizer .
show the current state of the featurizer .
"assign each goal a value , based on their expected reward , curiosity and features ."
"creates a decorator that generates event pairs of ` ` ( next_event , event ) ` ` where ` ` event ` ` are instances returned by the decorated function ."
generates a list of event pairs for a local symbol table .
"args : prefix_desc ( optional[string ] ): the prefix for the test parameter description . prefix_pairs ( optional[iterable[tuple[dataevent , ionevent ] ] ] ): the prefix of event pairs to put into the inner stream , should only be system values . token ( optional[callable ] ): the token encoder . append_start ( optional[int ] ): the start of the lst for direct append test cases ."
builds functions that leverage python ` ` str ( ) ` ` or similar functionality .
returns a function that serializes container start / end .
returns a raw text writer co - routine .
shutdown the websocket when this object is garbage collected .
overloaded method to write to the websocket instead .
overloaded method to read from the websocket instead .
ping webserver .
return the vertices of a cubes with side length 1 .
parse program arguments .
return the template for a large asteroid .
return the template for a small asteroid .
spawn ` ` num_asteroids ` ` and return their ids .
if a projectile collided with an asteroid that take action .
spawn ` n ` small asteroids based on the position / velocity in ` state ` .
shut down the simulation when the user closes the viewer ( if any was started with this simulation ) .
put the simulation in the default state .
print some status messages before entering the event loop .
connect to the broker .
disconnect from the broker .
establish the connection with rabbitmq .
for user to overload . triggers after a message was received .
triggers after the periodic timer expired .
pika / rabbitmq callback for when a message arrives - do not overload .
pika / rabbitmq callback for timeouts - do not overload .
signal the thread to terminate itself .
return all cached messages .
publish the binary ` ` msg ` ` to ` ` topic ` ` .
pika specific portion of : meth:`~blockingconsume ` .
connect to rabbitmq and commence the message consumption .
establish connection and start consuming .
parse program arguments .
"this is a helper method to return an argparse parser , to be used with the sphinx argparse plugin for documentation ."
initialize a new empty queue
add a new item to the queue
remove and return the item at the top of the queue
check whether the queue is empty
wrapper around : attr:`provider.scope.names ` to turn an int into a list of scope names in templates .
"format explanation as html . most styles are inline , but some are included separately in < style > tag , you can omit them by passing ` ` include_styles = false ` ` and call ` ` format_html_styles ` ` to render them separately ( or just omit them ) . with ` ` force_weights = false ` ` , weights will not be displayed in a table for predictions where it is possible to show feature weights highlighted in the document . if ` ` highlight_spaces ` ` is none ( default ) , spaces will be highlighted in feature names only if there are any spaces at the start or at the end of the feature . setting it to true forces space highlighting , and setting it to false turns it off . if ` ` horizontal_layout ` ` is true ( default ) , multiclass classifier weights are laid out horizontally . if ` ` show_feature_values ` ` is true , feature values are shown if present . default is false ."
"format just the styles , use with ` ` format_as_html(explanation , include_styles = false ) ` ` ."
return a list of rendered weighted spans for targets . function must accept a list in order to select consistent weight ranges across all targets .
return token wrapped in a span with some styles ( calculated from weight and weight_range ) applied .
return opacity value for given weight as a string .
"return hsl color components for given weight , where the max absolute weight is given by weight_range ."
format hsl color as css color string .
max absolute feature for pos and neg weights .
"color for "" remaining "" row . handles a number of edge cases : if there are no weights in ws or weight_range is zero , assume the worst ( most intensive positive or negative color ) ."
"format unhashed feature : show first ( most probable ) candidate , display other candidates in title attribute ."
format any feature .
"return an explanation of an xgboost estimator ( via scikit - learn wrapper xgbclassifier or xgbregressor , or via xgboost . booster ) as feature importances ."
"return an explanation of xgboost prediction ( via scikit - learn wrapper xgbclassifier or xgbregressor , or via xgboost . booster ) as feature weights ."
"for each target , return score and numpy array with feature weights on this prediction , following an idea from http://blog.datadive.net/interpreting-random-forests/"
"return a leaf nodeid - > node dictionary with "" parent "" and "" leaf "" ( average child "" leaf "" value ) added to all nodes ."
value of the parent node : a weighted sum of child values .
parse text tree dump ( one item of a list returned by booster.get_dump ( ) ) into json format that will be used by next xgboost release .
"return a copy of values where missing values ( equal to missing_value ) are replaced to nan according . if sparse_missing is true , entries missing in a sparse matrix will also be set to nan . sparse matrices will be converted to dense format ."
generate numpy arrays of random length
"format explanation as text and html , check json - encoding , print text explanation , save html , return text and html ."
remove whitespace and line breaks from html .
"write to html file in .html directory . filename is generated from calling function name and module , and clf class name . this is useful to check and debug format_as_html function ."
collect a dict of all features and their weights .
"check that feature weights sum to target score or proba , if both proba and score are present they match , and that there are no "" remaining "" features ."
return text representation of a decision tree .
"> > > _ format_array([0 , 1.0 ] , "" { : 0.3f } "" ) ' [ 0.000 , 1.000 ] '"
return an explanation of estimator parameters ( weights ) .
return an explanation of an estimator prediction .
return no more than ` ` k ` ` indices of largest values .
return no more than ` ` k ` ` indices of smallest values .
"the same as x[indices ] , but return an empty array if indices are empty , instead of returning all x elements , and handles sparse "" vectors "" ."
x is a 2d sparse matrix with it 's first shape equal to 1 .
convert indices to a boolean ( integer ) mask .
"return a list of ( target_id , display_name ) tuples ."
"return ( target_name , scale , label_id ) tuple for a binary classifier ."
"> > > _ get_value_indices(['foo ' , ' bar ' , ' baz ' ] , [ ' foo ' , ' bar ' , ' baz ' ] , ... [ ' bar ' , ' foo ' ] ) [ 1 , 0 ] > > > _ get_value_indices(['foo ' , ' bar ' , ' baz ' ] , [ ' foo ' , ' bar ' , ' baz ' ] , ... [ ' bar ' , ' foo ' ] ) [ 1 , 0 ] > > > _ get_value_indices(['foo ' , ' bar ' , ' baz ' ] , [ ' foo ' , ' baz ' , ' baz ' ] , ... [ ' baz ' , ' foo ' ] ) [ 2 , 0 ] > > > _ get_value_indices(['foo ' , ' bar ' , ' baz ' ] , [ ' foo ' , ' bar ' , ' baz ' ] , ... [ ' spam ' ] ) traceback ( most recent call last ): ... keyerror : ' spam '"
"> > > max_or_0 ( [ ] ) 0 > > > max_or_0(iter ( [ ] ) ) 0 > > > max_or_0(iter([-10 , -2 , -11 ] ) ) -2"
explain sklearn_crfsuite . crf weights .
"> > > coef = np.array([[0 , 1 , 2 ] , [ 3 , 4 , 5 ] , [ 6 , 7 , 8 ] ] ) > > > filter_transition_coefs(coef , [ 0 ] ) array([[0 ] ] ) > > > filter_transition_coefs(coef , [ 1 , 2 ] ) array([[4 , 5 ] , [ 7 , 8 ] ] ) > > > filter_transition_coefs(coef , [ 2 , 0 ] ) array([[8 , 6 ] , [ 2 , 0 ] ] ) > > > filter_transition_coefs(coef , [ 0 , 1 , 2 ] ) array([[0 , 1 , 2 ] , [ 3 , 4 , 5 ] , [ 6 , 7 , 8 ] ] )"
return labels sorted in a default order suitable for ner tasks :
read a file into a string
"return the readme file contents . supports text , rst , and markdown"
returns true if the file provided is a cpio file
unpacks a cpio archive and returns the contained files
do a search on the internet archive for a book
make a match search
"get rid of tutorial sections because they almost always have "" staff "" as the instructor this is just a heuristic of course"
run a search for courses
"tries to find a cached version of ` ` key '' if there is no cached version then it will evaluate thunk ( which must be a generator ) and cache that , then return the result"
setup the connection
"28/10/2015 without a test , pytest will fail"
move data from haveged to the kernel until the nonblocking pool is initialized .
load a csv file into a class . if any items are in additional columns then import them as aliases
read raaga and taala attributes from the webservice query and add them to the object
convert release artists to lead performers on instrumentperformances
becuase the default haystack operator is and if you search for john quincy adams then it looks for ` john and quincy and adams ' and hence wo n't find john adams . this results in missed matches and duplicates . so if it looks like there 's more than two names split them and search using the whole name provided or just the first and last . this results in ` ( john and quincy and adams ) or ( john and adams ) ` which is a bit more tolerant .
wraps get_change_metadata without requiring a request object
a tiny wrapper around edit_fields to make adding a single field easier
return reduced ee output for some known urls
get the vmr instance . : return : vmr
delete the vmr instance
"get meta data for release at pub_date , or the latest release"
must be overridden by all crawlers
the unix time of midnight at ` ` date ` ` in the comic 's time zone
check that we can list players .
test player deletion .
enter username that is already registered .
enter email that is already registered .
register with success .
build a report .
validate the form .
"return dict each key is string "" sample_id "" each value is a list of tuples ( "" library "" , "" barcode "" )"
"return dict each key is string "" sample_id "" each value is a list of metadata ordered as [ "" strain "" , "" sample_id "" , "" collect_date "" , "" country "" , "" division "" , "" location "" ]"
use nanopolish to construct a single fasta for all reads from a sample
run fasta_to_consensus script to construct consensus files
gather consensus files into genomes with ' partial ' ( 50 - 80 % coverage ) and good ( > 80 % coverage ) coverage
return the transformation of y according to mean value ( that is last element of lines )
copies the contents of ' other ' to ' self '
sets string at the given index
gets the string at the given index
returns the address ( as number ) of the qstring at the given index
add a string to the vector
populates the vector from a python string list
clears all strings from the vector . @param qclear : just reset the size but do not actually free the memory
insert a string into the vector
removes a string from the vector
creates a team .
abstract method that should be overrided by subclasses . launches an npc with player number player_num . the method that overrides this should call start_npc_process . see examples below .
"launches a player using the team - specific binary launchopts should be used to append player specific options ( e.g. , helios uses ' -g ' to signify launching a goalie )"
connects to the server on the specified port . the following information is provided by the ./bin / hfo
returns the number of state features
returns the current state features
performs an action in the environment
transmits a message
returns the message heard from another player
returns a player object who last touched the ball
advances the state of the environment
returns a string representation of an action
returns a string representation of a game status
returns the uniform number of the agent
returns the number of teammates of the agent
returns the number of opponents of the agent
build the theano symbolic graph representing the cnn model .
make a reporter that can be used when no reporter is specified .
construct a l{reporter } .
an unexpected error occurred trying to process c{filename } .
there was a syntax errror in c{filename } .
pyflakes found something wrong with the code .
initialization routine for the module
"if the module needs to startup threads or uses python modules that create threads , put thread creation code or the module startup code here ."
"if the module has started threads or uses python modules that created threads , put cleanup code here ."
make sure json library being used does not lose precision converting bsty values
first_node is the address of the first computer to connect to if it is none then you are bootstrapping the network and this is the first node .
get an item from the distributed hash table
set an item in the distributed hash table
creates gaussian kernel with side length l and a sigma of sig
layer for applying gaussian blur
concatenate conditioning vector on feature map axis .
: return : returns whether it is a gpu server or not . : rtype : boolean
: return : returns whether it is a circleci environment or not . : rtype : boolean
: param command : : type command : str : return : the path of program file or none : rtype : str
copy a file in the files/ subfolder at the given destination ( see usage below ) and change some stuff in the file
a main function is required by shallow - appify
"calculate arccos with its argument clamped to [ -1 , 1 ]"
two atoms are connected if their distance is less than or equals a given delta .
two atoms are connected if their distance is less than or equals the sum of their covalent radii times a radii_sum_factor ( e.g. 1.15 ) .
inserts all symetric bonds into the of bonds for each atom : param bond_target_index_arrays : list with all symetric bond indices : return :
return the normalized version of a numpy array
set the results that will be displayed
create gr3 meshes . ` ` self.results ` ` contains the mesh data and in ` ` self.settings ` ` is specified which meshes shound be rendered .
adjust the zoom level .
translate the model .
"rotate the model according to a mouse movement ( dx , dy ) on the screen ."
update the shown scene after the perspective has changed .
assigns an opengl context object that is set as current opengl context before rendering . the object must have have ` ` makecurrent ` ` and ` ` donecurrent ` ` methods as an interface .
refresh the opengl scene .
save a screenshot in the given resolution . ` ` first ` ` and ` ` last ` ` can be used to indicate if the first or last screenshot is taken when multiple images are saved in a loop for example .
just update the internal instance values : return :
the corrected weight in ounces : return :
the pounds portion of the scale reading : return :
the ounces portion of the scale reading : return :
"read the scale data and return the raw , uncorrected values : return :"
be sure to release the scale
"read the scale , update internal variables , and return the raw weight : return : raw weight"
close the device when cleaning up ... : return :
"update the session dictionary , and occasionally run action_<arg > function ."
"after setting a new proxy , reinitiate channel if already set"
"after setting a new channel , reinitiate it"
called by user to unset the session variables
called by user to set or show the session variables
------ input file ------ | no . of targets ( n ) | defender 's resources ( rd ) | r(c)_1 r(u)_1 | ... | r(c)_n r(u)_n | c(c)_1 c(u)_1 | ... | c(c)_n c(u)_n ------ example ( see bssg_input.txt)------ | 4 | 2 | 0 -15 | 0 -10 | 0 -13 | 0 -15 | -5 15 | -5 10 | -4 13 | -6 15 |----------------------------------------
convert headers in human readable format
": param field_string : : type field_string : : return : return pair : argument name , dict of updates for argument info : rtype : ` ` dict ` `"
separates the method 's description and paramter 's
return method docstring if method docstring is empty we get docstring from parent
": return : return dict description - method description arguments - dict of dicts arg_name : { description , type_name , required } return - dict : { description , type }"
"od.popitem ( ) - > ( k , v ) , return and remove a ( key , value ) pair . pairs are returned in lifo order if last is true or fifo order if false ."
"od.update(e , * * f ) - > none . update od from dict / iterable e and f."
"od.pop(k[,d ] ) - > v , remove specified key and return the corresponding value . if key is not found , d is returned if given , otherwise keyerror is raised ."
od.__eq__(y ) < = = > od==y . comparison to another od is order - sensitive while comparison to a regular mapping is order - insensitive .
search through the ledger
returns 0 in a way that makes everyone happy .
return the keras model of the network until the fc6 layer where the convolutional features can be extracted .
performs an http request set in ' method ' . returns requests object the method will try to catch some of the typical errors and gather error messages from newrelic api each known error has a corresponding exception . all exceptions are inherited from generic newrelicexception if http return code is not known a generic newrelicexception is raised .
wrapper for requests get method
wrapper for requests post method
wrapper for requests put method
wrapper for requests delete method
hack for numpy choice function .
"computes the autocorrelation function , i.e. the correlation of a data set with itself . to do this , shift data set by one bin each time and compute correlation for the data set with itself , shifted by i bins"
print to a the screen and a file at the same time .
returns x**2 and stores its gradient in g[0 ]
report optimization progress .
gets the specific user .
"delay_timedelta will be added to the current time . if an at_hour or at_minute is passed , the resulting date will have it 's hour and minute updated ."
"args : label : logit : unscaled log probabilities projection : ( w , b ) num_sampled :"
"mode filter , which falls back to median when there are multiple items which are ' most common ' ."
"get current trend , and its distance . history parameter should be a list of numbers , ordered by time descending . returns tuple(trend , dist ) ."
todo : calculate monthly : - select weekly items from product_price_history for given ( past ) month . - perform most_common ( ) for each result list . - result of most_common ( ) is monthly .
delete hanging references to deleted objects .
gets the url of the actual jpg file from the post object .
gets the filename from the post object .
makes a call to reddit and returns one post randomly from the page specified in url .
decorate methods with this to require that the user be logged in .
draw a figure that demonstrates the memory layout of individual genotypes .
"reads prior history in if available , returns either current state from history or clean initial state if there are errors / no history"
"given a tweet which is a tuple , where : tweet[0 ] - > tweet message tweet[1 ] - > number of retweets , basically our measure of how important / wide - spread this tweet is tweet[2 ] - > tweet timestamp , when the tweet was given"
adds a list of new companies to the current list new_companies[company name][0 ] = score new_companies[company name][1 ] = weight new_companies[company name][2 ] = timestamp
"given prior history / clean state , and an input file of new expressions , adds the new expressions to the current state , and returns the new state"
"given a list of viability scores , writes a trade down if it is above / below a certain threshold"
the first word in the history is an indicator : ' score ' = > the line contains a company name and current viability score tuple ' alias ' = > the line contains a company 's name and their stock ticker tuple
": param debug : if true , the registry records tracebacks for debugging purposes : type debug : bool : param strict_floats : if true , the registry does not allow ints as float parameters : type strict_floats : bool"
takes a request and dispatches its data to a jsonrpc method .
registers a method with a given name and signature .
syntactic sugar for registering a method
creates a dictionary mapping parameters names to their values in the method call .
returns a description of all the methods in the registry .
parses the request as a json message .
checks that the request json is well - formed .
valid keyword arguments .
valid arguments .
default arguments .
invalid args .
invalid kwargs .
invalid both args and kwargs are given .
invalid sw_gbuf_bypass type .
invalid sw_gbuf_bypass len .
invalid partition_hybrid and partition_ifmaps comb .
accessor option_list .
data reside solution .
data reside solution optimal .
data reside solution optimal with different resources .
data reside solution optimal with poolinglayer .
data reside solution optimal with zero size .
data reside solution count .
a wrapper around the acquisition function that is called by fmin_l_bfgs_b .
bayesian optimization using gaussian processes .
"set up test fixtures , if any ."
"tear down test fixtures , if any ."
write the equivalent static loads oftained for each node in the mode passed as parameter
print results of normal stresses in elastic range checking for an elment set whose material is a steel shape .
returns the corresponding xml element for the node properties . parameters : parent : owner of this object in the xml structure .
computes default dimension from the total height .
return total height of the wall .
return total width of the footing .
"return stem section depth for height "" y "" ) ."
return the height of the stem in the wireframe model .
returns the position of the stem top in the wireframe model .
returns the position of the stem bottom in the wireframe model .
returns the position of the toe end in the wireframe model .
returns the position of the heel end in the wireframe model .
returns the position of the toe ( for overturning moment computation ) .
returns the position of the foundation center ( for excentricity computation ) .
returns the midplane of the footing .
returns the foundation plane .
return wall foundation depth . args : : toefilldepth : ( float ) depht of the soil filling overt the toe .
write wall geometry in latex format .
extracts the element identifiers from a xc output file generated with the results for each conbination analyzed
extracts element and combination identifiers from the internal forces listing file .
creates a phantom element ( that represents a section to check )
creates the phantom model elements from the data read on the file .
creates the loads from the data read from the file .
builds the phantom model from the data read from the file .
runs the analysis ( linear ) and checking of combinations passed as parameters
writes results into the output file
"run the analysis , check the results and write them into a file"
returns object containers in a list .
display node labels
coefficient of reduction of bearing capacity for pinned supported footing near a slope . expression proposed by corté and garnier ( 1994 )
writes a comma separated values file with the element 's internal forces .
writes a comma separated values file with the element 's internal forces .
writes a comma separated values file with the element 's internal forces .
writes a comma separated values file with the element 's internal forces .
returns the corresponding xml element for the object . parameters : parent : owner of this object in the xml structure .
project directories constructor
return the path to esf_el * files .
return the path to results_verif * files .
return the path to store graphic output files .
return the path to store text output files .
return the file name for the results of crack control checking under frequent loads .
return the file name for the results of crack control checking under frequent loads .
return the file name for the results of fatigue checking .
return the file name for the results of shear strength checking .
return the file name for the results of normal stresses checking .
return the reinforced concrete sections file name .
return the paht to store section related output .
returns the corresponding xml element .. parameters : parent : owner of this object in the xml structure .
returns lateral torsional buckling reduction factor value for the elements inside the line .
installs recorder for verification of uls criterion .
constructs the sets of concrete fibers ' concrete ' and reinforcing steel fibers ' reinforcement ' for all the elements included in a set of elements .
returns the fibers under tension included in a set of fibers of a fiber section type
redefine the tension stiffening parameters of the concrete fibers in set passed as parameter .
returns a set of tensioned fibers ` tensionedreinforcement ` of a fiber section of reinforced concrete .
returns the fiber from a set of fibers where the maximum value of a certain property is reached parameters : fibers : set of fibers methodname : name of the method that returns the fiber property searched
returns the fiber from a set of fibers where the minimum value of a certain property is reached parameters : fibers : set of fibers methodname : name of the method that returns the fiber property searched
returns the fiber with the minimum strain from the set of fibers
returns the fiber with the maximum strain from the set of fibers
returns a set with those fibers in tension from the total set
returns the cross section area of concrete in the set of fibers
returns the maximum strain in the set of concrete fibers
returns the initial tangent in the stress - strain diagram of the material that makes up the fibers of concrete
returns the resultant of compressive stresses in the concrete fibers of the section
returns the number of reinforcing steel fibers in tension
introduces a prestressing tension on the elements in a line
introduces a post - tension on the elements in a line
set the diagonal entries of a square matrix to 0
uses lcm communication to send a message from the driver station
uses lcm communication to receive a message from the driver station
returns a boolean indicating if the robot to the team is connected and alive
modify sys.path so that we can import modules from our parent .
render the main interface page .
get a list of uids and their associated device types in json form .
send a disable all message to hibike .
get a dictionary representing information about a device .
get information about all devices .
"given a uid , get information about the device ."
read all parameters from a device .
read a single device parameter .
write values to a device .
create a sample dawn message .
send a sample dawn message on ` ` port ` ` .
receive messages on port to receive queue .
add timestamp messages to ` ` msgqueue ` ` .
sends and receives messages on ` ` port ` ` .
test that the reference count of thing is exactly ' count ' in caller
api : tabulate_formats is a list of strings
api : tabulate ( ) type signature is unchanged
api : simple_separated_format ( ) type signature is unchanged
use the variables returned in this function to render google analytics tracking code template .
"given a dataset file and word2id embeddings , read them to lists : param feature_label_file : : param max_sent : : param word2id : : return :"
pad data up till maximum length and create masks and lists of sentence lengths : param x : : param y : : param max_len : : return :
": param data : numpy arrays of data : param labels : numpy arrays of labels : param buckets : list of buckets ( lengths ) into which to group samples according to their length . : param mode : either ' truncate ' or ' pad ' : * when truncation , remove the final part of a sample that does not match a bucket length ; * when padding , fill in sample with zeros up to a bucket length . the obvious consequence of truncating is that no sample will be padded . : return : a dictionary of grouped data and a dictionary of the data original indexes , both keyed by bucket , and the bin edges"
"given bucket edges and data , put the data in buckets according to their length : param data_array : : param labels : : param buckets : : return :"
put in bucket according to input and label length : param inputs : : param labels : : param buckets : : param mode : : return :
"pad input data up till input_size , output up till output_size : param x : : param y : : param input_size : : param output_size : : param pad_id : : return :"
get a plugin class from its name .
discover the plugin classes contained in python files .
test ' _ range_from_slice ' .
test _ unique ( ) function
test _ normalize ( ) function .
test _ index_of .
test _ spikes_in_clusters ( ) .
test _ spikes_per_cluster ( ) .
get the number of samples before and after .
return a waveform slice .
raw traces .
load a waveform at a given time .
load the waveforms of the specified spikes .
"convert an rv of shape ( n , : , : , ... ) into n rvs of shape (: , : , ... ) ( or analogously for other axis!=0 ) ."
"given an rv representing a matrix , return two rvs representing the initial row_idxs rows and all following rows , respectively ."
return module that is able to handle the command . none if there is no such module .
initialize an abstract server
register the server in _ poll
unregister the server from _ poll
asynchronymously send a message to the server using send_callback
internal function used when the file descriptor is writable
send a formated message class
internal function used when the file descriptor is readable
assume lexing in default case is per line
exception occurs on fd
visit a node
check that all given message keywords are valid
class that accepts any passed keywords
initialize the datastore
lock the directory
release a locked path
get the path to the module data file
load data for the given module
backup given path
load data for the given module
try to determine the user and repository name .
add forks to the current project .
find forks .
main function to run as shell script .
urls_object is a reference back to the urls container .
"return the decoded html or xml or whatever . sometimes necessary for a quick "" if ' page not found ' in html : ... """
return the page 's lxml doc .
return the documents element tree .
just aggregates the validator methods into a defaultdict and stores them on cls._validators .
sets a urldata object on the instance for each named url given .
a generator of this object 's urldata members .
a decorator to mark validator functions for use on a particular named url . use like so :
run each validator function for the named url and its text .
squish whitespace and kill .
a helper to run xpath with the proper namespaces for the washington legislative api .
generator to obtain organization data .
get session list from billsearch page using xpath
scrapes idaho committees for the latest term .
"create and return a 2d array having rowcount rows and colcount columns , with each element initialized to value ."
"create a random matrix of size ( n*d , n*d ) with blocks of size d along ( -1 , 0 , 1 ) diagonals"
basic neighborlist test in tf
check several structures and repeats for consistency with ase .
tests if the neighbor indices agree with ase .
tests oneway list on a bunch of molecules .
check several structures and repeats for consistency with ase .
this test was put in to debug the lj oneway calculator .
create an image from a tensorflow graph .
strip large constant values from graph_def .
"open a graph in tensorboard . by default this is done in a browser . if you set browser to false , then html will be emitted that shows up in a jupyter notebook ."
creates shallow copy of package .
adds new token to space separated list of tokens .
"makes helper , that writes into several files simultaneously ."
"gets the path , size and checksum for files ."
checks that url reflects local path .
get the path from the url .
get the url from local path .
get filename from the uri .
convert url of repository to normal form .
creates directory if it does not exist .
finds executable by name in directories listed in ' path ' .
creates temporary directory .
moves files by pattern from directory src to directory dst .
creates the packaging manager .
"return jsonschema to validate data , which will be pass to driver"
build package from sources .
shorten the title if it is not going to fit on the worksheet
"converts components to up , south , east definition : :"
"converts components to north , east , down definition : :"
"for a given vector in use format , retrieve the azimuth and plunge"
converts a tensor in use coordinate sytem to ned
converts a tensor in ned coordinate sytem to use
"returns a tensor to six component vector [ mrr , mtt , mpp , mrt , mrp , mtp ]"
"normalise the tensor by dividing it by its norm , defined such that np.sqrt(x :x )"
performs and eigendecomposition of the tensor and orders into descending eigenvalues
inverse of euler_to_matrix ( ) .
"uniquify euler angle triplet . put euler angles into ranges compatible with ( dip , strike,-rake ) in seismology : alpha ( dip ) : [ 0 , pi/2 ] beta ( strike ) : [ 0 , 2*pi ) gamma ( -rake ) : [ -pi , pi ) if alpha is near to zero , beta is replaced by beta+gamma and gamma is set to zero , to prevent that additional ambiguity ."
uses hanks & kanamori formula for calculating moment magnitude from a scalar moment ( nm )
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
"return mean value ( eq . 1 , page 319 ) ."
return standard deviation as defined in eq.11 page 319 .
"compute and return magnitude scaling term ( eq.2 , page 319 )"
"compute distance scaling term ( eq.3 , page 319 ) ."
"compute faulting mechanism term ( see eq . 5 , page 319 ) ."
"compute far - source effect of local site conditions ( see eq . 6 , page 319 ) assuming ' firm rock ' conditions ."
"compute hanging - wall effect ( see eq . 7 , 8 , 9 and 10 page 319 ) . considers correct version of equation 8 as given in the erratum and not in the original paper ."
aggregate loss curves plotter .
"determine the source weight from the number of ruptures , by multiplying with the scale factor rupture_weight"
: returns : the number of sites affected by this source
: returns : a list of source group ids ( usually of 1 element )
get a generator object that yields probabilistic ruptures the source consists of .
override to implement source splitting
return the number of ruptures that will be generated by the source .
return minimum and maximum magnitudes of the ruptures generated by the source .
apply a single modificaton to the source parameters reflects the modification method and calls it passing ` ` parameters ` ` as keyword arguments .
"get a list of pairs "" magnitude -- annual occurrence rate "" ."
get the minimum and maximum magnitudes of the ruptures generated by the source from the underlying mfd .
"string representation of a source , displaying the source class name and the source i d."
calculates median fault area from magnitude .
returns zero for now
returns magnitude for a given fault area
returns zero for now
calculates median fault area from magnitude .
calculates median magnitude from fault area .
returns none for now
calculates recurrence using the weichert ( 1980 ) method
"return an ordered dictionary with the available gsim classes , keyed by class name ."
plot the sites and the assets
ensure that means match reference dataset .
ensure that standard deviations match reference dataset .
read the sample catalogue
": param data : array of shape ( n , r , l , 2 , ... ) : param multi_stat_dt : numpy dtype for statistical outputs : param number : expected number of units per asset : returns : array of shape ( n , r ) with records of type multi_stat_dt"
core function for a damage computation .
compute stats for the aggregated distributions and save the results on the datastore .
test magnitude to area scaling
test area to magnitude scaling
tests the standard deviation for area . trivial result - included only for coverage
tests the standard deviation for magnitude . trivial result - included only for coverage
test magnitude to area scaling
test area to magnitude scaling
this generates a minimum data - set to be used for the regression .
tests that the computed b value corresponds to the same value used to generate the test data set
tests that the computed b value corresponds to the same value used to generate the test data set
yield the ruptures of the underlying point sources
see : meth:`openquake.hazardlib.source.base . baseseismicsource.count_ruptures ` for description of parameters and return value .
the polygon containing all points expanded by the max rupture projection radius
parse the vulnerability model in nrml 0.4 format .
upgrade to the latest nrml version
upgrade all the nrml files contained in the given directory to the latest nrml version . works by walking all subdirectories . warning : there is no downgrade !
used to add the source_id to the error message . to be used as
": param dic_with_default : a dictionary with a ' default ' key : param key : a key that may be present in the dictionary or not : returns : the value associated to the key , or to ' default '"
: returns : a dict src_group_id - > sources
"build a bounding box around the given lon , lat by computing the maximum_distance at the given tectonic region type and magnitude ."
get the enlarged bounding box of a source .
": param src : a source object : returns : ( ( min_lon , min_lat ) , width , height ) , useful for plotting"
"returns the sites within the integration distance from the source , or none ."
": yields : pairs ( src , sites )"
": param trt : a tectonic region type ( used for the integration distance ) : param mag : a magnitude ( used for the integration distance ) : returns : a list of bounding boxes , one per site"
: param sources : a sequence of sources : yields : sources with .indices
filter the sources in parallel by using starmap.apply
: param sources : a sequence of sources : yields : rtree - filtered sources
checks the following constraints :
returns the predefined annual occurrence rates .
returns the minumun and maximum magnitudes
"applies absolute modification of the mfd from the ` ` magnitudes ` ` , ` ` occurrence_rates ` ` modification ."
: param hdf5 : a h5py . file object : param name : an hdf5 key string : param dtype : dtype of the dataset ( usually composite ) : param shape : shape of the dataset ( can be extendable ) : param compression : none or ' gzip ' are recommended : param attrs : dictionary of attributes of the dataset : returns : a hdf5 dataset
extend an extensible dataset with an array of a compatible dtype .
extend an hdf5 file dataset with the given array
the full python name ( i.e. ` pkg.subpkg.mod.cls ` ) of a class
the class associated to the given dotname ( i.e. ` pkg.subpkg.mod.cls ` )
"if the dataset has an attribute ' nbytes ' , return it . otherwise get the size of the underlying array . returns none if the dataset is actually a group ."
: param lst : a list of strings or bytes : returns : an array of variable length ascii strings
": param path : an .hdf5 pathname : param items : a generator of pairs ( key , array - like ) : param extra : extra attributes to be saved in the file"
"returns a temporary hdf5 file , open for writing . the temporary name is stored in the .path attribute . it is the user responsability to remove the file when closed ."
set the ` nbytes ` attribute on the hdf5 object identified by ` key ` .
"save a node dictionary in the .hdf5 file , starting from the root dataset . a common application is to convert xml files into .hdf5 files , see the usage in : mod:`openquake.commands.to_hdf5 ` ."
dtype of the underlying array
shape of the underlying array
tests the scale moment function
converts the ucerf source node into an ses control object
: param rupset_idx : indices of the rupture sets : param ucerf_source : an object taking the place of a source for ucerf : param src_filter : a source filter returning the sites affected by the source : param gsims : a list of gsims : param monitor : a monitor instance : returns : a probabilitymap
parse the logic tree and source model input
"run in parallel ` core_task(sources , sitecol , monitor ) ` , by parallelizing on the sources according to their weight and tectonic region type ."
as of may 2013 the following mfds should be available : andersonlucoarbitrary andersonlucoareammax youngscoppersmithexponential youngscoppersmithcharacteristic characteristic
returns a value equal to 1e-4 squared km independently of ` ` mag ` ` and ` ` rake ` ` values .
tests the instantiation of the reader class ( trivial )
tests to ensure longitudes greater than 180.0 are returned in the range ( -180 . to 180 . )
tests the reader on a simple strain file
test basic instantiation with a filename
test the function to slice some magnitude rate and add to dictionary
tests the writer to a file
uses the input properties to create the string of the filename
"if filename is specified , saves the image : param str filename : name of the file : param str filetype : type of file : param int resolution : dpi resolution of the output figure"
returns the magnitude bins corresponing to the catalogue
creates a histogram of the depths in the catalogue
creates a density plot of the magnitude and depth distribution
creates a simple scatter plot of magnitude with time
creates a plot of magnitude - time density
adds completeness intervals to a plot
"counts the number of earthquakes in each magnitude bin and normalises the rate to annual rates , taking into account the completeness"
plots the observed recurrence taking into account the completeness
this generates a catalogue to be used for the regression .
tests that the computed b value corresponds to the same value used to generate the test data set
calculates median area as ` ` 10 * * ( mag - 4.366 ) ` ` . rake is ignored .
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
compute terms 1 and 2 in equation 1 page 1 .
compute term 3 and 4 in equation 1 page 1 .
"compute the fith term of the equation ( 1 ) , p. 1 : ` ` c5 * s ` `"
"get site type dummy variables , ` ` s ` ` ( for rock and soil sites )"
return total standard deviation .
"compute mean value for pga and pseudo - velocity response spectrum , as given in equation 1 . converts also pseudo - velocity response spectrum values to sa , using :"
"constructs the "" kreemer cell "" from the input file . the kreemer cell is simply a set of five lines describing the four nodes of the square ( closed ) : param list data : strain data as list of text lines ( input from linecache.getlines ) : param int loc : pointer to location in data : returns : temp_poly - 5 by 2 numpy array of cell longitudes and latitudes"
gets the tectonic region type for every element inside the strain model
"returns the region type and area according to the tectonic region : param polygon : dictionary containing the following attributes - ' long_lims ' - longitude limits ( west , east ) ' lat_lims ' - latitude limits ( south , north ) ' region_type ' - tectonic region type ( str ) ' area ' - area of cell in m ^ 2"
applies the regionalisation defined according to the regionalisation typology of corne kreemer
run a hazard calculation by splitting the sites into tiles . warning : this is experimental and meant only for internal users
"return mean value computed using equation 2 , page 2 , plus site term and faulting style term , equations 3 and 5 , page 3 ."
"this computes the third term in equation 2 , page 2 ."
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
add site effects to an intensity .
get standard deviation for a given intensity on reference soil .
get an intensity on a reference soil .
tests the recurrence function in all cases if bbar > dbar ( 1.5 ) then models will fail !
tests the recurrence function in all cases if bbar > dbar ( 1.5 ) then models will fail !
tests the recurrence function in all cases if bbar > dbar ( 1.5 ) then models will fail !
tests the basic setup
tests the function to get mmax values come from wc1994 ( tested in openquake.hazardlib ) - only functionality is tested for here !
tests the function to get magnitude frequency distribution
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
"compute and return mean value ( table 8 , page 8)"
return total standard deviation .
see : meth:`superclass method < .base . groundshakingintensitymodel.get_mean_and_stddevs > ` for spec of input and result values .
"compute mean value on rock ( that is eq.1 , page 105 with s = 0 )"
return standard deviation as defined in eq.13 page 106 .
return fault type ( f ) and hanging wall ( hw ) flags depending on rake angle .
"return site class flag ( 0 if vs30 > 600 , that is rock , or 1 if vs30 < 600 , that is deep soil )"
"compute f1 term ( eq.4 , page 105 )"
"compute f3 term ( eq.6 , page 106 )"
"compute f4 term ( eq . 7 , 8 , and 9 , page 106 )"
compute f5 term ( non - linear soil response )
"if no data is given for the report , use default values . : return : default mandatory data for the bvr report ."
construct the data for printing payment slips . : param data : data collected from the print wizard . : return : html rendered report
include setting for telling 3bvr paper has offset between payment slips .
generates a bvr reference for the product . : param partner : : return : string : the bvr reference
push children to wordpress website .
change the report for communications to print with bvr update the count of succes story prints when sending a receipt . : return : true
letter is zip if it contains a zip attachment
detect if text is written in the language corresponding to the language_id
"use detectlanguage api to find the language of the given text : param text : text to detect : return : res.lang compassion record if the language is found , or false"
method for retrieving the image
"when a partner gets multiple letters , we make a zip and attach it to the first letter , so that he can only download this zip . : return : true"
regenerate communication if already existing
sends the communication to the partner . by default it wo n't do anything if a communication is already attached to the letter . context can contain following settings : - comm_vals : dictionary for communication values - force_send : will send the communication regardless of the settings . - overwrite : will force the communication creation even if one already exists . : return : true
tells if we should send the communication with a zip download link or with each pdf attached : return : true if multi mode should be used
generates the communication for given letters . : param config_id : partner.communication.config i d : return : true
tells if we can automatically send the letter by e - mail or should require manual validation before .
sends a summary each month of the donations : return : true
creates a thank you letter communication separating events thank you and regular thank you .
"given a recordset of paid invoices , return only those that have to be thanked . : return : account.invoice recordset"
reconcile given invoices with partner open payments .
remove children from the website when they are sponsored .
remove from typo3 when child is released
remove from typo3 when child is deallocated
"find new children on the global childpool , put them on wordpress , remove old children and release the holds . : return : true"
"called by wordpress to add a new sponsorship . : param form_data : all form values entered on the site { ' city ' : ' bienne ' , ' first_name ' : ' emanuel ' , ' last_name ' : ' cino ' , ' language ' : [ u'französich ' , ' englisch ' ] , ' zahlungsweise ' : ' dauerauftrag ' , ' consumer_source_text ' : ' times magazine ' , ' zipcode ' : ' 2503 ' , ' birthday ' : ' 10/04/1989 ' , ' beruf ' : ' agriculteur paysan ' , ' phone ' : ' 078 936 45 95 ' , ' consumer_source ' : ' anzeige in zeitschrift ' , ' street ' : ' rue test 1 ' , ' kirchgemeinde ' : u'mon église ' , ' mithelfen ' : { ' checkbox ' : ' on ' } , ' salutation ' : ' herr ' , ' patenschaftplus ' : { ' checkbox ' : ' on ' } , ' email ' : ' ecino@compassion.ch ' , ' childid ' : ' 15783 ' , ' land ' : ' suisse ' } : param child_local_id : local i d of child : param sponsor_lang : language used in the website : param utm_source : identifier from the url tracking : param utm_medium : identifier from the url tracking : param utm_campaign : identifier from the url tracking : return : true if process is good ."
use the form filled in website to create a new partner . : return : view of the partner
"write the sponsor languages given from the website onto a partner : param lang_string : selected languages on website , comma separated : param sponsor_lang : selected website language : param partner : res.partner record : return : odoo write list [ ( 4 , lang_id_1 ) , ( 4 , lang_id_2 ) , ... ]"
write the church in the partner given its name : param church_name : church name : param partner : res.partner record : return : dictionary { odoo_field : odoo_value }
copy django model instance as a dictionary excluding automatically created fields like an auto - generated sequence as a primary key or an auto - created many - to - one reverse relation .
collects positional and keyword arguments into ` data ` and applies units .
"applies units to data when a proxy reader is used . for example if the data is cached as json and retrieved using the : class:`~carousel.core.data_readers . jsonreader ` , then units can be applied from the original parameter schema ."
apply units to model . : return : data
sets an snmp variable using the snmpset command .
with left click the digitizing is finished
function called when a gully is identified in the map
custom form initial configuration
call functions depend on tab selection
fill tab ' element '
fill tab ' document '
fill tab ' o&m ' ( event )
fill tab ' custom fields '
with left click the digitizing is finished
with left click the digitizing is finished
link selected @geom_type to the pipe
class to control toolbar ' om_ws '
"button 36 : info show info , open giswater and visit web page"
open giswater.jar with last opened .gsw file
move selected node to the current point
called when set as currently active map tool
called when map tool is being deactivated
mouse movement event
mouse release event
create the instances for short - range and long - range potentials .
estimates one missing cutoff parameter and calculates sigma for gaussian distribution
estimates cutoff parameters for ewald summation and calculates sigma for gaussian distribution .
"adds particles with random position , charge = 1 , sigma = 1 and epsilon = 1 to the system_configuration"
"creates a basic system_configuration with random positions , charge = 1 , sigma = 1 and epsilon = 1 and a sampler object"
calculate the distance between two particles with periodic boundary conditions .
"creates an opengl context and a window , and acquires opengl resources"
setup for raii using ' with ' keyword
cleanup for raii using ' with ' keyword
render scene one time
press escape to quit the application
cleanup for raii using ' with ' keyword
setup for ' with ' keyword
cleanup for ' with ' keyword
render scene one time
press escape to quite the application
keep rendering until the user presses escape
"creates an opengl context and a window , and acquires opengl resources"
render scene one time
close the application when the player presses escape
called every time the on - screen window is resized
keep rendering until the user says quit
allocate opengl resources
set up a non - poissonian scan ( or poissonian if no np templates )
draw a selection of edges of the network .
draw labels for selected edges of the network .
run numba accelerated dynamic relaxation analysis .
numba accelerated dynamic relaxation solver .
create a mesh datastructure from a blender mesh .
the points of the polyline .
the lines of the polyline .
the number of points .
the number of lines .
the length of the polyline .
"return true if the polyline is ` self - intersecting ` , false otherwise ."
verify if the polyline is closed . the polyline is closed if the first and last point are identical .
implementation of the force density method to compute equilibrium of axial force networks .
compute the centroid of a set of points .
compute the centroid of a set of points lying in the xy plane .
compute the midpoint of two points .
compute the midpoint of two points lying in the xy - plane .
compute the center of mass of polyline edges defined as an array of points .
"compute the center of mass of polyline edges in the xy plane , defined as an array of points ."
compute the center of mass of the edges of a polyhedron .
compute the sum of this ` ` vector ` ` and another ` ` vector ` ` .
compute the difference between this ` ` vector ` ` and another ` ` vector ` ` .
scale this ` ` vector ` ` by a factor .
scale this vector by a factor n.
the dot product of this ` ` vector ` ` and another ` ` vector ` ` .
the cross product of this ` ` vector ` ` and another ` ` vector ` ` .
rotate a vector u over an angle a around an axis k.
render a dataframe to a console - friendly tabular output .
render a dataframe to a tabular environment table .
reads a zmat file .
write zmat - file
"deprecated , use : meth:`~chemcoord . zmat.to_zmat `"
entry point to the flask restful server application .
create a new user .
create a new oauth2 client associated with a given user ( username ) .
"returns min_x , max_y , max_x , min_y"
copy layers to a feature dataset in a file geodatabase .
"retuns the factorial of n , optionally printing it first ."
format path for sublime internal use .
dummy filter call that does nothing .
parse the color scheme .
strip transparency from the color value .
"get the core colors ( background , foreground ) for the view and gutter ."
get the plist file used during the process .
get the scheme file used during the process .
guess the colors and style of the text for the given sublime scope .
"tests mostly based around january 2014 , where two holidays , new years day and mlk day , fall on the 1st and 20th , respectively ."
test for https://github.com/seatgeek/businesstime/issues/3
test for https://github.com/seatgeek/businesstime/issues/13
test for https://github.com/seatgeek/businesstime/issues/13
test for https://github.com/seatgeek/businesstime/issues/13
hash string value
service - service object .
"sessionid float - idle time , in seconds ."
int - session id.
int - accept session id.
bool - connected flag .
str - reason .
str - local ip address .
int - local port number .
str - peer ip address .
int - peer port number .
bool - listen socket flag .
int - socket file descripter .
packet - packet object .
int - report layer .
int - report level
str - report message .
int - packet opcode .
bool - destroyed from service flag .
"int - error number , 0 if success ."
"int - sub error number , 0 if success ."
subgradient descent solver . optimized for numba . solves : min_x f(x ) for non - smooth f
calculates a kernel given the data x and y ( dims x exms )
calculates the kernel diagonal given the data x ( dims x exms )
outputs the result of a rdflib.query
append an item to the score set .
return a list of the items with their final scores .
return the items with the higest score .
renvoie le nombre d'enfant au sens des allocations familiales do nt l'âge est compris entre ag1 et ag2
base ressource des prestations familiales de la famille ' fam '
"these tests use the default backend , since we know it 's available ; that needs to have ` ` account_activation_days ` ` set ."
a ` ` get ` ` to the ` ` register ` ` view uses the appropriate template and populates the registration form into the context .
a ` ` post ` ` to the ` ` register ` ` view with valid data properly creates a new user and issues a redirect .
"a ` ` post ` ` to the ` ` register ` ` view with invalid data does not create a user , and displays appropriate error messages ."
any attempt to access the ` ` register ` ` view when registration is closed fails and redirects .
passing ` ` template_name ` ` to the ` ` register ` ` view will result in that template being used .
passing ` ` extra_context ` ` to the ` ` register ` ` view will correctly populate the context .
passing ` ` disallowed_url ` ` to the ` ` register ` ` view will result in a redirect to that url when registration is closed .
passing ` ` success_url ` ` to the ` ` register ` ` view will result in a redirect to that url when registration is successful .
"test that the ` ` activate ` ` view properly handles a valid activation ( in this case , based on the default backend 's activation window ) ."
"test that the ` ` activate ` ` view properly handles an invalid activation ( in this case , based on the default backend 's activation window ) ."
passing ` ` success_url ` ` to the ` ` activate ` ` view and successfully activating will result in that url being used for the redirect .
passing ` ` template_name ` ` to the ` ` activate ` ` view will result in that template being used .
passing ` ` extra_context ` ` to the ` ` activate ` ` view will correctly populate the context .
derives a pep386 - compliant version number from version .
find all files under ' dir ' and return the list of full filenames ( relative to ' dir ' ) .
runs validation of the task submission in the given directory
get the unique row number containing the key .
get a sequence of row numbers containing the key(s ) .
tell if all keys in the index are unique .
return the column names the index is made of .
tell the index that data has changed .
get the local variables some levels back ( -1 is top ) .
get the value of a local variable somewhere in the call stack .
substitute global python variables in a command string .
create a session to use connection pooling .
make a request to the gmaps api .
"returns ' lat , lng ' associated with the name of the place ."
"returns the reverse geocode dts associated with ' lat , lng ' ."
initializes base parameters for a filter .
create a dict representation of this filter .
initializes a new cache object for storing data between events .
export the data to a more permanent location .
replaces all terms contained in a dict
basic function for collecting the list of git commands that we need to get individual html files for
"returns a tuple ( { ' image_name':image , } , [ ( x , y , width , height ) , ] , )"
constructor for the kayak batcher class .
reset the state of the kayak batcher .
implementation of iterator functionality .
turns off batching . run before test - time .
| object containing amount and iso currency code attributes | note : make sure you submit the amount and currency code for each line item
| object containing the line items of the invoice or shopping cart
| object containing additional information that when supplied can have a beneficial effect on the discountrates
| object containing additional information that when supplied can have a beneficial effect on the discountrates
| name of the attribute that is shown to the consumer on selection pages or screens
| regular mask for the attributekey | note : the mask is optional as not every field has a mask
| contains the unique i d which is used by the device fingerprint collector script . this will must be set in the createpayment 's property fraudfields.devicefingerprinttransactionid .
| contains the ready - to - use device fingerprint collector script . you have to inject it into your code to get it run .
"| numeric status code that is returned by either ingenico 's global collect payment platform or ingenico 's ogone payment platform . it is returned to ease the migration from the local apis to ingenico connect . you should not write new business logic based on this field as it will be deprecated in a future version of the api . the value can also be found in the global collect payment console , in the global collect report files and the ogone backoffice and report files ."
convenience method that creates a payment request
test a request with idempotence key where the first request is successful
test that the client can successfully handle a response indicating a request has been sent prior
test a request where a request is rejected without prior requests
test a request where a request is rejected with a prior request
test a request where a request arrived twice
creates a request handler that receives the request on the server side
test that the client can successfully detect that an idempotent request is sent twice
": param authorization_type : based on this value both the ingenico epayments platform and the merchant know which security implementation is used . a version number is used for backward compatibility in the future . : param api_id_key : an identifier for the secret api key . the api_key_id can be retrieved from the configuration center . this identifier is visible in the http request and is also used to identify the correct account . : param secret_api_key : a shared secret . the shared secret can be retrieved from the configuration center . an api_key_id and secret_api_key always go hand - in - hand , the difference is that secret_api_key is never visible in the http request . this secret is used as input for the hmac algorithm ."
returns a v1hmac authentication signature header
returns the encoded uri path without the http method and including all decoded query parameters .
| object containing additional input on the order
| object containing amount and iso currency code attributes
| object containing the details of the consumer
| shopping cart data
| object that holds all reference fields that are linked to this transaction
| object containing seller details
"| shopping cart data , including items and specific amounts ."
"| your additional reference identifier for this transaction . data supplied in this field will also be returned in our report files , allowing you to reconcile the incoming funds ."
discover and load all unit tests in all files named ` ` test_*.py ` ` in ` ` .. /unit/ ` `
creates a handler that serves requests by calling the callable object with this handler as argument
context manager that creates a thread with a server at localhost which listens for requests and responds by calling the * call_able * function .
"| object containing data restrictions that apply to this field , like minimum and/or maximum length"
"| object containing display hints for this field , like the order , mask , preferred keyboard"
| the id of the field
"| the type of field , possible values are :"
| indicates that the product can be used in a get customer details < https://epayments-api.developer-ingenico.com/s2sapi/v1/en_us/python/products/customerdetails.html > call and that when that call is done the field should be supplied as ( one of the ) key(s ) with a valid value .
function to collect tests cases to run for the ' pip connect - sdk - python3 tests ' command
"| when the consumer is returned to your site we will append this field and value to the query - string . you should store this data , so you can identify the returning consumer ."
| this is the id under which the data for this checkout can be retrieved .
| tokens that are submitted in the request are validated . in case any of the tokens ca n't be used anymore they are returned in this array . you should most likely remove those tokens from your system .
"| the partial url as generated by our system . you will need to add the protocol and the relevant subdomain to this url , before redirecting your consumer to this url . a special ' payment ' subdomain will always work so you can always add ' https://payment . ' at the beginning of this response value to view your mycheckout hosted payment pages ."
| object that holds the payment related fields
| object containing payout details
| current high - level status of the payouts in a human - readable form . possible values are :
"| this object has the numeric representation of the current payout status , timestamp of last status change and performable action on the current payout resource . | in case of a rejected payout , detailed error information is listed ."
"| the url that the consumer is redirect to after the payment flow has finished . you can add any number of key value pairs in the query string that , for instance help you to identify the consumer when they return to your site . please note that we will also append some additional key value pairs that will also help you with this identification process . | note : the provided url should be absolute and contain the protocol to use , e.g. http:// or https://. for use on mobile devices a custom protocol can be used in the form of * protocol*://. this protocol must be registered on the device first . | urls without a protocol will be rejected ."
| unique mandate identifier
| paypal ( payment product 840 ) specific details
tests that an abstractparamrequest accepts a string as value
tests that an abstractparamrequest accepts an int as value
tests that an abstractparamrequest accepts a longer int as value
tests that an abstractparamrequest accepts a boolean as value
tests that an abstractparamrequest accepts a list with a single string as value
tests that an abstractparamrequest accepts a list of a single int as value
tests that an abstractparamrequest accepts a list of two booleans as value
tests that an abstractparamrequest refuses a float as value and responds with an appropriate error
tests that an abstractparamrequest refuses a float as value and responds with an appropriate error
| indicates if a new token was created
| id of the token
| the desired date for the payout | format : yyyymmdd
stores the given secret key for the given key id .
removes the secret key for the given key id .
removes all stored secret keys .
tests if the communicator can correctly construct an url using a known base url and a relative url
"tests if the communicator can correctly construct an url using a known base url , a relative url and a list of request parameters"
: return : the http status code that was returned by the ingenico epayments platform .
: return : the raw response body that was returned by the ingenico epayments platform .
: return : the headers that were returned by the ingenico epayments platform . never none .
": return : the header with the given name , or none if there was no such header ."
": return : the value header with the given name , or none if there was no such header ."
"| contains the payment product ids and payment product groups that should be excluded from the payment products available for the payment . note that excluding a payment product will ensure exclusion , even if the payment product is also present in the restrictto filter , and that excluding a payment product group will exclude all payment products that are a part of that group , even if one or more of them are present in the restrictto filters ."
"| contains the payment product ids and payment product groups that should be at most contained in the payment products available for completing the payment . note that the list of payment products available for completing the payment will only contain payment products present in these filters , but not all payment products in these filters might be present in the list . some of them might not be allowed in context or they might be present in the exclude filters ."
| object containing the card details ( without cvv )
| date of the first transaction ( for atos ) | format : yyyymmdd
| reference of the provider ( of the first transaction ) - used to store the atos transaction certificate
creates a webhookshelperbuilder that will use the given secretkeystore .
| indicates the requiredness of the field based on the fiscalnumber for boleto bancario
| indicates that the content should be validated against the rules for an email address
| indicates that the content should be validated against the rules for an expiration date ( it should be in the future )
"| indicates that content should be one of the , in this object , listed items"
| indicates that the content of this ( iban ) field needs to validated against format checks and modulo check ( as described in iso 7064 )
| indicates that the content needs to be validated against length criteria defined in this object
| indicates that the content needs to be validated using a luhn check
"| indicates that the content needs to be validated against a , in this object , defined range"
| a string representing the regular expression to check
| indicates that the content should be validated as such that the consumer has accepted the field as if they were terms and conditions of a service
": param parent : : class:`ingenico.connect.sdk.api_resource . apiresource ` : param path_context : dict[str , str ]"
resource /{merchantid}/productgroups/{paymentproductgroupid }
| object containing the name details of the consumer
| contains the regular expression that the value of the field needs to be validated against
| additional address information
| iso 3166 - 1 alpha-2 country code
| house number
| full name of the state or province
| state code
| zip code
tests that the metadataprovider can construct meta_data_headers when supplied with a full shopping cart
tests that the metadataprovider can construct meta_data_headers when supplied with a full shopping cart
tests that the metadataprovider functions correctly without any additional headers as arguments
tests that the metadataprovider can handle multiple additional headers
tests that the metadataprovider constructor does not accept any headers marked as prohibited
"assert that checks that the request_header is the default header "" x - gcs - servermetainfo "" , that the server_meta_data_info of the meta_data_provider is correct and that the shopping cart extension is consistent with the extension stored in meta_data_provider"
| determines the type of the authorization that will be used . allowed values :
"| the payment data if you want to do the decryption of the vendor 's encrypted payment data yourself . | typically you 'd use encryptedcustomerinput in the root of the create payment request to provide the payment data for mobile payment methods . only when you do not do this you need to use either this field or encryptedpaymentdata , depending on who should do the decryption of the vendor 's encrypted payment data ."
"| the payment data if you want to let us do the decryption of the vendor 's encrypted payment data . | typically you 'd use encryptedcustomerinput in the root of the create payment request to provide the payment data for mobile payment methods . only when you do not do this you need to use either this field or decryptedpaymentdata , depending on who should do the decryption of the vendor 's encrypted payment data . this maps to the following field in the vendor 's encrypted payment data :"
| android pay ( payment product 320 ) specific details .
"* true = the payment requires approval before the funds will be captured using the capture payment < https://epayments-api.developer-ingenico.com/s2sapi/v1/en_us/python/payments/approve.html > api * false = the payment does not require approval , and the funds will be captured automatically"
* true = fraud scoring will be skipped for this transaction * false = fraud scoring will not be skipped for this transaction
| the vendor 's transaction i d. this maps to the following field in the vendor 's encrypted payment data :
tests if the function withclientmetainfo alters a client when it needs to and does nothing if not required
checks that the ' clientmetainfo ' header with client_meta_info is stored properly in the client
tests that the setting to close an idle connection in a client propagates to the connection for an unpooled connection
tests that the setting to close an idle connection in a client propagates to the connection for a pooled connection
tests that the setting to close an expired connection in a client does not propagate to the connection for an unpooled connection
tests that the setting to close an expired connection in a client propagates to the connection for a pooled connection
| payment product identifier | please see payment products < https://epayments-api.developer-ingenico.com/s2sapi/v1/en_us/python/paymentproducts.html > for a full overview of possible values .
type : str
"| unique reference , for debugging purposes , of this error response"
| list of one or more errors
| object that contains details on the created payout in case one has been created
| object containing the details of the created payment
"| object that contains the action , including the needed data , that you should perform next , like showing instruction , showing the transaction results or redirect to a third party to complete the payment"
initializes the intervals object with a set of given intervals .
"given a value of an interval , this function returns the previous interval value"
"given a value of an interval , this function returns the next interval value"
this function returns the nearest interval to any given interval .
base method for response to successful api calls .
base method for response to unsuccessful api calls .
method to retrieve config file for screen .
method to turn hex colour code to kivy compatible list .
creates default entries in dictionary of tube status .
if user clicks on tube line we need to show extra data .
method to save local copy of recordings . backend may not be online all the time so a cache enables us to display recordings if if we ca n't poll the server for an update .
retrieves cached recorings and returns as a python list object .
converts the mythtv upcoming recording iterator into a list of dict objects .
attempts to connect to mythtv backend and retrieve recordings .
checks whether the backend is currently recording .
main method for rendering screen .
method to retrieve list of photos based on user 's preferences .
method to update the currently displayed photo .
converts the event object into the relevant variables needed to display the item .
method to retrieve list of available calendars on google account .
method to turn google event into a format that we can use more easily .
method to tidy up the raw event info into an ordered and grouped list .
method to draw the calendar on the screen .
return true if input is an integer or decimal number .
returns spelled - out numbers as integers . return_int : return an integer rather than a string .
return integer as a spelled - out string .
测试主函数 : return :
": param etcd_options : etcd配置选项 : param service_names : 需要监听的所有service的名称 : type etcd_options : dict : type service_names : list , tuple : return :"
: param service : : type service : service : return :
get service_list for the service_name . : param service_name : : type service_name : str : return : : rtype : list
向指定service_name下增加一个waiter ， 以等待该service_name下有新的事件发生 : param service_name : : param waiter : waiter : type service_name : str : type waiter : waiter : return :
移除指定service_name下的一个waiter : param service_name : : param waiter : : type service_name : str : type waiter : waiter : return :
通知指定service_name下的所有waiter : param service_name : : param action : 当前变更动作，定义与constatn . service_action : type service_name : str : type action : str : return :
: param result : watch 返回的etcdresult对象 : type result : etcd . etcdresult : return :
: param service_name : : param result : : type service_name : str : type result : etcd . etcdresult : return :
: param service_name : : param result : : type service_name : str : type result : etcd . etcdresult : return :
: param service_name : : param result : : type service_name : str : type result : etcd . etcdresult : return :
"run the given code snippet or files in a session . depending on the session id you give ( default is random ) , it may reuse an existing session or create a new one ."
terminate the given session .
emulation of secrets.token_bytes ( )
emulation of secrets.token_hex ( )
provides virtual folder operations .
list virtual folders that belongs to the current user .
create a new virtual folder .
delete the given virtual folder . this operation is irreversible !
show the information of the given virtual folder .
upload a file to the virtual folder from the current working directory .
download a file from the virtual folder to the current working directory .
list files in a path of a running container .
"returns a list of tuples ( file path , file content ) for a recursive walk of path"
"generate a go file with a map of file paths to content with an additional entry for the root index , ' / '"
"returns the pin instance identified by ' pin_id ' , or none if no pin exists with that identifier ."
read from the standard output of the forked program .
parse cli common login and repo arguments .
check password and prompt if missing and check repo is provided .
"http://api.map.baidu.com/marker?location=40.047669,116.313082&title=我的位置&content=百度奎科大厦&output=html&src=yourcomponyname|yourappname //调起百度pc或web地图，且在（lat:39.916979519873，lng:116.41004950566）坐标点上显示名称""我的位置""，内容""百度奎科大厦""的信息窗口 。"
create table structure
fills the database with institutions saved in filename
"this test patches the multiaddr 's string representation to return an invalid string in order to test that value_for_protocol properly throws a valueerror . this avoids some of the error checking in the constructor and is easier to patch , thus the actual values that the constructor specifies is ignored by the test ."
from recursive at http://stackoverflow.com/questions/493174/is-there-a-way-to-convert-number-words-to-integers-python
return whether a word is a pronoun .
expects the reference names to be annotated like ncbi_tid|<ncbi_tid>|<img_oid.img_gid > : param align_gen : : param tree : : param img_map : : return :
build a last common ancestor dictionary : param sam_inf : path to sam infile : param extract_ncbi_tid : function to extract ncbi_tid : param tree : ncbitree : return : dict key ( query name : string ) value ( ncbi_tid : int )
tries to remove files by filename wildcard path .
returns a string containing the tesseract version .
returns the result of a tesseract ocr run on the provided image to string
returns string containing recognized characters and their box boundaries
"returns string containing box boundaries , confidences , and other information . requires tesseract 3.05 +"
returns string containing the orientation and script detection ( osd )
read in a line delimited file of environment variables .
prompt the user for a yes or no .
"given a generator which yields strings and a separator string , joins all input , splits on the separator and yields each chunk ."
"like subprocess.call ( ) , but redirects stdout and stderr to /dev / null ."
"load the point group symbol , name and operators from file ."
"flatten a tree , assigning the label of the root to each node [ labels clusters ] = vl_flatmap(map ) labels each tree of the forest contained in map . labels contains the linear index of the root node in map , clusters instead contains a label between 1 and the number of clusters ."
perform quickshift segmentation - this function is a thin wrapper and expects an image in lab space use vl_imseg for easy segmentation .
"color an image based on the segmentation iseg = imseg(i , labels ) labels iseg with the average color from i of each cluster indicated by labels"
compute quickshift segmentation of image . @param image float rgb or grayscale image @param ratio tradeof between color and proximity ( between 0 and 1 ) @param kernelsize size of distance kernel @param maxdist maximum distance between modes to be joined into one segment
"create an edge image from a quickshift segmentation . iedge = vl_quickvis(i , ratio , kernelsize , maxdist , maxcuts ) creates an edge stability image from a quickshift segmentation . ratio controls the tradeoff between color consistency and spatial consistency ( see vl_quickseg ) and kernelsize controls the bandwidth of the density estimator ( see vl_quickseg , vl_quickshift ) . maxdist is the maximum distance between neighbors which increase the density ."
"create an edge image from a quickshift segmentation . iedge = mapvis(map , gaps , maxdist , maxcuts ) creates an edge stability image from a quickshift segmentation . maxdist is the maximum distance between neighbors which increase the density ."
get edges within an image by calculating image derivatives
"vl_ertr transpose exremal regions frames f = vl_ertr(f ) transposes the frames f as returned by vl_mser ( ) . this conversion is required as the vl_mser algorithm considers the column index i as the frist image index , while according standard image convention the first coordinate is the abscissa x."
"return extended attributes stored on the server . this not only contains tags and lease information , but might also contain some other sensitive information ."
standardize x so that they are z - scores ( as could have been done in matlab - land ) . note that default numpy and matlab std computation differ : see http://stackoverflow.com/questions/7482205/precision-why-do-matlab-and-python-numpy-give-so-different-outputs
"given a 1d array x , prepare it to be transferred to hctsa land . - hctsa expects floating point numbers . so we cast if needed . - hctsa expects column vectors . in order for this to work regardless of oned_as configuration of the engine , we reshape it to ( -1 , 1 ) . n.b. other preconditions for some hctsa operators , like z - scored time series , must be hadled somewhere else ."
warn that something is deprecated
deprecated function decorator
"creates and saves a user with the given username , email and password ."
installs gunicorn .
starts the gunicorn service .
stops the gunicorn service .
restarts the gunicorn service .
deploys the gunicorn configuration file .
deploys an upstart service for gunicorn .
thy willst generate an abode leaflet .
log users in in order to use moodbot .
clear the headers and allow for logout then route home .
conducts the bulk of our bot functionality .
display a page about the team .
set the login route and view .
extract tweets .
decorator auth by x - gitlab - token in view
decorator for check user permission in view
see docstring of this class .
parameters ---------- observation ( numpy.ndarray ):
"returns a n * t matrix of action probabilities , where n is number of trajectories , and t is the length of each trajectories ."
"put all the info in the paths into a single matrix . if stack is true , then we get a rank-3 tensor , n * t * dim , where the n is number of paths , t is the length of path , the dim is the dimension of either observation or action or something else . if stack is false , the trajectories will be concatenate together to form a very long trajectory , then we have a rank-2 matrix , where the first dimension is of n * t."
sample a batch of size batch_size from data .
train the discriminator
returns the parameters of the discriminator
set the parameters of the discriminator
see doc of extract_paths in imitationlearning class
"chop the data into smaller piece according to the info in paths . each of the smaller piece of data should have the same length as the observations in the corresponding paths . thus , data should have the length which is the summation of the all the length of observations in paths ."
attempts to leave a ps room
initializes the psbot class
decides bot behaviour wth the server based on the content from the websocket .
handles new users entering a room .
parses the message given by a user and delegates the tasks further
"returns a dictionary of all methods for all views available for this project , marked with the ` ` @allow_remote_invocation ` ` decorator . the return string can be used directly to initialize the angularjs provider , such as ` ` djangormiprovider.configure({­% djng_rmi_configs % ­ } ) ; ` `"
"returns a dictionary of all methods for the current view of this request , marked with the @allow_remote_invocation decorator . the return string can be used directly to initialize the angularjs provider , such as ` ` djangormiprovider.configure({­% djng_current_rmi % ­ } ) ; ` `"
conditionally switch between angularjs and django variable expansion for ` ` { { ` ` and ` ` } } ` ` keeping django 's expansion for ` ` { % ` ` and ` ` % } ` `
returns a script tag for including the proper locale script in any html page . this tag determines the current language with its locale .
create mer2 vrt
create ncep vrt
create ncep vrt parameters : filename : url date : str 2010 - 05 - 01 ds : netcdf.dataset previously opened dataset
convert time variable to np.datetime64
rollovers should roll for all handlers of the same file .
not particularly fast code to parse the text file and load it into three ndarray 's and product an ndarrayiter
"returns a pair of ndarraydataiter , one for train , one for test ."
start server / scheduler .
initialize a new kvstoreserver .
return the server controller .
"run the server , whose behavior is like ."
load image full path given specified index
load ground - truth of image given specified index
save imglist to disk
load class names from text file
some tricks of feature engineering are adapted from tensorflow 's wide and deep tutorial .
helper function for margin - based loss . return a distance matrix given a matrix .
try to configure cython and return cython configuration
lstm cell symbol
returns symbol for lstm model up to loss / softmax
adds symbol.contrib.ctc_loss on top of pred symbol and returns the resulting symbol
adds symbol . wapctc on top of pred symbol and returns the resulting symbol
adds ctc loss on top of pred symbol and returns the resulting symbol
"creates an unrolled lstm symbol for inference if loss_type is not specified , and for training if loss_type is specified . loss_type must be one of ' ctc ' or ' warpctc '"
returns name and shape of init states of lstm network
"get two list , each list contains two elements : name and nd.array value"
the name and shape of data provided by this iterator
the name and shape of label provided by this iterator
"return one dict which contains "" data "" and "" label """
callback to checkpoint module to prefix every epoch .
a callback that saves a model checkpoint every few epochs . each checkpoint is made up of a couple of binary files : a model description file and a parameters ( weights and biases ) file . the model description file is named ` prefix`--symbol.json and the parameters file is named ` prefix`-`epoch_number`.params
callback to log the training evaluation result every period .
callback to show speed .
callback to show progress bar .
install callback to executor . supports installing to multiple exes .
start collecting stats for current batch . call before calling forward .
end collecting for current batch and return results . call after computation of current batch .
end collecting and print results .
"use zero initialization for better convergence , because it tends to oputut 0 , and the label 0 stands for background , which may occupy most size of one image ."
convert caffe mean
returns a new dataset with each sample transformed by the transformer function ` fn ` .
returns a new dataset with the first element of each sample transformed by the transformer function ` fn ` .
"checkpoint the model data into file . : param prefix : prefix of model name . : param epoch : the epoch number of the model . : param arg_params : dict of str to ndarray model parameter , dict of name to ndarray of net 's weights . : param aux_params : dict of str to ndarray model parameter , dict of name to ndarray of net 's auxiliary states . : return : none prefix-epoch.params will be saved for parameters ."
"reads an image from file path or url , optionally resizing to given image dimensions and subtracting mean . : param img_path : path to file , or url to download : param image_dims : image dimensions to resize to , or none : param mean : mean file to subtract , or none : return : loaded image , in rgb format"
changes device of given mxnet arguments : param arg_params : arguments : param aux_params : auxiliary parameters : param ctx : new device context : return : arguments and auxiliary parameters on new device
"run the layer comparison on a caffe model , given its prototxt , weights and mean . the comparison is done by inferring on a given image using both caffe and mxnet model : param image_url : image file or url to run inference on : param gpu : gpu to use , -1 for cpu : param caffe_prototxt_path : path to caffe prototxt : param caffe_model_path : path to caffe weights : param caffe_mean : path to caffe mean file"
implementation of breadth - first search ( bfs ) on caffe network dag : param root_node : root node of caffe network dag : param process_node : function to run on each node
compare layer by layer of a caffe network with mxnet network : param caffe_net : loaded caffe network : param arg_params : arguments : param aux_params : auxiliary parameters : param exe : mxnet model : param layer_name_to_record : map between caffe layer and information record : param top_to_layers : map between caffe blob name to layers which outputs it ( including inplace ) : param mean_diff_allowed : mean difference allowed between caffe blob and mxnet blob : param max_diff_allowed : max difference allowed between caffe blob and mxnet blob
entrypoint for compare_layers
set the symbolic class to be cls
ctypes implementation of imperative invoke wrapper
initialize a new ndarray
ctypes implementation of imperative invoke wrapper
"return ground truth image regions database : return : imdb[image_index]['boxes ' , ' gt_classes ' , ' gt_overlaps ' , ' flipped ' ]"
get selective search roidb and ground truth roidb : param gt_roidb : ground truth roidb : param append_gt : append ground truth : return : roidb of selective search
"set status to training / not training . when training , graph will be constructed for gradient computation . operators will also run with ctx.is_train = true . for example , dropout will drop inputs randomly when is_train = true while simply passing through if is_train = false ."
returns a training scope context to be used in ' with ' statement and captures training code .
returns a testing scope context to be used in ' with ' statement and captures testing code .
mark ndarrays as variables to compute gradient for autograd .
compute the gradients of outputs w.r.t variables .
deprecated . please use backward
return function that computes both gradient of arguments and loss value .
clear all contents in the relay memory
reset all the flags stored in the replay memory . it will not clear the inner - content and is a light / quick version of clear ( )
function factory for file extension argparse assertion args : extension ( string ): the file extension to assert
generates the colormap for visualizing the segmentation mask args : num_colors ( int ): the number of colors to generate in the output palette
"get the ( 1 , 3 , h , w ) np.array data for the supplied image args : img_path ( string ): the input image path"
module main execution
decode image from str buffer . wrapper for cv2.imdecode that uses mx.nd . ndarray
decode image from str buffer . wrapper for cv2.imresize that uses mx.nd . ndarray
pad image border wrapper for cv2.copymakeborder that uses mx.nd . ndarray
scale down crop size if it 's bigger than image size
"crop src at fixed location , and ( optionally ) resize it to size"
randomly crop src with size . upsample result if src is smaller than size
normalize src with mean and std
randomly crop src with size . randomize area and aspect ratio
reset iterator position to 0
move iterator position forward
generate row ids based on the current mini - batch
generate row ids for all rows
seeds the random number generators in mxnet .
return indices of unique boxes
returns a pre - defined model by name
create a torch function from the functionhandle .
list and add all the torch backed ndarray functions to current module .
convert the caltech101 mat file to images examples -------- python convert_data.py --dataset /home / ubuntu / datasets / caltech101 / data / caltech101_silhouettes_28.mat --save_path /home / ubuntu / datasets / caltech101 / data/ --invert --height 32 --width 32
parses input args
find the path to xlearn dynamic library files .
remove all entries from the cache
"return value for key . if not in cache , return default"
add key to the cache with value val
remove key from the cache
"return value for key . if not in cache or expired , return default"
add key to the cache with value val
create cache decorator factory .
named arguments :
clear the given cache(s ) .
unit test for the gaussian estimator class : class:`gaussest ` .
unit test for the : class:`matrixlt ` class .
tests the matrix .
initial estimator .
unit test for vamp method using a gaussian prior .
unit test for vamp using a gaussian mixture model ( gmm )
unit test for vamp using a gaussian mixture model ( gmm )
run the vamp_gauss_test with various parameters
run the vamp_gmm_test
run vamp with a bg prior
projects any value : math:`z ` onto the feasible set . the default implementation performs no projection
penalty function . this must be implemented in the derived class .
augmented nonlinear function and its gradient .
initial estimator .
lotistic estimator with binary class label .
unit test for the : class:`matrixlt ` class .
tests the matrix .
unit test for the wavelet2dlt class .
run the conv2d test .
compute the initial estimates and message . if there are nlayers :
forward message passing sequence .
reverse message passing sequence .
computes the total cost from the node and message costs
main iterative solving routine using the forward - backward algorithm .
prints a summary of the model
"get the first unused supval table key , or 0 if the table is empty . useful for filling the supval table sequentially ."
does not support setting a value to none . value must be json - serializable . key must be a string or integer .
limited to 20 events .
untappd returns json instead of url encoded data .
shows a simple line plot of a specific temperature sensor .
shows a histogram of volume by day of the week .
clone of django.contrib.admin.views.decorators.staff_member_required that uses ` settings . kegbot_admin_login_url ` as the default login url .
sends a tweet using ` api ` .
compiles a template from ` kbvars ` variables .
"create instance of a class , with constructor call"
http request to get the html of the specified url
create a soup from url
"encode v , which is a string of bytes , to base58 ."
decode v into a string of len bytes
return 32 - bit checksum based on sha256
"b58encode a string , with 32 - bit checksum"
"decode a base58 string , check and remove checksum"
returns none if straddress is invalid . otherwise returns integer version of address .
"modify the signature in vin 0 of the tx to pass cltv prepends < height > cltv drop in the scriptsig , and sets the locktime to height"
"since dictionaries in python are unsorted make sure that our outputs are correctly ordered . note : comparing strings to get "" correct order "" is based on the fact that p2sh_1 string is < p2sh_2 string in this particular case ."
"create and send a transaction with a random fee . the transaction pays to a trivial p2sh script , and assumes that its inputs are of the same form . the function takes a list of confirmed outputs and unconfirmed outputs and attempts to use the confirmed list first for its inputs . it adds the newly created outputs to the unconfirmed list . returns ( raw transaction , fee )"
"we need to generate a lot of very small inputs so we can generate a ton of transactions and they will have low priority . this function takes an input from txins , and creates and sends a transaction which splits the value into 2 outputs which are appended to txouts ."
this function calls estimatefee and verifies that the estimates meet certain invariants .
we 'll setup the network to have 3 nodes that all mine with different parameters . but first we need to use one node to create a lot of small low priority outputs which we will use to generate our transactions .
"do a http request , with retry if we get disconnected ( e.g. due to a timeout ) . this is a workaround for https://bugs.python.org/issue3566 which is fixed in python 3.5 ."
return hash of raw file contents
return hash of rgba contents of image
add a p2p connection to the node .
tear down and bootstrap the p2p connection to the node .
1 . make sure that the interface exists in the name space . 2 . update the mac address .
"once the interface is operational , configure the ip addresses . for a bi - directional interface we use dhclient ."
"check if the currently watched instance ( model , feature or preprocessing ) is outdated and update it eventually ."
generate a string that contains a command with all necessary parameters to train the model .
train the model in ` ` model_folder ` ` .
main part of the training script .
return the parser object for this script .
get the dimension of the returned feature . this equals the number of elements in the returned list of numbers .
test if the functions execute at all .
check the parser .
the get_class function returns a class for feature and preprocessing algorithms .
"this function is used to get a binary decision by the user . sadly , there are two different ways to use it due to python 2 / 3 ."
another python 2/3 input hack .
another python 2/3 input hack .
another python 2/3 input hack .
check if a file exists . do this check within argumentparser .
similiar to is_valid_file .
test if the creation of the project configuration works .
check if get_latest_model works .
check the interactive function choose_raw_dataset .
test if all folders are catched .
test if the packaged model can be loaded .
test if the packaged model can be used .
convert an xml elementtree to a dictionary .
strip ` suffix ` from the end of ` text ` if ` text ` has that suffix .
return the parser object for this script .
parameters ---------- folder : str
parameters ---------- hwr_objects : list of hwr objects
create a model if it does n't exist already .
parse the info.yml from ` ` model_folder ` ` and create the model file .
return the parser object for this script .
validationerror errors are handled
look for cameras
poll does nothing
long poll send don
set the log debug level 0 = all 10 = debug 20 = info 30 = warning 40 = error 50 = critical
adds counter with dimensions to the global pyformance registry
adds histogram with dimensions to the global pyformance registry
adds meter with dimensions to the global pyformance registry
adds timer with dimensions to the global pyformance registry
adds gauge with dimensions to the global pyformance registry
decorator to track the number of times a function is called with with dimensions .
decorator to track the rate at which a function is called with dimensions .
decorator to check the distribution of return values of a function .
decorator to check the distribution of return values of a function with dimensions .
decorator to time the execution of the function with dimensions .
adds custom metric instances to the registry with dimensions which are not created with their constructors default arguments
adds counter with dimensions to the registry
adds histogram with dimensions to the registry
adds gauge with dimensions to the registry
adds meter with dimensions to the registry
adds timer with dimensions to the registry
clears the registered metrics and metadata
adds timer with dimensions to the registry
adds histogram with dimensions to the registry
adds counter with dimensions to the registry
adds gauge with dimensions to the registry
adds meter with dimensions to the registry
method position arguments .
method named arguments .
": keyword locals : if given , a dictionary of "" builtin "" values that will be available at the top - level . : keyword banner : if geven , a string that will be printed to each connecting user ."
interact with one remote user .
apply standard padding .
remove standard padding .
create a stateful counter block function suitable for ctr encryption modes .
return a fresh instance of the hash object .
continue hashing of a message by consuming the next chunk of data .
return the * * binary * * ( non - printable ) digest of the message that has been hashed so far .
return the * * printable * * digest of the message that has been hashed so far .
"return a copy ( "" clone "" ) of the hash object ."
return a fresh instance of the hash object .
continue hashing of a message by consuming the next chunk of data .
return the * * binary * * ( non - printable ) digest of the message that has been hashed so far .
return a file - like object that outputs cryptographically random bytes .
return a random byte string of the desired size .
method provided for backward compatibility only .
method provided for backward compatibility only .
method provided for backward compatibility only .
"mask generation function , described in b.2.1"
"implement the ` ` emsa - pss - encode ` ` function , as defined in pkcs#1 v2.1 ( rfc3447 , 9.1.1 ) ."
"implement the ` ` emsa - pss - verify ` ` function , as defined in pkcs#1 v2.1 ( rfc3447 , 9.1.2 ) ."
return a signature scheme object ` pss_sigscheme ` that can be used to perform pkcs#1 pss signature or verification .
initialize this pkcs#1 pss signature scheme object .
return true if this cipher object can be used or signing messages .
produce the pkcs#1 pss signature of a message .
verify that a certain pkcs#1 pss signature is authentic .
return a fresh instance of the hash object .
continue hashing of a message by consuming the next chunk of data .
return the * * binary * * ( non - printable ) digest of the message that has been hashed so far .
return a list of testcase instances given a testcase class
remove whitespace from a text or byte string
"convert hexadecimal to binary , ignoring whitespace"
convert binary to hexadecimal
return a fresh instance of the hash object .
continue hashing of a message by consuming the next chunk of data .
return the * * binary * * ( non - printable ) digest of the message that has been hashed so far .
cryptodome.random.new ( )
instantiate a cipher object that performs cfb encryption / decryption .
"create a new block cipher , configured in cfb mode ."
encrypt data with the key and the parameters set at initialization .
decrypt data with the key and the parameters set at initialization .
return a fresh instance of the hash object .
continue hashing of a message by consuming the next chunk of data .
return the * * binary * * ( non - printable ) digest of the message that has been hashed so far .
"return a copy ( "" clone "" ) of the hash object ."
sha256 : 512/520 mib test
parse a subjectpublickeyinfo structure .
extract subjectpublickeyinfo from a der x.509 certificate .
test pasting into text without a selection .
test pasting into text with a selection .
test pasting into an entry without a selection .
test pasting into an entry with a selection .
test pasting into a spinbox without a selection .
test pasting into a spinbox with a selection .
"extend the path variable by one slot , then rotate all the values one slot , then set path[0 ] to ' /sd '"
set up the vs2 module
"init the module , then run an infinite loop , polling the ps/2 trackball , and displaying the results"
send reset read 3 times send remote mode wait one clock cycle
"arguments seem to be needed to pass functions ? ? ? ? in an infinite loop : - poll the device for data - if the data is different from the last displayed data , then display it the device replies to the poll with 4 bytes : ack , status , deltax , deltay , all values since last poll - wait for 20 ms"
a little helper function to format the results read from the poll of the device
test function for verifying basic functionality .
set the lcd line linnb to display the val ; val is left justified to num_cols to overwrite any characters leftover from previous writes .
"instance creation , args : * pin is a pyb . pin object as per : pyb . pin('x1 ' , pyb . pin . analog ) * an optional rmap instance to provide a reading in the proper range"
returns the current reading as per config
instance creation ; print name .
return the current value
return the next value
"resets to state.loff , depending on arguments"
"updates the ' new ' value to the next , using addition if ' add ' argument is true . if ' add ' is false , then simply overwrites ."
copies next to current . does not change next .
"instance creation , we get a vector of 2 currentnextable 's and ' reset ' member variable is true , meaning there has been a reset since last connection was added ."
resets the next of each of the poles and sets the member variable ' rest ' to true should not need to be called from outside this class .
"the connection method is the worker of this class . arguments : 0 : a poleid i.e. 0 or 1 1 : a list of [ coilname , pole ] for the other side of the connection this works as follows : by default we assume that the connection will be appended to any existing connections . but if the member ' rest ' is false , then we need a reset first , and will not append . finally , the connectable member ' update ' is called with the arguments needed ."
"execute the connections to update the current values , but only for connections , do nothing for n one values ! set member variable ' reset ' to false to say that a reset is needed ."
"the callback simply : - sets the corresponding flag , - prints a message"
init the objects and vectors containing them set all leds to off
"this is called when a flag ( line ) is found to be true : - if there has n't been enough time , reset flag and return - otherwise - toggle the corresponding led - reset the flag to false - print a message"
"loop over all the flags and doflag if true , clean exit if ctrl - c detected"
this little helper function takes a node and an index and returns the element that is required : 0 : out+ 1 : out- 2 : internals
return the out+ of the node
return the out- of the node
return the internals of the node
"a and b are lists , this concatenates them just syntactic sugar , returns a list of a+b"
parallel connect nd1 nd2 means : out+ = the out+ of nd1 and nd2 connected together out- = the out- of nd1 and nd2 connected together whatever previous internal connections there were are maintained
"series connect nd1 nd2 means : out+ = the out+ of nd1 out- = the out- of nd2 internals = add a connection from out- of nd1 to out+ of nd2 to whatever previous internal connections there were . """
""" returns a list of n parallel connected nodes where n>0"
returns a list of n series connected nodes where n > 1
"return [ [ elt , ' out+ ' ] for elt in clis[0 ] ] + [ [ elt , ' out- ' ] for elt in clis[1 ] ] + ( [ ] if not clis[2 ] else reduce(lambda x , y : x+y,[mapconnect(x ) for x in clis[2 ] ] ) )"
keylen = len(namekey ) namelen = len(model . name ) pos = model . name.find(namekey )
writes out the arc header to the file like object ` f ` .
constructs an arc record from a string and returns it .
initialises a file like object that can be used to read or write arc files . works for both version 1 or version 2 .
writes out an arc header
writes out the given arc record to the file
"reads out the file header for the arc file . if version was not provided , this will autopopulate it ."
"reads out an arc record , formats it and returns it"
reads out an arc record from the file
there is a dependency between a and b b is the head of a and c is in turn the head of b a becomes the head of b and c becomes the head of a the deprel between b and c becomes the deprel between a and c
move dependents from a to b
update a dictionary adding counts of aux and main verb pos tags
"the function first looks for verb groups in the sentence . a verb group has a main verb and at least one auxiliary . when there 's just one auxiliary , it changes the dependency direction between the auxiliary and main verb and the head of the main verb becomes the head of the auxiliary when there are several auxiliaries , it attaches the closest one to the verb and the head of the main verb becomes the head of the outermost one it then deals with the dependents of the main verb to keep projecivity : dependents to the left of the leftmost verb get attached to the leftmost verb dependents to the right of the rightmost verb get attached to the rightmost verb remaining dependents get attached to the auxiliary that is closest to the verb"
attach auxiliaries and their dependents to the main verb
only auxiliary dependencies between verbal forms ( aux or verb ) are considered
return the id of the dependency relation if it is
"pass sentence left to right collecting auxiliares , their main verbs and the other auxiliaries of the main verb input : dependency graph output : list of verb group objects"
"recurse the chain of auxiliary dependency relations if the main verb is to the left , the recursion follows the heads of auxiliary dependency relations if the main verb is to the right , the recursion follows the dependents of auxiliary dependency relations until it finds the main verb"
combines the non - interactive zypper command with arguments / subcommands
parses the output of zypper --xmlout repos and return a parse repo dictionary
check whether the 2 given repos have different settings .
check whether the repository already exists .
"adds the repo , removes old repos before , that would conflict ."
removes the repo .
forces zypper to refresh repo metadata .
returns a new rolemetadata object based on the datastructure passed in .
"this is a helper loading function for the dependencies list , which returns a list of roleinclude objects"
"this is a helper loading function for the galaxy info entry in the metadata , which returns a galaxyinfo object rather than a simple dictionary ."
"override for the ' tags ' getattr fetcher , used from base ."
"loops through the conditionals set on this object , returning false if any of them evaluate as such ."
"this method does the low - level evaluation of each conditional set on this object , using jinja2 to wrap the conditionals for evaluation ."
query a livestatus backend
wrapper to lazily initialize connection info to galaxy
fetches the galaxy api current version to ensure the api server is up and reachable .
retrieve an authentication token
post an import request
check the status of an import task .
find a role by name .
fetch the list of related items for the given role . the url comes from the ' related ' field of the role .
fetch the list of items specified .
set up argument handling and callback routing
direct callback for when ` ` --list ` ` is provided
return dictionary of all device attributes
takes a group and returns inventory for it as dict
verifies if string is a pubkey
"downloads a key from url , returns a valid path to a gpg key"
"ensure a keyid does n't have a leading 0x , has leading or trailing whitespace , and make sure is lowercase"
"verifies if a key , as provided by the user is a keyid"
executes a haproxy command by sending a message to a haproxy 's local unix socket and waiting up to ' timeout ' milliseconds for the response .
capture the output for a command
discover all entries with svname = ' backend ' and return a list of their corresponding pxnames
run some command on the specified backends . if no backends are provided they will be discovered automatically ( all backends )
"find the state of specific services . when pxname is not set , get all backends for a specific host . returns a list of dictionaries containing the status and weight for those services ."
"wait for a service to reach the specified status . try retries times with interval seconds of sleep in between . if the service has not reached the expected status in that time , the module will fail . if the service was not found , the module will fail ."
"enabled action , marks server to up and checks are re - enabled , also supports to get current weight for server ( default ) and set the weight for haproxy backend server when provides ."
"disabled action , marks server to down for maintenance . in this mode , no more checks will be performed on the server until it leaves maintenance , also it shutdown sessions while disabling backend host server ."
"figure out what you want to do from ansible , and then do it ."
main execution path
"determines if the cache files have expired , or if it is still valid"
reads the settings from the libcloud.ini file
command line argument processing
"do api calls to a location , and save data in cache files"
gets the list of all nodes
gets details about a specific node
"adds a node to the inventory and index , as long as it is addressable"
get variables about a specific host
pushed an element onto an array that may not have been defined in the dict
reads the inventory from the cache file and returns it as a json object
reads the index from the cache file sets self.index
writes data in json format to a file
converts ' bad ' characters in a string to underscores so they can be used as ansible groups
converts a dict to a json object and dumps it as a formatted string
main entry point for module execution
connect to the jail ; nothing to do here
run a command on the jail . this is only needed for implementing put_file ( ) get_file ( ) so that we do n't have to read the whole file into memory .
run a command on the jail
make sure that we put files into a standard path
transfer a file from local to jail
fetch a file from jail to local
terminate the connection ; nothing to do here
add selinux port type definition to the policy .
delete selinux port type definition from the policy .
format json output ( uncompressed or uncompressed )
return a keystone client object
return true if tenant already exists
""" return true if user already exists"
retrieve a tenant by name
retrieve a user by name
retrieve a role by name
ensure that a tenant exists .
ensure that a tenant does not exist
check if user exists
check if role exists
dispatch to the appropriate method .
retrieves block device mapping from ami
returns true if the tap is valid .
returns true if already tapped .
adds a single tap .
adds one or more taps .
removes a single tap .
removes one or more taps .
display play start messages
display info about playbook statistics
this updates the module field names to match the field names tower - cli expects to make calling of the modify / delete methods easier .
: class:`attribute ` specifies constraints for attributes of objects which derive from playbook data . the attributes of the object are basically a schema for the yaml playbook .
return content of str before the srch parameters .
"convert set command to get command and set value . return tuple ( get command , set value )"
entry point .
run ovs - vsctl command
check if the bridge already exists
set attributes on a bridge .
create the bridge
delete the bridge
run check mode
make the necessary changes
return the bridge 's external ids as a dict .
set external i d.
get failure mode .
set failure mode .
we override the parent task ( ) classes get_vars here because we need to include the args of the include into the vars as they are params to the included tasks .
create an image with the specified name .
delete a specific image resource by name .
main entry point for module execution
logs the start of each task
"return ` ` ( stdout , stderr ) ` `"
handler for fetch operations
"for backwards compatibility , when only vars per host were retrieved this method should return both host specific vars as well as vars calculated from groups it is a member of"
get host specific variables .
get group specific variables .
check if the given locale is available on the system . this is done by checking either : * if the locale is present in /etc / locales.gen * or if the locale is present in /usr / share / i18n / supported
checks if the given locale is currently installed .
locale -a might return the encoding in either lower or upper case . passing through this function makes them uniform for comparisons .
replaces lines in /etc / locale.gen
sets the state of the locale . defaults to enabled .
create or remove locale .
create or remove locale .
main entry point for module execution
prepend a key with rax _ and normalize the key name
function to convert a clb node object to a dict
generic function to convert a pyrax object to a dict
find a servers bootable volume
find a server image by id or name
find a block storage volume by id or name
find a cloud network by id or name
find a cloud server by id or name
find a cloud load balancer by id or name
return standard base dictionary used for the argument_spec argument in ansiblemodule
return the default list used for the required_together argument to ansiblemodule
set up pyrax in a standard way for all modules
main entry point for ansiblemodule
create a new object ( collection.item ) by loading a datastructure directly
"combine two lists , removing duplicates ."
return matching items in both lists .
return changed items as they relate to baselist .
modify tags on an instance .
converts a dict to a json object and dumps it as a formatted string
reads the settings from the foreman.ini file
command line argument processing
fetch host params and convert to dict
fetch all host facts of the host
write data in json format to a file
converts ' bad ' characters in a string to underscores so they can be used as ansible groups
make calls to foreman and save the output in a cache
determines if the cache is still valid
read the index from the cache file sets self.index
read the index from the cache file sets self.index
read the index from the cache file sets self.facts
read the cache from the cache file sets self.cache
get variables about a specific host
calculates the estimated distance using the signal strength . the model used to calculate the distance can be found here : http://www.ee.ucl.ac.uk/lcs/previous/lcs2005/12.pdf
"calculates the estimated distance to each sniffer and return the position ( x , y ) of the device ."
calculates brünt - väisälä frequency squared ( n : sup:`2 ` ) at the mid depths from the equation :
"specific volume anomaly calculated as svan = 1 / dens(s , t , p ) - 1 / dens(35 , 0 , p ) ."
geopotential anomaly calculated as the integral of svan from the the sea surface to the bottom . thus relative to sea surface .
calculates geostrophic velocity given the geopotential anomaly and position of each station .
register a secret to be masked . the secret will be replaced with : < replacement >
make sure that pytest accepts our fixture .
equality up to a tolerance
create a deep copy of this linearconstraints object
returns a point in the center of the box
returns a list of the so - called diamond points of this box ( 2*dims of them )
returns a list of the unique corner points of this box ( up to 2^dims of them )
get the simulation bundle associated with the dynamics in this mode .
get the already - created simulation bundle for this mode
"this is an optimation where we try to guess the dwell time using a simulation , so we avoid repeated calls"
"' get the transpose of g(a , h ) * b , where g(a , h ) is defined as :"
"sets the non - inputs dynamics . c_vector can be none , in which case zeros are used"
"sets the input dynamics . b matrix can be none , in which case identity matrix is used ."
add a mode
add a transition
strengthen the guards to include the invariants of target modes
make the hybrid automaton and return it
"returns a list of ( mode , list(linearconstraint ] )"
get the hylaa settings object
"runs hylaa with the given settings , returning the hylaaresult object ."
add the standard _ _ init _ _ to the class .
extract a null - terminated string from bytestring .
helper function to print useful error messages .
module only loads on darwin
get a reference to an odnode instance given a path string eg . /ldapv3/127.0.0.1
add the specified group
remove the named group
add a user in the group .
remove a user from the group
return information about a group
return formatted information in a pretty way .
return info on all groups
get a list of registered nodes eg . /local / default
search for groups using the given criteria .
find a group object in the local directory by its unique i d ( gid )
find a user object in the local directory by their username
return the sha-1 hash of all data in the ' care ' regions of this image .
"generator that produces all the image data in ' ranges ' . the number of individual pieces returned is arbitrary ( and in particular is not necessarily equal to the number of ranges in ' ranges ' . this generator is stateful -- it depends on the open file object contained in this sparseimage , so you should not try to run two instances of this generator on the same object simultaneously ."
throw away the file map and treat the entire image as undifferentiated data .
"parse a text string consisting of a space - separated list of blocks and ranges , eg "" 10 - 20 30 35 - 40 "" . ranges are interpreted to include both their ends ( so the above example represents 18 individual blocks . returns a rangeset object . if the input has all its blocks in increasing order , then returned rangeset will have an extra attribute ' monotonic ' that is set to true . for example the input "" 10 - 20 30 "" is monotonic , but the input "" 15 - 20 30 10 - 14 "" is not , even though they represent the same set of blocks ( and the two rangesets will compare equal with = =) ."
return a new rangeset representing the union of this rangeset with the argument .
return a new rangeset representing the intersection of this rangeset with the argument .
return a new rangeset representing subtracting the argument from this rangeset .
returns true if the argument has a nonempty overlap with this rangeset .
"returns the total size of the rangeset ( ie , how many integers are in the set ) ."
pipeline for identifying marker alleles
compute the prevelance of the 4 nucleotides across samples
determine if marker present in each sample
fetch next marker allele from file
compute sharing between sample pairs
select samples from input mean_depth : filter samples based on average genome / gene depth fract_cov : filter samples based on the number of genomic sites covered by > = 1 read max_samples : stop when this numbe of samples reached keep_samples : only keep samples in this list exclude_samples : exclude any sample in this list rand_samples : select random subset of samples
yield genomic sites from species across samples
"fetch next row from freq and depth matrices store in sample objects : sample.freq , sample.depth"
filter samples at site based on coverage sets flag : sample.keep = [ true / false ]
determine if site passes quality control
compute summary stats for site across samples
compute average frequency of reference allele with optional weighting of samples
resample random number of reads per sample
call consensus allele at each position
requests the next page if there is one .
requests any remaining pages .
blocks until all * requested * pages have been returned .
returns count of * retrieved * pages which were not empty .
returns the number of results found at page_num
returns retreived data found at pagenum .
returns all retrieved data flattened into a single list ( instead of separated into page objects ) .
returns bool indicating if there are any pages not retrieved .
"test compatibility with 30 protocol version : if the flag is unset , schema agreement can not be reached"
"test compatibility with 30 protocol version : if the flag is set , schema agreement can be reached"
"test compatibility between post-13004 nodes , one of which is in compatibility mode"
test compatibility between post-13004 nodes
this is a hack to work around problems like cassandra-11811 .
"after upgrading one of two nodes , create a new table ( which will not be propagated to the old node ) and check that queries against that table result in user - friendly warning logs ."
set cookie .
returns the average structure for a trajectory . > > > avg = loos.pyloos.averagestructure(traj )
extracts coords from a trajectory as a numpy matrix > > > a = loos.pyloos.extractcoords(traj )
"returns a tuple containing svd results along with the average structure for a trajectory > > > ( l , s , v , avg ) = loos.pyloos.svd(traj )"
"this constructor sets the resources instances and the user agents to avoid to being banned by the api server . every last request made by the api saves the last response in the self.last_response . if the request fails because a 502 status , it attempts to do it again many times defined in the request_attempts argument . and the attempt is made after seconds defined in the seconds_between_attempts argument ."
"giving a service path and optional specific arguments , returns the response string ."
"giving a service path and optional specific arguments , returns the response string ."
"giving a service path and optional specific arguments , returns the xml data from the api parsed as a dict structure ."
randomly returns one of the items in the the user_agents list defined .
it requires the main thegamesdb object .
just this resource name .
the object string representation includes the important methods of this resource .
instantiate an item using the item_class defined in the class passing this resource as the first argument and the correspond data .
gets the dict data and builds the item object .
this method is abstract and needs to be implemented because the kwargs might be different per resource .
"check if vocab_file does n't exist , create from corpus_file ."
creates vocab tables for src_vocab_file and tgt_vocab_file .
get the file object located in ` path ` in this repo .
get the dir object located in ` path ` in this repo .
remove this repo . only the repo owner can do this
list the history of this repo
update the name of this repo . only the repo owner can do this .
get the settings of this repo . returns a dict containing the following keys :
restore the repo to this revision
"creates a genome subset from interval list file this is a file with cols chr , start , stop , strand , name strand and name are ignored , and actually it could have extra cols too and wo n't complain coordinates are 1 - indexed and inclusive"
"intervals is an iter of ( xstart , xend ) tuples"
"returns : list of ( variant , true / false ) tuples , indicating whether variant falls in this genomesubset"
"update project metadata - including one or more of these fields : name , description"
get any variants with an alternate allele in at least one unaffected indiv
get any variants with an alternate allele in at least one unaffected indiv
updates the ` case_review_status ` of one or more individuals .
updates the ` case_review_notes ` field for the given family .
updates the ` internal_case_review_summary ` field for the given family .
the following models are transfered between projects .
utility method that prints out a set of users .
"return ensembl id from arg , which can be ensembl i d or gene i d"
"extract a family variant from full variant it 's just a copy , with the following changes : -- all genotypes from non - family individuals are removed -- variant['alt_allele_count ' ] is updated to alt allele count in family indivs"
"extract a family variant from full variant it 's just a copy , with the following changes : -- all genotypes from non - family individuals are removed -- variant['alt_allele_count ' ] is updated to alt allele count in indiv_id_list"
get alt allele count for a variant
gets a map of indiv_id - > alt allele count from the variants in variant_list todo : can we use collections.counter ?
"given an arbitrary string s , see if you can use reference to get a gene id ( ensembl id )"
get alt allele frequency from a variant todo : consider sex chromosomes todo : tests
"return handle to a file , whether compressed or not gzip.open ( ) if file_path ends in .gz otherwise basic file handle"
"simplified , custom implementation of the functionality in the awesome - slugify python module . a custom approach was needed because awesome - slugify only supports one char as the separator , for example ' - ' or ' _ ' but here we keep both ' - ' and ' _ ' , while replacing all other special chars with ' _ ' ."
"applies a reversable encoding to the special chars in the given name or i d string , and returns the result . among other things , the encoded string is a valid elasticsearch or mongodb field name ."
decodes a name or i d string that was encoded by # _ encode_name ( .. ) and returns the original string
parses the gencode gtf file and yields a dictionary for each record
"the sub class check ( ) function usually will call this super function . and after the real checking , it should call self.judge(test_result ) ."
this function only can be invoked after sharable volume has already successfully attached . notice this fuction is just need to execute once although there are 2 hosts in the cluster .
this function configure the ocfs2 host machine
"this function touch a file named "" tag1 "" in vm1 , and then check the tag existence from vm2"
"add system tag for mn to monitor the storage network in network separated . currently , not support multiple ps case"
convert json string to google.protobuf.descriptor instance
convert google.protobuf.descriptor instance to json string
pass json conversation to self.conversation
create python bytecode from a python assembly file .
compute softmax values for each sets of scores in x.
this runs a server but also spawns a background process . it 's not safe to call this more than once per python process !
reads a project from a project file .
locates the project for a path .
auto discovers the closest project .
the path where output files are stored .
the path where plugin packages are stored .
given a filename returns the content path or none if not in project .
create a new environment for this project .
given a pacakge requirement this returns the information about this plugin .
this downloads and installs a specific version of a package .
this installs a local dependency of a package .
returns the name of a package at a path .
registers the plugin at the given path .
registers the plugin at the given path .
lists all local packages below a path that could be installed .
updates the package cache at package_root for the given dictionary of packages as well as packages in the given local package path .
this adds a path to as proper site packages to all associated import systems . primarily it invokes ` site.addsitedir ` and also configures pkg_resources ' metadata accordingly .
this loads all the packages of a project . what this does is updating the current cache in ` ` root / package - cache ` ` and then add the python modules there to the load path as a site directory and register it appropriately with pkg_resource 's workingset .
wipes the entire package cache .
collect metadata about the os
mount partitions in correct order
add initial output instances
call the error method of each of the output instances
call the warn method of each of the output instances
call the success method of each of the output instances
call the output method of each of the output instances
call the output method of each of the output instances
call the cleanup method of each of the output instances
call the clear method of each of the output instances
"if the user wants a fancy annotation , like ' add middle column ' , this gets processed here . it 's potentially the place where the user could add entropy score , or something like that ."
make a string representing metadata to add
find the place in filename at which to add the string
"open file , read lines , add or replace the line with the good one"
show a dry run of what the annotations would be
add annotation to a single file
show or delete the necessary lines
run the annotator pipeline over multiple files
used in paper : segmental spatiotemporal cnns for fine - grained action segmentation lea et al . eccv 2016
dilation_depth : number of layers per stack nb_stacks : number of stacks .
check if a language is supported by the current duckling version .
ensure a language identifier has the correct duckling format and is supported .
lookup an execution by its id .
generate a optionally filtered list of executions .
count the number of executions optionally filtered .
validates the passed zapp description against the supported schema .
start an execution .
terminate an execution .
delete an execution .
lookup a service by its id .
generate a optionally filtered list of services .
"retrieve the logs for the given service . if stream is true , a file object is returned , otherwise the log contents as a str object ."
retrieve statistics about the scheduler .
return a list of the services and public endpoints available for a certain execution .
test info api endpoint .
test userinfo api endpoint .
test list all executions api endpoint .
test start execution api endpoint .
test zapp validation endpoint
test zapp validation endpoint
convert the object into a dict .
convert the object into a dict .
total memory installed in the whole platform .
total number of cores installed .
total number of containers .
check if the workspace for user_id exists .
get the volume path of the workspace .
check if this workspace can be mounted as a docker volume
get the volume mount point .
return a volumedescription for the user workspace .
initializes the request handler .
set up the headers for enabling cors .
needed for cors .
http get method .
not implemented as we do not use stream uploads
initializes the request handler .
tornado callback for clients closing the connection .
http get method .
used for development and testing .
get the entire sub expressions as a string with spaces .
get all the dimensions as a single comma delimited string .
get this sub expression as a list .
get the function as it appears in the orig expression .
get the function upper - cased .
get the metric name as it appears in the orig expression .
get the metric name lower - cased .
get the dimensions .
get the dimensions as a list .
get the operator .
get the threshold value .
get the period . default is 60 seconds .
get the periods . default is 1 .
"get the operator as one of lt , gt , lte , or gte ."
get the i d used to identify this sub expression in the repo .
set the d used to identify this sub expression in the repo .
pure - python murmur2 implementation .
check if non - admin context passed to admin actions throws policy not authorized exception
deprovision this resource at the resource provider .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase . we allow to address single slivers ( ips ) rather than the whole slice at once .
documentation see [ geniv3rpc ] geniv3delegatebase . we allow to incrementally add new slivers ( ips ) .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase . { geni_users } is not relevant here .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
documentation see [ geniv3rpc ] geniv3delegatebase .
helper method to map ips to urns .
helper method to map urns to ips .
helper method to create the sliver_status return values of allocate and other calls .
initialise logger and clear delegate .
set this object 's delegate .
get this object 's delegate .
get details for this member authority implementation .
create object of given type with fields given in options .
update object of given type and urn with fields given in options .
delete object of given type and urn .
lookup objects with given type .
verifies if given certificate is valid and trusted : param cert_to_verify : certificate to verify
returns an updated certificate revocation list
provide list of credentials ( signed statements ) for given member this is member - specific information suitable for passing as credentials in an am api call for aggregate authorization . arguments : member_urn : urn of member for which to retrieve credentials options : potentially contains ' speaking_for ' key indicating a speaks - for invocation ( with certificate of the accountable member in the credentials argument )
revokes a member certificate . arguments : member_urn : urn of member whose certificate is to be revoked return :
assigns given privileges to a system member : param member_urn : urn of member : param credentials : actor 's credentials usually root : param privileges_list : list of privileges to be assigned : return : updated member credential
"return information about version and options ( e.g. filter , query , credential types ) accepted by this service"
"creates a new instance of the given object with a ' fields ' option specifying particular field values that are to be associated with the object . these may only include those fields specified as ' allowed or ' required ' in the ' creation ' column of the object descriptions below or in the ' create ' key in the supplemental fields in the get_version specification for that object . if successful , the call returns a dictionary of the fields associated with the newly created object ."
"updates an object instance specified by urn with a ' fields ' option specifying the particular fields to update . only a single object can be updated from a single update call . the fields may include those specified as ' yes ' in the ' update ' column of the object descriptions below , or ' true ' in the ' update ' key in the supplemental fields provided by the get_version call . note : there may be more than one entity of a given urn at an authority , but only one ' live ' one ( any other is archived and can not be updated ) ."
"deletes an object instance specified by urn only a single object can be deleted from a single delete call . note : not all objects can be deleted . in general , it is a matter of authority policy ."
"lookup requested details for objects matching ' match ' options . this call takes a set of ' match ' criteria provided in the ' options ' field , and returns a dictionary of dictionaries of object attributes keyed by object urn matching these criteria . if a ' filter ' option is provided , only those attributes listed in the ' filter ' options are returned . the requirements on match criteria supported by a given service are service - specific ; however it is recommended that policies restrict lookup calls to requests that are bounded to particular sets of explicitly listed objects ( and not open - ended queries ) ."
provide list of credentials ( signed statements ) for given member this is member - specific information suitable for passing as credentials in an am api call for aggregate authorization . arguments : member_urn : urn of member for which to retrieve credentials options : potentially contains ' speaking_for ' key indicating a speaks - for invocation ( with certificate of the accountable member in the credentials argument )
constructur for the server wrapper .
"returns the flask instance ( not part of the service interface , since it is specific to flask ) ."
starts up the server . it ( will ) support different config options via the config plugin .
this method will automatically be called by the serverproxy class when a transport channel is needed .
return the ine municipality code from the cadastre code
convert cdau address to cadastre attributes
conflate cdau over cadastre addresses datasets
args : a_path ( str ): directory where the source files are located .
try many times to get a http response or raise exception
download url to filename
initializes with total
increments progress by step and displays the percent as a bar
: param : settings object : return : channel object
return json - able dictionary .
slugify a unicode string .
trim leading variable declaration and load json data .
get ipv6 addresses of the host
main function ( for testing purposes ) . program is not meant to be called .
initialize class .
renumber atoms in fragment according to renumber dictionary .
write out the fragment .
hold set of fragments that represents the chain of atoms held in atom_lines .
determine whether or not to add n and c termini to this chain based on comparision of sequence in seqres entries and sequence in structure . i do not want to attempt a full alignment to determine if the termini are represented . i 'll just check the first and last $ num_compare residues of gene_seq and struct_seq to make sure that they are the same to add termini . this will fail in cases where : 1 ) long sequences are exactly repeated throughout protein and this seq happens to align with start ( not terribly likely ) 2 ) there is a gap in the structure within the first $ num_compare residues .
take lines of pdb in self.atom_lines and find breaks in chain .
renumber fragments in fragment list according to renumber dictionary . use renumbered fragments to renumber self.atom_list .
write out the chain .
read pdb file and find chains in the pdb file .
find the indiviual chains in a pdb file given all atom entries in the file .
"renumber all atoms . toggles between "" fixed "" and "" raw "" states . the "" fixed "" state has all residues in the protein renumbered from 1 , and no chain identifiers . the "" raw "" state has whatever numbering was originally assigned in the pdb file ."
write out the entire structure .
dump list of all fragments in structure with termini information .
write dictionaries used to convert number schemes to a file .
take file written by dumpnumberconversion and load into raw2fix and fix2raw . current_numbering must be specified to indicate the current state of the pdb relative to the loaded dictionaries . * * * note ! this will wipe out the automatically generated conversion dictionaries ! * * *
return a bytestring representation of the value .
"create nshares of the secret . threshold specifies the number of shares needed for reconstructing the secret value . a 0 - 16 bytes identifier must be provided . optionally the secret is hashed with the algorithm specified by hash_id , a class attribute of hash . this function must return a list of formatted shares or raises a tsserror exception if anything went wrong ."
shares must be a container with a sufficient number of well - formatted shares used to reconstruct the secret value . if any share format is invalid a tsserror exception is raised . if strict_mode is false all combinations of shares are tried in order to reconstruct the secret . otherwise this function raises an exception tsserror on the first error encountered ( either a duplicate share was detected or the provided hash value did n't match the one computed from the recovered secret ) . this function must return the secret value or raise tsserror .
initialise the script .
analyse the background
initialise the script .
run the script .
set the expected options .
parse the options .
output the datablock to file .
a constructor for the reflection predictor .
a constructor for the reflection predictor .
a factory function for the reflection predictor .
ensure non - overlapping reflections have all their values 1 .
ensure masks for overlapping reflections are set properly .
calculate sample covariance of two vectors
calculate covariance matrix between the arguments ( should be flex.double arrays of equal length )
calculate squared mahalanobis distance of all observations ( rows in the vectors contained in the list cols ) from the center vector with respect to the covariance matrix cov
finite sample correction factor for the mcd estimate . described in pison et al . metrika ( 2002 ) . doi.org/10.1007/s001840200191 . implementation based on ' rawcorfactor ' in fastmcd.m from continuous sound and vibration analysis by edward zechmann
"data expected to be a list of flex.double arrays of the same length , representing the vectors of observations in each dimension"
run the fast mcd calculation
get the raw mcd location ( t ) and covariance matrix ( s ) estimates
get the mcd location ( t ) and covariance matrix ( s ) estimates corrected for normal model consistency and finite - sample size
"prepare a dataset of equal length vectors for mahalanobis distance squared calculation . the maha_dist_sq function requires the vectors , the vector of their means and their covariance matrix . given the vectors , return the latter pair as a tuple"
sample ( without replacement ) the data vectors to select the same sample_size rows from each .
split each vector in the data sample into groups of approximately equal size .
method 2 of subsection 3.1 of r&vd
practical application of theorem 1 of r&vd
"when a dataset is small , perform the initial trials directly on the whole dataset"
"when a dataset is large , construct disjoint subsets of the full data and perform initial trials within each of these , then merge"
try to obtain the current git revision number and store a copy in .gitversion
display the reference profiles found in the reference_pickle_file generated by dials integration using intensity.algorithm = fitrs
"generate reference data set from integrate.hkl , check out the calculated x , y and z centroids as well as the miller indices as coordinates in some high dimensional space . only consider measurements with meaningful centroids ..."
generate a cctbx unit_cell from an integrate_hkl file .
derive a reindexing matrix to go from the orientation matrix used for xds integration to the one used for dials integration .
initialise the algorithm .
compute the background .
initialise the class with a mask of trusted regions
add an image to calculation .
complete the gain map of a single image .
remove strong pixels from the gain map .
compute the full gain map .
compute the full background map .
initialise the algorithm .
calculate state and derivatives for model at image number t
return crystal orientation matrix [ u ] at image number t
calculate state and derivatives for model at image number t
return crystal orthogonalisation matrix [ b ] at image number t
"send the calculated variance - covariance of the elements of the b matrix for all scan points back to the crystal model , if required"
initialise algorithm .
process the reflections .
initialise a predictor for each experiment .
predict all the observable reflections .
get the predictor for the given experiment index .
"args : name : name of the embedding to retrieve . d_emb : embedding dimensions . show_progress : whether to print progress . default : how to embed words that are out of vocabulary . can use zeros , return ` ` none ` ` , or generate random between ` ` [ -0.1 , 0.1 ] ` ` ."
returns : list : a list of lists of words corresponding to the ngrams in the sentence .
args : show_progress : whether to print progress .
"diversity value should be in [ 0.0 , 1.0 ] ."
both vectors must be of the same length .
generate a captcha consisting of the letters in answer .
cut text shaped like letter out of the given layer .
select * * length * * charaters to form a captcha answer string .
count the images with the given file extension in a directory .
make sure there are as many catchas in image_dir as goal .
record current commit .
install local static dependencies .
build static files via gulp .
build banshee binary via makefile .
make local temporary directory .
remove local temporary directory .
upload local directory to remote directory .
refresh service via supervisor .
deploy banshee .
returns the common root of all open folders in the window
get the common parent directory of multiple paths .
dumps one peer 's adj - rib - in .
dumps one peer 's adj - rib - out .
"wrapper of "" yabgp.api.send_update "" in order to hook sending update messages via rest api ."
creates a new tile .
information to be displayed when the player moves into this tile .
process actions that change the state of the player .
returns all move actions for adjacent tiles .
returns all of the available actions in this room .
log the given messages at the given log level . always use this method to send log messages from your spider
return a copy of this request
create a new request with the same attributes except for those given new values .
return libxml2 doc for htmls
return libxml2 doc for xmls
"this overridable method is called for each result ( item or request ) returned by the spider , and it 's intended to perform any last time processing required before returning the results to the framework core , for example setting the item guids . it receives a list of results and the response which originated that results . it must return a list of results ( items or requests ) ."
you can override this function in order to make any changes you want to into the feed before parsing it . this function must return a response .
this method must be overriden with your custom spider functionality
"this method is called for the nodes matching the provided tag name ( itertag ) . receives the response and an xpathselector for each node . overriding this method is mandatory . otherwise , you spider wo n't work . this method must return either a baseitem , a request , or a list containing any of them ."
this method has the same purpose as the one in xmlfeedspider
this method has the same purpose as the one in xmlfeedspider
this method must be overriden with your custom spider functionality
receives a response and a dict ( representing each row ) with a key for each provided ( or detected ) header of the csv file . this spider also gives the opportunity to override adapt_response and process_results methods for pre and post - processing purposes .
upload image to s3 storage
returns the bb node contained in the file save.pickle .
dump the tree representing the forum in a pickle file
iterator on the topics of the forum
iterator on the posts of the forum
iterator on the posts of the topic
decorator to annotate functions we will tell logging not to log .
: param prefix - the prefix for each line logged by this object .
""" writes data only if it constitutes a whole line . if it 's not the case , store it in a buffer and wait until we have a complete line . : param data - raw data ( a string ) that will be processed ."
""" writes itertable of lines"
passes lines of output to the logging module .
add string line - by - line with offset*offset_per_level
whole workflow with bad data
bus ' child ca n't be bus ( )
dev 's child ca n't be dev ( )
in info_block must contain info about file or backing_file
return a new attr instance and set properties from dargs
return ip attribute dict
return esp attribute dict
return sctp attribute dict
default slots ' value check
test guestfish slots
return icmpv6 attribute dict
initilizes a new yumrepo object
returns the default path for the a repo of a given name
returns a boolean in yum acceptable syntax
renders the repo file
saves the repo file
removes the repo file
return a list of dictionaries containing each channel 's attributes
set all channel to the value list of dictionaries of channel attributes
remove the list of dictionaries containing each channel 's attributes
convenience method for appending channel from dictionary of attributes
return a list of dictionaries containing each listen 's attributes
set all listens to the value list of dictionaries of listen attributes
remove the list of dictionaries containing each listen 's attributes
convenience method for appending listens from dictionary of attributes
change the graphic type name and passwd
add spice ssl or vnc graphic with passwd
del original graphic device
return ah attribute dict
чтение dataframe из excel : param filename : : param sheet : : return : dataframe
"find a zero using the bisection method : param funct : function the function whose zero is wanted . it must be a function of a single variable of the form f(x , a , b , c ... ) , where a , b , c ... are extra arguments that can be passed in the ` args ` parameter . : param left_x : : param right_x : : param args : tuple , optional extra arguments to be used in the function call . : param tol : : float , optional the allowable error of the zero value . : param maxiter : int , optional maximum number of iterations . : return : : float estimated location where function is zero ."
calculate the net present value of a series of cashflows at irregular intervals .
right ! calculate the internal rate of return of a series of cashflows at irregular intervals .
"return true if all values in df_data is zeros : return : true if empty , false if has non zeros values"
a simple method that runs a managementutility .
produce and consume
what would you like to cool ? list cookable items in inventorylist
what would you like to use to heal ? list items in inventorylist
returns a file object for reading a gzip compressed file in the current package directory
return a load_tests function suitable for using test discovery with our modified testsuite class
returns a sequence that is the background .
get json object representation .
see superclass .
see superclass .
see superclass .
* translated from matlab * http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html
use dftups to upsample an image ( but takes an image and returns an image with all reals )
1d upsampling ... not exactly dft becuase i still do n't understand it =(
fft - based sub - pixel image shift http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html
fft - based sub - pixel image shift http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html
create n ellipses from powerlaw sampling with the specified parameters
check if * keys ( nested ) exists in ` element ` ( dict ) .
open a connection to the board .
get to a mode where we can read & write flash .
get out of bootloader mode and go back to running main code .
write a binary to the address given .
read a specific range of flash .
erase a specific page of internal flash .
get a single attribute . returns a dict with two keys : ` key ` and ` value ` .
get all attributes on a board . returns an array of attribute dicts .
set a single attribute .
"check for the tock bootloader . returns ` true ` if it is present , ` false ` if not , and ` none ` if unsure ."
"return the version string of the bootloader . should return a value like ` 0.5.0 ` , or ` none ` if it is unknown ."
"return the address in flash where applications start on this platform . this might be set on the board itself , in the command line arguments to tockloader , or just be the default ."
figure out which board we are connected to . most likely done by reading the attributes . does n't return anything .
return the name of the board we are connected to .
return the architecture of the board we are connected to .
this function permit you to add the current song to a playlist . if the playlist does n't exist in the database so it will ask you if you create a playlist with the name : param name : name of playlist where you want add the current song : return :
add the current song in the playlist : param name : name of the playlist where you want add the current song : return :
delete the current song in the current playlist : return :
"create the playlist with "" name "" : param name : name of the playlist : return :"
delete the playlist : param name : name of the playlist : return :
parse an iso format date ( yyyy - mm - dd ) .
make a new instance from a database .
make instance from database .
forget cache for database .
add a priority rule for files .
override systemexit .
override printing to stderr .
test that properties with falsy empty values do n't throw exceptions
test that functional empty values are transient
test that ' empty ' definition errors are no longer possible
"invoked when a new ` ` record ` ` type is declared , and is responsible for copying the ` ` properties ` ` from superclass ` ` record ` ` classes , processing the ` ` primary_key ` ` declaration , and calling : py : meth:`normalize.property . property.bind ` to link : py : class:`normalize.property . property ` instances to their containing : py : class:`normalize.record . record ` classes ."
create a new collection property .
check that we still have our sanity ...
test that diff notices when fields are removed
expand the expression using the variables specified .
parse the expression as a string .
expand the expression using the variables specified .
return the attributes defined in the expression .
return the list of attributes that are referenced in this attribute mapping . these are the attributes that should be requested in the search .
construct a search filter for searching for the attribute value combination .
return a dictionary with every attribute mapped to their value from the specified variables .
extract the attribute value from from dn if possible . return none otherwise .
list the shells from /etc / shells .
check if the provided shell exists and is executable .
check if the specified shell is valid and exit if it is n't .
starts up the bot . connects to the homeserver and logs in .
stops the bot
push a message
push an image or video
leaves all rooms
leaves rooms that no target user is in
create rooms for users not found in any current room
fetches list of rooms
print exception and quit
copies docstrings from the methods of a source class to the methods of a target class .
"returns a converted position tuple ( x , y ) ( internal use )"
"returns a converted position tuple ( x , y ) ( internal use )"
returns a converted rgb gun
desc : resets plug - in settings .
desc : closes the connection with the eye tracker when the experiment is finished .
desc : a hook to prepare the canvas with the clibration target .
"desc : reloads pygaze modules to get a clean start . this is necessary , because otherwise pygaze will try to use the old experiment instance when the experiment is executed twice . explicitly reloading all opensesame - related modules will fix this ."
desc : the run phase of the plug - in goes here .
desc : applies the controls .
refreshes the controls .
desc : activates the relevant controls for each tracker .
"cloud(p , filename , display , color ) : display cloud of points p"
convert vec3 = > np.array and np.array = > vec3
attributes ---------- self : connect to a mysql database to save network
update constraint information
annulus_bound ( ):
rescale bounds of the constraint with vcw factor
answer whether constraint center is inside a box
check if a box is valid for the given constraint
test if a list of vertexes from a box is compatible with the constraint .
constraint volume estimation
evaluate mean and variance of output signal y
calculates decision problem densities under h0 and h1
calculates error probability
plot decision problem densities
determines receiver operating curve
check if mesh lines are valid
i d : cell i d p : cell position v : cell direction alpha : sector angle rmax : cell radius ( m )
annulus_bound ( ): compute the minimum and maximum distance of the enclosing annulus of the constraint for a given self.vcw
valid(b ) : check if box b is valid for the given constraint
test function to check admin audio file list
test function to check admin audio file add
audio player tag for admin
dispatch an ajax action to an xblock
returns a modulesystem for the specified descriptor that is specialized for rendering module previews .
"return a preview xmodule instantiated from the supplied descriptor . will use mutable fields if xmodule supports an author_view . otherwise , will use immutable fields and student_view ."
returns true if the specified xblock is in the set of reorderable xblocks otherwise returns false .
wraps the results of rendering an xblock view in a div which adds a header and studio action buttons .
"returns the html returned by the xmodule 's student_view or author_view ( if available ) , specified by the descriptor and idx ."
remove acid_aside and honor the config record
renders a placeholder xblock .
validates the data posted to the view .
enroll the user in the course .
"handle the marketing email opt - in flag , if it was set ."
attempt to create the basket and enroll the user .
add cookie from user request into server session
http handler .
"converts a datetime to a string representation . this is the default representation used in studio and lms . it is of the form "" apr 09 , 2013 at 16:00 utc "" ."
converts a datetime to a string representation .
returns true if these are w / in a minute of each other . ( in case secs saved to db or timezone are n't same )
sanity - check lti passport credentials
post a grade to the lti endpoint
issue a session - based lti request
get proper http authorization header for a given request
instantiate descriptor with most properties .
"tests that a course info module will render its updates , even if they are malformed ."
tests that a course info module will render its updates in the correct order .
do n't track requests to the specified url patterns
extract information from the request and add it to the tracking context .
gets and encrypts the django session key from the request or an empty string if it is n't found .
encrypts a django session key to another 32 - character hex value .
gets the primary key of the logged in django user
gets the username of the logged in django user
gets the ip address of the request
exit the context if it exists .
truncates the tracking log entry for problems for which the student response can be long winded .
assert that a tag in ` content ` has a certain value in a certain attribute .
"release a set of languages using the dark lang interface . languages is a list of comma - separated lang codes , eg , ' ar , es-419 '"
creates the user log in
log the user in
convert a string to int number from https://github.com/longld/peda
normalize argv to list with predefined length from https://github.com/longld/peda
"_ _ init__(self , model = defaultmodel , imgdim=96 , cuda = false )"
_ _ del__(self )
perform a forward network pass of an image on disk .
perform a forward network pass of an rgb image .
assume that we 're dealing with a human drb allele which netmhciipan treats differently because there is little population diversity in the dr - alpha gene
"netmhciipan has some unique requirements for allele formats , expecting the following forms : - drb1_0101 ( for non - alpha / beta pairs ) - hla - dqa10501 - dqb10636 ( for alpha and beta pairs )"
"parameters ---------- alleles : list list of strings containing names of hla alleles we 're making predictions for . example : [ "" hla - a*02:01 "" , "" hla - b*07:02 "" ]"
"given a list of peptide sequences , returns a bindingpredictioncollection"
"if peptide lengths not specified , then try using the default lengths associated with this predictor object . if those are n't a valid non - empty sequence of integers , then raise an exception . otherwise return the peptide lengths ."
check peptide sequences to make sure they are valid for this predictor .
"given a dictionary mapping sequence names to amino acid strings , and an optional list of peptide lengths , returns a bindingpredictioncollection ."
"given a list of hla alleles and an optional list of valid hla alleles , return a set of alleles that we will pass into the mhc binding predictor ."
l{eliot.adddestination } adds destinations to the l{destinations } attached to l{logger } .
l{eliot.adddestination } removes destinations from the l{destinations } attached to l{logger } .
l{eliot.addglobalfields } calls the corresponding method on the l{destinations } attached to l{logger } .
l{eliot.adddestionation } is the same as l{eliot.add_destination } .
l{eliot.removedestionation } is the same as l{eliot.remove_destination } .
l{eliot.add_global_fields } is the same as l{eliot.addglobalfields } .
l{eliot.writetraceback } is the same as l{eliot.write_traceback } .
l{eliot.writefailure } is the same as l{eliot.write_failure } .
l{eliot.starttask } is the same as l{eliot.start_task } .
l{eliot.startaction } is the same as l{eliot.start_action } .
read the contents of a file .
read the blast file and return an array with the number of times each base has been seen .
"convert the hits from a hash to a single list : param printcontigs : print out the locations and order of the contigs : type printcontigs : bool : param hits : the hash of hits on contig name : type hits : dict : return : a list with the hits concatenated by length , longest first and a list of all the breaks in the contigs : rtype : list , list"
"drop zero values and return two lists . one of the x 's , and one of the y 's : param hits : the list of hits : type hits : list : return : x and y lists : rtype : ( list , list )"
join the hits within a specified window : param hits : the hash of hits and contig sizes : type hits : dict : param window : the window size to use : type window : int : return : the hash of contig and coverage at each position . many positions will be zero : rtype : dict
"plot the hits ! : param breaks : an optional list of contig breakpoints to be added . if an empty list is provided no lines added : type breaks : list : param hits : the array of hits ( eg . from read_blast_file ) : type hits : list : param window : the window size used to make the plot . if 0 , this is not used in the image : type window : int : param maxy : the maximum y value to plot on the figure . if 0 ( default ) we use the maximum value of the data : type maxy ; int : return : void : rtype : void"
print out the regions with coverage higher than threshold . assumes a raw hits hash ( not windowized ) : param hitshash : the hits by contig : type hitshash : dict : param threshold : minimum coverage : type threshold : int : param merge : merge adjacent regions with x bp : type merge : int : return : none : rtype : none
find the next instance of the delimiter in the list of delimiters in the string s : param s : a string to search through : param start_posn : current position to start at . note we start at that posn . 0==start of string : param delimiters : the list of things that may be used to break that string : return : a tuple of the next instance or the length of the string if none of the delimiters found and the and the next place to start looking
print the consensus sequence about the pileup
test : remove white background
test : remove black background
test image with complete background
passes image to a deepnet and extracts from the specified layer
return the index of ` ` item ` ` in ` ` stuff ` ` using binary search .
returns a list of all tests in for this service . each test is given absolute from the squadron_dir .
"runs all the tests given by directly executing them . if they return with a non - zero exit code , it adds them to the dictionary returned ."
clones a git repository
"reports status via the https api . given the server , api key and secret , this method generates the hash_result of a nonce ."
"tell wether a value correspond to a type , optionally specifying the type as contravariant or covariant ."
a decorator that performs type checking using type hints at runtime : : @check_args def fun(a : int ): print(f'fun is being called with parameter { a } ' ) # this will raise a typeerror describing the issue without the function being called fun('not an int ' )
compares all the topic models against the first topic model of the all_term_rankings array and returns the mean stability ( as in greene 2014 )
"makes a pairwise comparison between each pair of topic models , making in total nc2 ( n combined 2 ) comparisons , where n is the number of topic models as in ( belford 2018 )"
for each one of the reviews this method predicts the rating for the user and item contained in the review and also returns the error between the predicted rating and the actual rating the user gave to the item
sleep for n seconds .
burn cpu cycles for n seconds .
return true if user_input is a valid input to a sql command .
returns the n x k matrix of square_distances between each of the n vectors and the k centroids .
returns associations of vectors on centroids .
"returns a matrix ( n , k ) of association wights , defined as : w_i , c = e^(- alpha * d_i , c^2 / d_min , i^2 ) / sum for normalization"
"default cmap depending on values ( all nonnegative , nonpositive , or neither ) ."
"custom legend . can be used in axe mode ( by setting ax = ax ) or figure mode ( fig= ... ) . if none is given , current axe is used . if both are set , ax is used ."
"plots a set of data : the mean is plotted as a standard curve , and an area around the curve of width twice the standard deviation is filled with colored background ."
"create a box - and - whisker plot showing the mean , 25th percentile , and 75th percentile . the difference from matplotlib is only the left axis line is shown , and ticklabels labeling each category of data can be added ."
"removes "" chartjunk "" , such as extra lines of axes and tick marks ."
"returns list of files in given directory , eventually filter by extension ."
get a list of speakers from directory names in path .
"@param version : acorns version , 1 for year 1 , 2 for year 2 ( default ) @param speakers : sound | info | text | everything ( default ) ( has sound | has info | has transcriptions | has everything )"
print long description
retries a build without cache
"lookup trajectory frames using pairs of ( trajectory , frame ) indices ."
get the forward committors of the reaction sources - > sinks .
computes the conditional committors : math:`q^{abc^+ } ` which are is the probability of starting in one state and visiting state b before a while also visiting state c at some point .
computes the conditional committors : math:`q^{abc^+ } ` which are is the probability of starting in one state and visiting state b before a while also visiting state c at some point .
get the forward committors of the reaction sources - > sinks .
"perform clustering . parameters ----------- x : array - like , shape=[n_samples , n_features ] samples to cluster ."
do the apm lumping .
find a discrete approximation to a multivariate normal distribution .
display the help menu
check nested looping
did we keep a reference after looping several time through a list of topological entities ?
parses an : emacs - rex command an returns lisp response .
return connection info available
create and wire up a bs . playerspaz for the provide bs . player .
establish a connection to a deepstream.io server .
creates the client but does n't connect to the server .
establishes a connection to the url given to the constructor .
sends authentication parameters to the server .
team map structure
task map structure
and now for something completely different
"so long , and thanks for all the fish !"
fit the clustering model
convenience routine to get graph segments
set the attribute ` current_action_dist ` to ` init_action_dist ` .
"install or update openssl from source ( statically linked , no shared libs ) ."
translate python code to lua code
create a lua code from the compiler output
get lua initialization code .
classify genomes based on aai to reference genomes .
ref : http://www.ruanyifeng.com/blog/2012/02/ranking_algorithm_hacker_news.html
"filter out items whose value is none . if ` keys ` specified , only return non - none items with matched key ."
get formatted time
return as timestamp
read file content
waiting for job complete ( success or fail ) until timeout
create router static .
create router static from json formatted string .
"@param instance_id : id of instance @param dhcp_config : formatted string "" key1 = val1&key2 = val2 "" such as "" domain - name - servers=8.8.8.8;fixed - address=192.168.1.2 """
"@param tunnel_entries : [ ( tunnel_type , ip_network , key ) , ... ]"
"@param peer_config : gre peer config , formatted as "" remote ip|key|local peer ip|remote peer ip "" , such as "" 6.6.6.6|1010|10.254.1.2|10.254.1.3 "" @param target_network : "" | "" separated multiple networks , such as "" 172.17.10.0/24|172.17.20.0/24 """
"@param peer_config : ipsec peer config , formatted as "" remote ip|alg|key|remote device "" , such as "" 1.2.3.4|aes|passw0rd|device - id "" @param target_network : "" | "" separated multiple networks , such as "" 172.17.10.0/24|172.17.20.0/24 """
@param local_domain : domain in private network @param local_addr : comma separated local ip address
make sure advective term vanishes for plane wave it is an unpleasant fact that we can not to get a double precision accuracy when the plane wave is slanted ( kx ! = 0 and ky ! = 0 )
returns the keyframe properties
returns the rule as a string
return a list of the programmer names supported by this cpu .
create and return a programmer instance that will be used to program the core . must be implemented by subclasses !
display info about the device .
lists serial port names
normalise each feature to have zero mean and unit variance .
normalise each feature to have unit variance .
normalise each feature to unit interval .
convert user train and test size inputs to integers .
split the data into a balanced training set and test set of some given size .
convert csv files to a hdf5 table .
this model takes as input an observation and returns values of all actions .
this model takes as input an observation and returns values of all actions .
this function checkpoints the model and state of the training algorithm .
load model if present at the specified path .
by defualt list_containers only returns a subset of results .
upload a file or directory from ` source_path ` to azure blob ` blob_name ` .
download a file or directory to ` dest_path ` to azure blob ` blob_name ` .
list all blobs in the container .
returns true if ` blob_name ` exists in container .
display image in terminal using w3mimgdisplay
automatically chooses best external viewer ( hopefully )
"returns : ( stdoutdata , stderrdata )"
"returns : ( stdoutdata , stderrdata )"
returns dict with default settings
sets key to json.dumps(value )
add json.dumps to value
remove json.dumps from value
set to empty list
"get value(s ) of key ( returns bool , int or string , not json encoded )"
read settings from file and to self.cfg ( configparser object )
create empty config file in configdir and add section main
returns a list of all settings values are stored as json objects on disk
update ( fetch ) catalog immediately
: param decl_type : declaration type to match by . for example : class:`enumeration_t ` . : type decl_type : any class that derives from : class:`declaration_t ` class
: param decl_type : variable type : type decl_type : string or instance of : class:`type_t ` derived class
: param return_type : callable return type : type return_type : string or instance of : class:`type_t ` derived class
: param symbol : operator symbol : type symbol : str
this function binds between class and it 's typedefs .
creates a test function to test if the client and serverconfig is correctly set for the given platform
global application exception handler
called as the main body of the utility
the rss2email command line interface
check that number can be parsed and does not begin with 0 .
adds arguments for an action to a parser based on values from a topology configuration .
utility method that adds a help argument to whichever parser is passed to it . this is needed to correctly handle display of help messages through the various parsers we create dynamically at runtime .
user must be a dictionary here default is checking username / password if login is ok returns true else false
checks if user is logged in if ` username ` is passed check if specified user is logged in username can be a list
get current logged in username
"decorate views to require login @login_required @login_required ( ) @login_required(username='admin ' ) @login_required(username=['admin ' , ' jon ' ] ) @login_required(basic = true ) @login_required(must=[function , another_function ] )"
helper to get internal messages outside this instance
to set login_checker as decorator : @simple.login_checher def foo(user ): ...
support basic_auth via /login or login_required(basic = true )
stdin_processor(data ) - > none
read_delimited_buffer(socket ) - > none
read_content_buffer(socket ) - > true / false
data_processors(socket ) - > none
validate_json_data(data ) - > none
close_client(socket ) - > none
"receive_data(socket , length ) - > data"
whether this hyperloglog has staged adds .
extracts the modification operation from the hll .
adds an element to the hyperloglog . datatype cardinality will be updated when the object is saved .
wait until solr index has been updated and a value returns from a query .
determines whether a given error is retryable according to the exceptions allowed to be retried by each transport .
wraps a client operation that can be retried according to the set : attr:`riakclient.retries ` . used internally .
wraps a retryable client operation that is only valid over http . used internally .
_ transport ( )
_ acquire ( )
performs the passed function with retries against the given pool .
selects a connection pool according to the default protocol and the passed one .
this is here as a stub to allow subclassing of shibbolethremoteusermiddleware to include a make_profile method that will create a django user profile from the shib provided attributes . by default it does nothing .
"if you want to add custom code to setup user sessions , you can extend this ."
parse the incoming shibboleth attributes and convert them to the internal data structure . from : https://github.com/russell/django-shibboleth/blob/master/django_shibboleth/utils.py pull the mapped attributes from the apache headers .
parse the shibboleth attributes for the group_attributes and generate a list of them .
split a pathname into components ( the opposite of os.path.join ) in a platform - neutral way .
helper function that convert the values of dictionary to int / float . optionally you can skip a list of values .
test case setup
test that the tempest test - list is correctly parsed .
test when the test listing subprocess returns a non - zero exit status .
test the test id to attribute dict builder function .
test that we can get the base test ids from a test list file .
test that we get an exception when passing in a nonexistent file .
test that we can parse the test cases from a test list url .
test a case of an invalid url schema .
test that full test ids can be formed .
test when a test id does n't exist in the tempest environment .
test that a normalized test list is written to disk .
test whether the proper script is called to setup a virtualenv .
test whether the proper script is called to setup a virtualenv .
test whether a test list is properly parsed to extract test names
bitbox words : arrrrrgggggbbbbb
apply default values for categories in a given list of jobthread objects
apply default option values on iterable of jobthread instances . default option values will be set only for options that were not pre defined by the user .
apply default option values for a given job thread object . default option values will be set only for options that were not defined by the user . this method will not overwrite user 's definitions .
repeats an event and returns ' num ' ( or fewer ) upcoming events from ' now ' .
"checks ' start ' to see if we should stop collecting upcoming events . ' start ' should be a datetime.datetime , ' start _ ' should be the same as ' start ' , but it should be a datetime.date to allow comparison w/ end_repeat ."
"simple tag - returns the weekday of the given ( year , month , day ) or of given ( weekday_number ) ."
test that it subtracts from month and adds to year to fix date when a ' next ' querystring makes month > 12 .
test that it subtracts from month and adds to year to fix date when a ' next ' querystring makes month > 12 ( w/ next qs > 12 ) .
test that it adds to month and subtracts from year to fix date when a ' prev ' querystring makes month < 12 .
test that an invalid month in the url returns current month and error .
test that a next or prev qs that puts the year out of bounds returns an error .
test valid ' next ' querystring at the end of the year
strips the line and replaces neighbouring whitespaces with single space ( except when within quotation marks ) .
"replaces variable indicators $ { and } with tags , so subsequent formatting is easier ."
replaces tags back with $ { and } respectively .
strips the lines and splits them if they contain curly brackets .
"when opening curly bracket is in it 's own line ( k&r convention ) , it 's joined with precluding line ( java ) ."
indents the lines according to their nesting level determined by curly brackets .
accepts the string containing nginx configuration and returns formatted one . adds newline at the end .
"performs the formatting on the given file . the function tries to detect file encoding first . : param file_path : path to original nginx configuration file . this file will be overridden . : param original_backup_file_path : optional path , where original file will be backed up . : param verbose : show messages"
generally should n't be instantiated directly . see : meth:`~chemspipy.api . chemspider.search ` instead .
perform the search and retrieve the results .
return true if the search finished .
return true if the search finished with no errors .
block until the search has completed and optionally raise any resulting exception .
current status string returned by chemspider .
any exception raised during the search . blocks until the search is finished .
a contextual message about the search . blocks until the search is finished .
the number of search results . blocks until the search is finished .
the time taken to perform the search . blocks until the search is finished .
get a single result or a slice of results . blocks until the search is finished .
test timestamp parser function on timestamps strings with microseconds .
test timestamp parser function on timestamps strings with no microseconds .
test duration parser function on duration strings with microseconds .
test duration parser function on duration strings with no microseconds .
create a connection to the camlistore instance at the given base url .
iterate up in the tree structure until we get an existing path
check if the specified path has to be a valid path
ensure that the path is writable
ensure it is large enough for containing an image
create a regular tcp socket of family ` family ` and protocol
"equivalent to socket.accept ( ) , but transforms the socket into a websocket instance and sends a server handshake ( after receiving a client handshake ) . note that the handshake may raise a handshakeerror exception ."
"equivalent to socket.connect ( ) , but sends an client handshake request after connecting ."
send a number of frames .
receive a single frames . this can be either a data frame or a control frame .
"receive exactly ` n ` frames . these can be either data frames or control frames , or a combination of both ."
enqueue ` frame ` to the send buffer so that it is send on the next ` do_async_send ` . ` callback ` is an optional callable to call when the frame has been fully written . ` recv_callback ` is an optional callable to quickly set the ` recv_callback ` attribute to .
send any queued data . this function should only be called after a write event on a file descriptor .
receive any completed frames from the socket . this function should only be called after a read event on a file descriptor .
transforms the regular socket.socket to an ssl . sslsocket for secure connections . any arguments are passed to ssl.wrap_socket : http://docs.python.org/dev/library/ssl.html#ssl.wrap_socket
constructor for a simple web socket server .
mocks a non - existing module in sys.modules .
converts to : class:`google.oauth2.credentials . credentials ` .
converts to : class:`google.oauth2.service_account . credentials ` .
converts to : class:`google.auth.compute_engine . credentials ` .
converts to : class:`google.auth.app_engine . credentials ` .
convert oauth2client credentials to google - auth credentials .
_ _ init _ _ creates the video list .
start_download starts downloading a video .
handle_program handles the downloading info from youtube - dl .
active_rows returns a list of active rows .
get the junk off a word .
"words is a dict of word : count pairs , and pos a nltk tag ."
"take a sentence and madlibify it , returning the result text ."
devise a fun replacement for a word using two words of context .
estimate class weights for unbalanced datasets .
compute sample weights for unbalanced datasets .
"return node with key , that is successor of current node key"
"return node with key , that is predecessor of current node key"
s = s[:i+1 ] - i - th prefix 1 . p[i ] = max k < |s| : s[:k ] = = s[i - k+1 : i+1 ] 2 . s[:p[k ] ] = = s[ ... :i+1 ] - prefix of prefix is suffix 3 . s[p[i ] ] = = s[i+1 ] = > p[i+1 ] = p[i ] + 1
compute prefix for s # t ' # ' is needed to prevent growing after s ( e.g aa#a ... ) complexity : o(|s+t| )
compute hashes for every prefix . only [ a - za - z ] symbols are supported
boyer - moore substring algorithm
move element with index i to the down to restore heap properties
move element with index i to the root to restore heap properties
transform list to heap in o(n ) .
add new item in o(log n )
pops minimum ( maximum ) element and restores heap property
replaces element with index i and restores heap property
merge heaps in o(n + m )
returns kth smallest element in o(k*log k ) . when k log k > = n it is better to use quick select algorithm
initialize ascii canvas
fill canvas with empty chars
print out canvas to console
"add ascii line ( x0 , y0 - > x1 , y1 ) to the canvas , fill line with ` fill_char `"
"add text to canvas at position ( x , y )"
add rectangle filled with ` fill_char ` and outline with ` outline_char `
add nine - patch rectangle
"check that coordinate ( x , y ) is in range , to prevent out of range error"
return canvas as a string
return canvas as a string
draw second hand
draw minute hand
draw hour hand
draw clock face with hour and minute marks
transform label to action
transform action into label
transform a feature list into a numeric vector with a given vocab
extract discourse relation on different level
reverse the { key : val } in dct to { val : key }
retrieve the phase across the objective 's back pupil from an experimentally measured psf .
utility to calculate mean square error
sub function that does the reshaping and the least squares
utility to reconstruct from coefs
the results of retrieving a pupil function 's phase and magnitude
fits the data to a number of zernikes
make a perfect psf
plot the retrieved results
diagnostic plots of the convergence criteria
return the complex pupil function
the results of decomposing a pupil function 's phase and magnitude into zernike modes
plot the first 15 zernike mode coefficients
same as ` plot_named_coefs ` but for all coefs
"reconstruct mag or phase , base function for dispatch"
reconstruct the phase from the specified slice
reconstruct the magnitude from the specified slice
reconstruct the complex pupil from the specified slice
simulate an error on close .
"create a table , insert a row and read it again , the basic db actions ."
try what happens if the connection is lost ( do a close ) and see that it is reopened again .
check the show test_query function .
"test that it is not possible to open a connection again , without closing it first ."
add a faulty close function and check that the db instance can handle that .
"this runs the main pipeline for all of the optourism project . after running , there will be plots and csv exported to the output directory"
creates a connection to the postgres database specified in the credentials file dbcreds.py
check if our packets are actually getting to the correct servers .
launches a session debus using a modified config file and sets the dbus_session_bus_address environment variable
kills the dbus session started by launch_session_dbus and removes the generated files .
returns a list of all aliases of the tnsnames.ora .
return a copy of the shell
set an environment variable
get an environment variable
( pretend to ) run a command in batch mode
( pretend to ) run a command in interactive mode
( pretend to ) run a command in popen mode
( pretend to ) redirect a command
build an executor with a dummy shell
forcing eq yields equals - style option
redirecting output and error
underscore is converted to a dash
calling in_docker_machine returns an executor that runs docker pointed at the machine
calling in_virtualenv returns an executor that runs pip in a virtual env
calling a built - in command runs it in the shell
adding an arbitrary command allows access via attribute
using the command method passes the arguments directly to the shell
calling pip_install ( ) runs ' pip install '
passing the index_url param to pip_install passes it to the pip install command
the conda_install ( ) method calls ' conda install '
interactive mode does not fail
non - existing commands raise attributeerror
popen does not fail
prepare with dict value explodes the dict
prepare with none option gives undecorated
prepare with int option stringifies the int
prepare with list option explodes into a list of options
changing directory changes the working directory
using a trailing _ protects keywords
"construct a command line for a "" modern unix "" command ."
run the shell 's batch
run the shell 's interactive
run the shell 's redirect
run the shell 's popen
bind a command to an executor .
add a new command .
prepare a command ( inspired by sql statement preparation ) .
prepare a command from a raw argument list .
return an executor where all docker commands would point at a specific docker machine .
return a new executor where the environment is patched with the given attributes
return a new executor where the working directory is different .
return an executor where all python commands would point at a specific virtual environment .
use pip to install packages
use conda to install packages
returns the bound ip address and port number at the proxy .
returns the ip and port number of the proxy .
returns the ip address and port number of the destination machine ( note : get_proxy_peername returns the proxy )
"load_config(config , path ) - load a config object from an alternate path ."
getbashpath - get the path to ' bash '
"a decorator that currently does , well , nothing . regardless , flag functions that should be transactional so that they can be dealt with in the future , when the neo4j rest interface supports transactions ."
a decorator that throws a notimplementederror instead of calling the supplied function .
copy methods from a target class onto this one .
a list of str identifiers required by this cypher snippet .
a list of identifiers yielded by this cypher snippet .
"arguments : identifier - the relationship identifier , if needed types - a list of string relationship types this component can match , if needed optional - whether or not the relationship is optional ( defaults to false ) length_or_range - an integer represention a length ( defaults to 1 ) or a tuple pair of ranges for variable - length relationships . none at either end means an unbound range ( eg , ` ( 5 , none ) ` with yield a ` 5 .. ` range . direction - a ' > ' or ' < ' indicating which direction the relationship string should point"
arguments : components - a list of alternating node and relationship components
"start_assignments - a dict of variable name keys and assignment expression values to make up a start clause . eg , ` { ' n':'node(5 ) ' } ` will lead to the expression ` n = node(5 ) ` in the output cypher str cypher_params - a list of all cypher parameters used in ` start_exprs ` . these wo n't affect the output , but are for later bookkeeping and manipulation"
"paths - a list of strs of objects with as_cypher ( ) methods that return cypher paths- eg , "" n-[:friends_with]->friend "" or "" path = n-->out "" ."
calculate heat index ( feels like temperature ) based on noaa equation .
returns the object the view is displaying .
reject users with is_active = false . custom user models that do n't have that attribute are allowed .
instancies a token bucket value
"check if the specific ` i d ` has at least ` amount ` tokens , and decrease the bucket if it is the case"
geocode an item in the background
find the location of an item using its location fields
find location of an item with its address
"this is the "" main "" which is called by "" nimbostratus "" file ."
( list of str ) - > nonetype
"( ) - > list of [ str , int ] list"
"( list of [ str , int ] list , list of list of str , list of str ) - > nonetype"
"( list of [ str , int ] list , list of list of str , list of str , int ) - > nonetype"
"( list of [ str , int ] list ) - > nonetype"
"shifts input number of keys left or right . type : typeshift(""your word "" , the number of keys to shift right ( use negatives to shift left ) )"
kill any ansi escape sequences .
converts xml to an object : param src : : return first attribute value of root element :
"check if the tweet is in multiple tweets of a single turn args : tweet : the target tweet group : list of groups of multiple tweets return : index of group in which the target is included if no group found , return -1"
"check if the dialog consists of multiple turns with equal or less than max_turns by two users without truncated tweets . args : dialog : target dialog max_turns : upper bound of # turns per dialog return : true if the conditions are all satisfied false , otherwise"
normalize and tokenize raw text args : text : input raw text ( str ) name : user name ( str ) first_name : user 's first name ( str ) sys_utt : flag if this is a sysmtem 's turn ( bool ) return : normalized text ( str )
print a dialog args : dialog ( list ): list of tweet groups sys_name ( str ): screen_name of system file ( object ): file object to write text debug ( bool ): debug mode
limit dialog extraction by ids
"fork off the child and return pid in the parent , 0 in the child ."
"clean up the process ' temporary directory . if cgroups are enabled , also kill the process ( if still running ) and all of its descendents ."
launch a new search process .
clean up the specified search process .
signal handler for sigchld .
clean up all forked search processes .
the main body of demo .
evaluate the estimated pdf on a set of points .
compute the estimator bandwidth with given method .
computes the covariance matrix for each gaussian kernel using covariance_factor ( ) .
test using the getter function returns the right fields .
test using the getter function throws errors .
get invalid field w/ fallback .
edit a pull request .
manage issues .
create a new pull request .
delete a milestone
list a user 's repositories .
use pybtex to validate that a reference is in proper bibtex format
parses a history node object from either a dict or a tuple .
string representation of an author
"parses an author object from either a string , dict , or tuple"
a convenience method for getting a list of structurenl objects by specifying structures and metadata separately . some of the metadata is applied to all of the structures for ease of use .
returns the value with its absolute value capped at max_abs_val . particularly useful in passing values to trignometric functions where numerical errors may result in an argument > 1 being passed in .
sorts a dict by value .
return the index of the ( first ) minimum in seq
return the index of the ( first ) maximum in seq
"uses enumerate , max , and min to return the indices of the values in a list with the maximum and minimum value :"
true if values are stricly increasing .
true if values are stricly decreasing .
true if values are not increasing .
true if values are not decreasing .
"returns false if values are not monotonic ( decreasing|increasing ) . mode is "" < "" for a decreasing sequence , "" > "" for an increasing sequence . two numbers are considered equal if they differ less that atol ."
rounds a number rounded to a specific number of significant figures instead of to a specific precision .
"given a symmetric matrix in upper triangular matrix form as flat array indexes as : [ a_xx , a_yy , a_zz , a_xy , a_xz , a_yz ] this will generate the full matrix : [ [ a_xx , a_xy , a_xz],[a_xy , a_yy , a_yz],[a_xz , a_yz , a_zz ]"
returns a boolean for any structure . structures that return true are kept in the transmuter object during filtering .
initializes the model . args have the same definitions as in : class:`pymatgen.analysis.ewald . ewaldsummation ` .
some inherent checks are in the run_gulp function itself . they should be suffcient for raising errors .
doc string .
tests if two arrays are almost equal to a tolerance . the camelcase naming is so that it is consistent with standard unittest methods .
tests if two arrays are equal . the camelcase naming is so that it is consistent with standard unittest methods .
test whether the object(s ) can be serialized and deserialized with pickle . this method tries to serialize the objects with pickle and the protocols specified in input . then it deserializes the pickle format and compares the two objects with the _ _ eq _ _ operator if test_eq = = true .
write string to a temporary file . returns the name of the temporary file .
tests if obj is msonable and tries to verify whether the contract is fulfilled .
"return the derivatives of y(x ) at the points x if scipy is available a spline is generated to calculate the derivatives if scipy is not available the left and right slopes are calculated , if both exist the average is returned putting fd to zero always returns the finite difference slopes"
reciprocal function to the power n to fit convergence data
predictor for first guess for reciprocal
exponential function base n to fit convergence data
reciprocal function to fit convergence data
reciprocal function to fit convergence data
reciprocal function to fit convergence data
reciprocal function to fit convergence data
reciprocal function to fit convergence data
return the parameters such that a + b / x^n hits the last two data points
measure the quality of a fit
"fit multiple functions to the x , y data , return the best fit"
calculates for a series of powers ns the parameters for which the last two points are at the curve . with these parameters measure how well the other data points fit . return the best fit .
"print the gnuplot command line to plot the x , y data with the fitted function using the popt parameters"
"test it and at which x_value dy(x)/dx < tol for all x > = x_value , conv is true is such a x_value exists ."
helper to return a time string
helper to clean up an input string
read the results of a full set of calculations from file
return the content of the file as a string .
similar to floatwithunittest.test_energy . check whether energyarray and floatwithunit have same behavior .
similar to floatwithunittest.test_time . check whether energyarray and floatwithunit have same behavior .
similar to floatwithunittest.test_time . check whether energyarray and floatwithunit have same behavior .
test whether floatwithunit and arraywithunit support pickle
the slug + the publish_date must be unique together
get all the arguments from post request . only get the first argument by default . : return : post_data .
split the url_str to array . : param url_str : the request url . : return : the array of request url .
check the user role for docs . : param userinfo : : return :
the current user .
: return :
: return :
generat whoosh database . : return :
return the warpped template path . : param tmpl : : return :
list the apps .
user most used .
user used recently .
todo : the name should be changed . list the infors .
list the recent .
find the infors .
update the order of the posts .
in infor .
delete by uid
用于首页。根据前两位，找到所有的大类与小类 。 : param qian2 : 分类id的前两位 : return : 数组，包含了找到的分类
"qeury all the categories , order by count or defined order ."
query the posts count of certain category .
return the category record .
update the count of certain category .
update the category .
add or update the data by the given id of post .
command entry : param argv : : return :
return some of the records . not all .
get the user 's info by user id .
get user by user_name .
set the time that send e - mail to user .
get user info by user 's email .
checking the password by user 's id .
checking the password by user 's name .
update the password of a user .
query the users who do not login recently ( 90 days ) . and not send email ( 120 days ) . time_model : num * month * hours * minite * second time_login : 3 * 30 * 24 * 60 * 60 time_email : 4 * 30 * 24 * 60 * 60
update the user info by user_id . 21 : standsfor invalide e - mail . 91 : standsfor unkown reson .
update the time when user reset passwd .
update the role of the usr .
update the login time for user .
create the user . the code used if ` false ` . 11 : standsfor invalid username . 21 : standsfor invalide e - mail . 91 : standsfor unkown reson .
get member by keyword
delete user in the database by ` user_name ` .
delele the user in the database by ` user_id ` .
helper function for passing the hmac secret when starting a jedihttp server :
"testing some files . not testing recursion in filenames . it is situation if there exist file0 , file1 , file2 and input file is file"
test datetimeutil.utc_now ( )
test datetimeutil.string_to_datetime ( )
takes a python dotted path or a jobs spec and returns crontabber jobs
converts job_list_string specification into list of jobs
mark jobs as successful in crontabber bookkeeping
set up this test class by populating the reports table with fake data .
"clean up the database , delete tables and functions ."
return the value as a string .
return none if the value is none . return ' true ' if the value is one of the accepted values . return ' false ' otherwise .
"cleanup the database , delete tables and functions"
take an iso date string of the form yyyy - mm - ddthh : mm : ss.s and convert it into an instance of datetime.datetime
return a timezone aware datetime instance in utc timezone
return a datetime.datetime instance with tzinfo . i.e. a timezone aware datetime instance .
transform a date or datetime object into a string and return it .
return a date created from the last 6 digits of a uuid .
return a string representing a weekly partition from a date .
returns an instance of elasticsearch - py 's elasticsearch class as encapsulated by the connection class above .
returns an instance of elasticsearch - py 's index client class as encapsulated by the connection class above .
verify that an association to a signature that no longer is part of the crash signatures list gets removed .
specifically setting 0 days back and no prior run will pick it up from now 's date
much test . so meta . wow test_test _ .
takes crash data via args and generates a socorro signature
prints out a warning line to stderr
outputs a data point
"return a dict by splitting the input string by ' , ' and splitting each item by a ' : ' to make it key and value ."
set - up application and ` tensorflow ` logging .
load a json configuration dict from guesslang config directory .
"retrieve guesslang model directory name , and tells if it is the default model ."
report graph creator command line
create a neuron with a single process that branches multiple times to form two separate arbors and then synapses onto a second neuron .
"create a neuron with three levels of branching , each level getting "" bushier "" . each final branch synapses onto another neuron ."
muscle objects represent muscles in the : class:`network < network . network . network > ` and can be : class:`innervated < network . innervation . innervation > ` by : class:`neurites < network . neurite . neurite > ` .
return the list of : class:`innervations < network . innervation . innervation > ` of this muscle .
book -- book object obtained from xlrd.open_workbook ( ) . name -- the name that 's being investigated . show_contents -- 0 : do n't ; 1 : non - empty cells only ; 2 : all cells f -- open output file handle .
"forcedirectedlayout(maxiterations = 50 , spacing = .005 , fill = false )"
write in pajek format to path .
read graph in pajek format from path .
parse pajek format graph from string or iterable .
"get the mod info returns : a three element tuple containing the mod name , version and description"
run various housekeeping tasks for ease of modding . disables the screen cache . adds the mods button to the main menu .
test the caps support method of contacts . see test_caps for more enhanced tests .
this test supports the migration from the old to the new contact domain model by smoke testing that no attribute values are lost
this test supports the migration from the old to the new contact domain model by asserting no attributes have been lost
"return the password for account_name , or none if not found ."
save password for account_name . return a bool indicating success .
"initialize backend connections , determining which ones are available ."
"block until some callback sets the event and clearing the event subsequently . returns true if event was set , false on timeout"
method called after connecting - after receiving < stream : features > from server ( not after tls stream restart ) or connect failure
"method called after authentication , regardless of the result ."
create person construct from node .
create new atom 0.3 entry object .
"return title of feed , where the entry was created . the result is the feed name concatenated with source - feed title"
get source link
get an entry 's title
get the uri the entry points to ( entry 's first link element with rel='alternate ' or without rel attribute )
get the time the entry was updated last time
set up a listener for music player signals
signal handler for propertieschanged event
"return a musictrackinfo for the currently playing song , or none if no song is playing"
return the list of channel class names
return a dictionary of channel base class info
return the list of channel class names
finalize object : this involves inferring types if necessary
finalize object : this involves inferring types if necessary
finalize object : this involves inferring types if necessary
finalize object : this involves inferring types if necessary
get absolute path relative to this file
remove empty entries from the spec
test that altair correctly round - trips json with to_dict ( ) and to_python ( )
"create a client , register a node and create a session ."
"decorator to mark classes or functions as deprecated , with a possible replacement ."
.. note : :
"this function replaces the original python traceback with an improved version from ipython . use ` color ` for colourful traceback formatting , ` verbose ` for ka - ping yee 's "" cgitb.py "" version kwargs are the keyword arguments passed to the constructor . see ipython.core.ultratb.py for more info ."
returns the greatest common divisor for a sequence of numbers .
return lowest common multiple of a sequence of numbers .
"returns the greatest common divisor for a sequence of numbers . uses a numerical tolerance , so can be used on floats"
initializes a wildcard .
returns a list with the names matching the pattern .
returns true if name matches one of the patterns .
"we are making sure a file containing line numbers is read in reverse order , i.e. the first line that is read corresponds to the last line . number"
"we are making sure a file containing line numbers is read in reverse order , i.e. the first line that is read corresponds to the last line . number"
"we are making sure a file containing line numbers is read in reverse order , i.e. the first line that is read corresponds to the last line . number"
make sure an empty file does not throw an error when reverse_readline is called this was a problem with an earlier implementation
"we are making sure a file containing line numbers is read in reverse order , i.e. the first line that is read corresponds to the last line . number"
"we are making sure a file containing line numbers is read in reverse order , i.e. the first line that is read corresponds to the last line . number"
make sure an empty file does not throw an error when reverse_readline is called this was a problem with an earlier implementation
this decorator can be used to create a singleton out of a class .
"decorator to cache class instances by constructor arguments . this results in a class that behaves like a singleton for each set of constructor arguments , ensuring efficiency ."
no - op
no - op
"for use with msgpack.packb(obj , default = default ) . supports monty 's as_dict protocol , numpy arrays and datetime ."
"for use with msgpack.unpackb(dict , object_hook = object_hook . ) . supports monty 's as_dict protocol , numpy arrays and datetime ."
creates the test database if it does n't exist .
make sure importing _ _ main _ _ does n't print anything .
test package as a script .
test colorize convenience methods .
test chaining color instances .
test with empty string .
test keep_tags keyword arg .
try to read readme.rst or return empty string if failed .
obtain sparse matrix representation of contiguity dictionary ( w )
construct an instance of the class from any iterable input .
compute the hash value of a set .
add an element .
remove an element . do not raise an exception if absent .
"remove an element . if not a member , raise a keyerror ."
return the popped value . raise keyerror if empty .
this is slow ( creates n new iterators ! ) but effective .
"return a list of acceptable qt apis , in decreasing order of preference"
"attempt to set the local of the given name to value , using locals_to_fast ."
a harness for testing methods that attempt to modify the values of locals on the stack .
you can print _ the results to check ...
"return true if this frame should be traced , false if tracing should be blocked ."
clear the trace filter cache . call this after reloading .
set the trace filter mode .
test case to validate custom property
test case to validate custom property
test case to validate custom property
returns the global interactive console . interactive console should have been initialized by this time : rtype : debugconsole
fetch an interactive console instance from the cache and push the received command to the console .
"fetch all completions , create xml for the same return the completions xml"
add messages in the console_messages list
more is set to true if further input is required from the user else more is set to false
"create an xml for console message_list , error and more ( true / false ) < xml > < message_list > console message_list</message_list > < error > console error</error > < more > true / false</more > < /xml >"
change built - in stdout and stderr methods by the new custom stdmessage . execute the interactiveconsole.push . change the stdout and stderr back be the original built - ins
execute a code object .
"java : boolean isvalid(pyselection ps , string sel , pyedit edit , int offset ) ;"
"java : list < icompletionproposal > getprops(pyselection ps , imagecache imagecache , file f , ipythonnature nature , pyedit edit , int offset )"
in this function we delete some modules from ` sys.modules ` dictionary and import them again inside ` _ pydev_saved_modules ` in order to save their original copies there . after that we can use these saved modules within the debugger to protect them from patching by external libraries ( e.g. gevent ) .
to be used as a decorator
returns a naturally sorted list
test that crc matches
updating 4 bits
check that updates work with other numbers
this is an example message that returns the stuff above
"checks that the dcb returns full length . either 64 bits for 5/2 mode , or 159 for 7 day mode ."
checks the target temperature is set to 22*c.
build the menu to select which object types are shown in the output .
build lighting menu .
enable or disable show menu when override is checked
set all object types off or on depending on the state
set all object types off or on depending on the state
return checked state of show menu items
get and parse the currently selected displaylights options .
return the widget options
apply the saved inputs from the inputs configuration
get the plugin outputs that matches ` capture.capture ` arguments
: param graph : : type graph : dict : param start_node : : return :
: type word1 : str : type word2 : str : rtype : int
: param l : linkedlist contained the node to be deleted : type l : linkedlist : param node : node to be deleted : type node : node : return : original linkedlist with the node deleted : rtype : linkedlist
find the intersection between two rectangles : param rectangle_1 : dict : param rectangle_2 : dict : return :
required method to auto register this checker
precondition : node is a condition in an if statement returns true if all the node is a structure / collection of values returns false otherwise
perform an all - by - all join of all elements in the input lists .
return the square of the number .
initialize a statreporter .
override the corresponding function in plainreporter .
test type setting of unaryop node(s ) with non - boolean operand .
test type setting of unaryop node representing boolean operation not .
increment global time by 1 .
"adds given ansi colouring tokens ( or key to colouring tokens in the class - level dict "" _ colouring "" ) to text as well as final colour reset ."
test whether visitors properly set the type constraint of the a for node representing for / else statement iterating over a homogeneous list .
test whether visitors properly set the type constraint of the a for node representing for / else statement iterating over a heterogeneous list .
"test whether visitors properly set the type constraint of the a for node representing for / else statement iterating over a more complex iterable ( ie , tuples , dicts , nested iterables ) ."
return an appropriate ' hint ' or suggestion given the binary operation and operand types .
helper to return a noun with the correct article .
required method to auto register this checker . @param linter : main interface object for pylint plugins @rtype linter : pylint object
divide the numerator by the denominator .
divide the numerator by the denominator .
"encode v , which is a string of bytes , to base58 ."
decode v into a string of len bytes
clustering of x by affinity propagation which the number of cluster is k.
sample test method for dependencies .
sample test method for special dependencies .
sample test method for branch coverage .
function to verify if the attributes is of the right type
test that the status code 200 is returned for get .
test if the image was converted correctly .
test that the status code 200 is returned for post .
test that the right prediction is returned .
test that fix_maf works correctly
test that preliminary_filtering works correctly .
check that check_coding works correctly
test that person_recurrence ( ) works correctly
test that family_recurrence ( ) works correctly
check that check_independence works correctly
check that filter_denovogear_sites ( ) works correctly
check that filter_denovogear_sites ( ) identifies strand biased sites
check that filter_denovogear_sites ( ) identifies parentally biased sites
creates a birthday between 1950 and 1990 : return : string
"as per ptcaccount by jepayne1138 , this function raises : ptcinvalidnameexception : if the given username is already in use . ptcinvalidpasswordexception : if the given password is not a valid password that can be used to make an account . ( currently just validates length , so this means the given password was not between 6 and 15 characters long . ) ptcinvalidemailexception : if the given email was either in an invalid format ( i.e. not local@subdomain.domain ) or the email is already registered to an existing account . ptcinvalidstatuscodeexception : if an invalid status code was received at any time . ( server or underlying code issue ; try again and submit bug report on continues failure if creation works in browser . ) assertionerror : if something a url is not as expected"
delete a file already uploaded to send
return a iterable object
return a iterable object
"shrink i m until its longest dimension is < = max_dim . returns new_image , scale ( where scale < = 1 ) ."
dilate the image until there are just a few connected components . returns contours for these components .
"union two ( x1 , y1 , x2 , y2 ) rects ."
basic test which uses qtmodeltester with a qt_api . qstandarditemmodel .
check that qtmodeltester correctly captures data ( ) returning invalid values for various display roles .
test a custom model which returns a good and alignments from data ( ) . qtmodeltest should capture this problem and fail when that happens .
"return a check_model(model , should_pass = true ) function that uses qtmodeltester to check if the model is ok or not according to the ` ` should_pass ` ` parameter ."
basic check with an invalid model .
sorting emits layoutchanged
we should not get a crash on cleanup with no model .
make sure overriden methods of a model are actually run .
run the given python code with the given executable .
get the files which should be ignored for link_pyqt ( ) on windows .
check if a file to be linked / copied needs to be updated .
get the path of a python library .
symlink the systemwide pyqt / sip into the venv .
copy or symlink source to dest .
"remove a given filename , regardless of whether it 's a file or dir ."
get the library path of a virtualenv .
get the system python based on a virtualenv created by tox .
main entry point .
ensure that we are exporting expected qtest api methods .
outputs the path to find the specified json file .
outputs a pandas dataframe generated from the specified json file or none if the file could not be loaded .
"outputs two pandas dataframes , one with time - series data of the acceleration or rotation rate and the second with pedometer data . the dataframes are from a random sample but have properties as specified by the user . the user has the following options : * choose between one of the three stages of the experiment ( outbound , rest or return ) ; * if the data is from a person with or without parkinson 's disease ; * choose between time - series data of the rotation rate or the acceleration . if the user selects the rest stage , the pedometer dataframe returned is none ."
converts the time - series table to a json string .
applies the specified smoothing to the time - series .
"input : - theta : float angle - ux , uy , uz : float vector components"
"input : - theta : float unit quaternion of the corresponding rotation - datax , datay , dataz : float vector components of the data that is going to be rotated"
"outputs two dataframes with time - series data in the world frame coordinate system , one of the acceleration and a second of the rotation rate ."
generates json augmented versions for the sample in one row of the table .
generates an augmented version of a given table .
input : args : tuple a tuple with the dataframe and the function to be applied .
applies a function to all the rows of a dataframe with the use of multiple processes .
"input : args : tuple a tuple with the dataframe , the function , and the function parameters ."
applies a function to all the rows of a dataframe with the use of multiple processes .
generates new ' extra_columns ' tables that do not contain healthcodes from a specific list of possible outliers .
outputs a new table without the rows from the input table that contain healthcodes from a specific list of possible outliers .
"input : - segments : bool ( default = false ) whether to add vertical bars for the segments of each step in the graph plotted by making use of the pedometer data . - totalavgstep : bool ( default = false ) whether to use the total number of steps as the reference to build the segments , resulting in equally spaced segments . the other option is to use each pedometer sample as the reference for the step duration in the respective interval of the time - series . this parameter is not considered if segments = false ."
displays a figure of the overview .
"input : - wavelet : string wavelet to use , empty string if no wavelet is used for smoothing . example : ' db9 ' - level : integer decomposition level for the wavelet ."
removes all the wavelets curves added by the addwavelet method .
removes the wavelet curve specified from the plotting .
plots vertical bars for the segments of each step in the graph .
accumulates metrics results from one random forest in the undersampling ensemble .
prints metrics results for the undersampling ensemble in the training set .
"input : - y_test : numpy.ndarray ground truth ( correct ) labels . - y_pred : numpy.ndarray predicted labels , as returned by a classifier . - y_prob : numpy.ndarray probability estimates of the positive class ."
input : - y_test : numpy.ndarray ground truth ( correct ) labels . - y_pred_total : numpy.ndarray sum of the votes of all the random forests in the undersampling ensemble . - setname : string name of the development set to be printed as the title . - ensemble_size : int the number of random forests in the undersampling ensemble . - threshold : float 0 < threshold < 1
loads table with the features and applies the selected preprocessing .
loads tables for all the folds used in the cross - validation .
loads all the folds tables with the features . builds a configuration for training and test sets as specified by the foldtestnumber applies the selected preprocessing .
outputs an undersampled configuration of the input table .
test the patch^ztmgrset(patchnumber=998 ) entrypoint
test the patch^ztmgrset(patchnumber=999 ) entrypoint
test the patch^ztmgrset(patchnumber=1000 ) entrypoint
test the reload^ztmgrset entrypoint
test the reload^ztmgrset entrypoint
test the reload^ztmgrset entrypoint
"slope of the ideal ph electrode , in v / ph"
relative slope .
offset voltage ( including the adc offset ) .
initalize the dir enum with proto values .
send an action request to the server ( via the context handler ) .
"construct a new robot api request with the owner name , and counter filled in ."
move the robot one block in the given direction .
turn the robot to face the given direction .
mine the adjacent block in the given direction and pick up the item that results from destrying that block .
"place a block next to the robot in the given direction , with the given type ."
find the type of the adjacent block in the given direction .
check if the adjacent block in the given direction is one that the robot can walk through or not ( returns a boolean ) .
return the location of the entity type specified .
returns the location object for the location coordinates of the robot itself .
returns the location object for the location coordinates of the robot 's owner player .
returns a list of the locations of blocks nearby that match the specified block type .
"returns the direction to move in , to ( hopefully ) reach the target location ( or none if the robot is completely stuck ) ."
"returns a list of pairs ( blocktype , count ) for all the items in the robot 's inventory ."
internal use only . used to convert the wireformat location into a more convenient location object .
returns the distance between this location and the given other location .
"find the direction ( north , south , east or west ) of the other location from this one ."
returns a type checker for a message field of the specified types .
type check the provided value and return it .
"call given command , yielding output line by line"
parse json data and return a point object
transform point object to json .
receives data in a loop until the event for disconnecting is set . checks the command queue for actions to be taken ( joining or leaving channels ) .
"forces the bot to disconnect , close its socket and database connection ."
"processes a command , either joining or leaving channels . command is expected to be a tuple of a string and a list . valid commands are ' join ' and ' part ' ."
flash all errors for a form .
"takes an iterator of strings , and attempts to wrap them in whole chunks to fit within width . takes an optional preamble which is prepended before the first line , and an optional per - line prefix ( which is appended to every line but the first ) . if return_gen is true , this function returns a generator that will produce the lines of output as needed , otherwise it returns a single joined string"
fetches the iana link relation registry
return true if all unit tests pass .
just load an abf
try setting sweeps to different use cases .
test abf.average ( )
test abf.averagesweep ( )
try loading swhlab . returns false if crashes .
ensure the osapi server responds to calls sensibly .
creates a new snapshot .
delete a snapshot .
gets the network object for the requested network .
gets reference to the network whose name is passed as the argument .
gets the vswitch associated with the physical network adapter with the name supplied .
checks if the vlan_interface exists on the esx host .
get the vlan i d and vswicth associated with the port group .
creates a port group on the host system with the vlan tags supplied . vlan i d 0 means no vlan i d association .
get the devices allocated to one or all requests for an instance .
create a pci device tracker .
sync the pci device tracker with hypervisor information .
update instance 's pci usage information .
update instance 's pci usage information when it is migrated .
remove all usages for instances not passed in the parameter .
set the compute node i d that this object is tracking for .
"return a tuple of ( major , minor , rev ) for the host version and a string of the product brand ."
return a string session_id . used for vnc consoles .
return exclusive session for scope of with statement .
return the xenapi host on which nova - compute runs on .
call the specified xenapi method on a background thread .
call host.call_plugin on a background thread .
allows a plugin to raise retryableerror so we can try again .
stubout point . this can be replaced with a mock session .
parse exception details .
retrieve all refs and recs for a xen record type .
get the cpu information .
return disk usage statistics about the given path .
"returns ipv4 and ipv6 addresses , ordered by protocol family ."
helper to construct an ec2 compatible error response .
create a response for the given webob.exc.exception .
generate a wsgi response based on the exception passed to ctor .
create the zk session object .
creates zookeeper session in lazy manner .
initializes new session .
join the given service with its group .
remove the given member from the service group .
"return all members in a list , or a servicegroupunavailable exception ."
called after a new websocket connection has been established .
create an nwfilter firewall driver
no - op . everything is done in prepare_instance_filter .
this filter protects false positives on ipv6 duplicate address detection(dad ) .
"the standard allow - dhcp - server filter is an < ip > one , so it uses ebtables to allow traffic through . without a corresponding rule in iptables , it 'll get blocked anyway ."
"set up basic filtering ( mac , ip , and arp spoofing protection ) ."
"obtain a list of base filters to apply to an instance . the return value should be a list of strings , each specifying a filter name . subclasses can override this function to add additional filters as needed . additional filters added to the list must also be correctly defined within the subclass ."
static filters are filters that have no need to be ip aware .
clear out the nwfilter rules .
check nova - instance - instance - xxx exists .
create an ip tables firewall driver instance
set up provider rules and basic nwfilter .
check nova - instance - instance - xxx exists .
returns the list of metadata for a given instance .
return a single metadata item .
deletes an existing metadata .
"parse device_path and mountpoint as they can be used by xenapi . in particular , the mountpoint ( e.g. /dev / sdc ) must be translated into a numeric literal ."
retrieve target host .
retrieve target port .
introduce vdi in the host .
forgets the storage repository without destroying the vdis within .
translate a mountpoint like /dev / sdc into a numeric .
return the storage repository given a uuid .
find the sr reference from the vbd reference .
find the sr reference from the vdi reference .
get the vbd reference from the device number .
determine if the root device is a volume .
returns the timestamp folder .
return a list of the images present in _ base .
ages cached images .
the cache manager entry point .
returns datastore path of folder containing the image .
returns a set of values based on a metadata key for a specific host .
returns a dict of all metadata for a specific host .
returns a corretly casted value based on a set of values .
check that the host_state provided by the compute service satisfy the extra specs associated with the instance type .
return a list of hosts that can create instance_type .
set the ip that was assigned by the dhcp server .
called when an old lease is recognized .
called when a lease expires .
get the list of hosts for a network .
parse environment and arguments and call the appropriate action .
create an instance of the appropriate driverfields class .
build a patch to add the required fields to deploy a node .
build a patch to clean up the fields .
get the deploy ramdisk and kernel ids from the flavor .
build a patch to add the required fields to deploy a node .
build a patch to clean up the fields .
only return hosts with sufficient available ram .
attempt to build instance(s ) or send msg to child cell .
pick a cell where we should create a new instance(s ) .
return whether the given object is a byte string or unicode string .
return the contents of a text file as a byte string .
quantizes waveform amplitudes .
recovers waveform from quantized values .
prepare any joins required through this field .
determine if the join set up by : meth:`prepare_join ` occurred .
select any fields that will be required to return the value of this field .
"extract the value for this field , raising : class:`nofielddata ` when no value should be returned ."
prepare an expression to use for an order clause .
"prepare an expression to use for a where clause , and raise : class:`filternotimplemented ` when the relation is not supported ."
prepare the data to insert or update for this field .
updates the configuration from command - line arguments .
"inner main function . if anything fails in here , file handles and database connections will be safely closed ."
render the data in html template .
save the rendered html to a file and return an iframe to display the plot in the notebook .
output an iframe containing the plot in the notebook without saving .
save the rendered html to a file in the same directory as the notebook .
": param cluster : the cluster passed by the client . either an created cluster contain a _ i d or one contain a machine field specify the machine type . : type cluster : dict : returns : true is cluster nodes have gpus , false otherwise ."
find the kernel base .
find the _ _ prelink_info segment .
find and parse the kernel _ _ prelink_info dictionary .
"return true if the method is post , or if the request user is staff . return false otherwise ."
yields payday events for the given participant .
"> > > str(_strip_prefix('https://api.example.com ' , ' https://api.example.com/foo/bar ' ) ) ' /foo / bar ' > > > _ strip_prefix('https://api.example.org ' , ' https://api.example.com/baz ' ) traceback ( most recent call last ): ... valueerror : "" https://api.example.org "" is not a prefix of "" https://api.example.com/baz """
convert a string to a string for an url .
return a listing of communities .
parses a line from the api dump .
fetches and parses the api dump from the server .
wraps ` services ` argument inside a wsgiapplication that uses soap 1.1 for both input and output protocols .
wraps ` services ` argument inside a pyramidapplication that uses soap 1.1 for both input and output protocols .
determines if this service definition has callback methods or not .
returns a user defined context . override this in your servicebase subclass to customize context generation .
called in place of the original method call . you can override this to do your own exception handling .
this is a typed dict implementation that optionally enforces given types on contained values on assignment .
simple function to count the number of elements returned by a generator .
"call this routine as a generator to return all the strings that match the input regular expression . for s in invregexp(""[a - z]{3}\d{3 } "" ): print s"
returns the schema documents in a dict whose keys are namespace prefixes and values are element objects .
returns the validation schema object for the given models .
returns an elementtree representation of a : class:`spyne.model.complex . complexmodel ` subclass .
returns a native : class:`spyne.model.complex . complexmodel ` child from an elementtree representation of the same class .
parses a schema string and returns a _ schema object .
parses a ` < xs : schema > ` element and returns a _ schema object .
parses a schema file and returns a _ schema object . schema files typically have the ` * .xsd ` extension .
"protocol that returns the response object according to the "" html microformat "" specification . see https://en.wikipedia.org/wiki/microformats for more info ."
this is what subserialize calls
"set player velocity by keys , move by velocity , check for collision . it 's important to check collisions for both on the x - axis and y - axis , rather than just once ."
blit player image to screen .
"get two list , each list contains two elements : name and nd.array value"
"given a list of dictionaries , generates new down - sampled dictionaries using the provided list of keys ."
"given a dictionary of featurename : dataarray , for each f in keylist , merge the dataarrays into a single array ."
"method to aggregate the values of a dictionary , where the values are assumed to be 2 - d numpy arrays ."
"method to aggregate values of dictionary , where values are assumed to be 1d lists ."
"method to parition feature data for all labels , from all training subjects in the training object -- partitions the training data features by label ."
method to build the response vector for response - specific data array .
"starting with list of dicts , aggregate and shuffle each dictionary in the list according to the same new ordering ."
initialize a new instance of an ibapipyerror .
"called by the str ( ) built - in function and by the print statement to compute the "" informal "" string representation of this object ."
initialize a new instance of an execution .
"return true if this object is strictly less than the specified object ; false , otherwise ."
"print args to the console , prefixed by the plugin name ."
return the view 's syntax .
"return true when a view is not lintable , e.g. scratch , read_only , etc ."
return a dict with os.environ augmented with a better path .
return whether the given path is a file and is executable .
return the full path to an executable searching path .
yield full paths to given executable .
short wrapper around subprocess.check_output .
return the result of sending code via stdin to an executable .
"decode and return a byte string using utf8 , falling back to system 's encoding if that fails ."
convert value to the type of type_value .
look up style definition in that order of precedence .
return default style for error_type of this linter .
bitmex websocket uses primus websocket lib which uses the following heartbeat scheme :
ensure heartbeat is enabled on the websocket .
ensure heartbeat is disabled on the websocket .
ensure heartbeat is disabled on the websocket .
"when calling bitmexwebsocket.subscribe_action ( ) , ensure a proper subscriptionmsg message is sent and a subscription event is received when the channel is subscribed ."
on_message should call on_subscribe when subscription error is received
"initialize / setup ourself ; load private key , create acme client and refresh our registration"
load our private key / the key to identify ourself against the acme server . this key must not be used for certificates .
create new private key to be used for identify ourself against the acme server
create acme client
requests for all given domains domain validations if we have cached a valid challenge return this . expired challenges will clear automatically ; invalided challenges will not .
processes a given authorizationresource that was fetch from the authzrs cache or updated by ` refresh_domain_authorization ` / ` acme.client.client.poll ` .
refreshes a authorization for status changes
requests a complete new authorization for the given domain
"initializes the xch state from the settings file . when the xch module is intialized , it will populate the market dict below ."
returns the exchange logfile name from the options .
returns the marketlog file name from the options .
returns the default exchange fee rate in percent .
sets the default exchange fee rate in percent .
gets the default exchange fee account where fees get routed to for any asset .
sets the default exchange fee account where fees get routed to for any asset .
gets the exchange fee rate for the specified asset .
sets the exchange fee rate for the specified asset .
"exchanges an amount of an asset specified in swap_a , with that of the asset specified in swap_b ."
adds an order to the user orders dict .
add a limit buy order to the book and executes and fills the orders until there is a spread between the bid and ask or no orders on the book left .
add a limit sell order to the book and executes and fills the orders until there is a spread between the bid and ask or no orders on the book left .
returns the orderbook as a dict
records the order in the marketlog .
sets a limit buy order and returns it .
sets a limit sell order and returns it .
"matches orders that can be matched , otherwise does nothing ."
print process information useful for debugging .
test hook designed to be used by cprofile or kernprof . does not include any network latency from communicating or synchronizing between processes because we run on just one process .
"this object contains all of the variables necessary for the partial lnprob calculation for one chunk . it is designed to first be instantiated within the main processes and then forked to other subprocesses . once operating in the subprocess , the variables specific to the order are loaded with an ` init ` message call , which tells which key to initialize on in the ` self.initialize ( ) ` ."
initialize to the correct chunk of data . : param key : key : param type : int this method should only be called after all subprocess have been forked .
unified lnprob interface .
wrap up the sampling and write the samples to disk .
"the infinite loop of the subprocess , which continues to listen for messages on the pipe ."
"interpret the messages being put into the pipe , and do something with them . messages are always sent in a 2 - arg tuple ( fname , arg ) right now we only expect one function and one argument but this could be generalized to * * args ."
determine environment name having : param cname : on : param app_name : .
parse request args dictionary and return aglayeroperation with operation parameters .
"return dictionary with error data for json.dumps ( ) to text , for sending error message as arcgis do"
"returns ( geometrytype , geometry ) tuple where geometrytype is string and geometry is dictionary according to arcgis spec http://resources.arcgis.com/en/help/rest/apiref/fsquery.html#response convert geojson style dictionary to arcgis json style ."
"returns tuple ( geomsr , geomwkt ) that is ogc geometry spatialreference wkid and geometry wkt converted from arcgis variation of geojson ."
returns ogc wkt multipolygon created from arcgis geojson esrigeometrypolygon .
arcgis rest api specified spatial query parameters .
check filter parameters
"set esri . spatialfilterparams members and set own inputgeomspatialref , inputgeomwkt data ."
arcgis rest api query parameters .
check filter parameters
"jsontext is string like ' { "" xmin"":3907314.1268439,""ymin"":6927697.68990079,""xmax"":3996369.71947852,""ymax"":7001516.67745022,""spatialreference"":{""wkid"":102100 } } '"
get outsr value from request params . return spatref wkid or 0 . for gmap / openstreet / bing outsr = 102100 or 3857
get spatialrel value from request params . returns ' esrispatialrelintersects ' or ... or '' .
get geometrytype value from request params . returns ' esrigeometryenvelope ' or ' esrigeometrypolygon ' or ... or '' .
get geometry value from request params . return json text or '' .
get ' where ' clause from request params . return text or '' .
"before each test , set up a blank database"
get rid of the database again after each test .
helper function to register a user
helper function to login
registers and logs in in one go
helper function to logout
records a message
make sure registering works
make sure logging in and logging out works
check if adding messages works
make sure that timelines work
unit test of get_user_info
unit test of get_user_info error case
unit test of get_all_tasks
unit test of get_all_tasks error case
unit test of get_all_categories
unit test of get_all_categories error case
unit test of get_task_by_id
unit test of get_task_by_id error case
unit test of delete_task_by_id
unit test of delete_task_by_id error case
unit test of delete_category_by_id
unit test of delete_category_by_id error case
unit test of create_new_category
unit test of create_new_category error case
unit test of create_new_task
unit test of create_new_task error case
unit test error_msg of anydo.error
unit test error_msg of anydo.lib.error
unit test of user_info
unit test of tasks
unit test of categories
unit test of task
unit test of delete task
unit test of delete category
unit test of create category
unit test of create task
unit test of create note
---6-|--5-|-4-|2|-3|2|-4-|2|---10 - ---|-----8-|----8 - -|--6 - -|---6-| hetatm atom 559 ca basp a 74 48.780 13.254 -1.818 0.50 16.34 c ----.----|----.----|----.----|----.----|----.----|----.----|----.----|----.----|----.---- 5 10 15 20 25 30 35 40 45 50 55 60 65 70 atom 9982 cz phe d 27 14.293 79.865 39.022 1.00 85.37 c hetatm
"returns tuple ( phi , psi ) in degrees for given residue . input can be any amino acid atom ."
"returns true of false if residue is helical by calling self.calcphipsi ( ) helical boundaries are : phi = range(-82,42 ) psi = range(-60,21 )"
determines minimum distance from a given atom to a given residue ( input is any atom of that residue )
determines minimum distance from a given atom to a given chain ( input is any atom of that residue )
compute the branch parameters of a transformer from the short circuit test values @param hv_nominal_voltage : high voltage side nominal voltage ( kv ) @param lv_nominal_voltage : low voltage side nominal voltage ( kv ) @param nominal_power : transformer nominal power ( mva ) @param copper_losses : copper losses ( kw ) @param iron_losses : iron losses ( kw ) @param no_load_current : no load current ( % ) @param short_circuit_voltage : short circuit voltage ( % ) @param gr_hv1 : @param gx_hv1 : @return : leakage_impedance : series impedance magnetizing_impedance : shunt impedance
parse json structure into gridcal multicircuit : param data : json structure ( list of dictionaries ) : return : gridcal multicircuit
parse json file into circuit : param file_name : : return : gridcal multicircuit
save json file : param file_path : file path : param circuit : gridcal multicircuit element
"given a dictionary containing name / value pairs , push those variables to the ipython console widget"
clears the terminal
prints some plain text to the console
execute a command in the frame of the console widget
computes the n/2 pade approximant of the series an at the approximation point s
args : y_series : series admittances matrix y_shunt : shunt admittances vector pq : pv : returns :
args : n : coefficient order m : reduced set voltages vector for the pv buses
args : n : coefficient order m : reduced set voltages vector for the pv buses
"compute the right hand side vector ( rhs ) args : n : coefficient order v : voltage coefficients matrix ( rows : coeff . order , columns : reduced bus index ) y_series : reduced series admittances matrix y_shunt : reduced shunt admittances vector sbus : reduced power injections vector m : reduced set voltages vector for the pv buses pq : array of reduced pq bus numbers pv : array of reduced pv bus numbers"
args : y_series : y_shunt : sbus : voltagesetpoints : pq : pv : ref : pqpv : eps : maxcoefficientcount :
prepare the system matrices : param ybus : : param vbus : : param pqpv : : param ref : : return :
calculation of the inverse coefficients w. @param n : order of the coefficients @param v : structure of voltage coefficients ( ncoeff x nbus elements ) @param w : structure of inverse voltage coefficients ( ncoeff x nbus elements ) @return : array of inverse voltage coefficients for the order n
"right hand side : param n : order of the coefficients : param v : voltage coefficients ( order , all buses ) : param w : inverse voltage coefficients ( order , pv buses ) : param q : reactive power coefficients ( order , pv buses ) : param vbus : initial bus estimate ( only used to pick the pv buses set voltage ) : param vst : start voltage due to slack injections : param pbus : active power injections ( all the buses ) : param nsys : number of rows or cols in the system matrix a : param nbus2 : two times the number of buses : param pv : list of pv indices in the grid : param pvpos : array from 0 .. npv : return : right hand side vector to solve the coefficients of order n"
assign the solution vector to the appropriate coefficients : param x : solution vector : param bus_idx : array from 0 .. nbus-1 : param nbus2 : two times the number of buses ( integer ) : param pvpos : array from 0 .. npv : return : array of : - voltage coefficients - reactive power of order n
computes the n/2 pade approximant of the series an at the approximation point s
helm method : param vbus : voltages array : param sbus : power injections array : param ibus : currents injection array : param ybus : system admittance matrix : param pq : list of pq node indices : param pv : list of pv node indices : param ref : list of slack node indices : param pqpv : list of pq and pv node indices sorted : param tol : tolerance : return : voltage array and the power mismatch
create dataframe to display the results nicely : param v : voltage complex vector : param sbus : power complex vector : param tpe : types : return : pandas dataframe
linearized ac load flow args : y : admittance matrix ys : admittance matrix of the series elements s : power injections vector of all the nodes vset : set voltages of all the nodes ( used for the slack and pv nodes ) pq : list of indices of the pq nodes pv : list of indices of the pv nodes
create dataframe to display the results nicely : param v : voltage complex vector : param sbus : power complex vector : param tpe : types : return : pandas dataframe
"should be run on the pisak program start before doing anything else . initializes any necessary tools , processes or resources ."
scroll the text field up .
scroll the text field up .
set easel line color .
set easel line width .
clear easel canvas .
save easel canvas picture to png file .
localize new drawing spot .
back to drawing and navigate .
erase one step backward .
engine that plays the movie .
button that can be clicked in order to exit a fullscreen mode .
button menu of the movie player .
enter or exit the fullscreen mode . when entering this widget is expanded and put on the top of the main window .
"load main content of the symboler , that is table of contents and then all the categories ."
get all previously saved symbols entries .
save the given entry .
save the current symbols buffer . open a dialog window .
load one of the previously saved symbols chains . put the symbols inside the entry . open a dialog window .
read the text loud .
delete the last symbol from the entry .
clear the whole entry .
scroll the entry panel left .
scroll the entry panel right .
create server based on the web sockets system .
prepare and make the server serve within the asyncio event loop .
read form the tracker standard output and send data to all the active clients .
run the server . server is run in a separate thread .
"stop and close the server , close the server thread ."
activate the client . activated client will be able to receive data from the tracker server .
deactivate the client . deactivated client will not be able to receive data from the tracker server but its connection will remain opened .
"implementation of the`websocketclient ` method , called when a new data arrives ."
view preparator .
view preparator .
view preparator .
view preparator .
current configuration object that contains all the specification .
apply all the properties from the config .
view preparator .
"returns contents of the given file , which path is supposed relative to this module ."
determine os and set copy ( ) and paste ( ) functions accordingly .
crossplatform crossdesktop clipboard .
"perform full walk , gather full path of all files , based on os.walk with multiple output types & extras ."
make a json from nested to flat with an arbitrary delimiter .
"translate from internet via api from mymemory.translated.net , legally ."
"get object interface properties . internal use only , do nt touch ."
check if we are connected to a ac power or battery .
check if we are running on battery power .
compute set of classification probabilities for a given chunk of data .
"return an independent copy of this classifier . can be overriden to implement more efficient cloning ,"
learn that given chunk of data represents given target .
adds given item as being dependent of this property
"called , when item on which this property depends is changed"
returns true if any property depends on this one
returns config node representing this property in configuration dictionary
"returns 0 , because property does n't have children :)"
"returns 2 , because properties has name and value columns"
returns data for given column ( name or value )
sets value of property
"returns true for value column , false otherwise"
redefine the method so that every added tag has ' rs : ' prefix .
redefine the method - return svarog document .
set all default ( hardcoded ) tags and other tags as now we we have all needed data .
redefine self._xml_factory so that it has tags required by svarog in required order .
return text value from tag in format : < param id = p_param_name > text_value</param > .
return a list of text values form tag in format : < p_param_name > < param > text value1</param > < param > text value2</param > ... < /p_param_name >
"for given dictinary describing tag in strings , return dictionary where numeric values are numbers , not strings . the method is fired by file tags reader , while parsing xml tags file ."
"for given tag parameters return a dictionary representing tag with those parameters . parameters : - p_start_timestamp - float - p_end_timestamp - float - p_tag_name - string - p_tag_desc - dictionary - p_tag_channels - string like "" 0 6 7 "" - numbers of channels"
method fired by multiplexer . it conveys decision to logic engine .
"called , when selection on lists of plugins changes . then it displays configuration window for newly selected plugin , and closes old one , unless it 's floating . p_newitem ( qtreewidgetitem ) - contains newly selected plugin p_olditem ( qtreewidgetitem ) - contains plugin that was selected before"
"processes list with module names , and loads appropriate modules into program"
processes sing module with given name and load it into program
"return logger with p_name as name . and logging level p_level . p_level should be in ( starting with the most talkactive ): ' debug ' , ' info ' , ' warning ' , ' error ' , ' critical ' ."
init tags file path .
"read tags file , store data in memory ."
return next tag or none if all tags were alredy returned by this method .
parse p_tags_file xml tags file and store it in memory .
receives message haptic_control_message and sends it to stimulation board .
to be subclassed .
- p_tag_def - must be an instance of smarttagendtagdefinition . - p_start_tag - must be a dictionary representaion of existing tag .
"this method must be fired only and only once , to set smart tag`s ending tag ."
return configuration gui in form of dock widget
fetch private emails from github account
return user details from github account
loads user data from service
render template tag with default versions .
render template tag with default settings .
render template tag with alternate theme .
render using theme from content variable .
get a translated attribute by language .
"formats val according to the currency settings for the desired currency , as set in l10n_settings"
include tasks for all applications in ` ` installed_apps ` ` .
"given an application name and a module name , tries to find that module in the application ."
load configuration from django settings .
"does everything necessary for django to work in a long - living , multiprocessing environment ."
called before every task .
called when the worker starts .
returns true if the obj is a django model
if the model is not defined in the ` ` models ` ` setting this check raises the ` ` modelnotactionable ` ` exception .
return user details from twitter account
return the tokens needed to authenticate the access to any api the service might provide . twitter uses a pair of oauthtoken consisting of an oauth_token and oauth_token_secret .
return user data provided
"completes login process , must return user instance"
checks existance of configured binaries
check platform directories
check api connection
template tag to render fresh notifications for the current user .
provide the count of unread messages for an authenticated user .
deletes a trunk .
updates a trunk .
retrieve the list of trunk resources .
creates a trunk .
updates a trunk . : param sid : a human readable 34 character unique identifier : param body : request body
deletes a trunk . : param sid : a human readable 34 character unique identifier
update this key
delete this key
create a : class:`key ` with any of these optional parameters .
update a : class:`key ` with the given parameters .
delete a : class:`key `
returns a page of : class:`key ` resources as a list
update the status of an account .
permenently deactivate this account
temporarily suspend this account
reactivate this account
returns a page of : class:`account ` resources as a list . for paging informtion see : class:`listresource `
: param sid : account identifier : param friendly_name : update the description of this account . : param status : alter the status of this account
"permenently deactivate an account , alias to update"
"temporarily suspend an account , alias to update"
"reactivate an account , alias to update"
returns a newly created sub account resource .
"todo : in the current setting , the selection of an episode does not follow pure uniform process . need to index every episode and then generate a random index rather than going on multiple levels of selection ."
"enrich the imdb 's roidb by adding some derived quantities that are useful for training . this function precomputes the maximum overlap , taken over ground - truth boxes , between each roi and each ground - truth box . the class with maximum overlap is also recorded ."
add information needed to train bounding - box regressors .
compute bounding - box regression targets for an image .
test that recv with a waiting sender * does not * give control to the waiting sender .
test that send with a waiting receiver * does * give control to the waiting receiver .
calculates which backend to use with the following algorithm :
starts a tasklet / greenlet .
runs a tasklet up until it blocks or finishes .
returns a new channel .
"yields control for other tasklets / greenlets to run . if none are available , do nothing ."
runs the given tasklet / greenlet immediately .
propagates an exception ( created via ` ` errtype(*args ) ` ` ) so the program hears it and it does n't die lonely in a tasklet .
return true if a send or receive would deadlock ( current tasklet / greenlet is the last one running ) .
upgrades to version 2
converts back to previous version and removes the newly created tables .
adds tasks to list of tasks to be executed .
executes the list of tasks .
shuts down the process pool to free up resources .
test basic serial get commands
test simple set against mock server
test seeing a first auth b2b
test seeing a bad auth b2b
"a decorator for functions that define tensorflow operations . the wrapped function will only be executed once . subsequent calls to it will directly return the result so that operations are added to the graph only once . the operations added by the function live within a tf.variable_scope ( ) . if this decorator is used with arguments , they will be forwarded to the variable scope . the scope name defaults to the name of the wrapped function ."
takes a screenshot of the screen .
returns the default plugin used for testing .
returns the default plugin version used for testing .
returns a node group template for the default plugin .
returns a cluster template for the default plugin .
make a request and check response status code .
make a request and check response status code .
"make a request , check response status code and parse response body ."
list all node group templates for a user .
returns the details of a single node group template .
creates node group template with specified params .
deletes the specified node group template by i d.
list all enabled plugins .
returns the details of a single plugin .
list all cluster templates for a user .
returns the details of a single cluster template .
creates cluster template with specified params .
deletes the specified cluster template by i d.
updates the specificed cluster template .
list all data sources for a user .
returns the details of a single data source .
creates data source with specified params .
updates the details of a single node group template .
deletes the specified data source by i d.
updates a data source
list all job binary internals for a user .
returns the details of a single job binary internal .
creates job binary internal with specified params .
deletes the specified job binary internal by i d.
returns data of a single job binary internal .
list all job binaries for a user .
returns the details of a single job binary .
creates job binary with specified params .
deletes the specified job binary by i d.
returns data of a single job binary .
list all jobs for a user .
returns the details of a single job .
creates job with specified params .
deletes the specified job by i d.
method to add a new item to a instapaper account
authenticate with the instapaper.com service
method to query a url with the given parameters
test the detail view that returns the object
test the detail view that returns the object
test the detail view that returns the object
"makes sure the retrieved file is not cached on disk , or cached by proxy servers in between . this would circumvent any checking whether the user may even access the file ."
return a list of constraint classes found in this directory . this method is used as the default for available constraints for scheduler and returns a list of all constraint classes available .
return the components of the constraint .
checkout a url to a given destination
update a repositry to a given revision
checkout a single file to out_path
get the current revision of a repository with svnversion
returns the g+c content in percentage .
alias to the class : class:`~biokit.viz.imshow . imshow `
.. rubric : : constructor
wrapper around imshow to plot a dataframe
return akaike information criterion ( aic )
bayesian information criterion
a simple example to play with and perform test
.. rubric : : constructor
: param gradient_span : none is default in r
"if ` name ` appears to be a source file name , this converts it to a module name . otherwise this returns ` name ` inchanged ."
"generate sequence of all submodules of name , including name itself ."
the core behavior of the operator .
extra arguments to display in operator reprs .
subclasses call this when they encounter a node they can potentially mutate .
mutate a node in an operator - specific manner .
visit a ' for ' node .
modify the for loop to evaluate to none
clear and initialize a work - db with work items .
apply each registered interceptor to the workdb .
adds work items to the workdb as mutatable nodes are found .
try to get the line number for ` node ` .
try to get the column offset for ` node ` .
"the sequence of ` ( idx , to - op ) ` tuples describing the mutations for ` ops ` ."
compares two ast nodes for equality .
context manager for temporarily setting ` directory ` as the current working directory .
put ` directory ` at the front of ` sys.path ` temporarily .
count mutants for a single module - operator pair .
count how many mutations each operator will peform on each module .
called when a mutation site is reached .
extra arguments to display in operator reprs .
the celery task which performs a single mutation and runs a test suite .
execute a suite of tests for a given set of work items .
"returns a httpresponse whose content is a javscript file . the template is loaded from ' tinymce/<name>_textareas.js ' or ' < name>/tinymce_textareas.js ' . optionally , the lang argument sets the content language ."
returns a httpresponse that implements the tinymce spellchecker protocol .
returns a httpresponse whose content is an html file that is used by the tinymce preview plugin . the template is loaded from ' tinymce/<name>_preview.html ' or ' < name>/tinymce_preview.html ' .
returns a httpresponse whose content is a javscript file representing a list of links to flatpages .
returns a gzip - compressed response .
returns a httpresponse whose content is a javscript file representing a list of links suitable for use wit the tinymce external_link_list_url configuration option . the link_list parameter must be a list of 2 - tuples .
returns a httpresponse whose content is a javscript file representing a list of images suitable for use wit the tinymce external_image_list_url configuration option . the image_list parameter must be a list of 2 - tuples .
test if the notes page renders .
test if an individual note view renders .
test if the add new note view works .
test if the add new note view returns 302 .
test if the add new note view works .
test if the add new note view returns 302 .
test if the add new note view works .
test if the delete note view returns 302 .
test if the manage view returns a 302 when model and object_id are provided .
tests the notes create view .
"split a given sequence contained in one line into lines of size "" length """
remove old plots add multiple plots if multiple images and all layers should be used else add one plot
remove old plots add multiple plots if multiple img and all layers should be used else add one plot
write setting to the preferences
add a parameter to change the graphs symbol for each layer
add a parameter to change the graphs symbol for each layer
add an action for all other displays and connect it to self._linkview
fill the menu with all available layers within other displays this function of often connected with the menu.abouttoshow signal
fill the menu with all available displays this function of often connected with the menu.abouttoshow signal
only show drop - down menu option if menu is filled with entries
often you 'll setup a tool within its menu then return to your image and then execute that tool . but which tool was it ? with this method the last tool whose menu was called will be drawn slightly darker to help you remember .
only show drop - down menu option if menu is filled with entries
if activate = true : run [ returnmethod(self ) ] when this tool is clicked
return the mouse coordinates
handle selections of locales
initialise ourself from gnome xkb
"iterate over watson.cli commands , generate commands markdown documentation and write it to the rowsput file ."
writes a heading into the buffer .
writes a usage line into the buffer . : param prog : the program name . : param args : whitespace separated list of arguments . : param prefix : the prefix for the first line .
writes re - indented text into the buffer .
writes a definition list into the buffer . this is how options and commands are usually formatted . : param rows : a list of two item tuples for the terms and values .
generates application manifest file .
compose required files for murano application package .
return path to system default ca file .
send an http request with the specified characteristics .
returns an application - catalog service client
hook to add global options
get obj 's i d or object itself if no i d
find a single item with attributes matching ` ` * * kwargs ` ` .
find all items with attributes matching ` ` * * kwargs ` ` .
add the popup to the popup chain .
"ensure the popup will be shown at some point in time . if there is no active popups , the popup will be shown now . if there are active popups , the popup will be shown as soon as previous popus will be closed ."
callback that shows the first pending popup from the chain .
"open the url passed as argument . if the url points to a local file , encode it using the right encoding ."
"open the url passed as argument . if the url points to a local file , encode it using the right encoding . calls another process to ensure it terminates right away and does not block the main process / thread ."
set an image using a key specified in source_map
set back the image to default
hide the status image widget . on_error - hide the widget even if it is showing an error icon .
show the status image widget .
get the path where the file should be stored in the cache .
get the file contents from the cache or none if the file is not present in the cache .
save the file contents to the cache . the contents of the file are saved to a temporary file and then moved to ensure that no truncated file is present in the cache .
"callback that is called when the user checks or unchecks the "" selected "" checkbox of a mod ."
this function is run in another process
this function is run in another process
test if a childprocess can react on termination flag of para
append additional options available only if set in devmode . the variable that needs to be set is : ` devmode_options ` .
prepare all the mods ' directories before downloading content . see preparer.run doc for more info .
handle all incoming messages passed from the main process .
a wrapper around message_queue.progress to send messages .
bind < callback > function to be called when < command > message arrives . note : there can be only one callback assigned to a command at any time .
helper function to get the mod object by its foldername attribute .
terminate message has been received .
"mod_reuse message has been received . if the argument is copy , copy the directory to the new location . if the argument is use , create a symlink ( ntfs junction currently ) . decrease missing_responses ."
mod_search message has been received . the user has decided whether to search for mods in yet another directory or to just download all the remaining mods from the internet .
wrapper around message_queue.reject .
find all the potential mods located in < locations > and send the message to present the results to the user so they can make a choice .
send a message with the list of missing mods to the main process .
"first , ensure all mods directories that already exist are reachable and remove all those that are not ( bad symlink ) . then repeatedly ask the user to find missing mods until all mods are found or marked to be downloaded from the internet ."
"try to read base_dir / relative_path . for git head , relative_path should be ' head ' . if it contains a sha1 , return it . if it contains a ref , open base_dir/<ref > and return its contents . on error , return none"
get the sha1 of the last commit of a repository . the base_repo_dir should contain a direct ' .git ' subdirectory
get the sha1 of the last commit . this works both in normal mode and in pyinstaller - wrapped mode . returns a string with the sha1 or none if the sha1 was impossible to be found .
dump the sha1 to a file that can then be used when wrapped by pyinstaller
create the ` argumentparser ` for the command ` decompose - cert ` .
"return der encoded certificate from "" raw "" certificate data which could be encoded as pem , base64 ( b64 ) or der ."
return list of scts of the sctlist san extension of the certificate .
return list of scts of the ocsp status response .
return list of scts of the tls extension 18 server reply .
"args : scts_tls : if true , register callback for tsl extension 18 ( for scts ) scts_ocsp : if true , register callback for ocsp - response ( for scts ) timeout(int ): timeout in seconds"
args : ctx(openssl.ssl.context ): openssl context object
"args : domain : string with domain name , for example : ' ritter.vg ' , or ' www.ritter.vg ' scts_tls : if true , register callback for tsl extension 18 ( for scts ) scts_ocsp : if true , register callback for ocsp - response ( for scts ) timeout(int ): timeout in seconds"
"return true if ee_cert is an extended validation certificate , else false ."
return true if ee_cert was issued by let 's encrypt .
return pyasn1_modules.rfc5280.certificate instance parsed from cert_der .
return openssl.crypto . x509 instance parsed from cert_der .
return pyasn1_modules.rfc2580.tbscertificate instance ` cert_pyasn1 ` without sctlist extension ( oid 1.3.6.1.4.1.11129.2.4.2 ) .
"return pyasn1_modules.rfc5280.tbscertificate instance ` cert_pyasn1 ` without sctlist extension ( oid 1.3.6.1.4.1.11129.2.4.3 ) and poison extension ( oid 1.3.6.1.4.1.11129.2.4.2 ) , if any ."
this is a special variant of the send message that will halt a tutor until a response is received . it will time out after a set amount of time .
starts the tutor in event - driven mode .
load class from path .
test send of sample data to an azure iot hub instance
perform polling of an azure iot hub instance
"densenet-121 model from ` "" densely connected convolutional networks "" < https://arxiv.org/pdf/1608.06993.pdf > ` _"
"densenet-169 model from ` "" densely connected convolutional networks "" < https://arxiv.org/pdf/1608.06993.pdf > ` _"
"densenet-201 model from ` "" densely connected convolutional networks "" < https://arxiv.org/pdf/1608.06993.pdf > ` _"
"densenet-161 model from ` "" densely connected convolutional networks "" < https://arxiv.org/pdf/1608.06993.pdf > ` _"
"replace * / ! by space and rief , @fn , \param , etc"
this is the best i could figure for missing clean ( ) function --cmb
whether line is a c++ style doxygen comment
"line ends , but does not begin , a c - style comment"
returns a list of doxygen comments ending at line line_index
returns a multiline c - style doxygen comment ending at line line_index
detects if tmp_str is code or not
will be used to create the console script
converts the kyoto university dataset txt files to csv files
we compute similarity of the same sentences . these should be exactly the same and therefor have similarity close to 1.0 . see https://github.com/miso-belica/sumy/issues/58
we compute similarity of the sentences without single common word . these are considered dissimilar so have similarity close to 0.0 . see https://github.com/miso-belica/sumy/issues/58
source : http://www.prevko.cz/dite/skutecne-pribehy-deti
"when all words is in upper case plaintext parser first line as heading and lexrank algorithm raises exception "" zerodivisionerror : float division by zero "" because there is no sentence to summarize . see https://github.com/miso-belica/sumy/issues/25"
computes cosine similarity of two text documents . each document has to be represented as tf model of non - empty document .
computes unit overlap of two text documents . documents has to be represented as tf models of non - empty document .
"converts loci file format to bpp file format , i.e. , concatenated phylip - like format , and produces imap and ctl input files for bpp ."
write outfile with any args in argdict
convert ipyrad .loci file to an iqtree - pomo ' counts ' file
"import all classes from the module specified by the dotted_path . if dotted_path is not a module , try importing it as a member of a module instead"
help : display this help text
robot help : display regular expressions that the bot responds to
give the path to object relative to ` ` parent_path ` ` .
add all our command line options
storing pylint settings on the session
collect files on which pylint should run
lint collected files and store messages on session .
"deprecated , but required"
get message and append to our data structure
launch layouts display
check the pylint messages to see if any errors were reported .
handle any test failures by checkint that they were ours .
generate our test report
refuse selected approval requests
accept selected approval requests
return a human - readable version of the sandbox contents
"return the desired object , augmented with a request attribute"
"if accessors are overriden , they should not be synthesized . we also check that there 's no bug if the naming convention is changed ."
"when applied to a class , this decorator adds getter / setter methods to it and overrides the constructor in order to set the default value of the member . by default , the getter will be named ` ` membername ` ` . ( ex . : ` ` membername = ' member ' = > instance.member ( ) ` ` )"
"when applied to a class , this decorator adds getter / setter methods to it and overrides the constructor in order to set the default value of the member . by default , the getter will be named ` ` member_name ` ` . ( ex . : ` ` member_name = ' member ' = > instance.member ( ) ` ` )"
"when applied to a class , this decorator adds a property to it and overrides the constructor in order to set the default value of the property ."
"when applied to a class , this decorator adds a property to it and overrides the constructor in order to set the default value of the property ."
this class decorator will override the class 's constructor by making it implicitly consume values for synthesized members and properties .
this class decorator will override the class 's _ _ eq _ _ and _ _ neq _ _ operations to be based on comparing the values of the synthetic members .
"when applied to a class , this decorator will override the camelcase naming convention of all ( previous and following ) : meth:`synthesizemember ` calls on the class to ` ` namingconvention ` ` ."
"when applied to a class , this decorator will override the underscore naming convention of all ( previous and following ) : meth:`synthesizemember ` calls on the class to ` ` naming_convention ` ` ."
: type membername : str : type readonly : bool : type privatemembername : str|none : type memberdelegate : imemberdelegate
: type namingconvention : inamingconvention
: type namingconvention : inamingconvention : type gettername : str|none : type settername : str|none
: type cls : type : type originalmembernamelist : list(str ) : type membername : str : type classnamingconvention : inamingconvention|none
: type cls : type : type originalmembernamelist : list(str ) : type membername : str : type classnamingconvention : inamingconvention|none
: type membername : str : type accessorname : str : type classnamingconvention : inamingconvention|none
: type membername : str : type classname : str
: type cls : type : type originalmembernamelist : list(str ) : type membername : str : type classnamingconvention : inamingconvention|none
: type cls : type : type originalmembernamelist : list(str ) : type classnamingconvention : inamingconvention|none
check if binary is executable
get all sections in config file
get all keys inside a particular section
get all genome names as specified in config file
return all files associated with a genome in the config file
returns absolute path to installed binaries
moca : motif conservation analysis
search motifs and create conservation plots
create conservation plots
connects to mongodb instance parameters ---------- configuration_file : string path to configuration file
get all records from collection
init : currently only analyzing samples which have idr peaks
builds and returns a hello world game .
build a slidingsprite .
build the convolutional neural net to be trained with the advi algorithm : param init : can pass in a function init which has to return a theano expression to be used as the weight and bias matrices : return :
测试 有辅助核算 余额方向为 借
测试 有辅助核算 余额方向为 贷
测试 无辅助核算 余额方向为 借
测试 无辅助核算 余额方向为 贷
创建 进项税行 公司 进项税科目 未设置
测试 money invoice name_get 方法
"this function returns an action that display buy history of given sells order ids . date range [ 365 days ago , now ]"
验证 work_email 合法性
"当前期间与工资期间相同 , 使用计提按钮"
审核方法异常 : 工资单还未计提，请先计提
审核销售变更单 : 正常情况
审核销售变更单 : 没输入明细行，审核时报错
审核销售变更单：调整后数量 5 < 原订单已出库数量 6，审核时报错
审核销售变更单 : 调整后数量6 = = 原订单已出库数量 6，审核后将产生的发货单分单删除
审核销售变更单 : 原始单据中一行商品已全部出库，另一行没有
"盘点单查询的盘点数量不应该包含移库在途的 , 在途移库数量恰好等于仓库中数量"
test : check_done state = = ' done '
test : _ get_difference_uos_qty
test : check_difference_identical
测试 业务伙伴应收 / 应付余额不为0时，不允许取消对应的客户 / 供应商身份
initialize the container .
return a list of all available attributes .
initialize a group .
"return the full path to the group , including any parent groups ."
load a group from an ncstream object .
return a string representation of the group and its members .
initialize the dataset .
return a string representation of the dataset and all contained members .
initialize the variable .
return the parent group .
"return the full path to the variable , including any parent groups ."
access the variable 's underlying data .
populate the variable from an ncstream object .
return a string representation of the variable .
initialize the dimension .
return whether the dimesion is unlimited .
load from an ncstream object .
return the length of the dimension .
return a string representation of the dimension information .
get datasets from a thredds radar server 's top - level catalog .
parse station list xml file .
create a : class:`station ` instance from an xml tag .
specify one or more stations for the query .
create a radarserver instance .
return a new query for the radar server .
validate a query .
fetch a parsed thredds catalog from the radar server .
fetch thredds catalog xml from the radar server .
use curl and set admin status to enable on pong and ping vnfs
use curl and set admin status to enable on pong and ping vnfs
use curl and set admin status to enable on pong and ping vnfs
this is to make sure that the state change will still work even if no callbacks are registered .
this is to make sure that the database will save the object with the initial state .
"asserts , that * d * is a jsonapi resource object ."
"asserts , that * d * is a jsonapi attributes object ."
"asserts , that * d * is a jsonapi relationships object ."
"asserts , that * d * is a relationship object ."
"asserts , that * d * is a resource linkage ."
"asserts , that * d * is a resource identifier object ."
"asserts , that * d * is a jsonapi links object ."
"asserts , that * d * is a jsonapi link object ."
asserts that * d * is a meta object .
"returns a dictionary with the uri re(s ) for each endpoint type ( collection , resource , related and relationships ) ."
"true , if the api is in debug mode ."
": rtype : jsonapi.base.database . database : returns : the database the api uses to load , save and delete resources ."
"builds the regular expressions , which match the different endpoint types ( collection , resource , related , relationships , ... ) and adds them to : attr:`_routes ` ."
returns the resource class associated with the * typename * .
returns the jsonapi schema which represents the structure of the resource type with the given typename .
returns the serializer used to serialize types of * typename * .
returns the unserializer used to unserialize types of * typename * .
returns the typename of the object * o * .
: rtype : list : returns : a list with all typenames known to the api .
"returns true , if the api has a type with the given name and false otherwise ."
encodes the object * d * as json string .
decods the json string * s * .
"the root uri of api , which has been provided in the constructor ."
returns the url for the api endpoint for the type with the given typename .
adds the serializer to the api .
parses the : attr:`request.uri ` and returns the handler for the requested endpoint .
handles the * request * and returns a : class:`response ` .
returns the identifier object for the * resource * :
"does the same as : func:`ensure_identifier_object ` , but returns the two tuple identifier object instead of the document :"
"walks through the document * d * and saves all type identifers . this means , that each time a dictionary in * d * contains a * type * and * i d * key , this pair is added to a set and later returned :"
returns a list with the ids of related resources .
configure handlers binded to root_logger .
configure logging to stdout .
configure logging to file .
log the calling function input params to ` logger ` with ` level ` severity .
"if progress has insreased sufficiently , log it to ` ` logger ` ` ."
log all uncaught exceptions in non - interactive mode .
"convert string to integer , if possible ."
get ftplib . ftp object that is connected to base_url .
get list of available species .
get list of available releases .
download annotation for given release / species / source .
download genome for given release / species / source .
read first few records and determine quality encoding in fastq file .
initialize attributes .
represent object .
open file handle in desired mode .
close file .
read fastq file .
write single fastq entry .
close file if it is stil open .
"return a command to diff two files , along with the diff output ( if it 's short ) ."
"like "" first_bad::first_good "" , but includes branches / csets that never got the first_good fix ."
return a list of revsets corresponding to known - busted revisions .
return a revset which evaluates to the first revision of the shell that compiles with |options| and runs jsfunfuzz successfully with |flags| .
"typical usage : normal bac0.log_level(file='warning ' , stdout='warning ' , stderr='error ' ) info on console .... but not in file bac0.log_level(file='warning ' , stdout='info ' , stderr='error ' ) debug bac0.log_level(file='debug ' , stdout='info ' , stderr='error ' )"
this will be used as a decorator on class to activate logging and store messages in the variable cls._notes this will allow quick access to events in the web app .
": param point : ( bac0.core.device . points . point ) name of the point to read : param delay : ( int ) delay between reads in seconds , defaults = 10sec"
"build a writeproperty request , wait for an answer , and return status [ true if ok , false if not ] ."
discover the bacnet points in a bacnet device .
test that the library registration mechanism is working .
parses a attributes injection file into an attribute injection dictionary .
expands a list of files definitions into the matching files paths .
expands a list of node definitions into the matching node names .
closes the account .
reopens the account .
creates the invoices for any uninvoiced charges in the account . creates one invoice per currency ( only when the total in that currency is positive ) .
add a charge to the account .
returns whether we 're trying to render an exception .
override this if you have a different way to get the schema .
add a new state to the state machine
change state of the state machine
return state of state machine
initialises the taskhelper object
"marks task and event as failed when interrupted by a signal , and then exits"
"runs the task , passing this object to the task to provide access to library routines and configuration options . handles task closures and sigint / sigterm signals ending tasks prematurely ."
returns a connection to the cortex database
logs an exception into the events for this task
logs a fatal error into the events for this task
"starts a new event within the tasks , closing an existing one if there was one"
updates the description of the currently running event
"ends the currently running event , updating it 's description and status as necessaru"
"end the tasks , updaing it 's status as appropriate . if any events within the task failed , this will mark the tasks as finishing with warnings even if the task succeeds"
returns the number of events within the task that have failed or finished with warnings .
get all the information about all the environments .
get all the information about all the environments that have a puppet environment .
get all the information about all the environments that have a servicenow environment .
get all the information about all the environments but as a dictionary keyed on the environment rather than an ordered list
this function connects to the neocortex job daemon using the pyro4 remote procedure call ( rpc ) library .
return a list of clusters from within a given vcenter . the tag parameter defines an entry in the vcenter configuration dictionary that is within the application configuration .
determines if a given hostname is valid
"strips the domain from a fully - qualified domain name , returning just the hostname name component"
"record a message in the ' events ' table , i.e. generate a log record"
"return context dict for a shell session so you can access app , db , and the user model by default ."
run the tests .
return a dictionary for use in ` ` package_data ` ` in a ` ` setup.py ` ` file .
equivalent to normpath(abspath(join(*c ) ) )
"return path , but assert its presence first"
"> > > require_option('foo - bar ' ) ... cmdlnusererror : required option , --foo - bar , is mising"
return the unicode / text representation of ` obj ` without throwing unicodedecodeerror
hack to convert unix paths in cmdln options ( via config file ) to windows specific netshare location
given a unix path return the platform - specific path
setup console output for logging calls
trace logging calls to a standard log file
momentarily handle logger ` l ` using filehandler
like ` handledby ` but the log file is stored in archive .
' with ' context to intercept and log any exceptions raised
run on console .. and exit the program appropriately .
move $ logfile to $ logfile.old if its size exceeds ` maxsize `
begin a new section in the logfile
clear the traceback cache stored in ` record ` ( logrecord )
temporarily assign ` exc_info ` to ` record `
arguments : - install_console : install console handlers in logger
this method is called by ` ` bootstrapped ` ` - once and only once .
run the sub - command after bootstrapping
read a text file .
configures logging to pipe to sentry .
": returns : revision number of this branch / checkout , if available . none if no revision number can be determined ."
"given ` ` value ` ` , return a boolean describing whether this serializer can operate on the given type"
"given ` ` value ` ` , coerce into a json - safe type ."
"given ` ` value ` ` , recurse ( using the parent serializer ) to handle coercing of newly defined values ."
"given ` ` value ` ` , return a boolean describing whether this serializer can operate on the given type"
returns the alias of a slave database .
send reads to slaves in round - robin .
send all writes to the master .
"allow all relations , so fk validation stays quiet ."
only allow syncdb on the master .
"send reads to slaves in round - robin unless this thread is "" stuck "" to the master ."
"get entity from memcache if available , from datastore if not ."
return the list of tags related to an object
print information message to default output : param message : information message : param color : color of output ( default = none ) : param force_exit : color of output ( default = false ) : param clear : clear screen before output ( default = false)w : type message : str : type color : str : type force_exit : bool : type clear : bool
humanize file size . : param size_of_file : size of file in bytes : param suffix : suffix which will be added to size format : type size_of_file : int : type suffix : str : return : humanized file size : rtype : str
clear user output
save image bytes ti file
executes the given shell command
creates a user account with the given username
create an intsance of the pyramid object .
return the string represetation of the pyramid instance .
return the value of the support for this pyramid object .
return the value of the support for the reference phase space point .
return the indicator function on the time interval .
sets up some structures and lists useful for the remaining test .
this routine tests that the initialization routine returns a bf object with the correct parameters.s
test the behavior of the routines associated with the flux lists .
abstract hci_send_cmd method
returns the current user 's vote for the given content :
"creates a profile object for the user if it does n't exist , or updates it with new information from the user ( e.g. the gravatar ) ."
"sends the "" joined "" activity to the stream on create"
builds a url for cas
"loops through the input files and yields each token , avoids reading from cache files given that these cache files are word oriented ( e.g. : they keep sentences only for specific words such as "" improves "" or "" finds "" and ignores all others ) ."
iterates through tokens for the given word being currently searched .
"given a sentence and a word , highlights the word in the sentence ."
module entry point for the command line .
module entry point for the command line .
module entry point for the command line .
"the rule applier class . it provides functionality as to centralize certain structures used into all rule applier objects and , more importantly , implements the @ruleapplier.register_function decorator . this decorator allows the programmer to , inside a class , mark which methods are rules to be applied directly in the tree . these types of rule methods expect a fixed signature and return a fixed set of parameters . an entry point then simply applies these rules in the order they were registered . this makes it easier to add / remove rules from the ruleset ."
the static method that serves as the decorator method . it adds a function to the the deco_list static list and returns the unaltered function .
returns a list with all the rules registered for this class .
"given a more complex dependency tag , returns its simplified version according to the rules inside self.translation_rules"
apply registered rules .
initializes default interface parameters and stores command line parameters internally .
runs the stanford open information extractor tool on the file containing the segmented sentence .
initializes default interface parameters and stores command line parameters internally .
runs the allenai open information extractor tool on the file containing the segmented sentence .
initializes default interface parameters and stores command line parameters internally .
runs the max planck institute open information extractor tool on the file containing the segmented sentence .
initializes default interface parameters and stores command line parameters internally .
runs the selected tool on the file containing the segmented sentence .
returns the class instance for the interface with the selected external tool .
"generate a gazette with keywords and concepts from the microsoft academic data , given "" topics "" set in the topics variable ."
entry point for gazette generation .
see : class:`bgpranking.api.get_ip_info `
see : class:`bgpranking.api.get_all_ranks_single_asn `
see : class:`bgpranking.api.get_all_ranks_all_asns `
see : class:`bgpranking.api.get_asn_descs `
see : class:`bgpranking.api.get_ips_descs `
see : class:`bgpranking.api.get_stats `
see : class:`bgpranking.api.get_block_descriptions `
see : class:`bgpranking.api.cache_get_dates `
see : class:`bgpranking.api.cache_get_daily_rank `
see : class:`bgpranking.api.cache_get_top_asns `
see : class:`bgpranking.api.cache_get_position `
display text in calltip window
"compare two files , use the cache if possible . return 1 for identical files , 0 for different . raise exceptions if either file could not be statted , read , etc ."
"return signature ( i.e. , type , size , mtime ) from raw stat data 0 - 5 : st_mode , st_ino , st_dev , st_nlink , st_uid , st_gid 6 - 9 : st_size , st_atime , st_mtime , st_ctime"
"compare two files , really ."
play a movie in a window
load a movie given an fsspec . return the movie object
highlight the single paren that matches
highlight the entire expression
highlight will remain until user input turns it off
the last highlight created will be removed after .5 sec
return the location of the last open paren
"encode the input , returning a tuple ( output object , length consumed ) ."
"decode the input , returning a tuple ( output object , length consumed ) ."
replace all line - ending characters with .
"the inverse of parseaddr ( ) , this takes a 2 - tuple of the form ( realname , email_address ) and returns the string value suitable for an rfc 2822 from , to or cc header ."
"return a list of ( realname , email ) for each fieldvalue ."
"returns a date string as specified by rfc 2822 , e.g. :"
"returns a string suitable for rfc 2822 compliant message - id , e.g :"
remove quotes from a string .
decode string according to rfc 2231
encode string according to rfc 2231 .
decode parameters list according to rfc 2231 .
"insert item x in list a , and keep it sorted assuming a is sorted ."
"return the index where to insert item x in list a , assuming a is sorted ."
"insert item x in list a , and keep it sorted assuming a is sorted ."
"return the index where to insert item x in list a , assuming a is sorted ."
parses a liboparl validationresult into a validator message .
initialize a cache instance
checks wether a key exists .
sets the contents of a key
gets the full key name of a key
connect the incoming_<entity>-signals of a liboparl body to the data processing method .
process a chunk of incoming objects
check whether an entity was already fetched
returns the demosaiced * rgb * colourspace array from given * bayer * cfa using bilinear interpolation .
cleans the project .
formats the codebase with * yapf * and converts unicode characters to ascii .
runs the unit tests with * nose * or * pytest * .
checks the codebase with * flake8 * and lints various * restructuredtext * files with * rst - lint * .
runs the examples .
builds the documentation .
export the todo items .
"performs the preflight tasks , i.e. * formatting * , * tests * , * quality * , and * examples * ."
"builds the project and runs dependency tasks , i.e. * docs * , * todo * , and * preflight * ."
create a virtual environment for the project build .
tags the repository accordingly to defined version using * git - flow * .
releases the project to * pypi * with * twine * .
computes the project * pypi * package * sha256 * with * openssl * .
tests : func:`colour_demosaicing.bayer.demosaicing.malvar2004.demosaicing_cfa_bayer_malvar2004 ` definition .
test_general - test basic listy operations of a domtokenlist
test_createfromstring - test that we can create a domtokenlist from a string
test_createfromcrazystring - test that we properly strip before splitting a tokenstring from string
test_emptyfromemptystr - test that we create an empty list with an empty str ( or only whitespace )
test_handlemultipleroot - make sure validator parser still works to parse
test_handleinvalidclose - properly raise exception when an invalid close is attempted
test_handlemissclose - properly raise exception when a close is missed that matters
test_handlemissoptionalclose - do n't throw exception on optional - close cases
"simple event manager duplicating the pygame events for the system ( runtime hardware management ) and the user ( game control ) the get ( ) method and the system - reserved _ get ( ) both poll the pygame event list to keep the list up - to - date and also avoid the pygame internal queue to be full todo : events pygame / touch to be merged into a unique format : param enable_system_events : enable the acquisition of system events , must be false if no arbalink polls the system event queue : return :"
get a copy of events dedicated to the user the list of user events has a limit to avoid swamping the memory with unread events : return :
"get a copy of events dedicated to the system this method is not to be called by the user , only by the system : return : the list of events"
"run the event manager that redistributes duplicated events to user and sdk , and todo gathers all events"
multiprocess . pipe reimplementation that uses mpconnection wrapper
"set target state for the object and clear the target event . once the target is reached , the event will be set , see also : ` check_target ( ) `"
"check the target state and set the target event in the case the state is reached . called from mutators , ` add ( ) ` and ` remove ( ) `"
"add an item to the set and all connected instances , check the target state ."
"remove an item from the set and all connected instances , check the target state ."
exclude key from cascade updates .
do not ignore key on cascade updates .
connect a linkedset instance to this one . connected sets will be updated together with this instance .
a server routine to run an iproute object and expose it via custom rpc .
find list of files containing python shebangs in the bin directory
translate /usr / bin / python and /usr / bin / env python shebang lines to point to our virtualenv python .
replace the ` virtual_env ` path in bin / activate to reflect the post - install path of the virtualenv .
access files in an unpacked debian source package .
@param vfs : a class that implements l{gitvfs } interface or a directory ( which will use the l{filevfs } class . the directory must be the toplevel of a debian source package .
whether this is a native debian package
check if package is releasable
return the l{gbp.deb . changelog }
return the l{gbp.deb . control }
the source package 's name
possible upstream tarball name for this source package
possible upstream tarballs names for this source package
check if pristine_tar has a certain feature enabled .
do we have a pristine - tar commit for a package matching i{archive_regexp } .
get the pristine - tar commit of a package matching i{archive_regexp } .
checkout an orig archive from pristine - tar branch
commit an archive i{archive } to the pristine tar branch using upstream branch $ { upstream } .
verify an archive 's i{archive } checksum using to the pristine tar branch
create a repository
create a repository
create a repository
> > > tristate('on').__repr _ _ ( ) ' on ' > > > tristate(true).__repr _ _ ( ) ' on ' > > > tristate(false).__repr _ _ ( ) ' off ' > > > tristate('auto').__repr _ _ ( ) ' auto '
> > > tristate('on').__nonzero _ _ ( ) true > > > tristate('auto').__nonzero _ _ ( ) true > > > tristate('off').__nonzero _ _ ( ) false
get current state
"run function if tristate is on or auto , only report a failure if tristate is on since failing is o.k . for autodetect ."
test default bts command extraction that is applicable to debian
test non - default bts commands . we use the example given in the documentation manpages .
"> > > repo_to_url(""https://foo.example.com "" ) ' https://foo.example.com ' > > > repo_to_url(""github : agx / git - buildpackage "" ) ' https://github.com/agx/git-buildpackage.git '"
capture an output and return its content
capture an output and return its content
decorator to easily set the return value of popen.communicate ( )
parse a the control of debian package
raise an error if no control file exist or is empty
test parsing a valid dsc file
test parsing a a 1.0 non - native dsc file without debian revision
"execute the correspond command against configured pulsar job manager . arguments are method parameters and data or input_path describe essentially post bodies . if command results in a file , resulting path should be specified as output_path ."
"retry reading a message from the publish_uuid_store once , delete on the second failure ."
build up the contents of a condor submit description file .
submit a condor job described by the given file . parse an external i d for the submission or return none and a reason for the failure .
stop running condor job and return a failure_message if this fails .
tests persistence and recovery of launched managers jobs .
tests persistence and recovery of preprocessing managers jobs ( clean ) .
tests persistence and recovery of preprocessing managers jobs ( dirty ) .
pipe - safe ( and 2.6 compatible ) version of subprocess.check_output
helper method for building and executing popen command . this is potentially sensetive code so should probably be centralized .
constructor for shell executor instance .
execute the specified command via defined shell .
logs the start of each task
prints the timings
runs the list and delete commands for keyrotator .
tests signal creation .
tests subscribe ( ) and unsubscribe ( ) .
tests actually emitting signals .
tests argument parsing
tests fixing environment variables
"convenience function that creates an exscript . queue instance , adds the given accounts , and calls queue.run ( ) with the given hosts and function as an argument ."
a wrapper around run ( ) that creates the account by asking the user for entering his login information .
"like run ( ) , but automatically logs into the host before passing the host to the callback function ."
"like quickrun ( ) , but automatically logs into the host before passing the connection to the callback function ."
"returns true if the given string is an ipv6 address , false otherwise ."
"transform the address into a standard , fixed - length form , such as :"
"cleans the ip address up , useful for removing leading zeros , e.g. : :"
"splits the given ip prefix into a network address and a prefix length . if the prefix does not have a length ( i.e. , it is a simple ip address ) , it is presumed to have the given default length ."
set the debug level .
returns the maximum number of concurrent threads .
set the maximum number of concurrent threads .
appends a function to the queue for execution . the times argument specifies the number of attempts if the function raises an exception . if the name argument is none it defaults to whatever id(function ) returns .
"like enqueue ( ) , but does nothing if a function with the same name is already in the queue . returns a job i d if a new job was added , returns none otherwise ."
"like : class:`enqueue ( ) ` , but adds the given function at the top of the queue . if force_start is true , the function is immediately started even when the maximum number of concurrent threads is already reached ."
"like priority_enqueue ( ) , but if a function with the same name is already in the queue , the existing function is moved to the top of the queue and the given function is ignored . returns a job i d if a new job was added , returns none otherwise ."
restart the execution of enqueued jobs after pausing them . this method is the opposite of pause ( ) . this method is asynchronous .
stop the execution of enqueued jobs . executing may later be resumed by calling unpause ( ) . this method is asynchronous .
waits until the job with the given i d is completed .
waits until the queue is empty .
"stop the execution of enqueued jobs , and wait for all running jobs to complete . this method is synchronous and returns as soon as all jobs are terminated ( i.e. all threads are stopped ) ."
"like shutdown ( ) , but does not restart the queue and does not wait for already started jobs to complete ."
"returns true if the queue is currently active ( i.e. not paused and not shut down ) , false otherwise ."
returns a list of all jobs that are currently in progress .
returns the number of currently non - completed jobs .
"returns the number of lines and columns of the current terminal . it attempts several strategies to determine the size and if all fail , it returns ( 80 , 25 ) ."
register a command / response pair .
wrapper around add ( ) that reads the handlers from the file with the given name . the file is a python script containing a list named ' commands ' of tuples that map command names to handlers .
evaluate the given string against all registered commands and return the defined response .
creates the wheel and uploads to pypi with twine .
yields all commit messages from last to first .
return last version from repo tags
checks the origin remote to get the owner and name of the remote repository .
gets the commit hash of the current head .
commits the file containing the version number variable with the version number as the commit message .
creates a new tag with the version number prefixed with v.
runs git push and git push --tags : param gh_token : github token used to push . : param owner : organisation or user that owns the repository . : param name : name of repository .
checkout the given branch in the local repository .
update weight vector
simulate clicks on the result_list . - labels contain relevance labels indexed by the docid
updated to match the original method
assign clicks for contributed documents
format mac address in internal representation into human readable form
parse mac address string in human readable format into internal representation
allows the client to lock the configuration system of a device .
"release a configuration lock , previously obtained with the lock operation ."
"create an instance . returns eventvrrpconfigreply(instance.name , interface , config ) on success . returns eventvrrpconfigreply(none , interface , config ) on failure ."
shutdown the instance .
"transmit a packet from the switch . this is internal use only . data is str - like , a packet to send ."
list instances . returns eventvrrplistreply([vrrpinstance ] ) .
change configuration of an instance . none means no change .
utility to log given stats to * stats * logger .
add a setting of a bonding i / f. ' add ' method takes the corresponding args in this order .
"packetin event handler . when the received packet was lacp , proceed it . otherwise , send a event ."
"flowremoved event handler . when the removed flow entry was for lacp , set the status of the slave i / f to disabled , and send a event ."
packet - in process when the received packet is lacp .
create a packet including lacp .
create a lacp packet .
get whether a slave i / f at some port of some datapath is enable or not .
set whether a slave i / f at some port of some datapath is enable or not .
get the timeout time at some port of some datapath .
set the timeout time at some port of some datapath .
get slave i / f at some port of some datapath .
enter a flow entry for the packet from the slave i / f with idle_timeout . for openflow ver1.0 .
enter a flow entry for the packet from the slave i / f with idle_timeout . for openflow ver1.2 and ver1.3 .
change log format .
this function instanticates an appropriate openflow message class from the given json style dictionary . the objects created by following two code fragments are equivalent .
* data * element as an : class:`~xml.etree . elementtree . element `
* data * element as an xml string
retrieve running configuration and device state information .
retrieve all or part of a specified configuration .
* rpc_command * specifies rpc command to be dispatched either in plain text or in xml element format ( depending on command )
syncs rt nlris for new and removed rtc_ases .
does book - keeping of local rt nlris based on all configured vrfs .
computes current global interested rts for global tables .
updates interested rt list .
lay out the list markers of ` ` box ` ` .
lay out and yield the fixed boxes of ` ` pages ` ` .
lay out the whole document .
resolve value of string function ( as set by string set ) .
clean up human - friendly test name into a method name .
decorate tested function to be used as a method for testcase .
decorate tested function to be used as a method for testcase .
"generate tests from the test data , class to build upon and function to use for testing ."
"可能是针对 token 的预处理 , 也可能是针对 ast 的预处理 / 后处理 ."
: return : true if last task in group
"run , resume , or skip"
"note : for wps intermediate file , x - dimension is the longitude , y - dimension is the latitude , data in the dimension of ( nlat , nlon ) ( c - order )"
foobarhttpplugin - > foo_bar_http
runs the v8 presubmit checks .
"runs checkdeps on # include statements added in this change . breaking - rules is an error , breaking ! rules is a warning ."
attempts to prevent inclusion of inline headers into normal header files . this tries to establish a layering where inline headers can be included by other inline headers or compilation units only .
attempts to prevent use of functions intended only for testing in non - testing code . for now this is just a best - effort implementation that ignores header files and may have some false positives . a better implementation would probably need a proper c++ parser .
runs verify_source_deps.py to ensure no files were added that are not in gn .
checks common to both upload and commit .
check the env var whether we want to skip tree check . only skip if include / v8 - version.h has been updated .
check that bug entries are well - formed in commit message .
git cl upload will call this hook after the issue is created / modified .
extracts those parts of this object that are required to run the test and returns them as a json serializable object .
creates a new testcase object based on packed task data .
serializes the output of the testcase after it has run .
applies the contents of a result to this object .
representation to pickle test cases .
git cl upload will call this hook after the issue is created / modified .
either do majority vote aggregation or conservative all or nothing vote
employ different prediction strategies
predict the class label based on a committee vote of the models in models
load annotation previously generated with hmmer and predict phenotypes with phypat and phypat+ggl models
clear the config cache .
gets the configuration file which defines all the repos we might want .
gets the configuration .
check if all tasks have been published
this sample code is taken from ` androguard ` and has been modified !
"overwrite this method , if you want to use your own result logging framework / object , you can supply it here and access it via ` self.cres ` ."
get an object implementing the ` apkcopyinterface ` .
stop the auto - commit thread .
inserts a document into neo4j .
insert multiple documents into neo4j .
removes a document from neo4j .
get the most recently modified node from neo4j . this method is used to help define a time window within which documents may be in conflict after a mongodb rollback .
lemmatize the string s depending on its part of speech tag
lemmatize the wordlist and build a resource from it
"assume that tree.wordlist is a verb v produce ( v1 , v2 ) where v1 = lemmatize(v ) and v2 is the past participle of v"
"produce a predicate from the root of tree , assume that wordlist is a verb v return a couple ( a , b ) where a must be the predicate , and b the inverse predicate ( b = none if there is no inverse predicate )"
"produce a predicate from the root of tree return a couple ( a , b ) where a must be the predicate , and b the inverse predicate ( b = none if there is no inverse predicate )"
"handle rspl dependency ( superlative , ordinal )"
handle rconj dependency ( conjunction )
map the tree to a normal form
"transform conjonctions to get a tree similar to the old parsing tree . if n1 - -cc-->nconj and n1 - -conj-->n2 , then it removes the first dependency and transforms the second one into n1 - -conj_nconj-->n2 . the node nconj seems to always be a leaf . it contains a conjonction , such as "" or "" or "" and "" . this function is a temporary fix for compatibility with the new version of corenlp ( from december 2015 ) ."
"transform prepositions to get a tree similar to the old parsing tree . if n1 - -nmod-->n2 and n2 - -case-->n3 , then it removes the second dependency and transforms the first one into n1 - -f(n3)-->n2 . the node n3 seems to always be a leaf . it contains a preposition , such as "" of "" or "" by "" . for instance , f(""of "" ) = "" prep_of "" and f(""by "" ) = "" agent "" . this function is a temporary fix for compatibility with the new version of corenlp ( from december 2015 ) ."
remove the nodes with a ' punct ' dependency . this function is a temporary fix for compatibility with the new version of corenlp ( from december 2015 ) .
"compute the dependence tree . take in input a piece of the result produced by stanfordnlp ( if foo is this result , then stanfordresult = foo['sentences'][0 ] ) apply quotation and ner merging return the root of the tree ( word ' root-0 ' ) ."
return true if and only if the word is a verb ( according to its pos tag ) .
return true if and onlf if the word is a noun ( according to its pos tag ) .
append the given string at the end of the word .
return true if and only if one word of wordlist is a verb ( according to its pos tag ) .
return true if and only if one word of wordlist is a noun ( according to its pos tag ) .
assume the wordlist contains only one element . append the given string at the end of the word of the wordlist .
build a dfs annotation on the tree . useful to distinguish ( in printing ) nodes that are different but contain the same wordlist .
"set text attribute for all nodes , with string s."
sort the wordlists of the tree .
return the string represented by wordlist .
print dependency graph in dot format
merge the root of the two given trees into one single node . merge the two wordlist if mergewords = true ( otherwise only keep the wordlist of self ) . the result is stored in node ' self ' .
compute the edges of the dependency tree .
compute the tags of the dependency tree nodes .
"if a word v is between 2 words u and w that have the same ner tag , and v is linked to u or w by a nn relation , then add the tag of u and w to v"
"correct the tree returned by the stanford parser , according to several heuristics ."
generate the tree and return it .
function called by the wsgi server .
"filter out all users who signed up via a microsite , which usersignupsource tracks"
users : set of django users exclude [ optional ] : set of django users to exclude
parses ` options ` of the command .
connect to a mongodb .
ensures the proper fields are indexed
insert the event in to the mongo collection
this can be used within a mako template to include a django template in the way that a django - style { % include % } does . pass it context which can be the mako context ( ' context ' ) or a dictionary .
"this allows a mako template to call a template tag function ( written for django templates ) that is an "" inclusion tag "" . these functions are decorated with @register.inclusion_tag ."
return an httpresponse with the data json - serialized and the right content type header .
split a string both by commas and whitespace . returns a list .
create cohort to partition_id / group_id link .
remove any existing cohort to partition_id / group_id link .
returns a json representation of a course cohort settings .
returns a json representation of a cohort .
the restful handler for cohort setting requests . requires json . this will raise 404 if user is not staff . get returns the json representation of cohort settings for the course . patch updates the cohort settings for the course . returns the json representation of updated settings .
"the restful handler for cohort requests . requires json . get if a cohort id is specified , returns a json representation of the cohort ( name , i d , user_count , assignment_type , user_partition_id , group_id ) . if no cohort id is specified , returns the json representation of all cohorts . this is returned as a dict with the list of cohort information stored under the key ` cohorts ` . put or post or patch if a cohort id is specified , updates the cohort with the specified id . currently the only properties that can be updated are ` name ` , ` user_partition_id ` and ` group_id ` . returns the json representation of the updated cohort . if no cohort id is specified , creates a new cohort and returns the json representation of the updated cohort ."
"return users in the cohort . show up to 100 per page , and page using the ' page ' get attribute in the call . format :"
return json dict of :
expects ' username ' : username in post data .
debugging view for dev .
"receive group configuration as a json ( ` json_string ` ) , deserialize it and validate ."
deserialize given json that represents group configuration .
validate group configuration representation .
assign i d for the json representation of group configuration .
assign ids for the group_configuration 's groups .
return a list of ids that already in use .
get user partition for saving in course .
get usage info for unit / module .
get usage information for all group configurations currently referenced by a split_test instance .
returns json split_test group configurations updated with usage information .
"returns all units names , their urls and validation messages ."
returns all units names and their urls .
get usage information on items for content groups .
returns all items names and their urls .
iterate through items and group ids in a course .
update usage information for particular group configuration .
update usage information for particular partition configuration .
"returns the first user partition from the course which uses the cohortpartitionscheme , or generates one if no such partition is found . the created partition is not saved to the course until the client explicitly creates a group within the partition and posts back ."
returns all the available partitions with updated usage information
test case setup
tests that coursecreatorrole().has_user always returns true if enable_creator_group and disable_course_creation are both not turned on .
"tests creator group feature on , but group empty ."
"tests creator group feature on , user added ."
tests that the course_creation_disabled flag overrides course creator group settings .
tests that adding to creator group fails if user is not authenticated
tests that adding to creator group fails if user is not active
set up test variables
test that global admins have no write access
test that course staff have no write access
test that global admins have no read access
test that course staff have no read access
test case setup
tests adding user to course group ( happy path ) .
verifies permissiondenied if caller of add_user_to_course_group is not instructor role .
tests removing user from course group ( happy path ) .
verifies permissiondenied if caller of remove_user_from_course_group is not instructor role .
decorator for ` apiview.check_throttles ` .
class decorator that allows rate limiting to be disabled .
generates commands for alton to cut amis from the git hash of the hotfix .
generates command to tag the git hash of the hotfix .
return the current problem name .
input a response to the prompt .
click the run code button .
returns the text value of given class .
tests subbing course name in various scenarios
test that anonymous_id is subbed
test that the user 's full name is correctly subbed
test that sub - ing does n't ocurr with illegal tags
test that sub - ing does n't work without subtags
test that subbing works with multiple subtags
tests that no subbing occurs if no user_id or no course_id is given .
a step to be used in * .feature files . enables / disables automatic saving of screenshots before and after each step in a scenario .
"a decorator that will take a screenshot before and after the applied function is run . use this if you do not want to capture screenshots for each step in a scenario , but rather want to debug a single function ."
go to the courseware page containing the item stored in ` world.scenario_dict ` under the key ` item_key `
"returns dict of lists of courses available , keyed by course.org ( ie university ) . courses are sorted by course.number ."
"given a course_id ( string ) , return a courseware array of dictionaries for the top three levels of navigation . same as get_courseware ( ) except include the tabs on the right hand main navigation page ."
"override each task 's "" created "" date"
"after the command is run , this queries again for the tasks we created in ` setup ` ."
tests that nothing is updated when run with the ` dry_run ` option
"test that tasks created outside the window of dates do n't get changed , while tasks created in the window do get changed . verifies that tasks in other states never get changed ."
test that only tasks with specified states are failed .
"test that if we specify which task types to update , only tasks with those types are updated"
test that we get a commanderror when we do n't supply before and after dates .
test that the command will throw an error if called with a value that 's neither ' queuing ' nor ' progress '
update enrollments for a specific user identifier ( email or username ) .
log and overview of the results of the command .
return given valid page or default of 1
return given valid page_size ( capped at 100 ) or default of 10
return a default choice
return a default choice
"verify that the homepage , when accessed at edx.org , has the edx footer"
"verify that the homepage , when accessed at something other than edx.org , has the open edx footer"
parses course key from string
"by convention set by django developers , this method actually executes command 's actions . so , there could be no better docstring than emphasize this once again ."
verify that relevant tasks are only enqueued when the commit option is passed .
verify the task can handle both professional and no - id - professional modes .
verify that program structures are flattened correctly .
verify that only one task is enqueued for a user with multiple eligible course run certificates .
verify that course run types are taken into account when identifying qualifying course run certificates .
verify that only course run certificates with a passing status are selected .
verify that failure to enqueue a task does n't halt execution .
helper function to create the url for certificates
helper method for requests with oauth token
test that only the owner of the certificate can access the url
verify inactive users - those who have not verified their email addresses - are allowed to access the endpoint .
verify access with a valid django oauth toolkit access token .
verify the endpoint is inaccessible for authorization attempts made with an invalid oauth access token .
verify the endpoint is inaccessible for authorization attempts made with an expired oauth access token .
test for case with no certificate available
tests case user that pulls her own certificate
"configures and returns a django storage instance that can be used to physically locate , read and write profile images ."
"returns the user - specific part of the image filename , based on a hash of the username ."
"returns the full filename for a profile image , given the name and size ."
"returns a dict containing the urls for a complete set of profile images , keyed by "" friendly "" name ( e.g. "" full "" , "" large "" , "" medium "" , "" small "" ) ."
"returns a dict containing the filenames for a complete set of profile images , keyed by pixel size ."
"return a dict { size : url } for each profile image for a given user . notes : - this function does not determine whether the set of profile images exists , only what the urls will be if they do exist . it is assumed that callers will use ` _ get_default_profile_image_urls ` instead to provide a set of urls that point to placeholder images , when there are no user- submitted images . - based on the value of django.conf.settings . profile_image_backend , the url may be relative , and in that case the caller is responsible for constructing the full url if needed ."
"returns a dict { size : url } for a complete set of default profile images , used as a placeholder when there are no user - submitted images ."
"system ( not user - facing ) api call used to store whether the user has uploaded a profile image , and if so , when . used by profile_image api ."
test that a user can successfully post on course updates and handouts of a course
verify that the organization names list api returns list of organization short names .
adds the registered transformers to the self.transformers collection .
sending an activation email to the user .
path for block
find the section and unit urls for a block .
returns summary dict for the given video module
create a blockoutline using ` start_block ` as a starting point .
log in the specified user and set its is_active field
ensure that sending a get request to self.url returns the expected status code ( 200 by default ) .
verify that courseoverviews are filtered by the provided org key .
create an oauth client application that is confidential .
create an oauth client application that is public .
get the oauth client application with the specified filters .
"given an accesstoken object , return the associated client application ."
"given a token string , return the matching accesstoken object ."
"given a list of scopes , return a space - separated list of those scopes ."
"given an access token object , return its scopes ."
execute the command
"if a user 's userpreference contains a language preference , use the user 's preference . save the current language preference cookie as the user 's preferred language ."
generate and save a user and an lti user model
escape output of json dumps that is safe to be embedded in a < script > tag .
json dumps and escapes objects that are safe to be embedded in javascript .
mako filter that escapes text for use in a javascript string .
"remove the existing admin , and register it anew with the given modeladmin"
"if the learner 's mode does not match their assigned cohort , move the learner into the correct cohort . it is assumed that this task is only initiated for courses that are using the automatic verified track cohorting mvp feature . it is also assumed that before initiating this task , verification has been done to ensure that the course is cohorted and has an appropriately named "" verified "" cohort ."
add each registered transformer to the block structure . mimic collection by setting test transformer block data .
initialize the class with a provider_id
check if the oauth client associated with auth token in current request has permission to access the information for provider
decorator for block structure tasks .
updates the course blocks ( mongo - > blockstructure ) for the specified course . keyword arguments : course_id ( string ) - the string serialized value of the course key . with_storage ( boolean ) - whether or not storage backing should be enabled for the generated block structure(s ) .
updates the course blocks ( mongo - > blockstructure ) for the specified course .
updates the course blocks ( mongo - > blockstructure ) for the specified course .
"gets the course blocks for the specified course , updating the cache if needed . keyword arguments : course_id ( string ) - the string serialized value of the course key . with_storage ( boolean ) - whether or not storage backing should be enabled for any generated block structure(s ) ."
"gets the course blocks for the specified course , updating the cache if needed ."
"gets the course blocks for the specified course , updating the cache if needed ."
"calls the given api_method with the given course_id , retrying task_method upon failure ."
test the retire_order command
"takes a list of order_ids , writes them to a tempfile , and then runs the "" retire_order "" command on the tempfile"
creates a cart and adds a certificateitem to it
adds utility methods to a model to obtain related model instances via a cache .
displays the home page for the specified course .
renders the course 's home page as a fragment .
start the server for lms or studio .
run the lms server .
run the studio server .
start the devstack lms or studio server
runs celery workers .
"runs celery workers , studio , and lms ."
migrates the lms and cms across all databases
checks settings files .
disable the middleware if the feature flag is disabled .
skip the usual csrf referer check if this is an allowed cross - domain request .
disable the middleware if the feature is not enabled .
set the cross - domain csrf cookie .
create a unique identifier for the course used in this test .
validate the acid block 's preview
verify that all expected acid block tests pass in studio preview
verify that all expected acid block tests pass in studio editor
verify that all expected acid block tests pass in studio preview
"rest api endpoint for listing all the blocks information in the course , while regarding user access and roles ."
"retrieves the usage_key for the requested course , and then returns the same information that would be returned by blocksview.list , called with that usage key"
create site and siteconfiguration models and initialize test client with the created site
initializes the test client with the domain of the given site
return dict version of self
set internal dict of correctmap to provided correct_map dict
takes an answer_id returns true if the problem is correct or partially correct .
takes an answer_id returns true if the problem is partially correct .
"return the number of points for an answer , used for partial credit ."
- hint : ( string ) html text for hint - hintmode : ( string ) mode for hint display ( ' always ' or ' on_request ' )
update this correctmap with the contents of another correctmap
"set a message that applies to the question as a whole , rather than to individual inputs ."
"retrieve a message that applies to the question as a whole . if no message is available , returns the empty string"
create the team membership .
change the enrollment mode of users for a course .
returns the argparse parser for the resend_lti_scores command .
set up the lti provider configuration .
return true if scores are sent to the lti consumer when the command is called with the specified arguments .
returns a jwt access token .
returns a dictionary mapping scopes to methods that will add claims to the jwt payload .
add the email claim details to the jwt payload .
add the profile claim details to the jwt payload .
encode the provided payload .
create search page and course content to search
logout and login with given credentials .
publish content on studio course page under specified section
edit chapter name on studio course page under specified section
add content on studio course page under specified section
reindex course content on studio course page
login and search for specific content
"login and search for specific content in the legacy sidebar search arguments : search_term - term to be searched for perform_auto_auth - if false , skip auto_auth call . returns : ( bool ) true if search term is found in resulting content ; false if not found"
make sure that you can search for something .
make sure new content gets reindexed on button press .
function and class decorator that abstracts the authentication and permission checks for api views .
adds errors from serializer validation to field_errors . data is the original data to deserialize .
build an error dict corresponding to edx api conventions .
build an error response with the given status code and developer_message
build a 400 error response from the given validationerror
generalized helper method for managing specific api exception workflows
adds expand information from query parameters to the serializer context to support expandable fields .
retrieves the specified resource using the retrievemodelmixin .
"checks for validation errors , then updates the model using the updatemodelmixin ."
validates a json merge patch . captures drf serializer errors and converts them to edx 's standard format .
retrieve an object or return none if the object ca n't be found .
redirect if the user does not have access to the course . in case of blocked if access_point is not enrollment and course has enabled is_disabled_access_check then user can view that course .
check is the user with this ip_address has access to the given course
determine the url path for the message explaining why the user was blocked .
check whether the user is embargoed based on the country code in the user 's profile .
return the country code associated with an ip address . handles both ipv4 and ipv6 addresses .
check whether any country access rules block the user from enrollment .
"show an error to staff . todo ( vshnayder ): proper style , divs , etc ."
"show an error to a student . todo ( vshnayder ): proper style , divs , etc ."
build a new errordescriptor . using ` ` system ` ` .
create an instance of this descriptor from the supplied data .
"if the definition data is invalid xml , export it wrapped in an "" error "" tag . if it is valid , export without the wrapper ."
test create_xblock to create non persisted xblocks
looks at the currently active configuration model to determine whether the persistent grades feature is available .
create and configure an api client for authenticated http requests .
"given a set of completed courses , determine which programs are completed ."
find the uuids of all the programs for which the student has already been awarded a certificate .
issue a new certificate of completion to the given student for the given program .
"this task is designed to be called whenever a student 's completion status changes with respect to one or more courses ( primarily , when a course certificate is awarded ) ."
test case scaffolding
tests get_organization_by_short_name api when app is disabled .
tests get_organization_by_short_name api when app is enabled .
"finds course asset in the deprecated contentstore . this method was previously searching for the course asset in the assetstore first , then in the deprecated contentstore . however , the asset was never found in the assetstore since an asset 's metadata is not yet stored there.(removed calls to modulestore().find_asset_metadata(asset_key ) ) the assetstore search was removed due to performance issues caused by each call unpickling the pickled and compressed course structure from the structure cache ."
exercise branching code of import
"returns a string , specified by format string , of the current date / time of the time zone ."
returns the time zone abbreviation ( e.g. est ) of the time zone for given datetime
returns the time zone offset ( e.g. -0800 ) of the time zone for given datetime
"returns a formatted display time zone ( e.g. ' asia / tokyo ( jst , utc+0900 ) ' )"
a set of assertions for an anonymous xblockuser .
a set of assertions for comparing a xblockuser to a django user
tests for convert_django_user_to_xblock_user behavior when django user is anonymoususer .
tests for convert_django_user_to_xblock_user behavior when django user is user .
tests for anonymous_user_id method to return none if user is non - staff .
tests for anonymous_user_id method to return none username does not exist in system .
tests for anonymous_user_id method returns anonymous user i d for a user .
handler url function for studio
"the use of ' zh - cn ' for ' simplified chinese ' and ' zh - tw ' for ' traditional chinese ' are now deprecated , as discussed here : https://code.djangoproject.com/ticket/18419 . the new language codes ' zh - hans ' and ' zh - hant ' are now used since django 1.7 . although majority of browsers still use the old language codes , some new browsers such as ie11 in windows 8.1 start to use the new ones , which makes the current chinese translations of edx do n't work properly under these browsers . this function can keep compatibility between the old and new language codes . if one day edx uses django 1.7 or higher , this function can be modified to support the old language codes until there are no browsers use them ."
returns a fuzzy match for lang_code
remove any language that is not either in ` ` self.released_langs ` ` or a territory of one of those languages .
check the user 's dark language setting in the session and apply it
prevent user from requesting un - released languages except by using the preview - lang query string .
test that typedfileuploadparser returns empty data and content stored in files['file ' ] .
test that typedfileuploadparser raises an exception when parsing an unsupported image format .
test that typedfileuploader allows any extension for mimetypes without specified extensions
test that typedfileuploadparser raises an exception when the specified content - type does n't match the filename extension in the content - disposition header .
"if the view does n't specify supported types , the parser rejects everything ."
stub the discovery service 's program list and detail api endpoints .
stub the discovery service 's program type list api endpoints .
use this to change the catalog integration config model during tests .
"renders the children of the module with html appropriate for studio . if can_reorder is true , then the children will be rendered to support drag and drop ."
test the rendering of the student view .
catches the signal that course pacing has changed and enable / disable the self - generated certificates according to course - pacing .
enable or disable self - generated certificates for a course according to pacing .
"listen for a learner passing a course , send cert generation task , downstream signal from course_grade_changed"
enroll the test user in the given course 's mode . use course / mode if they are provided .
makes sure that get_credit_state returns none if user_id can not be found
makes sure that get_credit_state returns none if user_id is not enrolled in the test course
makes sure that get_credit_state returns none if the user 's enrollment is inactive
makes sure that get_credit_state returns none if the test course is not credit eligible
makes sure that get_credit_state returns none if the user does not have a corresponding userprofile . this should n't happen in real environments
happy path through the service
happy path when deleting the requirement status .
try removing requirement status with a invalid user_id
assert that we can still try to update a credit status but return quickly if a course is not credit eligible
make sure we can get back the optional course name
assert that we can still try to update a credit status but return quickly if a course is not credit eligible
test that we can still try to update a credit status but return quickly if user has non - credit eligible enrollment .
try setting requirements status with a bad user_id
make sure we can pass a course_id ( string ) and get back correct results as well
create an oauth client application that is public .
create an oauth client application that is confidential .
return the set of keys provided when requesting an access token
create an oauth client application that is public .
create an oauth client application that is confidential .
return the set of keys provided when requesting an access token
send the score to the lti consumer for a single assignment .
get all the graded assignments in the system .
get all the graded assignments for the given course .
whether responses from the ecommerce api will be cached .
test for getting inner html as string from xpath node .
test for markup removal with bleach .
restore default list_display behavior .
test that instantiating configurationservice raises exception on passing a class which is not subclass of configurationmodel .
test the correct configuration on instantiating configurationservice .
enroll user in a course scoped in a site and make sure that template with tabs is overridden
make sure the site is honoring the visible_about_page permissions that is set in configuration
make sure that site overrides on the enable_shopping_cart and enable_paid_course_enrollments are honored
renders the studio preview view .
renders the children of the module with html appropriate for studio . reordering is not supported .
org display names are not implemented . this just provides api compatibility with coursedescriptor . always returns the raw ' org ' field from the key .
display numbers are not implemented . this just provides api compatibility with coursedescriptor . always returns the raw ' library ' field from the key .
enable or disable previews in studio for library children .
render javascript to override default requirejs paths .
a view that enables notifications for the authenticated user
a view that disables notifications for the authenticated user
a view that retrieves notifications status for the authenticated user .
a view that disables or re - enables notifications for a user who may not be authenticated
return ` input_str ` with pkcs#7 padding added to match aes block length
return ` input_str ` with pkcs#7 padding trimmed to match aes block length
"determine whether the user specified by the lti launch has an existing account . if not , create a new django user model and associate it with an ltiuser object ."
"generate a new user on the edx platform with a random username and password , and associates that account with the lti identity ."
"log out the current user , and log in using the edx identity associated with the lti id ."
"create a valid random edx user id . an id is at most 30 characters long , and can contain upper and lowercase letters and numbers . : return :"
"try to authenticate a user . this method will return a django user object if a user with the corresponding username exists in the database , and if a record that links that user with an lti user_id field exists in the ltiuser collection ."
return the user object for a user that has already been authenticated by this backend .
render the course 's sock fragment .
"stores the given piece of content in the cache , using its location as the key ."
retrieves the given piece of content by its location if cached .
"delete content for the given location , as well versions of the content without a run ."
determine if the request came from a crawler or not .
verify that the key supplied by the lti consumer is valid for an lti launch . this method is only concerned with the structure of the key ; whether the key is associated with a known lti consumer is checked in validate_client_key . this method signature is required by the oauthlib library .
verify that the nonce value that accompanies the oauth signature is valid . this method is concerned only with the structure of the nonce ; the validate_timestamp_and_nonce method will check that the nonce has not been used within the specified time frame . this method signature is required by the oauthlib library .
"verify that the request is not too old ( according to the timestamp ) , and that the nonce value has not been used already within the period of time in which the timestamp marks a request as valid . this method signature is required by the oauthlib library ."
"ensure that the client key supplied with the lti launch is on that has been generated by our platform , and that it has an associated client secret ."
fetch the client secret from the database . this method signature is required by the oauthlib library .
check the oauth signature on a request . this method uses the signatureendpoint class in the oauthlib library that in turn calls back to the other methods in this class .
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
unused abstract method from super class . see documentation in requestvalidator
a stub of the method that generates transactions returns : a mocktransaction object ( instead of a py2neo transaction )
"deletes all nodes associated with a course . normally ` run ` executes an arbitrary query , but in our code , we only use it to delete nodes associated with a course . args : query : query string to be executed ( in this case , to delete all nodes associated with a course )"
adds elements to the transaction 's temporary backend storage args : element : a py2neo node object
takes elements in the transaction 's temporary storage and adds them to the mock graph 's storage . throws an error if the graph 's transaction_errors param is set to true .
clears the transactions temporary storage
selects nodes that match a label and course_key args : label : the string of the label we 're selecting nodes by course_key : the string of the course key we 're selecting node by
"returns : the first element of a list if the list has elements . otherwise , none ."
creates and returns a block structure from the modulestore starting at the given root_block_usage_key .
"deserializes and returns the block structure starting at root_block_usage_key from the given store , if it 's found in the store ."
returns a new block structure for given the arguments .
test that credit requirements can not be added for non credit course .
test that credit requirements are added properly for credit course .
make sure that proctored exams are being registered as requirements
make sure that timed or inactive exams do not end up in the requirements table also practice protored exams are not a requirement
test that adding credit requirements is retried when ' invalidcreditrequirements ' exception is raised .
test ordering of proctoring blocks .
client api operation adapter / wrapper
client api operation adapter / wrapper
client api operation adapter / wrapper
client api operation adapter / wrapper
client api operation adapter / wrapper
client api operation adapter / wrapper
client api operation adapter / wrapper
returns boolean indication if organizations app is enabled on not .
decorator that makes components annotatable .
verify if we are on correct page
check if bookmarks results are present
verifies that anonymous user going to the courseware info with an unanswered survey is not redirected to survey and info page renders without server error .
set up a course for testing gated content .
setup a gating milestone for testing . gating content : seq1 ( must be fulfilled before access to seq2 ) gated content : seq2 ( requires completion of seq1 before access )
verifies access to gated content for the given user is as expected .
verifies whether or not the user has the prereq milestone
"verifies the given user 's course grade is the expected percentage . also verifies the user 's grade information contains values for all problems in the course , whether or not they are currently gated ."
"setup course , user and request for tests"
"test that changes made * after * migration , but * before * turning on new code are handled properly"
build a request object for the specified user .
return the courseserializer for the specified course .
a decorator to run a test with a configuration enabled .
a function to get a context manger to run a test with a configuration enabled .
add the course as a credit
"create a request object for the user , if specified ."
only run the decorated test in the cms test suite
only run the decorated test in the lms test suite
start cache isolation by overriding the settings . caches and flushing the cache .
end cache isolation by flushing the cache and then returning settings . caches to its original state .
clear all of the caches defined in settings . caches .
"same as django 's _ assertnumqueriescontext _ _ init _ _ , with the addition of the following argument : table_blacklist ( list ): a list of table names to filter out of the set of queries that get counted ."
"used to replace django 's assertnumqueries with the same capability , with the addition of the following argument : table_blacklist ( list ): a list of table names to filter out of the set of queries that get counted ."
"before any tests start , reset all django database connections ."
a context manager to save and restore the mako template lookup path .
add a new directory to the template lookup path .
overridden method for locating a template in either the database or the site theme .
"course id is currently of the form "" edx/999/2013_spring "" but this format could change ."
construct a url to the page within the course .
returns true if the current page is showing a tab with the given name . : return :
populate the available countries with all 2 - character iso country codes .
clear all available countries .
returns all js test suites
run the tests using karma runner .
"adds "" mode "" property to "" files "" section in configurations , if missing"
plot a one - sample confidence interval for 0d data .
plot a paired- or two - sample confidence interval for 0d data .
plot a condfidence interval .
plot a multi - mean condfidence interval .
plot an arbitrary error cloud surrounding a datum continuum .
plot mean continuum with standard deviation cloud .
plot an * * spm1d * * spm object as a line .
plot the design matrix .
plot an * * spm1d * * spm inference object as a line .
plot an * * spm1d * * spm inference object 's p values as text ( if they exist ) .
plot an * * spm1d * * spm inference object as a line .
generate random docker - like name with the given separator .
test default type .
test str type .
test int type .
test float type .
test boolean type .
test ast type .
test loading of a config without yaml anchors .
test loading of a config with yaml anchors .
test if major_vote works properly .
create three dummy models in the tmp dir .
test if ensemble model ` ` _ _ init _ _ ` ` works properly
test if ensemble model propagates all the arguments properly .
test if ensemble model aggregates the results properly .
test if ensemble model raises the exceptions as expected .
test loading of a yaml without yaml anchors .
test loading of a yaml with yaml anchors .
test yaml_to_file and yaml_to_str function .
test yaml make_simple utility function .
prettify pythonic variable name .
return the value for the given key of the multidict .
import module by name
import attribute using string reference .
checks if importerror was raised because module does not exist or something inside it raised importerror
recursive getattr .
get attribute of the object without triggering its _ _ getattr _ _ .
arguments : - ` options ` :
gets output file path by source js file
compiles js file
compress all js files into one big file .
arguments : - ` self ` : - ` jsfile ` : - ` l ` :
arguments : - ` self ` :
"read configure file which use "" .gitingore "" 's rules ."
save content to file with json format .
"stores a single nba_response , creating a table if necessary with the given data_name and primary keys ."
"stores a given list of nba responses , creating a table if necessary with the given data_name and primary keys ."
keeps all columns specified in desired_column_headers and returns the processed list of rows .
returns a new list with renamed columns . renamed columns have a nba _ prepended .
creates a table with column names and rows corresponding to the provided json responses .
returns the string representing the declaration of columns in a sqlite3 table declaration which includes . - column name - column type ( sqlite3 ) - primary key
returns a list of sqlite3 types defined by the data in the json response rows .
adds the rows to the table .
note : may modify buffer size
"note : may modify buffer size , should error if frame exists"
: param socket : : param n : : return :
reclaim buffer space before the origin .
construct a frame around the first complete message in the buffer .
dynamically create a point subclass .
create a new instance of a point subclass from a raw set of fields . the subclass chosen is determined by the given srid ; a valueerror will be raised if no such subclass can be found .
dehydrator for point data .
pushes the latest images to the repository .
tars up a directory using the normal docker.util.tar method but adds tag if it 's not none .
replace the from clause like
returns a streaming tarfile suitable for passing to docker build .
test simple use
test error classes inherit
test echo ( io )
test behavior when spawn fail
test env passing
test cwd in spawn
"n : input , m : no of nodes in hidden layer , p : no of output"
convenience method returning url pk kwarg .
"convenience method returning resource 's object model , if any ."
convenience method returning all resource 's object model objects .
sets ` self.pk ` to the requested pk sets ` self.obj ` to a retrieved resource object .
get the number of identical characters at ` string ` 's head .
"push the current line to the end , aligning it to right border of editor ."
move half a page up .
is ` string ` a python expression ?
is ` string ` a dotted name ?
is ` string ` a whitespace - less name ?
` select - more ` until reaching biggest text that satisfies ` condition ` .
select the python expression that the cursor is currently on .
"select the dotted name that the cursor is currently on , like ` foo.bar.baz ` ."
select the whitespace - less name that the cursor is currently on .
select the next scope name like ` def thing ( ): ` or ` class thing ( ): ` .
select the previous scope name like ` def thing ( ): ` or ` class thing ( ): ` .
"move , select or delete words ."
move half a page down .
initialize the all globally available constants .
acts as an interface for all commands . this is where your logic goes .
"load the cars dataset , split it into x and y , and then call the label encoder to get an integer y column ."
"load the mushroom dataset , split it into x and y , and then call the label encoder to get an integer y column ."
"load the mushroom dataset , split it into x and y , and then call the label encoder to get an integer y column ."
fit encoder according to x and y.
perform the transformation to new categorical data .
perform the inverse transformation to encoded data .
"ordinal encoding uses a single column of integers to represent the classes . an optional mapping dict can be passed in , in this case we use the knowledge that there is some true order to the classes themselves . otherwise , the classes are assumed to have no true order and integers are selected at random ."
return priority for a give object .
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
returns the lxml element for the comment @rtype : lxml element @return : the lxml element for the comment
returns the node of the element @rtype : xml element @return : the node of the element
returns the token identifier @rtype : string @return : the token identifier
returns the from attribute of the clink @rtype : string @return : the from attribute
returns the to attribute of the clink @rtype : string @return : the to attribute
set the identifier for the token @type this_id : string @param this_id : the identifier
sets the from attribute @type f : string @param f : the from attribute
sets the to attribute @type t : string @param t : the to attribute
sets the xml comment for the clink @type c : string @param c : the string comment
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
iterator that returns all the causalrelations in the layer @rtype : l{cclink } @return : list of causalrelations ( iterator )
adds a clink object to the layer @type my_clink : l{cclink } @param my_clink : the clink object to be added
removes the clink for the given clink identifier @type clink_id : string @param clink_id : the clink identifier to be removed
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
returns the term identifier @rtype : string @return : the term identifier
sets the identifier for the term @type i : string @param i : lemma identifier
returns the lemma of the object @rtype : string @return : the markable lemma
sets the lemma for the markable @type l : string @param l : lemma
returns the source attribute of the markable @rtype : string @return : the source of the markable feature
sets the source attribute @type s : string @param s : the source value
returns the span object of the markable @rtype : l{cspan } @return : the markable span
sets the span for the markable @type this_span : l{cspan } @param this_span : markable identifier
adds an external reference object to the markable @type ext_ref : l{cexternalreference } @param ext_ref : an external reference object
iterator that returns all the external references of the markable @rtype : l{cexternalreference } @return : the external references
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
converts the object to kaf ( if it is naf )
converts the object to naf ( if it is kaf )
iterator that returns single markable objects in the layer @rtype : l{cmarkable } @return : markable objects
returns the markable object for the supplied identifier @type markable_id : string @param markable_id : term identifier
adds a markable object to the layer @type markable_obj : l{cmarkable } @param markable_obj : the markable object
returns the markable object for the supplied identifier @type mark_id : string @param mark_id : term identifier
adds a markable object to the layer @type mark_obj : l{cmarkable } @param mark_obj : the markable object
adds an external reference for the given markable @type markable_id : string @param markable_id : the markable identifier @type external_ref : l{cexternalreference } @param external_ref : the external reference object
removes a list of markables from the layer @type list_term_ids : list @param list_term_ids : list of markable identifiers to be removed
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
returns the identifier of the statement element
sets the i d of the element @type this_id : string @param this_id : the resource defining statement
adds the target of the element @type starget : l{cstatement_target } @param starget : the target of the statement
retrieves the statement target @rtype : l{cstatement_target } @return : statement target
adds the source of the element @type ssource : l{cstatement_source } @param ssource : the source of the statement
retrieves the statement source @rtype : l{cstatement_source } @return : statement source
adds the cue of the element @type scue : l{cstatement_cue } @param scue : the cue of the statement
retrieves the statement cue @rtype : l{cstatement_cue } @return : statement cue
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
returns the span of the statement_target element @rtype : l{cspan } @return : span object
sets the i d of the element @type my_span : l{cspan } @param my_span : the span of the statement_target
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
returns the span of the statement_source element @rtype : l{cspan } @return : span object
sets the i d of the element @type my_span : l{cspan } @param my_span : the span of the statement_source
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
returns the span of the statement_cue element @rtype : l{cspan } @return : span object
sets the i d of the element @type my_span : l{cspan } @param my_span : the span of the statement_cue
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object @type type : string @param type : the type of the object ( kaf or naf )
iterator that returns single statement objects in the layer @rtype : l{cterm } @return : term objects
returns the statement object for the supplied identifier @type statement_id : string @param statement_id : statement identifier
adds a statement object to the layer @type statement_obj : l{cstatement } @param statement_obj : the statement object
capture stdout into dest
can we use naf.dump ( ) to stdout and file ?
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
returns the identifier of the object @rtype : string @return : the non terminal identifier
sets the identifier for the element @param this_id : identifier @type this_id : string
returns the label of the object @rtype : string @return : the label of the object
sets the label of the non terminal @param label : label @type label : string
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
returns the identifier of the object @rtype : string @return : identifier of the terminal object
returns the term span of the object @rtype : l{cspan } @return : the span object
sets the span for the terminal @type this_span : l{cspan } @param this_span : span
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
returns the from node identifier of the relation @rtype : string @return : the from node identifier of the relation
sets the from node identifier for the element @param this_from : from node identifier of the relation @type this_from : string
returns the to node identifier @rtype : string @return : the to node identifier of the relation
sets the to node identifier for the element @param this_to : to node identifier of the relation @type this_to : string
sets the edge as a head element
sets the comment for the element @type c : string @param c : comment for the element
returns whether the from is head of the constituent ( none if not ) @rtype : string @return : the head value
sets the head value for the edge element ( see also ' set_as_head ' ) @param hv : head value @type hv : string
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
iterator that returns all the non terminal objects @rtype : l{cnonterminal } @return : non terminal objects ( iterator )
iterator that returns all the terminal objects @rtype : l{cterminal } @return : terminal objects ( iterator )
returns the type of the tree @rtype : string @return : the tree type
sets the type for the tree @type t : string @param t : type for the tree
iterator that returns all the terminal objects @rtype : l{cterminal } @return : terminal objects as list
iterator that returns all the edge objects @rtype : l{cedge } @return : terminal objects ( iterator )
"appends a node to the tree , could be a terminal or non terminal or edge @param this_element : the element to be appended @type this_element : object"
"appends a node to the tree , could be a terminal or non terminal or edge @param this_element : the element to be appended @type this_element : object"
appends a node to the tree ; for non terminals @param this_nonterminal : the element to be appended @type this_nonterminal : cnonterminal object
appends a node to the tree ; for terminals @param this_terminal : the element to be appended @type this_terminal : cterminal object
appends a node to the tree ; for edges @param this_edge : the element to be appended @type this_edge : cedge object
iterator that returns all the edge objects @rtype : l{cedge } @return : terminal objects ( iterator )
constructor of the object @type node : xml element or none ( to create and empty one ) @param node : this is the node of the element . if it is none it will create a new object
iterator that returns all the tree objects @rtype : l{ctree } @return : tree objects ( iterator )
adds a tree to the constituency layer @param this_tree : the constituency tree @type this_tree : l{ctree }
this test verifies everything works properly if our logic function is decorated and the decorator passes an extra positional argument to it . this was broken in v1.1.3 as it would cause a 400 saying that ` pos_arg ` is required as a request parameter since it was not taking into accout ` omit_args ` and just determining required arguments based on the function signature 's non - keyword arguments .
"this tests that if we want to reuse a logic function with a different route , and give it a unique title that it persists . previously if you defined a title for 2 different routes using the same logic function , it would use the last defined title on both routes ."
tests handler name comes from one defined on route
tests handler names is generated from logic func name .
tests that we get the handler name from the defined heading and http methods . since post is included it infers it 's a list endpoint .
tests that we get the handler name using the logic function and also including list in the name since it contains a post method .
tests that we get the handler name using the route heading for a non list endpoint .
normalize standard devanāgari to mangled devanāgari .
converts normalized ( mangled ) devanāgari to standard devanāgari .
split by matching mss- * i d.
split text into separate verses .
"yields ( blocks , consumed ) where blocks are ( text_fragment , should_highlight ) , and consumed is the number of characters consumed in text ."
"splits text into blocks of text ; each block is ( text , should_highlight ) ."
splits text into blocks of selected and not selected .
identifier should fail with empty input .
"identifier should return no result , for input containing no syllabes ."
good anuṣṭubh should be recognized .
anuṣṭubh with first pāda wrong should be recognized .
a valid example of mandākrāntā should be recognized .
mandākrāntā with viṣama - pādānta - laghu .
a known example of āryā should be recognized .
an example of āryā that has not been explicitly added .
"test a verse that has typos , and see if correct metre can be guessed ."
"gets a list of the deployment group based on optional sorting and filtering , and constrained by start and count parameters ."
retrieves the overview details of the selected deployment group as per the selected attributes .
gets all deployment groups that match the filter .
gets a deployment group by name .
retrieve a task by its uri .
gets all the tasks based upon filters provided .
retrieves the list of registered san managers .
retrieves a single registered san manager by id or uri .
updates a registered device manager .
adds a device manager under the specified provider .
gets uri for a specific provider .
gets default connection info for a specific provider .
removes a registered san manager .
gets a san manager by name .
gets a san manager by provider display name .
get list of sas interconnects each with port details .
gets the sas interconnect with the specified id or uri .
gets all sas interconnects that match the filter .
"update powerstate , uidstate , softresetstate or hardresetstate using patch operation"
refresh a sas interconnect .
"gets information about all drive enclosures . filtering and sorting are supported with the retrieval of managed storage systems . the following storage system attributes can be used with filtering and sorting operation : name , model , serialnumber , firmware , status , manageddomain , and state ."
gets the specified drive enclosure resource by id or by uri .
gets all drive enclosures that match the filter .
use to get the drive enclosure i / o adapter port to sas interconnect port connectivity .
refreshes a drive enclosure .
"performs a specific patch operation for the given drive enclosure . if the server supports the particular operation , the operation is performed and a response is returned to the caller with the results ."
"gets a paginated collection of fcoe networks . the collection is based on optional sorting and filtering , and constrained by start and count parameters ."
deletes a fcoe network .
gets a fcoe network .
creates fcoe network .
updates a fcoe network .
gets all fcoe networks that match the filter .
uses the patch to update the given resource .
"gets a list of deployment servers based on optional sorting and filtering , and constrained by start and count parameters ."
get the details of the particular os deployment server based on its uri or id .
gets all os deployment servers that match the filter . the search is case - insensitive .
gets the os deployment server by name .
"adds a deployment server using the information provided in the request body . note : the type of the deployment server is always assigned as "" image streamer "" ."
updates the deployment server resource . the properties that are omitted ( not included as part of the request body ) are ignored .
deletes a deployment server object based on its uuid or uri .
gets a list of all the one view networks .
"gets a list of all the image streamer resources based on optional sorting and filtering , and constrained by start and count parameters ."
gets the particular image streamer resource based on its id or uri .
gets the particular image streamer resource based on its name .
build the package
build the release
build and release
upload the release files to pypi
special static method that 's automatically called by python when constructing a new instance of this class .
called while initializing this instance in _ _ new _ _
special static method that 's automatically called by python when constructing a new instance of this class .
called while initializing this instance in _ _ new _ _
display the about box for permit .
display the preferences window for permit .
signal handler for closing the permitwindow .
called when the permitwindow is closed .
only affects gui
a decorator to turn something that modifies the url a request is directed at into a request mangler .
raise an assertion if there 's no parents to return .
raise an assertion if there 's no elements to return .
assert that ` get_children_of_type ( ) ` works fine .
raise an assertion if there 's no elements to return .
raise an assertion if the elements list is invalid .
raise an assertion if the elements are n't correct .
class 's constructor .....
checks whether the given type has regions that connect it to the base data .
returns all the elements that are above a given type in the type hierarchy .
helper function for get_parents_of_type .
returns all the elements that are above a given type in the type hierarchy .
helper function for get_children_of_type .
return the appended list of a certain data hierarchy .
append element values and it 's ids to the data structure elements .
flat the elements appended to a new list of elements .
class 's constructor .
this method is called by the constructor . it will parse the input file and collect the data in intermediate data structures for later processing .
this method retrieves all the root tiers .
this method retrieves all the child tiers of a specific tier .
this method returns the primary data of the obt file .
class 's constructor .
this method is called by the constructor . it will parse the input file and collect the data in intermediate data structures for later processing .
"function to remove unwanted character(s ) from the line . to define which characters are to be removed , add them to the sanitation_tokens dictionary declared in the beginning of the module ."
this method retrieves all the root tiers .
this method retrieves all the child tiers of a specific tier .
this method retrieves all the child tiers of a specific tier .
this method returns the primary data of the mandinka file .
class 's constructor .
this method will set the variables to make possible to do the parsing correctly .
this method retrieves all the root tiers .
this method retrieves all the child tiers of a specific tier .
this method retrieves all the annotations of a specific tier .
this method gets the information about the source data file .
write the graf object into a elan file .
parse standard command - line args .
decorates a function to retry up to 5 times using an exponential backoff function .
returns true if exception is in the 4xx range .
a decorator that will catch exceptions and log the exception 's message as a critical log .
takes in a time ( in milliseconds ) and returns a formatted string . examples : 1000 - > ' 01.00 ' 100293 - > ' 01:40.29 ' 100298 - > ' 01:40.30 ' 4100298 - > ' 1:08:20.30 '
newtime and prevtime should be given in milliseconds
performs basic validation of python and installed python packages . this is a useful place to check version numbers ( for known bad packages ) and to provide nicer error messages instead of import errors .
adds a job to the queue .
"takes a job from the queue , or blocks until a job is ready to go ."
"returns a list containing references to all jobs currently in the queue . because of python gc semantics , we do n't need to worry about synchronization after the list has been constructed ."
registers a dockergrader worker thread globally . this is used so that we can check the status of all workers to see if the queue is stuck .
"returns debugging information for a worker , given its number ."
returns debugging information for all registered workers .
retrieves the commit hash of a branch .
"retrieves a commit message , given a repository name and a commit hash . the commit hash should be the unabbreviated hash ."
gets a list of files that have changed between base_hash .. head_hash in the particular repo .
downloads a repository to a local directory . returns whether the download was successful .
"( private method , use the repomanager instead ) creates the repository and adds the members as contributors , idempotently ."
enqueues an email to be sent on the background thread . see docstring for create_email for arguments .
prepares an email to be sent by the email queue background thread . templates are taken from templates/*.html and templates/*.txt . both a html and a plain text template is expected to be present . parameters should be passed as keyword arguments to this function .
"sets the global web application ` app ` , for use in generating external web urls for email templates . we can not import this directly , because it creates a cyclic dependency ."
connects to the configured smtp server using connect_to_smtp defined in config / algorithms and sends an email .
this test is actually kind of dumb and useless ...
converts xml tree to event generator
converts events stream into lxml tree
parses file content into events stream
selects sub - tree events
merges each run of successive text events into one text event
locates enter peer for each exit object . convenient when selectively filtering out xml markup
extracts text content from event stream
"a quick way jump from one pointer to another . starting from start address , reading the pointer at ( start + l[0 ] ) , and then reads the pointer at the last result + l[1 ] and so on . the verbose option would print all of the pointers including the starting address . the islookingforcycles option would alert the user in case one pointer is read more than once during the offsets walk ."
"display memory as qwords tabls , does not return anything"
"display memory as dwords tabls , does not return anything"
"display memory as words tabls , does not return anything"
"display memory as bytes tabls , does not return anything"
same as parse ( ) but you pass in an environment variable name that will be used to fetch the dsn
"same as parse_environ ( ) but will also check name_1 , name_2 , ... , name_n and return all the found dsn strings from the environment"
parse a dsn to parts similar to parseurl
"the scheme , split by plus signs"
return username : password@hostname : port
the path attribute split by /
"the hostname , but i like host better"
alias for username to match psycopg2
alias for password to match postgres dsn
return host : port
alternative name for the fragment
set a default value for key
return the dsn back into url form
a full - state static feedback control design solver for which the following quadratic cost function is integrated ( summed ) over all positive time axis : :
convert the output of str(document ) to the format used in the testcases
"if the current heading is a test section heading return the heading , otherwise return false"
"render a r0 - 3 belt , a r0 - 2 partial belt ( plus optionally a r3 event ) , or an all - block ( with or without r3 ) format ."
render a complex format that contains a multi - row r3 event .
validate user for saving later .
arrange an html node for comparison .
convert a queryset to list .
convert a queryset to a ` collections . counter ` .
decorator that performs basic comparisons for a diff tag .
generate a schedule to prevent the schedule page from returning 404 .
test to make sure all in - site links in a content page work .
"we only has one field , so let 's make it available without keyword ."
limit times to those in the current conference 's time .
"we almost always need the proposal info , so let 's always join it ."
@param name : the attribute 's name with i{optional } namespace prefix . @type name : basestring @param value : the attribute 's value @type value : basestring
clone this object . @param parent : the parent for the clone . @type parent : l{element . element } @return : a copy of this object assigned to the new parent . @rtype : l{attribute }
get the b{fully } qualified name of this attribute @return : the fully qualified name . @rtype : basestring
set the attributes value @param value : the new value ( may be none ) @type value : basestring @return : self @rtype : l{attribute }
"get the attributes value with optional default . @param default : an optional value to be return when the attribute 's has not been set . @type default : basestring @return : the attribute 's value , or i{default } @rtype : l{text }"
get whether the attribute has i{text } and that it is not an empty ( zero length ) string . @return : true when has i{text } . @rtype : boolean
"get the attributes namespace . this may either be the namespace defined by an optional prefix , or its parent 's namespace . @return : the attribute 's namespace @rtype : ( i{prefix } , i{name } )"
"resolve the specified prefix to a known namespace . @param prefix : a declared prefix @type prefix : basestring @return : the namespace that has been mapped to i{prefix } @rtype : ( i{prefix } , i{name } )"
"match by ( optional ) name and/or ( optional ) namespace . @param name : the optional attribute tag name . @type name : str @param ns : an optional namespace . @type ns : ( i{prefix } , i{name } ) @return : true if matched . @rtype : boolean"
get a string representation
get an xml string representation
function to find out which function is the caller of the current function .
log an info message
log an error message
log a debug message
display message in the screen
display message in the screen
log an error
creates a new instance of the operadriver .
codec support read / write excel file 97 - 2003 ( xls )
return cell value according the column and row i d
return column value
return row value
create a new excellfile object
add a new row into the workbook with a row i d defined
save the current workbook
"split the name into a tuple ( i{prefix } , i{name } ) . the first element in the tuple is i{none } when the name does not have a prefix . @param name : a node name containing an optional prefix . @type name : basestring @return : a tuple containing the ( 2 ) parts of i{name } @rtype : ( i{prefix } , i{name } )"
"@param url : the url for the wsdl . @type url : str @param kwargs : keyword arguments . @keyword faults : raise faults raised by server ( default : true ) , else return tuple from service method invocation as ( http code , object ) . @type faults : boolean @keyword proxy : an http proxy to be specified on requests ( default : { } ) . the proxy is defined as { protocol : proxy , } @type proxy : dict"
"get an instance of a wsdl type by name @param name : the name of a type defined in the wsdl . @type name : str @return : an instance on success , else none @rtype : l{sudsobject . object }"
"get an instance of an enumeration defined in the wsdl by name . @param name : the name of a enumeration defined in the wsdl . @type name : str @return : an instance on success , else none @rtype : l{sudsobject . object }"
construct a template for a gui event
construct a template for a sip packet
returns a template for sip request
returns a template for sip status response
construct a template for a sip phone event
add tabulation for each lines
returns the current backtrace .
returns current timestamp ( yyyy - mm - dd hh - mm - ss . sss )
construct a template for socket generic error
construct a template for starting
construct a template for sniffing
construct a template for sniffing failed
construct a template for ethernet stopping
construct a template for ethenert stopped
construct a template for stopping failed
construct a template for a ethernet packet
function to find out which function is the caller of the current function .
returns the singleton
destruction of the singleton
class db manager mysql is only supported
"make a sql query , a new connection made each time ."
should be nice but not yet implemented
should be nice but not yet implemented
try to connect to the database detect the version of the mysql server
return the mysql version
"get a reference that is i{qualified } by namespace . @param ref : a referenced schema type name . @type ref : str @param resolvers : a list of objects to be used to resolve types . @type resolvers : [ l{sax.element . element } , ] @param defns : an optional target namespace used to qualify references when no prefix is specified . @type defns : a default namespace i{tuple : ( prefix , uri ) } used when ref not prefixed . @return : a qualified reference . @rtype : ( name , namespace - uri )"
get whether the object is a i{qualified reference } . @param object : an object to be tested . @type object : i{any } @rtype : boolean @see : l{qualify }
new in v17 public decorator for documentation
return default version
return generic version
set as deprecated
function to find out which function is the caller of the current function .
return default version
return generic version
all libraries must inherent from this class
return the from level
accessor to the testcase
display an info message
display an error message
trace message nothing is displayed if txt = none
display an debug message
display an debug message
"on reset , called automatically by framework function to overwrite"
remove invalid xml
"bytes 2 str conversion , only for python3"
"this class describes the model of one script document , and provides a xml < = > python encoder the following xml : < ? xml version=""1.0 "" encoding=""utf-8 "" ? > < file > < properties "" > < descriptions > < description > < key > author</key > < value> ... </value > < /description > < description > < key > creation date</key > < value> ... </value > < /description > < description > < key > summary</key > < value> ... </value > < /description > < /descriptions > < parameters > < parameter > < name> ... </name > < type> ... </type > < description> ... </description > < value> ... </value > < /parameter > < /parameters > < /properties > < testdata> ... </testdata > < /file >"
python data to xml
fix encodage not pretty ....
fix encodage not pretty ....
set test data
called on data model loading
wav file container
set raw data
returns raw data
@param filename : @type filename :
translate using the schema type
construct a template for a icmp packet
construct a template for catalyst
construct a template for a prompt event
construct a template for a prompt event
construct a template for a prompt event
construct a template for a password prompt event
construct a template for a username prompt event
construct a template for a bad username event
construct a template for a bad username event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
construct a template for a catalyst event
"get the document root . for i{rpc/(literal|encoded ) } , this is the name of the method qualified by the schema tns . @param method : a service method . @type method : i{service . method } @return : a root element . @rtype : l{element }"
get the appropriate schema based xml decoder . @return : typed unmarshaller . @rtype : l{umxtyped }
returns the singleton
destruction of the singleton
construct agent server interface
called on ws handshake successful
search and return a specific agent by the name
returns all registered agents
called on connection
reimplemented from serveragent
called on notify
called on the registration of a new agents
reimplemented from serveragent
creates a new actionchains .
performs all stored actions .
clears actions that are already stored on the remote end .
clicks an element .
holds down the left mouse button on an element .
performs a context - click ( right click ) on an element .
double - clicks an element .
"holds down the left mouse button on the source element , then moves to the target element and releases the mouse button ."
"holds down the left mouse button on the source element , then moves to the target offset and releases the mouse button ."
"sends a key press only , without releasing it . should only be used with modifier keys ( control , alt and shift ) ."
releases a modifier key .
moving the mouse to the middle of an element .
move the mouse by an offset of the specified element . offsets are relative to the top - left corner of the element .
releasing a held mouse button on an element .
sends keys to current focused element .
sends keys to an element .
returns the location of the binary otherwise an empty string
allows you to set where the chromium binary lives
returns the address of the remote devtools instance
allows you to set the address of the remote devtools instance that the chromedriver instance will try to connect to during an active wait .
returns a list of arguments needed for the browser
adds an argument to the list
returns a list of encoded extensions that will be loaded into chrome
adds the path to the extension to a list that will be used to extract it to the chromedriver
adds base64 encoded string with extension data to a list that will be used to extract it to the chromedriver
returns a dictionary of experimental options for chrome .
adds an experimental option which is passed to chrome .
creates a capabilities with all the options that have been set and
@return : @rtype :
@return : @rtype :
"new in 1.2.0 , to fix issue 9"
"set value and write to file be careful , comments are removed with this function"
returns the singleton
destruction of the singleton
"rfc 6455 , minimal support"
returns id for ping requet
create sec - websocket - key
create sec - websocket - accept value
return x - forwarded - for header
checking headers on request
decode ws message
encode ws message
encode a binary message
encode a text message
encode a ping message
encode a pong message
closes the browser and shuts down the
get cap file format by magic num . return file format and the first byte of string : type infile : file
"read tcp data.http only build on tcp , so we do not need to support other protocols ."
"read udp only build on tcp , so we do not need to support other protocols ."
decode ipv4 packet
parse ethernet packet
parse linux sll packet
test upload / download / cache operations with two users
generate a manager from a manager_config dictionary
generate a service from a service_config dictionary
creates a mongodb instance and shuts it down after testing has concluded .
drops the db and shuts down the mongodb instance .
get and set log level of a given logger .
alias for logging.getlogger(name )
returns a dictionary of contextual information about the user at the time of logging .
initialize the api loggers .
store record into the db .
store record into the db .
do n't excessively emit the same message .
should return a json error message when url not found
should return a list of supported networks when calling /networks
should return a list of profiles when present in db for a given network
should return profile when found in db
should return 202 and enqueue job when profile not found in db
marks all objects as viewed for viewtracker . post to this view and all objects will be marked as viewed .
marks all objects of a particular type as viewed for viewtracker . post to this view and all objects of that type will be marked as viewed .
default class constructor . update as you need .
print a list of n hits from google
return the name that identifies the ratings source
return the base currency to which the rates are referred
return a dictionary that maps currency code with its rate value
creates or updates rates for a source
"in template : { { active(""namespace(optional):name "" ) } } for further usage , if you need something more specific , remember to parse all kwargs here ."
remove meza debugging statements
"returns 0 on success , 1 on failure"
qif constructor args : mapping ( dict ): bank mapper ( see csv2ofx.mappings ) kwargs ( dict ): keyword arguments
get the qif header
gets qif transaction data
gets qif format account content
gets qif format transaction content
gets qif format split content
gets qif transaction end
gets qif transaction footer .
generate the qif body
generate the qif groups
send a simple create_session
reboot with valid claim_previous
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh followed by getfh should end up with original fh
putfh with bad filehandle should return nfs4err_badhandle
open_confirm done twice in a row should return nfs4err_bad_stateid
openconfirm should fail with nfs4err_nofilehandle if no ( cfh )
open_confirm with a bad seqid should return nfs4err_bad_seqid
open_confirm with a bad state should return nfs4err_bad_stateid
open_confirm with a stale state should return nfs4err_stale_stateid
get a new unique i d. these are used only internally for printing
generate the opaque part of device_addr4 used by nfs4.1 .
recursively scan for all devices in tree .
returns filled ( and unpacked ) pnfs_block_volume4 structure .
map a byte offset to the corresponding simple volume and byte offset .
"same as resolve , with addition of how far mapping extends ."
write out disk signature to open fd .
"since this is always a leaf node of tree , end recursive scan ."
0 1 2 3 4 5 6 7 8 global_stripe_number | | | | | | | | | | | | | | | | | | 0 1 2 local_stripe_number 0 1 2 0 1 2 0 1 2 disk_number
"as of ospfv2 , sequence numbers should simply be treated as signed integers ranging from the oldest sequence number possible 0x80000001 ( -n+1 in decimal ) to the highest 0x7fffffff ( n-1 in decimal ) ."
return whether the lsa is too old to be considered valid
builds an lsa from the extracted lsa info
give the list of endpoint ips / router - id for that link : param graph : a igpgraph of the network : param lsdb : an lsdb instance in order to resolve e.g. routerid or interface ips : return : list of ips or router - id
create a new lsa based on the property dicts given : param lsa_header : an lsaheader instance : param lsa_prop : a property dictionary : return : a new lsa instance
what is the unique key identifying this lsa among all other lsa of that type : return : key
"apply this lsa on the graph , thus adding links / node as needed : param graph : the graph to manipulate : param lsdb : the lsdb instance that can be used to retrieve information from other lsas"
"this test ensures that we can build an ipvxnetwork from another one . if this breaks , need to grep through for ip_network calls as i removed the checks when instantiating these ... test passing with py2 - ipaddress ( 3.4.1 )"
ensures that a command is available in $ path : param cmd : the command to test : param help_str : an optional help string to display if cmd is not found
ensures that the program is run as root
sleep some time after executing the function : param amount : the amount of seconds to wait : return : the return value of the function
"force the execution of function and log any exception : param f : the function to execute : param args : its arguments : param kwargs : its kw - arguments : return : the return value of f is any , or none"
should n't be used except for debugging purpose ( e.g. find deadlocks )
extract a pid from a file : param n : path to a file : return : pid as a string
"return and iterator on a new set of paths , built by copying the original paths and appending a new node at the end of it"
return whether x is a container (= iterable but not a string )
flatten a list of list in a new one
build a daemon thread
create a daemon thread and start it
: param i d : the identifier for this node : param prefix : the namespace prefix
: return : the next available port number on this node
associate the given port to this node : param port : the port object to register
remove the given port from this device : param port : a port object
execute a command on this node
execute a command on this node and return an object that has communicate ( ) available for use with stdin / stdout
wrapper around the brctl command
disable and delete this bridge
": param i d : router i d , set automatically if none : param namespaced : run the router in a new network namespace ?"
: return : nsname : port | port | port
startup this router processes
add physical ports to its assigned ports : param link : a physicallink to ' the outside world '
return the list of forwarding address from src to dst
create a configuration node reflecting the router : param router : the router object to analyze
draw this graph to dest
return the list of edges that other does not have wrt . this graph
add a controller node to the graph
add a router node to the graph
add routes to the graph
add a fake prefix node to the graph
add a fake local route available for specified targets
return whether n is a router or not
return whether n is a controller or not
return whether n is a prefix or not
return wether a given edge is a link between two routers
"return whether edge _ , v is a route"
"return whether u , v is an edge mapping to a real lsa"
"return whether edge u , v is a route from a fake lsa"
"return wether u , v is a global lie"
"return wether u , v is a local lie , optionally check if it applies to the given target(s )"
return the target node(s ) as a list for that local lies
returns a generator over all routers in the graph example : all_routers = list(graph.routers )
returns a generator over all controllers in the graph example : all_controllers = list(graph.controllers )
returns a generator over all prefixes in the graph
returns a generator over all routes in the graph
returns a generator over all real routes in the graph
returns a generator over all fake routes in the graph
"returns a generator over all local lies in the graph , possibly return the target neighbours of it ."
returns a generator over all global lies in the graph
return a generator over all intra - router links
"return the link metric for link u->v , or set it if m is not none"
contract nodes from nbunch into a single node named into
return the exportable properties of an edge
"return a generator yielding a 3 - tuple for all edges : src , dst , exportable properties"
list the real ( non dest ) nodes in this graph
"define the edge multiplicity , typically to encode splitting ratios in the graph ."
"return the multiplicity of the edge u , v"
compute the actual used paths due to fibbing . ! the router to which a fake edge is attached does not use it
"return the path , as seen by the routers , between u and v , or a dictionary of all shortest - paths starting at u if v is none"
"return the cost of the fibbed path between u and v , or a dict of cost of all shortest - paths starting at u"
"return the paths of the pure igp shortest path if fibbing was not in use on the current network , between u an v or a dict of paths if v is none"
"return the cost of the pure igp shortest path if fibbing was not in use on the current network , between u and v or a dict of cost if v is none"
view showing flicket main page . we use this to display some statistics .
": param action : string ' assign ' , ' unassign ' , ' close ' , ' claim ' , ' release ' : param ticket : ticket object : param post : post object : param user : user object : return :"
indents input with ' > ' . used for quoting text in posts . : param foo : : return :
"with untyped s , return dicts ."
"with typed s , return objects of type ."
"with values_dict , return list of dicts ."
"with values_dict , return list of dicts ."
specifying no fields with values_list returns what 's stored .
"with values_list fields , returns list of tuples ."
test default results form has metadata .
test default results form has metadata .
test default results form has metadata .
calling values_dict ( ) with no args fetches all fields .
calling values_list ( ) with no args fetches all fields .
datetime strings in es results get converted to python datetimes
datetime strings in es results get converted to python datetimes
creates entry instances of multiple items and returns an entry - list .
retorna o objeto da classe categoriafilme
recebe um objeto da classe categoriafilme
"xref type , flags excluded ."
"xref flags , type excluded ."
name of the xref type .
do a uniform latin hypercube sampling
create a rawd3plot file object
get the names of the raw data fields
get a variable from its name
save the raw d3plot to hdf5
check if a file is a hdf5 file
"load a d3plot , which was saved as an hdf5 file"
returns a proxy back to the user .
removes the given proxy from the proxyselector .
static method to check if the given proxy is valid .
check if the given address is valid ipv4 .
returns a user - agent to the user .
append items from the given list to self._user_agent_list .
retrieves a list of user - agents from the internet .
3d error in mm
compel gt data to have mean joint length of one
build 3d model
build model and rotate according to the identified rotation matrix
upgrades complex parameterisation of planar rotation to tensor containing per frame 3x3 rotation matrices
center data according to each of the coordiante components
center all data
normalise data according to height
transform the set of joints according to what the probabilistic model expects as input .
"quick switch to allow reconstruction at unknown scale returns a , r and scale"
"quick switch to allow reconstruction at unknown scale returns a , r and scale"
reconstruct 3d pose given a 2d pose
reconstruct 3d poses given 2d estimations
draw the 2d pose without the occluded / not visible joints .
plot the 3d pose showing the joint connections .
defines the vgg arg scope .
oxford net vgg 11 - layers version a example .
oxford net vgg 16 - layers version d example .
oxford net vgg 19 - layers version e example .
sobrepõe : meth:`~satcfe.base . funcoessat.ativar_sat ` .
sobrepõe : meth:`~satcfe.base . funcoessat.comunicar_certificado_icpbrasil ` .
sobrepõe : meth:`~satcfe.base . funcoessat.enviar_dados_venda ` .
sobrepõe : meth:`~satcfe.base . funcoessat.cancelar_ultima_venda ` .
sobrepõe : meth:`~satcfe.base . funcoessat.consultar_sat ` .
sobrepõe : meth:`~satcfe.base . funcoessat.teste_fim_a_fim ` .
sobrepõe : meth:`~satcfe.base . funcoessat.consultar_status_operacional ` .
sobrepõe : meth:`~satcfe.base . funcoessat.consultar_numero_sessao ` .
sobrepõe : meth:`~satcfe.base . funcoessat.configurar_interface_de_rede ` .
sobrepõe : meth:`~satcfe.base . funcoessat.associar_assinatura ` .
sobrepõe : meth:`~satcfe.base . funcoessat.atualizar_software_sat ` .
sobrepõe : meth:`~satcfe.base . funcoessat.extrair_logs ` .
sobrepõe : meth:`~satcfe.base . funcoessat.bloquear_sat ` .
sobrepõe : meth:`~satcfe.base . funcoessat.desbloquear_sat ` .
sobrepõe : meth:`~satcfe.base . funcoessat.trocar_codigo_de_ativacao ` .
populates the cmdset
populates the cmdset
populates the cmdset
"this is the only method defined in a cmdset , called during its creation . it should populate the set with command instances ."
return a config as a dictionary
"write our image to a temp file , then give it back to the user"
initialise assets on the app .
should return none if no files to combine .
output cube should only include flow for input ids .
output cube should return -9999.0 for masked values .
output cube should concatenate dates in input .
identifies files for the most recent complete simulation .
identifies files for the most recent complete simulation .
"returns a pair of the "" child "" content of minidom_node : the first element of the pair is a concatenation of the text content the second element is a list of non - text nodes ."
builds a dictionary from the dom element x the function uses as hacky splitting of attribute or tag names using { } to remove namespaces . returns a pair of : the tag of ` x ` and the honeybadgerfish representation of the subelements of x indirect recursion through _ hbf_handle_child_elements
indirect recursion through _ gen_hbf_el
checks if the minidom_meta_element can be represented as a key / value pair in a object .
we still have some un - prefixed ids ( at least on the devapi )
"returns a tuple : the boolean for whether or not pushes succeed , and the entire object returned by a call to push_failure on the phylesystem - api . this should only be called with wrappers around remote services ( runtimeerror will be raised if you call this with a local wrapper ."
"syntactic sugar around to make it easier to get fine - grained access to the parts of a file without composing a phyloschema object . possible invocations include : w.get('pg_10 ' ) w.get('pg_10 ' , ' trees ' ) w.get('pg_10 ' , ' trees ' , format='nexus ' ) w.get('pg_10 ' , tree_id='tree3 ' ) see :"
returns a list of strings which are the collection ids
returns a list of strings which are the collection ids
"load charge density in a plane , in the format used by lev00"
initialise the nowplaying file with a filename .
overwrite the nowplaying file with an empty file
overwrite the nowplaying file with a string
high level command handling
request resend of current line
of older command that we 've previously acked . tricky
support instance methods .
template function of public api
get latest information of coincheck market
get latest deal history of coincheck market
get latest asks / bids information of coincheck market
execute import .
"save final status , results , etc ."
send user notifications this task has finished .
post parm : ( stringify json ) payload ( string ) response_data ( int ) module_id : return : none
: param message : chrome request object : return :
parse command line arguments
return a prototype scanner instance for scanning latex source files
add builders and construction variables for pdflatex to an environment .
the input parameters describe a option with only certain values allowed . they are returned with an appropriate converter and validator appended . the result is usable for input to options . add ( ) .
add a builder factory function and construction variables for sccs to an environment .
add builders and construction variables for ilink to an environment .
"the input parameters describe a ' path list ' option , thus they are returned with the correct converter and validator appended . the result is usable for input to opts . add ( ) ."
test booloption creation
test the booloption converter
test the booloption validator
create and return lists of java rmi stub and skeleton class files to be created from a set of class files .
"parses the extended package syntax and returns a tuple of ( package , hash , version , tag ) ."
read a file into a string pre : fname is a small file ( to avoid hogging memory and its discontents )
compress a string . same as gzip.compress in python3 .
child directories ( non - recursive )
child files ( non - recursive )
check if string could be a valid python identifier
check if string could be a valid node name
makes a python identifier ( perhaps an ugly one ) out of any string .
makes a quilt node name ( perhaps an ugly one ) out of any string .
read bytes and update the progress bar .
read the next line and update the progress bar .
get the file position .
set the new file position .
close the file .
"digest files using sha-2 ( 256 - bit ) testing produces identical output to ` openssl sha256 file ` for the following : * on all source .py files and some binary pyc files in parent dir * empty files with different names * 3.3 gb dnase hypersensitive file * empty file , file with one space , file with one return all produce * distinct output perf takes about 20 seconds to hash 3.3 gb file on an empty file and on build.py inspiration : http://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file warning : not clear if we need to pad file bytes for proper cryptographic hashing"
only exists to make it easier for subclasses to customize ` _ _ repr _ _ ` .
returns the contents of the node : a dataframe or a file path .
every child key referencing a dataframe
every child key referencing a group that is not a dataframe
keys directly accessible on this object via getattr or .
create and set a node by path
handle raw input .
reloads gunicorn . this must be done to re - compile the code after a new revision has been checked out .
"given some feature vector , predict ( down to a certain maximum depth if specified ) and draw a heatmap of the 2d results"
actually plot the heatmap
parse the contents of the ` ~io . iobase.readline`-supporting file - like object ` ` fp ` ` as a simple line - oriented ` ` .properties ` ` file and return a ` dict ` of the key - value pairs .
parse the contents of the string ` ` s ` ` as a simple line - oriented ` ` .properties ` ` file and return a ` dict ` of the key - value pairs .
"parse the contents of the ` ~io . iobase.readline`-supporting file - like object ` ` fp ` ` as a simple line - oriented ` ` .properties ` ` file and return a generator of ` ` ( key , value , original_lines ) ` ` triples for every entry in ` ` fp ` ` ( including duplicate keys ) in order of occurrence . the third element of each triple is the concatenation of the unmodified lines in ` ` fp ` ` ( including trailing newlines ) from which the key and value were extracted . the generator also includes comments and blank / all - whitespace lines found in ` ` fp ` ` , one triple per line , with the first two elements of the triples set to ` none ` . this is the only way to extract comments from a ` ` .properties ` ` file with this library ."
decode escape sequences in a ` ` .properties ` ` key or value . the following escape sequences are recognized : :
"write data rows to a given file , separated by some delimiter ."
read a data file as a delimited table of numbers and/or strings .
"coerce a list of strings to a list of numeric types , and return ( coerced_values , coerced_types ) ."
return whether the data is likely to include a header row .
"return a ( header , data ) tuple , where ' header ' is none if the file does not have a header row ."
write the data out to a file with the specified delimiter and newline characters .
backport of ` ` socket.makefile ` ` from python 3.5 .
this function is unimplemented
helper for the image.show method .
get the tkinter photo image identifier . this method is automatically called by tkinter whenever a photoimage object is passed to a tkinter method .
get the width of the image .
get the height of the image .
paste a pil image into the photo image . note that this can be very slow if the photo image is displayed .
get the tkinter bitmap image identifier . this method is automatically called by tkinter whenever a bitmapimage object is passed to a tkinter method .
shortcuts for generating request headers .
"if a position is provided , move file to that point . otherwise , we 'll attempt to record a position for future use ."
attempt to rewind body to a certain position . primarily used for request redirects and retries .
"ping 3 次输入的ip , 3次操作超过3s超时中断，返回无穷大 返回 3 次 ping 的平均值"
"parse the jpeg 2000 codestream to extract the size and component count from the siz marker segment , returning a pil ( size , mode ) tuple ."
"parse the jp2 header box to extract size , component count and color space information , returning a pil ( size , mode ) tuple ."
"adds a ( name , value ) pair , does n't overwrite the value if it already exists ."
generic import function for any type of header - like object . adapted version of mutablemapping.update in order to insert items with self.add instead of self.__setitem _ _
returns a list of all the values for the named field . returns an empty list if the key does n't exist .
"iterate over all header lines , including duplicate ones ."
"iterate over all headers , merging duplicate ones together ."
read headers from a python 2 httplib message object .
": param tag : integer tag number : returns : taginfo namedtuple , from the tags_v2 info if possible , otherwise just populating the value and name from tags . if the tag is not recognized , "" unknown "" is returned for the name"
load texture from a gd image file .
reset the internal data .
add data to this qr code .
compile the data into a qr code array .
find the minimum size required to fit in the data .
find the most efficient mask pattern .
output the qr code only using tty colors .
output the qr code using ascii characters .
make an image from the qr code data .
"return the qr code as a multidimensonal array , including the border ."
return whether dirpath refers to a library .
find library .
initialize library .
get the path of a resource for a library .
this tests for a bug where a non - existant timestamp is used to create a unix timestamp ( from none ) and throws an exception .
this tests for a bug where titles were not stripped of html despite a cleaner being supplied to speedparser .
this tests for a bug in 0.1.6 where the strip_outer_tag function would be called on none and raise an exception .
"this is a placeholder test . lxml punts because the title trips an unrecoverable parser error , and we have no way of cleaning it . this would be a big issue , but feedparser apparently can not figure this out either as it breaks saxparser ."
stop the server
"parse a series of distribution specs of the form : { project_name}-{version } [ optional , indented requirements specification ]"
"build a minimal egg - info , enough to invoke egg_info"
gather command - line arguments .
returns subset of os.walk
gather command - line arguments .
svm_load_model(model_file_name ) - > model
"svm_save_model(model_file_name , model ) - > none"
"svm_train(y , x [ , ' options ' ] ) - > model | acc | mse svm_train(prob , [ , ' options ' ] ) - > model | acc | mse svm_train(prob , param ) - > model | acc| mse"
"svm_predict(y , x , m [ , "" options "" ] ) - > ( p_labels , p_acc , p_vals )"
tests get_pointee_address on host ctypes pointer and haystack pointer
returns the offset of a member fields in a record
"from a pointer to a member , returns the parent struct"
array to bytes
bytes to ctypes array
tests home made xrange that handles big ints . not an issue in py 3
test the case where a commit includes changes to .hgtags and other files
"tests that tags not containing a "" . "" are ignored , the same as for git . note that will be superceded by the fix for pypa / setuptools_scm / issues/235"
generates config .
a helper function to validate that the project is either under a folder or under an organization and not both
generates a container manifest given a template context .
generate the yaml config for a pool of instances .
helper method to create the config for a single compute instance .
helper method to create a boot disk property .
helper method to create a network config .
generates config .
generate yaml resource configuration .
generate template config based on python objects .
trigger a new value if appropriate
"x : 2d array , [ n_samples , n_features ] y : 1d array , [ n_samples ] . class for each sample"
: param p : file to backup : param backupdir : directory to add backed up file : param kw : keyword args for unique_date_path : return :
"uses glob root : directory to list extension : only return files of this file type e.g .txt or txt extension can be list , tuple or str"
make a unique path with the a timestamp appended e.g foo_11 - 01 - 2012 - 001
unique_path suffers from the fact that it starts at 001 . this is a problem for log files because the logs are periodically archived which means low paths are removed .
: param root : : param base : : param extension : : return : int max+1
p : absolute path delimiter : str cast : callable . applied to each delimited field
p : absolute path to file
f : file - like object return list
return a valid file path ` ` p ` ` where ` ` p ` ` = = root / name.extension
"rid : str . typical runid e.g 12345 , 12345 - 01 , 12345 - 01a"
rid : str . e.g 12345
rid : str . e.g 12345 - 01 or 12345 - 01a only revert this specific analysis
the high nibble of the command sequence indicates the number of data bits to follow
"gets all dock widgets in left - to - right , top - to - bottom order ."
create and set the toolkit - specific control that represents the pane .
removes an editor from the pane .
wait for completion of all the tasks in the queue
age in years : param age : : param r : : return : linear error propagation age error in years
": param ds : list of 3 - tuples ( power , start , end ) : return :"
"return a list of 3 - tuples ( power , start , end ) : return :"
is mswd acceptable based on mahon 1996
press et . al 2007 numerical recipes chi2 = sum((y_i-(a+b*x_i)^2*w_i ) where w_i=1/(sy_i^2+(b*sx_i)^2 )
"see murray 1994 , press 2007"
f : value to format n : number of sig figs
this method for calculating the x intercept error is incorrect . the current solution is to swap xs and ys and calculate the y intercept error
recursively calculate slope b = slope a = intercept
a = y - bx
"use a crc32 to generate a hash for this set of pr ratio values . pack each value as a binary single , concat , then calculate : param vs : : return :"
return true if connection to dest made
correct for sense of camera
initialize the mftable
convert a dac value ( voltage ) to mass for a given detector use the mftable
convert a mass value from amu to dac for a given detector
convert a dac voltage to isotope name for a given detector
set the self.mass attribute suppress mass change handler
http://stackoverflow.com/questions/8392640/how-to-implement-a-lock-with-a-timeout-in-python-2-7 @param timeout : @return :
return nshots vs 40/36
"min at dy=0 ( ax2+bx+c)dx = dy==2ax+b 2ax+b=0 , x=-b/(2a )"
"pts = list of points xy = list of corresponding x , y tuples"
"calculate pt ( x , y ) that is l units from x1 , y1"
"r1 = x , y p1 in frame 1 ( data space ) r2 = x , y p2 in frame 1 r1 = x , y p1 in frame 2 ( screen space ) r2 = x , y p2 in frame 2"
"given p1 , p2 of an arc with radius r find the center cx , cy of the arc"
weight by angle between p0 - p1 .
"given a list of polygon vertices and a known radius approximate the center of the polygon using the mean of xs , ys where xs , ys are the arc centers for different arc segments of the polygon"
this is the ideal solution however it does nt work as well as approximage_polygon_center when there are outliers
return the input required to produce the requested response
"use the model object for the traits ui context , if appropriate ."
dets : list of detector instances
adds the handle_uncaught_exception decorator to all methods of the class
"this method implements text to speech using the flite tts . flite tts is completely offline . usage of flite is recommended if good internet connection is not available "" : param text : text which is needed to be spoken : return : none"
"this method implements text to speech using the ibm watson tts . to use this , set username and password parameters in config file . : param text : text which is needed to be spoken : return : none"
this method implements text to speech using the google translate tts . it uses google speech python package . : param text : text which is needed to be spoken : return : none
"executed on the entry to the recognizing state . upon entry , audio is captured from the microphone and recognition with preferred speech recognition engine is done . if successful , the machine transitions to busy state . on failure , it transitions to error state . : param payload : no payload is expected by this state : return : none"
method to executed upon exit from recognizing state . : return :
"this method is executed on entry to busy state . susi api is called via susi python library to fetch the result . we then call tts to speak the reply . if successful , we transition to idle state else to the error state . : param payload : query to be asked to susi : return : none"
method executed on exit from the busy state .
perform an http get request for a given url . returns the response object .
perform an http post request for a given url . returns the response object .
perform an http put request for a given url . returns the response object .
perform an http delete request for a given url . returns the response object .
dumps biclusterings to a file using the json module .
load biclusterings from a json file .
compute biclustering .
generates a initial bicluster based on the results of several k - means runs over the matrix of residuals .
creates a new layer .
computes k - means with k = 2 to find the initial components ( rows or columns ) of a new layer / bicluster .
fits a new layer .
prune rows and columns from the layer / bicluster being computed .
tests a layer for significance .
performs back fitting steps .
compute biclustering .
finds the column subset for which the correlation between ri and rj stands above the correlation threshold .
finds the column which deletion causes the maximum increase in the correlation value between ri and rj
checks if row r satisfies the correlation threshold .
calculates the pearson correlation and returns its absolute value .
checks if a bicluster has already been found .
change a cartpole environment using a different length and/or masspole .
make environments using a list of descriptions .
make n_envs random environments of the env_name class .
instantiates an instance of the environment with appropriate kwargs
get the actions for a batch of states .
get the action for a single state .
get the actions for a batch of states using the target actor network .
choose an action based on the actor and exploration noise .
run the appropriate learning algorithm .
learn using updates like in the reinforce algorithm .
learn using updates like in the karpathy algorithm .
"when a ( sigint ) signal is received , request the threads ( via the master ) to stop after completing an iteration ."
run learning algorithm
override command - building method so we can add more suppressions .
initializes parser .
tests that a long subtraction does not wrap the value into more than a single constantoperand .
tests that a long addition does not wrap the value into more than a single constantoperand .
this should work properly .
this should create an alert box due to missing parts .
this should work properly .
this should create an alert box due to missing parts .
this should work properly .
iterator yielding unprefixed events .
backend - specific wrapper for ijson.common.parse .
backend - specific wrapper for ijson.common.items .
tmp_path -- this is where the downloaded archives will be stored . packages_path -- this is where the packages will be installed .
install the package to the packages cache .
uninstall the package from the packages cache .
update the package from the network .
set the window title
"initialize sound , voice , screen , window title , keyboard"
"initialize sound , voice , screen , window title , keyboard , and sound cache"
"increase or decrease the main volume , and say it"
"toggle full screen mode , and say it"
return true if in full screen mode
try to clean up before closing the client
"play a sequence of sounds or texts , each one interruptible"
generate the list of genres .
generate the catalog ( list of mangas ) of the site .
generate the list of issues for a manga
generate the list of new mangas until a date
generate the list of genres .
generate the catalog ( list of manga ) of the site .
generate the list of issues for a manga
generate the list of new manga until a date
list current spiders than can be activated .
get the list of valid proxies and update the model .
"initialize all fields at once . if no password is specified , it will be set as an empty string"
save / updates the user
"grant revoke rights on a database , ' access ' is supposed to be boolean . arangodb grants / revokes both read and write rights at the same time"
permanently remove the user
"returns all available users . if rawresults , the result will be a list of python dicts instead of user objects"
"returns a single user . if rawresults , the result will be a list of python dicts instead of user objects"
add a given permission to this acl .
check whether this acl contains a given permission .
return the acls associated with this share .
set the acls associated with this share .
check whether a user has a given permission .
args : # font_family : name or path of the font that should be used . default is pygame - font # font_size : size of the font in pixels antialias : ( bool ) determines if antialias is used on fonts or not text_color : color of the text
load the acapela config parameters
"given a folder with images of objects on uniform background and different colours fingerprints , it associate the colours to the object name ."
get all effect directories for registered effects .
find all effect modules .
find and return an effect class in a module
"initialize , load and run"
key event callback for glfw
mouse event callback from glfw
window resize callback for glfw
scan for available templates in effect_templates
get the absolute path to the root of the demosys package
get the absolute path to the template directory
initialize camera using a specific projection
set the 3d position of the camera
: return : the current view matrix for the camera
updates the camera vectors based on the current yaw and pitch
look at a specific point
the standard lookat method
set the camera position move state
set the rotation state of the camera
: return : the current view matrix for the camera
update the internal projection matrix based on current values or values passed in if specified .
"returns the ( x , y ) projection constants for the current projection . : return : x , y tuple projection constants"
"attach some summaries to a tensor for tensorboard visualization , namely mean , standard deviation , minimum , maximum , and histogram ."
create a list of new cards .
shuffle the deck .
deal the top card from the deck .
evaluate the rank of the hand .
convenience function for setting up simple logging to console .
"any live cell with fewer than two live neighbours dies , as if caused by underpopulation . any live cell with two or three live neighbours lives on to the next generation . any live cell with more than three live neighbours dies , as if by overpopulation . any dead cell with exactly three live neighbours becomes a live cell , as if by reproduction ."
called when an originator changes it 's ` duration ` attribute
on stop either trigger a new playing of the signal if more iterations are required or hangup the call . if the current call is being recorded schedule the recordings to stop and expect downstream callbacks to schedule call teardown .
"trigger clip playback on the given session by doing the following : - start playing a silence stream on the peer session - this will in turn trigger a speech playback on this session in the "" playback_start "" callback"
1 ) mute the peer session 2 ) trigger endless clip playback on both sessions
on stop either swap the mute state of the channels if more iterations are required or hangup the call . if the current call is being recorded schedule the recordings to stop and expect downstream callbacks to schedule call teardown .
an inbound router which processes sessions from the ` external ` sip profile .
a switchy routing service .
async dial all fs servers in the test cluster with the given ` ` did ` ` . ` ` expect ` ` is a bool determining whether the calls should connect using the standard sipp call flow .
verify route registration order is maintained .
verify that if a guard is not satisfied the call is rejected .
raising ` ` stoprouting ` ` should halt all further processing .
test routing based on request - uri user part patterns .
test that multiple routers will work cooperatively . in this case the second rejects calls due to guarding .
run service optionally blocking until stopped .
return bool indicating if a least one event loop is alive .
stop service and disconnect .
load the measurement sub - module as long as there are no import issues otherwise skip this test set .
deliver a storage type
deliver a ` datastorer ` type
verify the storer 's internal in - mem buffering and disk flushing logic
"ensure that when no explicit dtype is provided , all row entries are cast to float internally ."
assert we can write and read quickly to the storer
test that using a ` datastorer ` with a single row dataframe stores data correctly
return the error message .
get a context to map os errors to their ` fs.errors ` counterpart .
convert datetime to epoch .
convert epoch time to a utc datetime .
globaly override sbatch template
override sbatch template per uc
override sbatch template per uc with default value
override sbatch arguments in a benchmark tag
ben - umb entry point
loader that loads any eggs in ` sys.path ` .
load all plugin components found in ` sys.path ` .
inits trainer .
train model .
inits sigmoid .
processes given input vector .
generate an rst file listing all classes and functions .
convert a capacity value from a unit to another one .
convert a time / delay value from a unit to another one .
load given model .
tokenize the text and return list of ufal.udpipe . sentence - s.
load text in the given format ( conllu|horizontal|vertical ) and return list of ufal.udpipe . sentence - s.
tag the given ufal.udpipe . sentence ( inplace ) .
parse the given ufal.udpipe . sentence ( inplace ) .
write given ufal.udpipe . sentence - s in the required format ( conllu|horizontal|vertical ) .
provide high level details about the setup of the current cluster .
"retrieve input ids for collections , normalizing to a list ."
retrieve files in the input collection .
retrieve remote file references .
retrieve an open handle to a file in an arvados keep collection .
flexibly search for files in an arvados collection .
"retrieve file size in keep , in mb"
"check for existence of a remote file , returning path if present"
add cache of files to avoid multiple api lookups .
retrieve files associated with the potential inputs .
"add remote files to data , retrieving any files not present locally ."
retrieve reference genome data from a standard bcbio directory structure .
add genome resources defined in configuration file to data object .
create set of system mountpoints to link into docker container .
"resolve relative and symlinked path , providing mappings for docker container ."
normalize sample configuration file to have absolute paths and collect directories .
handle external non - docker installed biodata located relative to config directory .
retrieve all directories specified in an input file .
"expand files to be absolute , non - symlinked file paths ."
"run a full analysis on a local machine , utilizing multiple cores ."
""" run a single defined function inside a docker container , returning results ."
create a ready to run local system configuration file .
retrieve system configuration file from input or default directory .
retrieve a system configuration with galaxy references specified .
write elasticluster configuration file with user and security information .
create a bcbio keypair and import to ec2 . gives us access to keypair locally and at aws .
create a bcbio iam user account with full access permissions .
create an iam instance profile with temporary s3 access to be applied to launched machines .
"move a sample configuration locally , providing remote upload ."
find uploaded jars for gatk and mutect relative to input file .
"receive n bytes from a socket , or fail"
handle socks5 request according to rfc1928
class decorator for enum types : :
makes dest have the same css classes as src
responsible for populating self.model ( eg with values from disk )
"returns a list of tuples representing k , v pairs of the given file"
"save to a filename . if create is true , any needed parent directories will be created ."
"save to a filename . if create is true , any needed parent directories will be created ."
log str / unicode .
remove all entries .
"get a list of unicode strings for the specified category . oldest entry first . passing no category will return all content . if ` limit ` is specified , the last ` limit ` items will be returned ."
yields all active coversourceplugin classes sorted by priority
register the cover sources plugin handler with the global plugin manager .
notify the world that the artwork for some songs or collections containing that songs might have changed ( for example a new image was added to the folder or a new embedded image was added )
try to get covers from all cover sources until a cover is found .
gets * cached * cover synchronously .
same as acquire_cover_sync but returns a cover for multiple images
returns a cover file object for one song or none .
returns a cover file object for many songs or none .
returns a pixbuf which fits into the boundary defined by width and height or none .
see get_pixbuf_many ( )
async variant ; callback gets called with a pixbuf or not called in case of an error . cancel is a gio . cancellable .
search for all the covers applicable to ` songs ` across all providers every successful image result emits a ' covers - found ' signal ( unless cancelled ) .
you need to override this to do something with the actual data . usually - this is sending to a server
override this method for asynchronous transports . call ` success_cb ( ) ` if the send succeeds or ` error_cb(exception ) ` if the send fails .
if the gsd plugin is active atm
tells gsd that ql started or got the focus . update : whether to send the current time or the last one
"if _ _ interface is none , set a proxy interface object and connect to the key pressed signal ."
enable events for dbus name owner change
disable name owner change events
this gets called when the owner of the dbus name changes so we can handle gnome - settings - daemon restarts .
tells gsd that we do n't want events anymore and removes all signal matches
set up the library and return the main one .
save all registered libraries that have a filename and are marked dirty .
return a new element instance or none
apply settings to the instance
call if you want to update settings
returns a guess for the local ip
test if widgets are properly set and in the correct order .
set the time in seconds
"disable the time display temporarily , means there is no meaningful time to show . re - enabling will show the previous time value"
hide the slider and do n't allow showing it again until it is enabled again
replace ngettext with a dummy implementation that returns predefined translations if given source text equals expected value and otherwise the source text unchanged .
generator for copool to copy songs to the folder
tell the copool to stop copying songs
returns all the active contexts for the current thread .
update the resolution in milliseconds
emit a tick event
creates and shows a new browser instance
see which browser windows are open and save their names so we can restore them on start .
restore saved browser windows
chargement du dictionnaires des noms de communes de l'insee
"normalise fix in e normal form is [ [ { ' + ' : { ' k1':'v1 ' , ' k2 ' , ' v2 ' } , ' -':{'k3':'v3 ' } , ' ~':{'k4','v4 ' } } , { ... } ] ] array of alternative ways to fix - > array of fix for objects part of error - > dict for diff actions - > dict for tags"
pretty print a file size .
open a hdf5 file .
add a child .
return the list of children .
"return an attribute , a children , or any descendant from its full name ."
access a child .
return the list of attributes and children .
return the associated h5py object ( group or dataset ) .
"for a dataset , access any part of the array ."
return an attribute .
return the list of attributes .
pretty print this item .
pretty print this item and all its descendants recursively .
open the file in read - only mode .
close the file .
"enter the file , to use with ` with ` ."
"exit the file , to use with ` with ` ."
callback function for ` visit ` : register the item .
visit the whole hierarchy of groups and datasets in the file .
"return a complete pretty print representation of the file and all its groups , datasets and attributes ."
register a signal handler to execute when maltego forcibly terminates the transform .
write a maltegomessage to stdout and exit successfully
internal api : returns the colorized version of the text to be returned to a posix terminal . not compatible with windows ( yet ) .
throw an exception in the maltego gui containing error_msg .
internal api : returns the entity type based on the following best match algorithm :
internal api : returns an instance of an entity of type entity_type with the specified value and fields ( stored in dict ) . this is only used by the local transform runner as a helper function .
"internal api : returns the version of the transform function based on the transform function 's signature . currently , only two versions are supported ( 2 and 3 ) . this is what version 2 transform functions look like :"
send debug messages to the maltego console .
send a progress report to the maltego console .
initialize the basic lstm cell .
long short - term memory cell ( lstm ) .
initialize the basic lstm cell .
long short - term memory cell ( lstm ) .
http get handler for the aeagle users page .
add customblock to markdown instance .
build the default postprocessors for markdown .
"iterate over html stash and restore "" safe "" html ."
get config for given directory name .
normalize whitespace for a string of html using tidylib .
write expected output file for given input .
generate expected output for all outdated tests .
set defaults and load config file if it exists .
get config value for given section and option key .
get name of config section for given file .
get args to pass to markdown from config for a given file .
compare expected output to actual output and report result .
"given a filename , inspects the corresponding outputted json files from the diarization analysis ( must be called after diarization ) and splits audio according to the times specified in jsons"
takes a list of many individual results and returns a dictionary of aggregated data .
receives data from threads and stores in the thread_data dict
returns number of load test threads running
returns total run time of the load test
increases lambda invocation error count
increases lambda invocation count
returns ratio of lambda invocations to invocation errors
increases total request count
increases total request fail count
returns ratio of failed to total requests
logs results from a locust exection . all results needs to be aggregated in order to show meaningful statistics of the whole load test
returns summary statistics in a dict
returns current statistics in a dict
returns a list of locust results
add lambda exection time to the total
returns current total rpm across all threads
checks if the current lambda and request fail ratios are within thresholds
returns true if a new thread should be started when ramping up over time
sets a boolean to stop threads
creates a new load test thread
this method is a single thread and performs the actual execution of the lambda function and logs the statistics / results
"starts the load test , periodically prints statistics and starts new threads"
"reads an isochrone in the dotter format and determines the age ( log10 yrs and gyr ) , metallicity ( z and [ fe / h ] ) , and creates arrays with the initial stellar mass and corresponding magnitudes for each step along the isochrone . http://stellar.dartmouth.edu/models/isolf_new.html"
"reads an isochrone in the dotter 2016 format and determines the age ( gyr ) , metallicity ( z ) , and creates arrays with the initial stellar mass and corresponding magnitudes for each step along the isochrone ."
break catalog into chunks by healpix pixel .
translate queue to wallclock runlimit .
translate queue into mpi options .
generate the command for running the likelihood scan .
untested . should return a boolean array representing the pixels in the footprint .
open each valid filename for the set of pixels and determine the set of subpixels with valid data .
"submit likelihood analyses on a set of coordinates . if coords is ` none ` , submit all coordinates in the footprint ."
submit the likelihood job for the given pixel(s ) .
"almost the same as in tex.py , but try to detect ' biber '"
find the cray fortran compiler ( will look in the environment variable ' fc ' )
bind the asm extension to the asm task
detect the sun c++ compiler
flags required for executing the sun c++ compiler
see waf issue 285 and also and also http://trac.macports.org/ticket/17059
"create bundle folders , used by : py : func:`create_task_macplist ` and : py : func:`create_task_macapp `"
"to compile an executable into a mac application ( a .app ) , set its * mac_app * attribute : :"
create a : py : class:`waflib . tools.c_osx.macplist ` instance .
"to make a bundled shared library ( a ` ` .bundle ` ` ) , set the * mac_bundle * attribute : :"
process a * .pyx * file given in the list of source files . no additional feature is required : :
perform a double - check to add the headers created by cython to the output nodes . the scanner is executed only when the cython task must be executed ( optimization ) .
"return the dependent files ( .pxd ) by looking in the include folders . put the headers to generate in the custom list "" bld.raw_deps "" . to inspect the scanne results use : :"
process all languages to create .mo files and to install them : :
detect kde4 - config and set various variables for the * use * system : :
return true if the given filename is binary . @raise environmenterror : if the file does not exist or can not be accessed . @attention : found @ http://bytes.com/topic/python/answers/21222-determine-file-type-binary-text on 6/08/2010 @author : trent mick < trentm@activestate.com > @author : jorge orpinel < jorge@orpinel.com >
turn the list of all flags we found into a regex find both - and _ versions
creates the interface .
sets the performer entered and closes the dialogue .
sets the performer entered and closes the dialogue .
gives the performer 's name
encode parameters .
encode object as json str .
generate authorize_url .
in callback url : http://host / callback?code=123&state = xyz
performs linting of a cobol document .
gets the log file path
"configures the logger , adds a stream handler and a file handler ."
set current keyring backend .
get current keyring backend .
get password from the specified service .
set password for the user in the specified service .
delete the password for the user in the specified service .
load a keyring specified in the config file or infer the best available .
load the keyring class indicated by name .
"load the specified keyring by name ( a fully - qualified name to the keyring , such as ' keyring.backends.file . plaintextkeyring ' )"
load a keyring using the config file in the config root .
load the keyring - path option ( if present )
remove a repository from storage
exec gunicorn with our wsgi app .
build the website
"return "" kubectl "" or "" oc "" , the command - line tool we should use ."
examine the local machine 's kubernetes configuration
construct session info based on user arguments
generate target textures that are the size of the target image
generate the cone that 's drawn for each sample point
renders the voronoi diagram to self.tex
draws the current array of samples as cones
draws small circles at the location of each stipple
updates stipple locations from an image cells should be an image of the same size as self.img with pixel values representing which voronoi cell that pixel falls into
variant of pytest_runtest_call ( ) that stores traceback info for postmortem debugging .
run tests in a given file if it is run as a script
input : sequence output : sequence : reversed version
@param string : string @return : integer : no . of vowels or 0
@param some_seq : sequence of anything @return : boolean : palindrome check of sequence passed
@param string : a string @param file : a file to be read
just an examplke for someone .
"pig latin – pig latin is a game of alterations played on the english language game . to create the pig latin form of an english word the initial consonant sound is transposed to the end of the word and an ay is affixed ( ex . : "" banana "" would yield anana - bay ) . read wikipedia for more information on rules ."
"this function takes clustered contours and splits them into multiple images , also does a check to make sure that the number of inputted filenames matches the number of clustered contours ."
creates a binary image from a gray image based on the threshold value .
identifies objects and fills objects that are less than size .
this function take a image with multiple contours and clusters them based on user input of rows and columns
this is a function used to add images . the numpy addition function ' + ' is used . this is a modulo operation rather than the cv2.add fxn which is a saturation operation . ddepth = -1 specifies that the dimensions of output image will be the same as the input image .
join two images using the bitwise xor operator .
"given just the columns field , fill in alias information ."
creates a type context from the union of others .
gets the full identifier for a column from any possible alias .
handle the case where a subquery has an alias .
create a ` document ` object from ` name ` .
"create a ` design ` object from ` name ` , like so :"
shortcut to ` database.document ` .
creates ` doc ` with an id of ` name ` .
shortcut to synchronously deleting the document from the database . for example :
return an ` index ` object referencing all documents in the database . you can treat it like an iterator :
formats ` database.all_docs ` for use as an iterator .
"save many docs , all at once . each ` doc ` argument must be a dict , like this :"
gets a list of the changes made to the database . this can be used to monitor for update and modifications to the database for post processing or synchronization .
refers to [ this method](http://docs.cloudant.com / api / database.html#retrieving - missing - revisions ) .
refers to [ this method](http://docs.cloudant.com / api / database.html#retrieving - differences - between - revisions )
cleans up the cached view output on disk for a given view . for example :
converts the passed hostname to a ipv4 ip adress . if the name already is a ipv4 ip it is returned unchanged
this method performs a lookup of a certain server . its like a search with the adress as paremeter so it clears the serverlist on the requesting tab and only adds the server object with the looked up data to the list afterwards .
adds a favorite server .
removes a server from the favorites list .
adds a new name to the buddylist
removes a name from the buddylist
removes a server from the list of recent servers
clears the recent server list .
starts executing the search for game servers .
starts executing the loading of the buddies
starts executing the loading of favorites .
starts executing the loading of recent servers .
starts the execution of the refreshe of a serverlist @param liststore - the liststore which contains the servers to be refreshed @param tab - the tab requesting the refresh
sets serverdetails on a ui tab .
requests updated status data of a certain sever
let the gui controller know with which window it works together
loads the buddylist and append the values to the treeview on the passed tab
refreshes the serverlist of a tab
loads the favorite server list from a file using the filemanager and update the serverlist on the requesting tab . all of this is done on background threads using the querymanager
loads the list of recent servers from a file using the filemanager and update the serverlist on the requesting tab . all of this is done on background threads using the querymanager
loads the serverlist from the masterserver . this method is executed in a background thread which is triggered by the executemasterserverquery method
launches urban terror and connect to the passed server
initiates the sending of a rcon command to a server launches a thread that does the rcon command sending
this is the method that runs in a backgroundthread and sends a rcon command to a server
convert a ipv4 address into a 32 - bit integer .
callback of the the connect button
callback method for the remove button . triggers the removal of the favorite entry by calling the gui controller which then removes the favorite ( from list in memory and also from file ) also removes the favorite directly from the liststore .
callback of the refreshbutton .
add a server to the listview / store . called by the guicontroller .
clears the embeded serverlist treeview
updates the embedded serverdetails element
callback method executed when the search has finished
"converts coordinates from corners to cx , cy , w , h."
mask the data .
"args : b1 : 2d array of [ cx , cy , width , height ] . b2 : a single array of [ cx , cy , width , height ] returns : ious : array of a float number in range [ 0 , 1 ] ."
compute the intersection - over - union of a batch of boxes with another batch of boxes .
"compute size of bytedata , in bytes ."
"generates a list of [ x , y , w , h ] , where centers are spread uniformly ."
setup the logs are ./logs / model.log
provide generator for images and labels as byte objects .
write set of images and labels to the provided file .
alias for next(object ) .
yield the next datum for mxnet to run .
read image from the byte buffer .
convert a standard numpy array into mxnet - ready arrays .
read label from the byte buffer .
convert standard label into squeezedet - specific formats .
step forward by ` steps ` in the byte buffer .
"starts the process of cleaning unnessesary changes using given processors if no processor is given , we 'll use the default ones ."
creates a prology list from arguments
applies fct on a prology list and returns the result in a python list
yields an iterable of unbound variables used in the instance
the tuple of arguments
apply create a new instance by substituting unbound variables
yields substitutions making the instance true .
"yields a possible substitution , torename contains the variable names already taken ( since fsubst and subst coexist )"
"@parameter{xpath , string } xpath in which text should appears @parameter{text_list , list } list containing possible texts @parameter{max_time , int } describes how long method should search for text @parameter{sleep_time , double } describes gaps between consecutive searches @parameter{fail , boolean } describes if failure should brake test case"
"@parameter{text_list , list } is list containing possible texts @parameter{max_time , int } describes how long method should search for text @parameter{sleep_time , double } describes gaps between consecutive searches"
"@parameter{col_name , string } name of column in which text should appear @parameter{text , string } text @parameter{path_body_trs , string } xpath for searching rows of table @parameter{path_head_tds , string } xpath for searching head 's cells of table @parameter{max_time , int } describes how long method should search for text @parameter{sleep_time , double } describes gaps between consecutive searches @parameter{check_data , dict } fields : @dictkey{path , string } path of table @dictkey{dict , dict } contains pairs : * col name * and * text * which are additional requirements for searched row"
"@parameter{col_name , string } name of column @parameter{path_head_tds , string } xpath for searching head 's cells of table"
"@parameter{ind_col , int } index of column @parameter{text , string } text @parameter{path_body_trs , string } xpath for searching rows of table"
"@parameter{menu_item_text , string }"
"@parameter{col_name , string } name of column which together with text describe row @parameter{text , string } text @parameter{action_name , string } name of column which together with row describes cell @parameter{element , string } element in cell which sholud be clicked @parameter{path_body_trs , string } xpath for searching rows of table @parameter{path_head_tds , string } xpath for searching head 's cells of table @parameter{check_data , dict } fields : @dictkey{path , string } path of table @dictkey{dict , dict } contains pairs : * col name * and * text * which are additional requirements for searched row"
"@parameter{col_name , string } name of column which together with text describe row @parameter{text , string } text @parameter{path_body_trs , string } xpath for searching rows of table @parameter{path_head_tds , string } xpath for searching head 's cells of table @parameter{check_data , dict } fields : @dictkey{path , string } path of table @dictkey{dict , dict } contains pairs : * col name * and * text * which are additional requirements for searched row"
"@parameter{col_name , string } name of column which together with text describe row @parameter{text , string } text @parameter{action_name , string } name of column which together with row describe cell @parameter{menu_item_text , string } xpath for searching rows of table @parameter{check_data , dict } fields : @dictkey{path , string } path of table @dictkey{dict , dict } contains pairs : * col name * and * text * which are additional requirements for searched row"
"@returns{dict } image 's data fields : @dictkey{id } @dictkey{user_id , int } @dictkey{name } @dictkey{platform } @dictkey{description } @dictkey{creation_date }"
"method returns image \c i d if it belongs to user \c user_id ( and optionally to listed \c groups , if any given )"
"getter , which should be called by admin . it does n't check image 's ownership ."
"@parameter{user_id , int }"
"attaches this storageimage to specified vm . it searches for first free device and if there 's any , tries to attach this to it via libvirt . further it updates db information ."
requests libvirt to detach from given vm this storageimage .
adds specified cc1 user to current cm .
changes specified user 's quota .
changes quota of multiple users .
get specified user 's qouta .
returns all users .
view rendering network list .
ajax view returning network list .
ajax view fetching network details .
ajax view fetching pool list .
creates virtual machines .
"this function only destroys vm . all the cleanup ( removing disk , saving , rescuing resources , ... ) is done by hook through \c contextualization.update_vm method ( yeah , intuitive ) ."
calls vm.save_and_shutdown ( ) on specified vm
returns caller 's vms .
returns requested caller 's vm .
safely restarts selected callers vms
updates vm 's attributes .
attaches vnc redirection to vm .
detaches vnc redirection from vm .
remove all leases from this network
"@cmview_ci @param_post{remote_ip , string } @param_post{state } @param_post{comment , string } @param_post{error , string }"
returns list of the news .
creates new group of users . caller becomes its leader . he also becomes a member of that group with @val{ok } state .
sends request for acceptation in specified groupfor caller . adds caller to members with ' waiting ' state .
"returns group.dict property of each existing groups , supplemented by callers membership status : @val{ok } , @val{waiting } or @val{not member } under @val{user_status } key ."
returns list of caller 's groups ( only those where caller is accepted ) .
method returns members of the group with i d @prm{group_id } .
method returns list of the groups caller is leader of .
function returns list of the users requesting acceptation in group with i d @prm{group_id } .
method deletes specified group .
method edits specified group .
method activates @prm{user_id } user in group @prm{group_id } . activated user gains access to isoimage - s shared by that group .
method deletes membership of a user from a specified group . only group leader and user - to - delete may call this .
"function changes owner of the specified group . only owner may be the caller , otherwise exception is thrown . @prm{user_id } becomes new group 's leader ."
"@clmview_user @param_post{group_id , int } i d of the requested group"
ajax view for fetching farm list .
action executed on last step submition .
cast ' ec2name ' to int .
configure the root logger for log output .
returns compiled model .
it returns a list of spiders available in the spider_settings dict
search for the spider_name in the spider_settings dict and start running the spider with the scrapy api
plays games against a variety of algorithms to see how good a network is . results are currently just printed to std out
sample a single rollout from the current board_state and side . moves are made to the current board_state until we reach a terminal state then the result and the first move made to get there is returned .
evaluate the best from the current board_state for the given side using monte carlo sampling .
evaluate the best from the current board_state for the given side using monte carlo sampling with upper confidence bounds for trees .
return the regular expressions and functions list for this module .
parse the command - line arguments .
validate the arguments .
main application entry .
compile the regex and add it to the list .
create the list of regular expressions and functions .
just a simple interface to the _ val function with a more meaningful name .
just a simple interface to the _ val function with a more meaningful name .
"tries to determine the appropriate value of a particular variable that is passed in . if the value is supposed to be a percentage , a whole integer will be sought after and then turned into a floating point number between 0 and 1 . if the value is supposed to be an integer , the variable is cast into an integer ."
returns an image with reduced opacity .
"scales an image using a specified ratio , ' f ' or ' r ' . if ` scale ` is ' f ' , the image is scaled to be as big as possible to fit in ` img ` without falling off the edges . if ` scale ` is ' r ' , the watermark resizes to a percentage of minimum size of source image . returns the scaled ` mark ` ."
determines the number of degrees to rotate the watermark image .
options : tl : top - left tr : top - right br : bottom - right bl : bottom - left c : centered r : random x%xy% : relative positioning on both the x and y axes x%xy : relative positioning on the x axis and absolute positioning on the y axis xxy% : absolute positioning on the x axis and relative positioning on the y axis xxy : absolute positioning on both the x and y axes
adds a watermark to an image
make predictions for the single input sequence .
clean up the headers to valid filenames .
reads and cleans the jsonl input files .
read text and return dictionary that encodes vocabulary
minimally update the indices and frequency of symbol pairs
"count frequency of all symbol pairs , and create index"
"replace all occurrences of a symbol pair ( ' a ' , ' b ' ) with a new symbol ' ab '"
prune statistics dict for efficiency of max ( )
construct a new ` sequence ` object .
construct a new instance of ` embeddedfactorsequence ` .
link embeddings with vocabulary wordlist .
return a list of embedding matrices for each factor .
return the embedded factors .
feed the placholders with the data .
construct a new instance of ` embeddedsequence ` .
return a 2d placeholder for the sequence inputs .
return the embedding matrix for the sequence .
return the input vocabulary .
return the input data series indentifier .
return set of symbol pairs in a word .
"encode word based on list of bpe merge operations , which are applied consecutively"
segment single sentence ( whitespace - tokenized string ) with bpe encoding
check shape of a tensor .
check if two tensors have the same shape .
get reader for space - separated tokenized text .
get a tokenizing reader for plain text .
get reader for delimiter - separated tokenized text .
get the feedables and tensors to run .
construct a new instance of the sequence classifier .
split a tensor for multi - head attention .
apply mask to the attention energies before passing to softmax .
mask energies of keys using lower triangular matrix .
run multi - head scaled dot - product attention .
run a multi - head attention getting context vector for a given query .
get a reader of images loading them from a list of pahts .
load and prepare image the same way as caffe scripts .
rescale and/or crop the image based on the rescale configuration .
create an instance of the exception .
convert this exception to string .
create an instance of the exception .
convert this exception to string .
create an instance of the exception .
convert this exception to string .
get xent objective from decoder with cost .
create a single highway layer .
concatenate processors .
get a reader of audio files loading them from a list of pahts .
read a wav file .
read a nist sphere audio file using the sph2pipe utility .
canonicalizes the input string by removing non - hexadecimal characters and making everything uppercase
clear all the documents of the travelrequests collection .
delete multiple travel_request_documents .
"generate random number of travel_request_documents for each bus_line , for a 24hour period starting from a selected datetime , and store them at the corresponding collection of the system database ."
"generate a specific number of travel_request_documents , for the selected bus_line , for a 24hour period starting from a selected datetime , and store them at the corresponding collection of the system database ."
returns a list of the most recent entry for each of the most common entry labels
green : you 're under your budget and under your average . blue : you 're under your budget but not your average . orange : your within 25 % of your budget . red : you 're over 25 % of your budget
impersonate a user .
unimpersonate a user .
rebuild visitor counts .
rebuild the blog index .
adds missing keys to the given status and returns it .
asserts that a get request was sent with the given path and parameters .
asserts that ` ` func ( ) ` ` obtains the contents of the given file .
asserts that ` ` func(directory ) ` ` obtains the given file and saves it to ` directory ` .
error code ( ` int ` ) .
short message describing what went wrong ( ` str ` ) .
longer description of what went wrong ( ` str ` ) .
starts a decompilation with the given parameters .
"starts a decompilation with the default input file and , additionally , the given parameters ."
": param folder_name : filename with a gif : param offset : how many frames into the gif we want to start at : param desired_fps : how many fps we 'll sample from the image : return : [ t , h , w , 3 ] gif"
"find or make an aggregate object with the given urn , giving it also this url . uses a local cache ."
"parse the workflow struct from the scs into the given rspec data structure . includes computing am dependencies , hop import_from pointers , etc ."
"set the hop that the given hop will import vlans from , when its am is ready to run"
add the aggregate and import_vlans info to the hop if it does n't already have it .
"parse the dependencies struct deps , adding info to the given path object ."
parse the hop dependencies in deps .
follow the hop dependencies and generate aggregate to aggregate dependencies from them .
return none or a normalized absolute path version of the argument string . does not check that the path exists .
run the clearinghouse server .
"create a connection to an xml rpc server , using ssl with client certificate authentication if requested . returns the xml rpc server proxy ."
create an ssl connection to an xml rpc server . returns the xml rpc server proxy .
connect to a host on a given ( ssl ) port .
returns a class from a string including module and class .
parse a gamespy message .
generate a list based on the input dictionary .
generate a string based on the input list .
create a message based on a dictionary ( or list ) of parameters .
emscripten does n't support processing ' - ' like clang / gcc
emscripten does n't like absolute include paths
"find the program gcc , and if present , try to detect its version number"
common flags for gcc on nearly all platforms
configuration flags for executing gcc on windows
configuration flags for executing gcc on cygwin
configuration flags for executing gcc on macos
configuration flags for executing gcc on aix
execute platform - specific functions based on * gcc_modifier_+name *
configuration for gcc
bind the .resx extension to a resgen task
"create the eclipse cdt .project and .cproject files @param appname the name that will appear in the project explorer @param build the buildcontext object to extract includes from @param workspace_includes optional project includes to prevent "" unresolved inclusion "" errors in the eclipse editor @param pythonpath optional project specific python paths"
create : py : class:`rst ` or other rst - related task objects
a recursive regex - based scanner that finds rst dependencies .
adds a course mode to the test course .
log in a user .
create the user 's account .
return a list of users with the specified role / course pair
post function for updating the email opt in preference .
"wraps a xmoduledescriptor.from_xml method , and modifies xml_data to replace any immediate child < include > items with the contents of the file that they are supposed to include"
removes sections with single child elements in favor of just embedding the child element
"transforms the xml_data from < $ custom_tag attr= "" "" attr=""""/ > to < customtag attr= "" "" attr= "" "" impl=""$custom_tag""/ >"
returns the studio url to a static resource .
render the view to manage an xblock 's visibility settings in studio . args : _ context : not actively used for this view . returns : ( fragment ): an html fragment for editing the visibility of this xblock .
asserts that the given grade object has the expected score .
test that a zero grade is returned .
"assuming the underlying score reporting methods work , test that the score is calculated properly ."
"test that scores are not persisted when a learner has never attempted a problem , but are persisted if the learner 's state has been deleted ."
will receive a delegated ' course_published ' signal from cms / djangoapps / contentstore / signals.py and kick off a celery task to update the credit course requirements .
receive ' min_grade_requirement_status ' signal and update minimum grade requirement status .
setup method - create courses
get 's library key as it is passed to indexer
builds a list of mock.call instances representing calls to reindexing method
test that raises commanderror for incorrect arguments
test that raises invalidkeyerror for invalid keys
test that raises commanderror if library key is passed
test that reindexes courses when given single course key or a list of course keys
test that reindexes all courses when --all key is given and confirmed
test that does not reindex anything when --all key is given and cancelled
test that fails on first reindexing exception
creates and returns a schedule according to the provided upsell deadline values . also returns the offset and target_day as computed for messaging .
calls the task for sending a message to the given schedule and for the given offset and target_day . returns the message that would have been sent .
returns whether the given message would contain upsell text .
returns encoded course sharing utm parameters .
arguments : course : this can be either a course overview object or a course descriptor .
convenience function for testing command failures
validate argument checking
various exit path tests for test_add_repo
test repo that is in detached head state .
exercise branching code of import
this wil create conditions to exercise bad paths in the switch_branch function .
return the appropriate logging config dictionary . you should assign the result of this to the logging var in your settings . the reason it 's done this way instead of registering directly is because i did n't want to worry about resetting the logging state if this is called multiple times when settings are extended .
go through each interface and ensure it works .
test that course updates does n't break on old data ( content in ' data ' field ) . note : new data will save as list in ' items ' field .
test trying to add to a saved course_update which is not an ol .
posts an update to the course
test that a user can successfully post on course updates and handouts of a course
test to make sure that a non - match returns false
test to make sure that a match works across course runs
"test that the default setting for courses_with_unsafe_code is an empty setting , e.g. we do n't use @override_settings in these tests"
return true if asides are enabled for this type of block in studio
"looks at the currently active configuration model to determine whether the feature that enables editing of "" request username "" and "" request email "" fields of lti consumer is available or not ."
get the expected redirect url for the current django version and the given relative url :
test to make sure multiple users are created .
the view should return json .
make a request to the auto - auth end - point and check that the response is successful .
test case to check user creation is forbidden when allow_public_account_creation feature flag is turned off
passing role names via the course_access_roles query string parameter should create courseaccessrole objects associated with the user .
"test the "" devstack "" task ."
"test the "" devstack "" task ."
"test the "" devstack "" task ."
"test the "" run_all_servers "" task ."
"test the "" celery "" task ."
"test the "" update_db "" task ."
"test the "" check_settings "" task ."
verify the output of a server task .
verify the output of a server task .
returns the expected sass commands for the specified system .
helper method to create a new request object for the lti launch .
verifies that the lti launch succeeds when passed a valid request .
verifies that the lti launch succeeds when passed a valid request .
helper method to remove a parameter from the lti launch and call the view
runs through all required lti parameters and verifies that the lti_launch view returns bad request if any of them are missing .
verifies that the lti launch will fail if the enable_lti_provider flag is not set
verifies that the view returns forbidden if the lti oauth signature is incorrect .
overridable method to get the response from the endpoint that is being tested .
override since lti allows access to unenrolled students .
override since lti allows access to unauthenticated users .
"override because mongo queries are higher for this particular test . this has not been investigated exhaustively as mongo is no longer used much , and removing user_partitions from inheritance fixes the problem ."
get /api / user / v1 / me
"get /api / user / v1 / accounts?username={username1,username2 }"
get /api / user / v1 / accounts/{username}/
patch /api / user / v1 / accounts/{username}/
post /api / user / v1 / accounts/{username}/deactivate/
"signal receiver for unenrollments , used to automatically initiate refunds when applicable ."
helper to get the authenticated user from the current http request ( if applicable ) .
helper method to process a refund for a given course_product
"attempt to initiate a refund for any orders associated with the seat being unenrolled , using the commerce service ."
attempt a refund of a course entitlement : param course_entitlement : : return :
create a zendesk ticket via api .
returns a refund notification message body .
notify the support team of the refund request .
returns course_team object from team_id .
"by convention set by django developers , this method actually executes command 's actions . so , there could be no better docstring than emphasize this once again ."
just return .
test that when isolation level is set to read committed get_or_create ( ) for the same row in concurrent requests does not raise an integrityerror .
test that outer_atomic raises an error if it is nested inside another atomic .
test that commit_on_success raises an error if it is nested inside atomic or if the isolation level is changed when it is nested inside another commit_on_success .
test that a named outer_atomic raises an error only if nested in enable_named_outer_atomic and inside another atomic .
verify that we get a random integer within the specified range when there are no used ids .
verify that we get a random integer within the specified range but not in a list of used ids .
"tests that the migration files are in sync with the models . if this fails , you needs to run the django command makemigrations ."
"returns true if the xmodule linked to the descriptor supports "" author_view "" ."
"renders the children of the module with html appropriate for studio . if can_reorder is true , then the children will be rendered to support drag and drop ."
helper method for getting preview view name ( student_view or author_view ) for a given module .
clear static file finders cache and register cleanup methods .
log into lms .
test that theme footer is used instead of default footer .
test that theme header does n't show marketing site links for account settings page .
test that theme logo is used instead of default logo .
test that theme title is used instead of parent title .
test that theme title is used instead of parent 's parent 's title .
test that parent 's body is present in self inherited template .
test that theme template can include template which is not part of the theme .
test that theme template can include template which is overridden in the active theme .
"test that theme template can include template which is only present in the theme , but has no standard lms equivalent ."
clear static file finders cache and register cleanup methods .
test that theme templates are used instead of default templates .
clear static file finders cache .
test that default logo is picked in case of no comprehensive theme .
clear static file finders cache and register cleanup methods .
test that defaults templates are used when no theme is applied .
clear static file finders cache and register cleanup methods .
test stanford theme footer .
test custom logo .
test correct favicon for custom theme .
test custom theme overrides for index page .
retrieves the course tab list from xmodule.tabs and manipulates the set as necessary
returns the dynamic tab types for the current user .
returns true if this tab is enabled .
returns a function that takes a course and reverse function and will compute the course url for this tab .
a generator for iterating through all the singletextbooktab book objects associated with this collection of textbooks .
validate that the tab_dict for this course tab has the necessary information to render .
validate that the tab_dict for this course tab has the necessary information to render .
perform the course structure generation workflow
wrapper around log.debug that prefixes the message .
wrapper around log.info that prefixes the message .
returns whether storage backing for block structures is enabled .
noop delete method .
arguments : cache ( django.core.cache.backends.base . basecache ) - the cache into which cacheable data of the block structure is to be serialized .
stores and caches a compressed and pickled serialization of the given block structure .
"deserializes and returns the block structure starting at root_block_usage_key , if found in the cache or storage ."
deletes the block structure for the given root_block_usage_key from the cache and storage .
returns whether the data in storage for the given key is already up - to - date with the version in the given modulestore .
returns the model associated with the given key .
updates or creates the model for the given block_structure and serialized_data .
adds the given serialized_data for the given blockstructuremodel to the cache .
returns the serialized data for the given blockstructuremodel from the cache . raises : blockstructurenotfound if not found .
returns the serialized data for the given blockstructuremodel from storage . raises : blockstructurenotfound if not found .
serializes the data for the given block_structure .
deserializes the given data and returns the parsed block_structure .
returns the cache key to use for the given blockstructuremodel or stubmodel .
"returns the version - relevant data for the given block , including the current schema state of the transformers and blockstructure classes ."
returns the version - relevant data for the given blockstructuremodel .
test that only one filename starts with 000 .
asserts the value of get_internal_api_url matches the expected value .
test the behavior of the property controlling whether api responses are cached .
requests made without a microsite should return the value from settings .
requests made to microsites that do not have course_catalog_api_url overridden should return the default value from settings .
"if a microsite has overridden the value of course_catalog_api_url , the overridden value should be returned ."
return the precalculated completion of a block within the block_structure :
mutates block_structure adding extra field which contains block 's completion .
returns whether the given course is in the block structure cache .
returns whether the given course is in block structure storage .
test helper to clear out any cached values of registered transformers .
context manager for mocking the transformer registry to return the given transformers .
returns the children of the mock xblock .
updates the mock modulestore with a dictionary of blocks .
returns the mock xblock ( mockxblock ) associated with the given block_key .
a context manager for notifying the store of bulk operations .
associates the given key with the given value in the cache .
returns the value associated with the given key in the cache ; returns default if not found .
deletes the given key from the cache .
creates and returns a mockmodulestore from the given children_map .
returns a block key object for the given block_id . override this method if the block_key should be anything different from the index integer values in the children maps .
factory method for creating and returning a block structure for the given children_map .
converts and returns the given children_map to a parents_map .
verifies that the relations in the given block structure equate the relations described in the children_map . use the missing_blocks parameter to pass in any blocks that were removed from the block structure but still have a positional entry in the children_map .
returns a block key object for the given block_id .
returns the command that is expected to be run for the given test spec and store .
using 1 process means paver should ask for the traditional xunit plugin for plugin results
"using multiple processes means specific xunit , coloring , and process - related settings should be used ."
"with the above test , validate that num_processes can be set to various values"
"verify that the homepage , when accessed via a site domain , returns html that reflects the site branding elements"
make sure we see the right content on the homepage if there is no site configuration defined .
verify that the number of courses displayed on the homepage honors the homepage_course_max setting .
"verify that the copyright , when accessed via a site domain , returns the expected 200 response"
verify that the copyright page does not exist if we are not in a configured site .
verify that a user going to homepage will not redirect if he / she has no course enrollments
verify that a user going to homepage will not redirect to dashboard if he / she has a course enrollment
enroll user in a course scoped in a site and one course outside of a site and make sure that they are only visible in the right dashboards
enroll user in a course scoped in a site and make sure that template with tabs is overridden
make sure the site is honoring the visible_about_page permissions that is set in configuration
make sure that site overrides on the enable_shopping_cart and enable_paid_course_enrollments are honored
tests retrieving a subsection grade before and after losing access to a block in the subsection .
prints out the course i d and a numbered list of tabs .
add arguments to the command parser .
"returns the namespaced , cached , audited waffle class for completion ."
"legacy : not to be used as a model for constructing badge slugs . included for compatibility with the original badge type , awarded on course completion ."
returns a description for the earned badge .
"generates a url to the user 's certificate html view , along with a get variable that will signal the evidence visit event ."
constructs the ' criteria ' url from the course about page .
"given a course key and a user , find the user 's enrollment mode and get the course completion badge ."
"takes a generatedcertificate instance , and checks to see if a badge exists for this course , creating it if not , should conditions be right ."
returns the title for the course home page .
returns the default course url name for the current user .
returns the course home page 's url name for the current user .
returns the namespace of the message collection .
"given a course with no discussion set up , add the discussions and set the cohort config on the course descriptor ."
set and configure cohorts for a course .
returns the users associated with the cohort .
set up an array of various courses to be tested .
set up and enroll our fake user in the course .
set up for the tests .
creates a test course that can be used for non - destructive tests
set up and enroll our fake user in the course .
creates a test course .
set up for the tests .
navigates to the provided sequential .
tests that the start course button appears when the course has never been accessed .
tests that two resume course buttons appear when the course has been accessed .
tests resume course when the last accessed sequential is deleted and there is another sequential in the vertical .
tests resume course when the last accessed sequential is deleted and there are no sequentials left in the vertical .
toggle masquerade state .
verify the behavior of preview for the course outline .
send analytics event for a sent email
connect handlers to signals .
"when an unexistent path is passed to the filter , it should return the same path"
test get_backend returns none for invalid paths and raises typeerror when invalid class or class name is a method .
test get_backend raises valueerror when module does not have a class .
test get_backend loads class if class exists .
add arguments to the command parser .
get url for the specified xblock handler
student login and enroll for the course
staff login and enroll for the course
"call a ajax event ( vote , delete , endorse ) on a resource by its i d several times"
"call a ajax event ( add , edit , flag , etc . ) by specifying the resource it takes"
"call the event specified by the handler with the resource , and check whether the element ( resp_key ) in response is as expected ( resp_val )"
check that a generic statement is returned when no default / specific hints exist
test the ability to add a new specific hint
check that specific hints are returned
test hint upvoting
test hint downvoting
test hint reporting
check that reported hints are returned
check that hint / answer information from previous submissions are returned upon correctly answering the problem
check that the most upvoted hint is shown
return true if certificate is valid else return false .
make sure unicode representation of restrictedapplication is correct
read back one of the confidential clients ( there are two ) and verify that we get back what we expected
make sure when generating an access_token for a restricted client that the token is immediately expired
test that any template directories added are not cleared when microsites are enabled .
simple test to make sure that you do n't get a 500 error when the modal is enabled .
renders the current learner 's achievements .
returns a user 's certificates sorted by course name .
"confirm rate limits work as expected . note that drf 's rate limiting makes use of the default cache to enforce limits ; that 's why this test needs a "" real "" default cache ( as opposed to the usual - for - tests dummycache )"
"helper method to get a course / usage key either from a string or a key_cls , where the key_cls ( coursekey or usagekey ) will simply be returned ."
finds and returns the earned subsection grade for user
finds the subsection grade for user and returns the override for that grade if it exists
override subsection grade ( the persistentsubsectiongrade model must already exist )
delete the override subsection grade row ( the persistentsubsectiongrade model must already exist )
convienence function to return the state of the coursewaffleflag rejected_exam_overrides_grade
execute the command
"filter fields based on feature flag , i.e. enabled , disabled ."
fetches all key : value pairs from persistence and returns a coursemetadata model .
convert stellar magnitude into snr for given exposure time .
convert 5 - sigma limiting magnitude into exposure time
convert exposure time into 5 - sigma limiting magnitude
copying from deimos assuming that deimos and gmacs will have the same spectral resolution and thus same snr vs v_error relation
* * * copied from gmacs * * *
this function converts from signal - to - noise ration ( snr ) to statistical velocity uncertainty using a functional fit to data in figure 1 of simon & geha 2007 .
compare emi values with reference matlab code
implement this in your queuetask subclasses
override this if you need a custom queue implementation
enqueue ` item ` into this task 's queue . returns a ` future `
enqueues ` items ` into the queue
thrift http post request .
task constructor . requires a ` service ` vservice instance
override this to do any task - specific initialization
override thread - specific initialization for multi - threaded tasks
called during bootstrap to spin up threads post - creation .
custom stopping logic for this task .
"block , waiting for all child worker threads to finish ."
returns true if task is still doing work .
"for normal ( non - loopless ) tasks , this must be implemented"
indicate that execution has started
indicate that execution has completed
indicate that execution has failed
convenience property . returns timer duration .
fallback errback for deferred processing
custom comparators for comparing contexts ' work ` item`s
override _ _ lt _ _ explicitly for priority queue implementations
register task_class with the collection
register multiple ` tasks ` classes with the collection
unregister ` task_class ` from the collection
create all registered tasks .
remove created ` task ` from the collection
initialize all created tasks . remove ones that throw skiptask .
"start all the tasks , creating worker threads , etc"
"returns the ` task ` or its class , if creation has n't happened yet ."
"return the ` task ` instance or class , raising if not found ."
accessor for accessing a copy of registered task classes
accessor for accessing a registered or instantiated task classes
helper for accessing tasks using their name as an attribute .
"iterates on created or registered tasks , as appropriate ."
"returns the number of created or registered tasks , as appropriate"
returns the created or registered task at the specified ` index `
initialize the parser instance .
attempt to parse source code .
keeps track of the furthest point in the source code the parser has reached to this point .
a special default callout for special handling .
puts a process in the idle io priority class .
"find which of these inodes are in use , and give their open modes ."
retry calling the decorated function using an exponential backoff . : param callback_by_exception : callback / method invocation on certain exceptions : type callback_by_exception : none or dict
return a spark session object
called when a new tracker is initialized .
called before the thread exits .
called after the thread exits / has been killed
"called when message other than "" tracker "" has been received ."
called everytime we receive a gps position string .
called if last two positions are the same .
called if moving again after stationary destection .
install requirements packages
check the project for pep8 compliance using ` pep8 `
tag new version
fetch git version
calculate the equilibrium water vapor pressure over ice .
calculate the equilibrium water vapor pressure over water .
calculates gas density by ideal gas law .
convert mass mixing ratio to specific humidity .
convert mass mixing ratio to volume mixing ratio .
convert specific humidity to mass mixing ratio .
convert specific humidity to volume mixing ratio .
convert volume mixing ratio to mass mixing ratio .
convert volume mixing ratio to specific humidity .
run all test methods with empty config and environment .
restore config and environment .
test if environment variables are considered .
test if environment variables are updated .
test behavior for undefined variables .
test the membership check .
test the membership check ( negative ) .
implement membership test operators .
"d.get(k [ , d ] ) - > d[k ] if k in d , else d.d defaults to none ."
bin / bucket y according to values of x.
bin / bucket data in arbitrary number of dimensions
get the distribution of y vs. x as percentiles .
calculate allan deviation in its simplest form
calculate correlation coefficient with p - values
create coutcapture for given workspace object .
test golden ratio for figures sizes .
test the determination of subplot arrangements .
check matplotlib stylesheet paths .
compute fid score using tf.gan library .
evaluate model at given checkpoint_path .
evaluates all checkpoints for the given task .
"returns a filename that 's free on the target storage system , and available for new content to be written to ."
get a copy of union of two dicts .
"get a copy of dict , removed keys ."
"get a copy of union of two dicts , removed keys ."
generate db_api.add_item mock function .
generate db_api.get_items mock function .
generate db_api.get_item_by_id mock function .
generate db_api.get_items_by_ids mock function .
generate db_api.get_items_ids mock function .
generate neutron create an object mock function .
generate mock function for getter by 1st argurment .
generate mock function for getter by 2nd argurment .
"initialize , but do not start the wsgi server ."
reset server greenpool size to default .
initialize a manager object appropriate for this service .
start serving this service using loaded configuration .
stop serving this api .
wait for the service to stop serving this api .
build a mesh object using getfem .
build a mesh object using getfem .
"compute the column vector k such that the eigenvalues of a - b*f are the ones given by the vector p a is an nxn matrix , b and p are vectors please note that if you want to specify complex eigenvalues , p is a matrix with 2 rows : the first for the real part of the eigenvalues and the second for the imaginary part ."
initialise the color object .
"gets color at pt[0 ] , pt[1 ] . yields integer ."
"find a color in a box , with a specific tolerance . returns a tuple of the x , y value of a matched color . none if no color was found ."
"find all colors in a box , with a specific tolerance . returned are all the matching points"
"find a color in a box , searching in the direction of a spiral , with a specific tolerance . yields a tuple of x , y values of found color ."
"finds a colored area in box with min area min_a with a specific tolerance . yields a tuple of x , y values of found area ."
counts color col in box with tol . yields integer of count .
compares col1 and col2 with tol . yields boolean
sets cts to ncts .
gets cts . yields cts .
"sets cts2 modifiers with hue , sat ."
gets cts2 modifiers . yields tuple of hue and sat mods .
"this gives us all the fields that we should care about changes for , excludes fields added by tests ( nose adds ' c ' ) and the i d which is an implementation detail of django ."
child classes interested in executing logic based upon aggregate field changes should override this method
make sure an ipv6 address is ignored gracefully for now .
create some fake data in a dataframe
all the sequences ids in a set
"given a new file path , will rename all sequences in the current fasta file using the mapping dictionary also provided ."
will take all the sequences from the current file who 's i d appears in the ids given and place them in the new file path given .
get http content : param url : contents url : param headers : http header : return : beautifulsoup object
find xml : param url : contents url : param features : markup provider : param headers : http header : return : beautifulsoup object
find xml(list ) : param url : contents url : param markup : markup provider : param tag : find tag : param pattern : xml file pattern : return : beautifulsoup object list
get attribute for beautifulsoup object : param soup : beautifulsoup object : param key : attribute key : param unknown : attribute key not exists value(default : none ) : return : attribute value
"get attribute for beautifulsoup object : param soup : beautifulsoup object : param key : attribute key : param data_type : data type(int , float , etc ... ) : param unknown : attribute key not exists value(default : none ) : return : ( data_type)attribute value"
: param timestamp : game day
game dataset(row ) : return : { ' retro_game_id ' : retrosheet game i d ' game_type ' : game type(s / r / f / d / l / w ) ' game_type_des ' : game type description ( spring training or regular season or wild - card game or divisional series or lcs or world series ) ' st_fl ' : spring training flag(t or f ) ' regseason_fl ' : regular season flag(t or f ) ' playoff_fl ' : play off flag(t or f ) ' local_game_time ' : game time(utc -5 ) ' game_id ' : game i d ' home_team_id ' : home team i d ' home_team_lg ' : home team league(al or nl ) ' away_team_id ' : away team i d ' away_team_lg ' : away team league(al or nl ) ' home_team_name ' : home team name ' away_team_name ' : away team name ' home_team_name_full ' : home team name(full name ) ' away_team_name_full ' : away team name(full name ) ' interleague_fl ' : inter league flag(t or f ) ' park_id ' : park i d ' park_name ' : park name ' park_loc ' : park location }
read xml object : param url : contents url : param features : markup provider : param timestamp : game day : param game_number : game number : return : pitchpx.game.game . game object
get game data : param soup : beautifulsoup object : param timestamp : game day : param game_number : game number : return : pitchpx.game.game . game object
get game type description : param game_type : game type : return : game type description
get spring training flg : param game_type : game type : return : spring training flg(t or f )
get regular season flg : param game_type : game type : return : regular season flg(t or f )
get play off flg : param game_type : game type : return : play off flg(t or f )
get team attribute : param soup : beautifulsoup object : param team_type : team type(home or away ) : param name : attribute name : return : attribute value
get stadium attribute : param soup : beautifulsoup object : param name : attribute name : return : attribute value
get inter league flg : param home_team_lg : home team league : param away_team_lg : away team league : return : inter league flg(t or f or u )
get retro i d : param home_team_id : home team i d : param timestamp : game day : param game_number : game number : return : retro i d
game object data(row data )
game object data
spring training data
regular season data
wild - card game data
divisional series data
world series data
unknow game type
league champion ship data
inter league(not )
inter league(unknown )
team attributes data
team attributes data(not exists )
stadium data(not exists )
": meta_configs : dict like and contains checkpoint_dir , session_key , server_uri etc : app_name : the name of the app : collection_name : the collection name to be used . don""t use other method to visit the collection if you are using statestore to visit it ."
": state : any json serializable : return : none if successful , otherwise throws exception"
": meta_configs : dict like and contains checkpoint_dir , session_key , server_uri etc"
": state : any json serializable : return : none if successful , otherwise throws exception"
": meta_configs : dict like and contains checkpoint_dir , session_key , server_uri etc"
": state : any json serializable : return : none if successful , otherwise throws exception"
read at most * n * characters from this stream .
read at most * n * characters from this stream .
parse results and messages out of * stream * .
"create a data loader with default event_writer , job_scheudler"
@configs : a list like object containing a list of dict like object . each element shall implement dict.get/ [ ] like interfaces to get the value for a key . @job_scheduler : schedulering the jobs . shall implement get_ready_jobs @event_writer : write_events
@return : asyncresult
": param context : http connection context can contain the following key / values : { ' proxy_hostname ' : string , ' proxy_port ' : int , ' proxy_username ' : string , ' proxy_password ' : string , ' key_file ' : string , ' cert_file ' : string ' pool_connections ' , int , ' pool_maxsize ' , int , } : type content : dict"
get http data input global settings .
update http data input global settings .
create http data input .
update http data input .
delete http data input .
get http data input .
get http input limits .
set http input limits .
gets the logger_file .
sets the logger_file .
gets the debug status .
sets the debug status .
gets the logger_format .
sets the logger_format .
gets api key ( with prefix if set ) .
gets http basic authentication header ( string ) .
gets auth settings dict for api client .
gets the essential information for debugging .
returns a dictionary of the response headers .
returns a given response header .
": param method : http request method : param url : http request url : param query_params : query parameters in the url : param headers : http request headers : param body : request json body , for ` application / json ` : param post_params : request post parameters , ` application / x - www - form - urlencoded ` and ` multipart / form - data ` : param _ preload_content : if false , the urllib3.httpresponse object will be returned without reading / decoding response data . default is true . : param _ request_timeout : timeout setting for this request . if one number provided , it will be total request timeout . it can also be a pair ( tuple ) of ( connection , read ) timeouts ."
custom error messages for exception
inlineresponse2003 - a model defined in swagger
gets the cursor of this inlineresponse2003 . special string to return the same items in this array in a future request
gets the next_cursor of this inlineresponse2003 . special string to return the following items in this array in a future request
gets the count of this inlineresponse2003 . total number of poll objects matching this search
gets the items of this inlineresponse2003 .
"' zyfw ' , 主营范围 ' jyps'#经营评述 ' zygcfx ' 主营构成分析"
market engine stock
获取股票除权信息 / 数据库
get the account
0 限价委托 ； 上海限价委托 / 深圳限价委托 1 市价委托(深圳对方最优价格 ) 2 市价委托(深圳本方最优价格 ) 3 市价委托(深圳即时成交剩余撤销 ) 4 市价委托(上海五档即成剩撤 / 深圳五档即成剩撤 ) 5 市价委托(深圳全额成交或撤销 ) 6 市价委托(上海五档即成转限价 )
annualized returns : 策略年化收益率。表示投资期限为一年的预期收益率 。 具体计算方式为 ( 策略最终价值 / 策略初始价值)^(250 / 回测交易日数量 ) - 1
对order / market的封装
[ summary ]
get the order and choice which market to trade
"基准组合的行情数据(一般是组合 , 可以调整 )"
save to mongodb
brinson model analysis
returns a pd - dataframe format accumulate return for different periods
save the performance analysis result to database
"expected recall probability now , given a prior distribution on it . 🍏"
evaluates exp(x ) - exp(y ) a bit more accurately than that . ⚾ ️
variance of recall probability now . 🍋
update a prior on recall probability with a quiz result and time . 🍌
fit a beta distribution to a mean and variance . 🏈
find the half - life corresponding to a time - based prior on recall . 🏀
convert recall probability prior 's raw parameters into a model object . 🍗
callable only on the engines .
"return the str value of ` self.count ` , then increment its value ."
return a ` proxy ` object given an object ` obj ` .
test the mpi_type_for_ndarray method .
estimate pi using ipython.parallel .
"watch iopub channel , and print messages"
return symbolic logic for an n - bit ripple carry adder .
return symbolic logic for an n - bit kogge - stone adder .
return symbolic logic for an n - bit brent - kung adder .
return a solution point for a sudoku grid .
return a solution point for a sudoku grid as a string .
return the input constraints for a sudoku grid .
convert a sudoku solution point to a string .
return the string value for a solution coordinate .
convert a binary - coded vector into a gray - coded vector .
convert a gray - coded vector into a binary - coded vector .
returns number of matches ( tokens )
function to generate an attribute list .
function to declare an element and its sub - elements .
function that combines the output of the two functions above .
recursive function that generates a dtd - template for the xml file .
return graph definitions for this component along with all graphs from the implementation components
"return graph definitions for this software comoponent , along with any graphs from the associated implementation components . this method is for 5.x compatibility"
calculate the bond distance .
calculate the angle ( of the angle ) .
calculate the dihedral angle .
calculate the dihedral angle .
calculate the bond energy using the harmonic potential .
calculate the angle energy using the harmonic potential .
calculate the torsion energy using the periodic potential .
calculate the improper energy using the periodic potential .
intended to be the third plugin that will run and adds a term to the message to signal it has run
plugin used to fix object type discretions with cloudtrail messages
"given a dictionary , potentially with multiple sub dictionaries return a list of the dict keys and values"
"register our criteria for being passed a message as a list of lower case strings or values to match with an event 's dictionary of keys or values set the priority if you have a preference for order of plugins to run . 0 goes first , 100 is assumed / default if not sent"
allow a list or a specific filter / query object to get added to build a query
setup the default options and override with any in our .conf file
validate that a compliance item has all the necessary keys
"the complianceitems plugin is called when an event is posted with a doctype ' complianceitems ' . compliance items are stored in the complianceitems index , with doctype last_known_state"
routines for computing polynomials .
routines for computing polynomials when coefficient of x^n is 1.0 .
evaluates a rational integral .
this class can evaluate an arbitrary cl function implementation on some input data .
evaluate the given cl function at the given data points .
"for functions that require private arrays as input , change the address space of the global arrays ."
create a new optimizer that will minimize the given model using the given environments .
get the optimization flags and settings set to the optimizer .
minimize the given model using the given environments .
"get the optimization result , that is , the matrix with the optimized parameter values ."
"get the return codes , that is , the matrix with for every problem the return code of the optimizer"
get the objective values for each of the problem instances .
simple optimization results container which computes some values only when requested .
args : optimizer_settings ( dict ): extra options one can set for the optimization routine . these are routine dependent .
get the kernel data specific to the optimization routines .
get the optimization kernel function .
get the optimizer calling arguments .
get the optimization cl code that is called during optimization for each problem .
get the cl code for the evaluation function . this is called from _ get_optimizer_cl_code .
return the optimization function as a cl string for the implementing optimizer .
get the call name of the optimization routine .
return all checks for required variables before returning to desired view
"get_experiments will return loaded json for all valid experiments from an experiment folder : param base : full path to the base folder with experiments inside : param load : if true , returns a list of loaded config.json objects . if false ( default ) returns the paths to the experiments"
"load_experiments a wrapper for load_experiment to read multiple experiments : param experiment_folders : a list of experiment folders to load , full paths"
"load_experiment : reads in the config.json for a folder , returns none if not found . : param folder : full path to experiment folder : param return_path : if true , do n't load the config.json , but return it"
"we compare the basename ( the exp_id ) of the selection and available , regardless of parent directories"
"make_lookup returns dict object to quickly look up query experiment on exp_id : param experiment_list : a list of query ( dict objects ) : param key_field : the key in the dictionary to base the lookup key ( str ) : returns lookup : dict ( json ) with key as "" key_field "" from query_list"
"validate : param folder : full path to experiment folder with config.json . if path begins with https , we assume to be starting from a repository ."
"return the raw library , without parsing"
"assumes a flat ( file system ) database , organized by experiment i d , and subject i d , with data ( json ) organized by subject identifier"
"list users , each associated with a filesystem folder"
"print a filesystem database user . a "" database "" folder that might end with the participant status ( e.g. _ finished ) is extracted to print in format"
"generate a new user on the filesystem , still session based so we create a new identifier . this function is called from the users new entrypoint , and it assumes we want a user generated with a token . since we do n't have a database proper , we write the folder name to the filesystem"
"finish user will append "" finished "" ( or other ) to the data folder when the user has completed ( or been revoked from ) the battery . for headless , this means that the session is ended and the token will not work again to rewrite the result . if the user needs to update or redo an experiment , this can be done with a new session . note that if this function is called internally by the application at experiment finish , the subid includes a study i d ( e.g. , expfactory / xxxx - xxxx ) but if called by the user , it may not ( e.g. , xxxx - xxxx ) . we check for this to ensure it works in both places ."
"restart user will remove any "" finished "" or "" revoked "" extensions from the user folder to restart the session . this command always comes from the client users function , so we know subid does not start with the study identifer first"
retrieve a subject based on a token . valid means we return a participant invalid means we return none
"refresh or generate a new token for a user . if the user is finished , this will also make the folder available again for using ."
"revoke a presently active token , meaning append _ revoked to it ."
"save data will obtain the current subid from the session , and save it depending on the database type . currently we just support flat files"
init_db for the filesystem ensures that the base folder ( named according to the studyid ) exists .
"apply the "" almost "" part of almost from scratch . create a column that contains the tokens capitalization . only difference from acutal nlp ( almost ) from scratch is that i 'm adding punctuation and digit information"
pad and window sentence example for winlen of 1 for part of speech tagging
output sentence for convolution . each sentence is output with relative position information from the classifying token
write vocab and features to a file for embedding visualization
shamelessly stolen from cifar 10 in tf tutorial :)
update the state of the file(s ) at self._tree_cache['path ' ]
class decorator for setting a widget template
pick only the vcs with the longest repo root
should encode the element from first to the element is_last = true .
set up function .
reference data should follow referencefield .
the decoded reference data should be self.reference .
actually data store .
should encode the element from first to the element is_last = true .
init the class .
init the class .
build multinet from csv files .
add nodes represents the layers in multiplex network to the bipartite graph
project a multinet to a bipartite graph using layer - node view .
project a multinet to a bipartite graph using layer - edge view .
project a multinet to a bipartite graph using layer - edge view .
return two nodes sets of a bipartite graph .
reconstruct a multiplex network from a layer - edge bipartite graph .
new measure working in progress .
extract the information on a concrete project version from pkg_configs requirement information .
read the list of requested software .
verify whether the given version of the package is matched by the given requirements file .
saves the ` data ` object ` d ` in the photon - hdf5 format .
normalize and type - check a record dict .
write a database csv file .
notify that a record has been changed and the database should be written to disk .
return all existant devices .
execute a config file or directory with the special environment .
wait for the provided deferred before assuming the configuration to be finished .
set whether clients are allowed to send output to the server audio device .
deprecated alias for self.features.(en|dis)able('stereo ' ) .
flask app factory function .
"returns a json response , transforming ' context ' to make the payload ."
convert the context dictionary into a json object
check if the request should be permitted . raises an appropriate exception if the request is not permitted .
"common params for app_container , ssl , etc . it 's safe to pass salt module useless params , which are simply ignored"
"simple login view , always redirect to surface root"
repalce aggregation output of pk with groupserializer
"convert cms i d to tars i d , complete application if not given"
"if ' i d ' field is found in request body , we assume the new deployment is derived by an old deployment , treat as original_deployment , and the rop of the original deployment will be reused ."
"in incre - deploy mode , we should never rollback as it indeed cannot ."
find a file on the path
set up selenium
inserts one element in your queue
"removes ( or ' pops ' ) the first element from your queue and returns it . if the queue is empty , raises a valueerror ."
base : int or float . exp : int > = 0
uses a generator to create a variety of lat - lon 's across the global and tests a range of precision settings from 4 to 8
filter out hosts with more nodes per ip
"translate a list of gdal filenames , into file_info objects ."
initialize file_info from filename
makes it possible to activate / prevents the activation of quick nav based on the current object .
activates quick nav .
deactivates quick nav .
concatenates script names to be used with the current rotor setting .
turns quick nav either on or off if possible .
session that is reused across tests
session that is reused across tests
decorates a kwarg accepting function to deprecate a renamed kwarg .
decorates a method / property that was moved to another location .
deprecates a function that was moved to another location .
decorates an * instance * method that was moved to another location .
decorates an * instance * property that was moved to another location .
deprecates a class that was moved to another location .
warns about some type of deprecation that has been ( or will be ) made .
helper to generate a common message ' style ' for deprecation helpers .
helper to fix / workaround https://bugs.python.org/issue3445
get class name for object .
gets the ` ` self ` ` object attached to this method ( or none ) .
generate a name from callable .
"create the geometry content for a single object . creates a node_library , geometry_library"
create a scene node instance for the given object .
create the content for the data file of each object . contains the node_library and geometry_library .
create the content of the scene file as a list of entries into the scene 's node - list .
merge multiple * _ libraries into one and gives them a common i d. it simply joins the entries of the given list of dictionaries .
create a json scene containing the given nodes .
"create assets for the given objects . export_dic lists the objects that are to be exported , its keys are composed of tuples ( type , blender - object ) , values is the dataid . kwargs can contain additional properties for exporting ."
write assets to the lib - directory .
test reordersmoothskinninginfluencesop types
test reordersmoothskinninginfluencesop with same names
test reordersmoothskinninginfluencesop with reordered names
test reordersmoothskinninginfluencesop with wrong names
test reordersmoothskinninginfluencesop with extra names
test reordersmoothskinninginfluencesop with no new names
test copy - on - write behavior
test search functions
test update function
test setdefault function
test pop functions
test keys / values listing
test equality function
test by value return type
test load / save
testing meshprimitiveevaluator with empty mesh
testing meshprimitiveevaluator with mesh containing single triangle
testing meshprimitiveevaluator with sphere mesh
testing special case of intersection query .
testing meshprimitiveevaluator with random triangles
test attributecache constructors
test attributecache read / write
test attributecache read / write headers
test attributecache attributes
test attributecache remove
test attributecache contains
test attributecache overwriting
test orientation of dpx files
test parameterised subclassing
segement each digit of a picture
"shortcut for get /v1 / query , except with argument format='dataframe ' ( the default ) , in which case it will simply wrap the result of the get query to /v1 / query ( with format='table ' ) in a ` pandas . dataframe ` ."
"put and track progress , displaying progress bars ."
"post and track progress , displaying progress bars ."
"takes the contents of the message parameter , formatted as in rfc 2822 , and encrypts them , so that they can only be read by the intended recipient specified by pubkey . : return : string containing the new encrypted message ."
return a cluster list from the model .
return a cluster object by its name
return a list of services from a cluster name
this method returns a service list as a dict list .
this method returns a service as a dict .
build a service dictionary
to do . this function should wrap everything up .
forms the knn model .
calculates the distance between a training and test instance .
returns a tensor with distances between all training and testing instances .
gets the scaling factors for each dimension from the training data .
trims the training data so there are an equal number in each class .
chooses the kernel to use .
concatenates multiple ttrees of different classes into one ndarray .
creates a one - hot array from ttrees representing different classes .
creates a binary array ( -1 to 1 ) from a signal and background ttree .
converts the ttrees to the main data structure .
chooses which cost function to use .
tiles two tensors in perpendicular dimensions .
returns the linear kernel ( dot product ) matrix of two matrices of vectors element - wise .
returns the gaussian kernel matrix of two matrices of vectors element - wise .
returns the kernelised cost to be minimised .
tests a set of test instances .
: return : a redirection to the oauth server ( oauth_authorization_url ) provided in the settings
log out user
context manager for reserving a client from the pool .
fill * n_slots * of the pool with clones of * mc * .
reserve a client .
relinquish any reserved client for the current context .
"translate / normalize specification * server * into 4 - tuple ( scheme , addr , port , weight ) ."
turn numeric constants into symbolic strings
inverse function of behaviors_symbolic
initialize a memcached client instance .
gets the behaviors from the underlying c client instance .
sets the behaviors on the underlying c client instance .
measure reference counts during testing .
get a subaspect from an aspectclass or aspectclass instance .
explode an aspect into list of its leaf aspects .
"instantiate an aspectclass with specific ` taste_values ` , including parent tastes ."
"get a dictionary of all taste names mapped to their specific values , including parent tastes ."
do n't allow attribute manipulations after instantiation of aspectclasses .
contains documentation for an aspectclass .
tests whether ` ` traverse_graph ` ` throws a ` ` circulardependencyerror ` ` on a given cyclic graph .
creates a test which tests the ` ` traverse_graph ` ` function .
extracts all documentation texts inside the given source - code - string using the coala docstyle definition files .
generates diff between the original doc_comment and its fix new_comment which are instances of documentationcomment .
checks and handles the fixing part of documentation .
this function creates an argparser to parse command line arguments .
creates a new textposition object that represents the position inside a string with line / column numbers .
test whether ` ` self ` ` is behind or equals the other ` ` textposition ` ` .
test whether ` ` self ` ` is ahead of or equals the other ` ` textposition ` ` .
this docstring will not be lost .
find every possible term this word could be . our variant table holds every possible conjugation and declension .
"find every possible term that this word could be , tolerating spelling errors ."
get keystone client
get nova client for the region .
get cinder client for the region .
get neutron client for the region .
get glance client for the region .
get list of all region names
get a user by name or i d
get all user projects
get a project by name or i d
get all users in project
error(message : string )
this is used to populate the --help argument on the command line .
to be implemented by subclasses .
converts an object and returns a ` ` json``-friendly structure .
"convert the screenplay into html , written to the file - like object ` out ` ."
"convert the screenplay into a complete html document , written to the file - like object ` out ` ."
"convert the screenplay into html , written to the file - like object ` out ` . does not create a complete html document , as it does n't include < html > , < body > , etc ."
initializes the formatter .
converts a number of paragraphs into html and writes it to the output stream . ` screenplay ` is a sequence of paragraphs .
": return : list of all device ids from xinput , excluding xtest devices ."
"open file , move cursor to ( row , col ) , and run cell . : param row , col : new cursor position in the matlab editor . 1 - indexed . : param filename : absolute path to target file ."
": param commands : list of matlab commands to run in command window . : param is_invisible : insert backspaces to erase command window if true . : param is_multiline : if true , delimiter will be , otherwise semicolon ."
": param row , col : new cursor position in the matlab editor . 1 - indexed . : param filename : open this file before moving the cursor . : param callback_name : matlab sends this tcp message back after the operation completes . : return :"
": rtype : list of strings : return : [ command widow i d , editor window i d ] : raise exception :"
": return : list of all device ids from xinput , excluding xtest devices ."
pick an unused port and start a tcp server . matlab will send callback requests through this socket . : return : port
"routine for a process that handles key press requests from matlab . : param port : : param window_ids : [ command window , editor window , vim window ] : param queue :"
"calculates regression line parameters using m=(x'y'-(xy)')/((x')^2-(x^2 ) ' ) b = y'-m*x ' where x ' is a mean of x values and so on . thus a tuple is returned with ( m , b ) of the line y = mx+b ."
calculates the r^2 or the coefficient of determination.uj
test finding the field that represents the parent / child relationship in a normal ` foreignkey ` backed relationship .
test finding the field that represents the parent / child relationship in a ` genericforeignkey ` backed relationship .
test finding the field that represents the parent / child relationship in a ` manytomanyfield ` backed relationship when the child model is the one which has the ` manytomanyfield ` declared on it .
test finding the field that represents the parent / child relationship in a ` manytomanyfield ` backed relationship when the parent model is the one which has the ` manytomanyfield ` declared on it .
test that the serializer field can be found when it is the same name as the child to parent accessor attribute name .
test that the serializer field can be found when the serializer field has the ` _ i d ` suffix as is sometimes the case with ` foreignkey ` fields .
test that a field declared on a base class of the serializer is still found . just in case there is something fishy going on with ` serializer.base_fields ` .
for the relationship where childparent.parent is a foreignkey field which points to the parentmodel
the manager class that django uses for reverse relationships is constructed dynamically using code generation so this is an approximation guaranteeing they are the same .
"retrieve user config , empty dict if no config exists ."
save user config .
returns all hosts .
"given a livequery , returns all matching hosts ."
returns a specific host .
returns config from a specific host .
returns a wsgi filter app for use with paste.deploy .
initialize auth header list .
handle incoming request .
remove headers so a user ca n't fake authentication .
remove http headers from environment .
add http headers to environment .
convert header to wsgi env variable .
get http header from environment .
redirect client to auth server .
submit a new check result .
returns all macro modulation objects .
create a new macro modulation object .
returns a specific macro modulation .
update a specific macro modulation .
returns a specific macro modulation .
returns all contact groups .
create a new contact group .
delete a specific contact group .
update a specific contact group .
returns a contact group .
returns all time periods .
create a new time period .
returns a specific time period .
update a specific time period .
returns a specific time period .
gets a dataset tuple with instructions for reading 2d shapes data .
rotate a pil image and return the output image and size .
scale a pil image and return the output image and size .
paste input image at given location on a black canvas .
intializes the perturbations for images .
initializes the canvas image on which we overlay a digit .
binds an mnist image to the canvas .
construct the unimodal variational autoencoder .
gives a set of networks for the convolutional multi vae .
get color according to different possible correctness combinations .
plot images in a tight grid with optional labels .
draw a single image as a stand - alone figure with an optional border .
turn a pyplt figure into an np image array of bytes or floats .
defines a cnn model for classifying mnist digits
locate all files matching supplied filename pattern in and below supplied root directory .
show the latest published puzzle .
show a puzzle by puzzle number .
redirect from the old url scheme where no author is specified .
edit a saved crossword .
show a solution by puzzle number .
initialise the online puzzle creation page with images of the available grids .
"save a puzzle to the database , then redirect to show it ."
show a list of users and their puzzles .
show a list of puzzles belonging to the logged in user .
"enters the default context ( as returned by # get_ddefault_context ( ) ) and registers the exit function with # atexit.register ( ) . the returns the result of the default context 's ` require ( ) ` with the specified arguments , or alternatively the result of a require at the specified * directory * ( keyword argument only ) ."
return dictionary of wiki urls by name .
sets the file in local storage . returns file name .
gets the specified file from local storage .
varint encoder / decoder .
encode an integer up to 64 bit to varint .
decode an integer up to 64 bit from varint .
output the encoded value to the standard output .
output the decoded value to the standard output .
show module that fails to load .
adapt the pool to the profile size .
clone a resource .
retrieve resource attributes .
reset profile and remove all resources from the host .
pop one resource from the pool .
push one resource by i d.
reclaim a resource and rebuild it .
destroy a single resource .
name of resource .
return the name of the resource .
"list all code snippets , or create a new snippet ."
retrieve specific profile .
ac_seconds quire a vm that is ready .
release vm .
parses a multi - matrix file from uniprobe
: todo switch to reading hdf5
nsamps - number to sample from mcmc posterior
"test to calculate the unique regions such that , given an annotation , regions are unique iff a set of s. note , regions defined in such a manner can be disjoint ."
calculate the number of surrogate variables
convert temperature in degrees celsius to degrees kelvin .
convert temperature in degrees kelvin to degrees celsius .
convert angular degrees to radians
convert radians to angular degrees
adds a new item to the order with all of the required keys .
connecting to shipstation required an account and a : return :
this is a constructor for connectedcomponent class .
this method find any connected component in a graph .
the processed string are preprocessed message from raw event log messages .
get longest common substring from multiple string .
constructor of class dunnindex .
get distance from a node to its neighbor .
maximum node distance as diameter to show a compactness of a cluster .
separation or minimum distance between clusters .
get dunn index . the basic formula is separation / compactness [ liu2010 ] _ .
handling backup file works
update_persons joins test lists correctly
"constructor . called in the urlconf ; can contain helpful extra keyword arguments , and other things ."
"if ` message.method ` does not correspond to a handler method , determine what kind of exception to raise ."
"returns a dict that is passed through to exception_handler , as the ` context ` argument ."
"return some descriptive text for the view , as used in options responses and in the browsable api ."
returns the initial request object .
update the database.php file with settings from the chosen environment
create an empty database in mysql dropping the existing database if need be .
create redcap tables via the remote host
move the redcap / edocs folder out of web space .
deploy the redcap cron task .
"deploy a new redcap instance defined by < package_name > , optionally forcing redcap cron deployment"
"assert that all connections in the connections list exists in the cfg , as well as all connections not in the list do not exist ."
optionally set import names and module name .
add definition to list .
get definitions by name .
set definition by name .
""" nrml "" < num bytes for this form > , { ulong } "" bmsh "" < version , of this basicmesh . note : this should always be 1400 ( type does n't matter ) , big endian(be ) > { ulong } < lod of the mesh(es ) , little endian(le ) > { ulong } < number of mesh(es ) in this bmsh form , le > { ulong } < stat(material ) number used , probably le > { ulong } < vertex mask , this is 27 for normal multi - meshes , and 11 if the vertex data only has x y z co - ords ( no normals , uvs , of colours ) ( ie not a background ) , le > { ulong } ? ? ? < num vertices in this part , le > { ulong } < vertex data ... > < num face lists\strips , le > , { ulong } < face list data ... > ---- vtxd ---- < co - ords , le > { float , ie single } < filler1 , always 1 , le > { float , ie single } < vertex normal , le > { float , ie single } < filler2 , always 1 , le > { float , ie single } < uv coords > { float , ie single } ---- end ---- ---- facd ---- < type of facelists , 514 ( ( optimized ? ) strips ) or 518(lists ) , le > , { ulong } < number of faces this this list , not faces , but entries , for lists , this is numfaces * 3 , for strips , this is , should be , numfaces - 2 , le > , { ulong } < face list , in triplets , le > , ushort ( important ! ! ! this starts from zero ! wobj starts from 1 ! ) ( strips are a bit ... different that lists , stay sharp ) ---- end ----"
it adds inline comment to selected lines based on the file extesion .
it removes the inline comments .
used to drop irc commands .
create areavi instance for a target and installs basic irc commands .
create private messages channels .
private messages sent to the user are handled here .
drop msgs and update the areavi .
"allocate a new struct of the given size , and write the resulting pointer at position i. return the newly allocated position ."
"allocate a new list of the given size , and write the resulting pointer at position i. return the newly allocated position ."
similar to copy_from_pointer but : 1 . it assumes that p is a pointer to a struct
"copy from : basesegment src , pointer p living at the src_pos offset to : segmentbuilder dst at position dst_pos"
"returns true / false for whether a is evenly divisible by b within a ( small ) numerical tolerance examples -------- > > > isevenlydivisiblefloat ( 1.5 , 0.5 ) true > > > isevenlydivisiblefloat ( 1.0 , 1./3 ) true"
"returns true / false for whether a and b are numerically "" close "" aka roughly equal at m significant figures"
initialize ( in - place ) the global params of the given hmodel by copying the global parameters of a previously saved hmodel
"args ------- seed : integer seed for random number generator , used for actually * generating * the data nobstotal : total number of observations for the dataset ."
"args -------- seed : integer seed for random number generator , used for actually * generating * the data dataorderseed : integer seed that determines ( a ) how data is divided into minibatches ( b ) order these minibatches are traversed"
grab data from database to initialize ( used only once really )
"data is primarily loaded through admixminibatchiteratordb . if creating from database , put in true number of documents and vocabulary size for the entire corpus initialize with only a handful of documents however , specified by doc_id_select"
"constructs the pubsub for summarization for now this is not used , but could be if pubsub was added"
serves the summarization page
set summarization status for a folder and publish to the main menu
grabs the relevant summarize db items for a folder id
"the learning step for the summarize model . each document in the folder is sentence segmented , and each sentence classified as being a fact or not ."
returns the full text of the document whose id was posted
add the posted sentences to the current summary
"using a similarity metric and a query , get the top candidates from a folder"
post json of doc index / sentence index pairs to form a query
post json of doc index / sentence index pairs to form a query
"posting json of doc index / sentence index pairs deletes them from the current summary , and returns the new summary to update the summary page"
sets the global variable ` wantdown ` to ` true ` to stop everything after the current files have been processed .
"returns a list of maximum ` count ` filenames ( as fileformat matches ) to process , given the ` directory ` and the ` sensor ` ( or , if it is ` none ` , from any sensor ) ."
creates the insertion process for the given ` sensor ` using ` progname ` .
"this function is the main loop , creating the processes when needed and feeding them with the data from the files ."
parses the arguments and call worker ( )
"coarse pos tags of treebank corpus : n : noun , v : verb , a : adjective , d : adverb , z : pronoun , t : determiner , e : preposition , p : postposition , u : number , j : conjunction , o : punctuation , r : residual , l : classifier , i : interjection"
the entry point of the application .
a callback method used by a publisher to notify this subscriber about updates .
a callback method used by a publisher to notify this subscriber about updates .
add a new subscriber .
remove an existing subscriber .
send update data to to all registered subscribers .
construct a regular triangular mesh in the unit square
create prolongator using direct interpolation
linear elasticity problem discretizes with q1 finite elements on a regular rectangular grid
q1 elements in 2 dimensions
local stiffness matrix for two dimensional elasticity on a square element
p1 elements in 2 or 3 dimensions
local stiffness matrix for p1 elements in 2d
local stiffness matrix for p1 elements in 3d
"conjugate gradient , normal error algorithm"
parse each rule line and return a dict representation of a rule : param rule_line : : return : rule dict
: param filename : the rule file to parse parse the rule file to use in reporting : return : rule_dict : return a dict of rule_id : rule
"reverse the regular expression , returning a string that would match it ."
"resolve a dictionary of capture group values ( mapped from either their names or indices ) , returning an array of those values ( "" mapped "" only from capture groups indices ) ."
generates string matching given sequence of nodes from regular expressions ' abstract syntax tree ( ast ) .
generates string matching given node from regular expression ast .
generates string matching the ` ` sre_parse . literal ` ` node from regexp . ast .
generates string matching the ` ` sre_parse . not_literal ` ` node from regexp . ast .
generates string matching the ` ` sre_parse . in ` ` node from regular expr . ast .
generates string matching ` ` sre_parse . min_repeat ` ` or ` ` sre_parse . max_repeat ` ` node from regular expression ast .
generates string matching the ` ` sre_parse . branch ` ` node in regular expr . ast .
generates string matching the ` ` sre_parse . subpattern ` ` node in regular expr . ast .
generates string matching the ` ` sre_parse . groupref ` ` node in regular expr . ast .
generates string matching the ` ` sre_parse . groupref_exists ` ` node in regexp . ast .
return chars belonging to charset of given name . : param flags : optional flags override
returns negated version of given charset .
initialize the instance of this class .
find samllest eigenvalue of the hm matrix .
generate the bases of the krylov subspace .
return the representation of vectors and matrix in the krylov space .
return the representation of vectors and matrix in the krylov space .
"a short syllable in a word is either : - a vowel followed by a non - vowel other than w , x or y and preceded by a non - vowel - a vowel at the beginning of the word followed by a non - vowel . checks the three characters before the given index in the word ( or entire word if none ) ."
a word is called short if it consists of a short syllable preceded by zero or more consonants .
"r1 is the region after the first non - vowel following a vowel , or the end of the word if there is no such non - vowel ."
"r2 is the region after the first non - vowel following a vowel in r1 , or the end of the word if there is no such non - vowel ."
"returns the index of the first vowel in the word . when no vowel is found , returns len(word ) ."
returns true if there is a vowel in the given string .
returns the number of consecutive vowel - consonant pairs in the word .
step 1a handles -s suffixes .
step 1b handles -ed and -ing suffixes ( or -edly and -ingly ) . removes double consonants at the end of the stem and adds -e to some words .
"step 1c replaces suffix -y or -y by -i if preceded by a non - vowel which is not the first letter of the word ( cry = > cri , by = > by , say = > say ) ."
step 2 replaces double suffixes ( singularization = > singularize ) . this only happens if there is at least one vowel - consonant pair before the suffix .
"step 3 replaces -ic , -ful , -ness etc . suffixes . this only happens if there is at least one vowel - consonant pair before the suffix ."
"step 4 strips -ant , -ent etc . suffixes . this only happens if there is more than one vowel - consonant pair before the suffix ."
"step 5a strips suffix -e if preceded by multiple vowel - consonant pairs , or one vowel - consonant pair that is not a short syllable ."
"step 5b strips suffix -l if preceded by l and multiple vowel - consonant pairs , bell = > bell , rebell = > rebel ."
applies the letter case of the word to the stem : ponies = > poni
"sets the initial y , or y after a vowel , to y. of course , y is interpreted as a vowel and y as a consonant ."
"returns the stem of the given word : ponies = > poni . note : it is often taken to be a crude error that a stemming algorithm does not leave a real word after removing the stem . but the purpose of stemming is to bring variant forms of a word together , not to map a word onto its "" paradigm "" form ."
returns the given value as a unicode string ( if possible ) .
returns the given value as a python byte string ( if possible ) .
"cache with data stored as files with hashed filenames . content retrieved from urls and search engines are stored in cache for performance . the path where the cache is stored can be given . this way you can manage persistent sets of downloaded data . if path = tmp , cached items are stored in a temporary folder ."
"returns the data stored with the given i d. with unicode = true , returns a unicode string ."
"returns the age of the cached item , in days ."
clears all items from the cache ( whose age is the given amount of days or older ) .
produces graphviz representation of pytorch autograd graph
ensure string is binary
name of benchmark
"give a coords , a polygon and max_ratio , generate random position inside a polygon or inside circle generated by center and max_ratio ."
test that the backward - compatible ` ` zestiamte ` ` works .
returns the route uri for current session
invokes the image streaming service for the creation of a new route for the current session
invokes the image streaming service for the removal of an existing route for the current session
queries the image streaming service for the route corresponding to the current session
"creates an http request and invokes the image streaming service : param method method to be used by the http request ( get , post , delete , etc ) : param uri json formatted uri to attach to the http request : return 200 if successful , error code and message otherwise"
"checks for active sessions . if no keep - alive message was received in the last n seconds , the session is closed ."
wrap the lua_object into a class using the data as the container for all the relevant factorio data .
this returns the list of all tables that comprise the subclasses of the given type .
convert a table ( pseudo-)name into a class name in this module .
parse and convert the value according to the descriptor type . the data parameter is the reference to the factorio context variable .
convert a luatable into a python list or dict . this is not recursive .
this creates a python class object with the given name and superclass .
the key in the table of this data object . other properties may refer to this thing by this name . the localization also uses this name to find the localization key .
the table in which this thing will be inserted .
returns a json - ifiable dictionary for this data member .
load json from ( ram)disk .
dump json to ( ram)disk atomically .
close the file here ( to be overloaded )
"returns the n - th block of the array . : param idx : the block number to return . can be specified as flat index or as tuple . : param index : if set to true , additionally the centre coordinates of the block are returned ."
"returns an iterator of all input blocks . : param index : if set to true , additionally the centre coordinates of the blocks are returned ."
sets ( accumulates ) the blocks provided by getiterblocks ( ) and processed after .
sets ( accumulates ) the n - th block of the result . : param block : the processed block : param idx : the block number to return . can be specified as flat index or as tuple .
returns the ( accumulated ) output array .
"returns a single event or a tuple of from / to events in case of a paired move event . if this buffer has been closed , immediately return none ."
"read event from ` inotify ` and add them to ` queue ` . when reading a in_move_to event , remove the previous added matching in_move_from event and add them back to the queue as a tuple ."
create a public / private key pair .
create a certificate request .
generate a client certificate : param cname : the client name : type cname : str : param email : the client email address : type email : str : param serial : a certificate serial number to set : type serial : int : param desc : the client description : type desc : str : returns : generated pub and priv key certificate . : rtype : tuple of bytes
returns certificate authority .
returns certificate authority private key .
automatically populate function handlers from the handlers
this code routes requests to the appropriate handler
pretty print the dictionary ' params '
get parameter names for the estimator
get parameters for this estimator .
set the parameters of this estimator .
"evaluate the reward function for the ( state , action ) pair"
dimension of the reward function
reward loss between ` ` r1 ` ` and ` ` r2 ` `
execute a local controller at ` state ` using ` action ` for period lasting ` duration `
generate a trajectory by executing the local controller
check if a state is terminal ( goal state )
find the true reward function
initialize reward function based on solver
compute the policy induced by a given reward function
"the scrapy documention said that : "" if it returns a request object , the returned request will be rescheduled ( in the scheduler ) to be downloaded in the future . the callback of the original request will always be called . if the new request has a callback it will be called with the response downloaded , and the output of that callback will then be passed to the original callback . if the new request does n’t have a callback , the response downloaded will be just passed to the original request callback . "" but actually is that if it returns a request object , then the original request will be droped , so you must make sure that the new request object 's callback is the original callback ."
: param str|unicode username : user name : param str|unicode password : user _ password : param str|unicode|none prime : prime hex string . default : prime_1024 : param str|unicode|none generator : generator hex string . default : prime_1024_gen : param str|unicode hash_func : function to calculate hash . default : hash_sha_1 : param str|unicode multiplier : multiplier hex string . if not given will be calculated automatically using _ prime and _ gen . : param int bits_random : random value bits . default : 1024 : param int bits_salt : salt value bits . default : 64
: param val : : rtype : bytes
: param args : : param kwargs : joiner - string to join values ( args ) as_bytes - bool to return hash bytes instead of default int : rtype : int|bytes
generates a random value .
s = random
u = h(pad(a ) | pad(b ) )
s = ( b - ( k * g^x ) ) ^ ( a + ( u * x ) ) % n
k = h(s )
s = ( a * v^u ) ^ b % n
a = random ( )
b = random ( )
a = g^a % n
b = ( k*v + g^b ) % n
"x = h(s | h(i | "" : "" | p ) )"
v = g^x % n
m = h(h(n ) xor h(g ) | h(u ) | s | a | b | k )
h(a | m | k )
"( < _ user > , < _ password verifier > , < salt > )"
test all files in test_files that start with test_*.pan using lint_file
"function to create a tf - idf list of dictionaries for a corpus of docs . if you opt for dumping the data , you can provide a file_path with .tfidfpkl extension(standard made for better understanding ) and also re - generate a new tfidf list which overrides over an old one by mentioning its path ."
hacks into dumper and changes its fetchvariables method to a wrapper that calls stop_event_handler . this allows us to retrieve the list of locals every time the user changes the local stack frame during a debug session from qtcreator interface .
set a list of attributes to extract
set a list of fields to extract as target args : attrs ( list ): a list of strings refering isear fields .
tell the extractor whether to load the free text field . behaviour is true by default
serializes an array for the vector space myvs
deserializes an array for the vector space myvs
memory allocation and size setting
y < - x ( shallow . no memory allocation . )
x < - alpha * x
x < - 0
y < - alpha * x + y
"< - < x , y >"
x < - random
"jordan product , z < - x o y"
"identity element , x < - e such that x o e = x"
"jordan product inverse , z < - inv(l(x ) ) y where l(x ) y = x o y"
"barrier function , < - barr(x ) where x o grad barr(x ) = e"
"line search , < - argmax { alpha \in real > = 0 : alpha x + y > = 0 } where y > 0"
"symmetrization , x < - symm(x ) such that l(symm(x ) ) is a symmetric operator"
"solves an equality constrained optimization problem basic solve : getmin(x , y , msg , fns , state ) solve with a state manipulator : getmin(x , y , msg , fns , state , smanip )"
deamonize class . unix double fork mechanism .
start the daemon .
stop the daemon .
restart the daemon .
you should override this method when you subclass daemon .
set up braintree calls that the controller will use .
server / build information
list installed packages ordered by size
return a list of preserved libraries ( if any )
list the best available versions in portage for the specified packages
list the installed versions for the specified packages
print yes / no is there is an update available for the specified package
return a list of runs made for the day
a list of runs made for the day
return a list of downgrades
a list of merge downgradess
return information on the server
"handle gentoo - sources , aufs - sources ... etc"
remove the kernel and kernel modules of the specified kernel version . also remove the efi entry ( on an efi ) server .
unmerge the specified kernel source tree
remove binaries and source tree of the specified kernel ( if they exist ) . does not remove binaries if the kernel is the one that is actually running .
generate a server report
build a context for subsequent rendering
return the current profile
the current profile
initializer method for client object
method to add noise to client
method to test equality of two clients
"fill out a list of kargs based on the given request and its post arguments . will iterate over all of the allowable scoreresult fields , and will add an item into the kargs dicitionary for each one , using the fields default value if it is not present in post . the result will be a dictionary of field_name - > integer value"
"creates a new score result and match ( if possible ) . uses the team and match number from the form to search for an existing score result . if one exists , it will re - direct the user back to the form so they can attempt to input the data again ."
return the canonical string representation of the frontend .
return a nice string representation of the frontend .
join all startup channels as specified by the config file .
process a single message from irc .
store credentials ( * cred * ) and * opener * for searching later on .
return the canonical string representation of the search engine .
return a nice string representation of the search engine .
open a url ( like urlopen ) and try to return its contents .
return a list of packages required by this search engine .
use this engine to search for * query * .
do a bing web search for * query * .
do a google web search for * query * .
"works like urllib.urlencode ( ) , but uses % 20 for spaces over + ."
do a yahoo ! boss web search for * query * .
do a yandex web search for * query * .
publish some data
called to connect or open a connection / file .
close current stream / connection .
will this mutation strategy ever end ?
return the number of test cases .
go to next test sequence . throws mutatorcompleted when we are done .
return the current mutator in use .
called as we start a test case .
called as we exit a test case
called if a fault was detected during our current test case .
called as we enter the state machine .
called as we exit the state machine .
called as we enter a new state .
called as we exit a state .
called before state is changed . if result if non - none we can select a different state to change to .
called as we enter an action .
called as we exit an action .
called before getting a value from a data model .
set up the key schedule from the encryption key .
: param salt : salt for crypt ( optional ) : type salt : str
@type msg : string @param msg : value to output @type generator : generator @param generator : generator to wrap
"@type group : group @param group : group to use @type startingdepth : integer @param startingdepth : how many deep to start at , default 1 @type increment : integer @param increment : incrementor , default 1 @type maxdepth : integer @param maxdepth : max depth , default 1000 @type nodeprefix : generator @param nodeprefix : node prefix , default is static('peachfuzz ' ) @type nodepostfix : generator @param nodepostfix : node postfix , default is none @type elementattributes : generator @param elementattributes : element attributes , default is none"
"@type group : group @param group : group to use @type startingdepth : integer @param startingdepth : how many deep to start at , default 1 @type increment : integer @param increment : incrementor , default 1 @type maxdepth : integer @param maxdepth : max depth , default 1000 @type nodeprefix : generator @param nodeprefix : node prefix , default is static('peachfuzz ' )"
@type group : group @param group : group this generator belongs to @type testfiles : string @param testfiles : location of test files
@type group : group @param group : group this generator belongs to @type testsfolder : string @param testsfolder : location of test files @type testsfile : string @param testsfile : file with listing of test files
@type group : group @param group : group this generator belongs to @type testsfolder : string @param testsfolder : location of test files
@type group : group @param group : group this generator belongs to @type testsfolder : string @param testsfolder : location of test files
@type group : group @param group : group this generator belongs to @type testsfolder : string @param testsfolder : location of test files
@type group : group @param group : group this generator belongs to @type testsfolder : string @param testsfolder : location of test files
extract a metadata link tuple from an xml node
load the widgets and setup for the annotations ' display .
insert text annotations into the tree view that displays them .
adjust wrap width in annotations when they are resized .
try scrolling the annotations window .
set up the required widgets and queue an initial draw .
remove current media overlays .
remove current media overlays .
"remove current media overlays , add new ones if page contains media ."
resize all media overlays that are a child of an overlay
adjust the relative margins of child widgets for notes mode update .
starts playing a media . used as a callback .
stops playing a media and hides the player . used as a callback .
toggles playing and pausing a media . used as a callback .
set the player of a given media at time t. used as a callback .
check whether the vlc support is enabled or not .
set the cursor named cursor_name '
manage events on the current slide label / entry .
manage key presses for the editable label .
perform the actual work of starting the editing .
"make sure that the editable label is not in entry mode . if it is an entry , then replace it with the label ."
start the editing of the label if it is disabled .
disable the editing of the label if it was enabled .
load all the widgets we need from the spinner .
"set the max number of pages , both on display and as the range of values for the spinner ."
get the page number from the spinner and go to that page
make the ui re - display the pages from before editing the current page .
"implement directions ( left / right / home / end ) keystrokes , otherwise pass on to : func:`~gtk . spinbutton.do_key_press_event ( ) `"
scroll event . pass it on to the spin button if we 're currently editing the page number .
perform the actual work of starting the editing .
"make sure that the current page number is displayed in a label and not in an entry . if it is an entry , then replace it with the label ."
update the displayed page numbers .
setup the talk time .
"connect callbacks later than at init , due to circular dependencies . call this when the page_number module is initialized , but before needing the callback ."
update estimated talk time from the input/
pass on keystrokes to : func:`~gtk . entry.do_key_press_event ( ) `
perform the actual work of starting the editing .
"make sure that the current page number is displayed in a label and not in an entry . if it is an entry , then replace it with the label ."
a response is valid if server code is 2xx . it is recoverable in case of server error 5xx .
user_id is email in case of kanbox
return a cquota object .
"upload returns a single char "" 1 "" as response"
"wrapper for scipy.spatial.distance.pdist function . returns a distance matrix in squareform for a 1d array of x , y coordinates"
wrapper for the different distance functions .
returns the upper triangle of the distance matrix for an array of 2d coordinates .
returns the upper triangle of the distance matrix for an array of n - dimensional coordinates . : param x : np.array of n - dimensional coordinates : return : upper triangle of the distance matrix
convert good - sounds path to codes / parameters .
convert a base directory of good - sounds files to a pandas dataframe .
"segment an audio file given an onset file , writing outputs to disk ."
parameters ---------- segment_index_file : str input file containing all pointers to audio files and onsets files .
test that an input folder with files in rwc format is correctly converted to a dataframe .
"runs a subprocess as a coroutine . returns its exit code , its stdout string , and its stderr string . args is passed whoesale as the first parameter value to tornado.process . subprocess . kwargs are expanded as keyword parameters values to tornado.process . subprocess ."
converts a tmpnb id to a docker container id .
hashes a username as an identifiable volume prefix .
bcrypts a password as an unidentifiable volume suffix .
"gets if the password "" unlocks "" the given volume ."
creates a new volume .
mounts an existing volume on the given tmpnb container .
unmounts a volume from the tmpnb container .
"gets the volume id given its prefix , if it exists ."
gets if the container already has a volume mounted .
"creates a new docker volume for the user protected by the given password if the proper registration key is provided . errors if the key is incorrect / missing , if the volume already exists , or if the volume can not be created for any other reason ."
mounts the given docker volume on the given running container using nsenter .
@todo : to be defined1
@todo : docstring for depth : returns : @todo
@todo : docstring for ticker : returns : @todo
@todo : docstring for trades : returns : @todo
@summary : get information about funds .
@summary : order placement .
@summary : cancel an order .
@summary : get detailed info about specific order .
provide a transactional scope around a series of operations .
performs database connection using database settings from settings.py . returns sqlalchemy engine instance
"given a point p in the quadrant 1 unit square , transforms it so that it lies in the bounding box ."
"draws the fractal on the given imagedraw instance , within the given bounding box ."
deletes the specified instance id from firebase .
returns the absolute path to a test resource .
returns the contents of a test resource .
connects to a cluster and optionally sets the database and table to be used .
asserts that containers ` a ` and ` b ` are equal disregarding ordering .
returns a ` netusetable ` that describes the current windows session 's status regarding all unc paths .
return ` string ` with double quotes escaped for use in a windows shell command .
this applies only to windows usernames ( logons ) .
this applies only to windows paths .
this applies only to windows file names .
checks the source code using flake8 .
updates the authors file with a list of committers from git .
create a new release and upload it to pypi .
set up the test case by initiating the class .
cleaning up after the test .
make sure default values are set correctly .
"make sure the class catches wrong inputs , etc ."
a single point should be converted to a single test group .
radiance cone .
create a radiance material from a string .
"make radiance material from json { "" type "" : "" cone "" , // geometry type "" modifier "" : { } or "" void "" , "" name "" : "" "" , // geometry name "" center_pt_start "" : { "" x "" : float , "" y "" : float , "" z "" : float } , "" radius_start "" : float , "" center_pt_end "" : { "" x "" : float , "" y "" : float , "" z "" : float } , "" radius_end "" : float }"
update value dictionaries .
"translate radiance material to json { "" type "" : "" cone "" , // geometry type "" modifier "" : { } or "" void "" , "" name "" : "" "" , // geometry name "" center_pt_start "" : { "" x "" : float , "" y "" : float , "" z "" : float } , "" radius_start "" : float , "" center_pt_end "" : { "" x "" : float , "" y "" : float , "" z "" : float } , "" radius_end "" : float }"
return true for surface types .
return class name .
return type based on key value .
get surface type based on surface normal angle to z axis .
get based type of the surface .
re - evaluate base type for special types .
check if this surface is underground .
check if this surface is on the ground .
return types dictionary .
init honeybee surface .
init honeybee shading from an ep_string .
return true for hbfensurface .
return true if honeybee surface is fenestration surface .
get or set parent zone .
set parent zone .
create temporary files and directories needed for objview
"based on the inputs provided , create options for running rad / glrad and also set rendering options ."
create a list of riffile variables based on user input and defaults .
initialize radiance command .
get and set path to radiance binaries .
get and set path to radiance binaries .
get and set path to radiance libraries .
norm white spaces in path .
return full command as a string .
return list of input files for this command .
make sure input files are set to a path .
check if executable file exist .
check if path to libraries is set correctly .
check files before runnig the command .
overwrite this method to add extra specific checks while generating rad string .
overwrite this method to add extra specific checks for the command .
execute the command .
class representation .
init paramters .
create analysis recipe .
create analysis grid from json object .
return true to indicate it is an analysis recipe .
return true if the recipe is calculated .
get list of result files for this recipe .
list of recipe commands .
get and set honeybee objects for this recipe .
collection of opaque surfaces in this recipe .
collection of glazing surfaces in this recipe .
collection of window groups in this recipe .
a radfile for opaque surfaces in this recipe .
a radfile for glazing surfaces in this recipe .
collection of radfiles for window groups in this recipe .
sub - folder for grid - based analysis .
sub - folder for grid - based analysis .
a base honeybee.radiance.scene for the recipe .
get the header for bat file .
radiance representation of the recipe .
write geometry and material files to folder for this recipe .
run the analysis .
returns suggested legend parameters for this recipe .
write contents and commands to a local drive .
return results for this analysis .
return a relative path .
init global geometry .
init paramters .
find all source files and return their complete contents .
return x squared .
return hmmm .
return x doubled .
"the grading protocol provides grading_results , a dictionary which provides the count of tests passed , failed or locked for a single question . return true if all tests have passed ."
returns some analytics about this autograder run .
"for a question snippet containing some default code , return true if the default code is replaced . default code in a snippet should have ' \ # replace with your solution ' at the end of each line ."
record this run of the autograder to a local file .
customize the cacerts.pem file that requests uses . automatically updates the cert file if the contents are different .
"prepares a set of setup , test , and teardown code to be run in the console ."
opens up an interactive session with the current state of the console .
runs the suites associated with this doctest .
scheme tests can not be unlocked .
scheme tests can not be locked .
"scheme tests do not need to be dumped , since no state changes ."
run a read - eval loop that reads from src_file and collects outputs .
summarize results of running tests .
locks the given text using the given key and returns the result
"send messages to server , along with user authentication ."
runs the conceptual test case .
unlocks the conceptual test case .
"send messages to server , along with user authentication ."
runs the suites associated with this doctest .
doctests can not be unlocked .
doctests can not be locked .
"doctests do not need to be dumped , since no state changes ."
parses command line input .
run the lockingprotocol .
registers / updates a kube service registration into consul
deregisters a kube service registration from consul
creates a doc from a kube manifest .
"gets new , removed and current subscriptions"
returns the episode updates since the timestamp
get episode data for an episode status object
"parses the "" since "" parameter"
test that the expected number of queries is executed
test that the expected number of queries is executed
retrieve an already existing thumbnail
make sure that save_podcast_logo(none ) does not fail
"this is a helper function used by both ' require_valid_user ' and ' has_perm_or_basicauth ' that does the nitty of determining if they are already logged in or if they have provided proper http - authorization and returning the view if all goes well , otherwise responding with a 401 ."
a simple decorator that requires a user to be logged in . if they are not logged in the request is examined for a ' authorization ' header .
decorator to check whether the username passed to the view ( from the url ) matches the username with which the user is authenticated .
this is similar to the above decorator ' logged_in_or_basicauth ' except that it requires the logged in user to have a specific permission .
sends the activation email for the given user
called whene the form was posted and its contents were valid
check if the username is already in use
called whene the form was posted and its contents were valid
search if a podcast is found in the search results
validates allowed combinations of time - values
"loads or creates the device indicated by user , uid ."
creates a userprofile if a user does n't have one
displays the row of buttons for delete and save .
rotate cd matrix
make jwst / niriss image header
make jwst / nircam image header
make hst / wfc3 - ir image header
make wfirst wfi header
"use the header from niriss , wfc3 / ir or wfirst and make an ' flt ' image that ` grizli ` can read as a reference ."
if our categorical variable is outside the training range we should get an error
"y must be int or float , or we should get a value error"
check_y will try to cast data to numerical types
check_y expects a minimum number of samples
"if you give labels outide of the links domain , check_y will raise an error"
x must be an in or a float
check_x accepts at most 2d inputs
our check_x and check_y functions should be invoked any time external data is input to the model
abstracted out for 2.7 versus 3.x support
register command line options
"setup the initialization for the driver , and load the config"
before each test set the self.driver/self.drivers attribute for the test .
run after the test completes . kill the browser or just clear cookies depending on config
checks for tell tale signs of being a fresher test
get virtualchain 's logger
facade to implementation 's first block
get the absolute path to the config file .
get the absolute path to the last - block file .
get the absolute path to the chain 's consensus snapshots file .
get the absolute path to the chain 's backups directory
get the absolute path to the chain 's indexing lockfile
set bitcoind options globally . call this before trying to talk to bitcoind .
is the given private key bundle a multisig bundle ?
is the given address a multisig address ?
is the given script a multisig script ?
is the given private key bundle a single - sig key bundle ?
"given a private key bundle , get the ( single ) private key"
is the given address a single - sig address ?
get the address from a private key bundle
"load pos raw data from data directory "" data_path "" . args : data_path returns : tuple ( train_data , valid_data , test_data , vocab_size ) where each of the data objects can be passed to iterator ."
"iterate on the raw pos tagging file data . args : raw_data : one of the raw data outputs from ptb_raw_data . batch_size : int , the batch size . num_steps : int , the number of unrolls ."
test load_data method and iterator method
"load ner raw data from data directory "" data_path "" . args : data_path returns : tuple ( train_data , valid_data , test_data , vocab_size ) where each of the data objects can be passed to iterator ."
"iterate on the raw ner tagging file data . args : raw_data : one of the raw data outputs from ptb_raw_data . batch_size : int , the batch size . num_steps : int , the number of unrolls ."
test load_data method and iterator method
"remove coordinates that are closer than 0.01 ( 1 cm ) : param coords : list of ( x , y ) coordinates : return : list of ( x , y ) coordinates"
"calculate angle in degrees from coord1 to coord2 : param coord1 : ( x , y ) coordinate : param coord2 : ( x , y ) coordinate : return : angle in degrees"
"inspects all coordinates of a linearring counterclockwise and checks if they are a left or a right turn . : param geom : linearring : rtype : a list of ( ( x , y ) , is_left ) tuples"
