docstring_tokens
apply cqt wrapping to a single entity given an i / o stash pair .
create some template existing experiment data .
contextmanager to change into a directory
move files or directories to ( into ) a new location
check if string is a valid package name
try to make a valid package name identifier from a string
generate a python syntax list string with an indention
decorator to convert given exceptions to exit messages
calculate the levenshtein distance between two strings
finds proper license name for the license defined in txt
encode a python 2 unicode object to str for compatibility with python 3
decode a python 2 str object to unicode for compatibility with python 3
check the validity of namespace_str and split it up into a list
check minimum required version of setuptools
create a file in the given path .
create a directory in the given path .
replace underscores with dashes in the string .
retrieve the template by name
template of setup.py
template of setup.cfg
template of .gitignore
template of empty .gitignore
template of conf.py
template of index.rst
template of license.rst
template of authors.rst
template of changelog.rst
template of sphinx 's makefile
template of readme.rst
template of authors.rst
template of requirements.txt
template of license.txt
template of _ _ init__.py
template of .coveragerc
template of tox.ini
template of .travis.yml
template of travis_install.sh
template of .gitlab - ci.yml
template of .pre - commit - config.yaml
template of _ _ init__.py defining a namespace package
template of skeleton.py defining a basic console script
template of unittest for skeleton.py
template of changelog.rst
template of conftest.py
try to get a fully specified command path .
create a callable from a command inside a virtualenv .
add some travis files to structure
"on windows and python 2 , environment dictionaries must be strings and not unicode ."
remove all skeleton files from structure
lists solution stacks
decorate repeating code .
initialize instance .
retrieve bookkeeping data for all ecosystems .
retrieve bookkeeping data for given ecosystem .
retrieve bookkeeping data for given package and ecosystem .
"retrieve bookkeeping data for the given ecosystem , package , and version ."
retrieve bookkeeping data for monitored upstreams .
parse version statistics from html definition .
schedule analyses of packages based on pypi index using xml - rpc .
schedule analyses of packages based on pypi ranking .
run core analyse on python packages .
a module that gets deleted after use
: param path : directory containing the images . : type path : str : param interval : interval between images : type interval : float : return : none
: param app : the flask webb app : type app : flask : return :
: type logger : scanomatic.io.logger . logger : type factory : scanomatic.generics.abstract_model_factory . abstractmodelfactory : type model : scanomatic.generics.model . model : return : none
gives a dictionary of the servers status
gives a list or statuses .
used to communicate with active jobs .
removes job from queue
clears the queue
enques a new analysis job .
enques a new feature extraction job .
use half - size to select area and give each pixel the weight of the convolution result of that coordinate times the 2d gaussian value based on offset of distance to hit ( sigma = ? ) .
"this whas hidden and should be taken care of , is it needed"
this returns the best locations as a list of coordinates on the current image regardless of if it was scaled
this function returns the image positions as numpy arrays that are scaled to match the original image size
loads a csv - file produced by qc as a numpy array of plates .
generates a dictionary lookup for unique strains and the positions they occur in .
"if forceplatewise was true when getting uniques , this method returns the uniques of a specific plate ."
"if ` forceplatewise ` was ` true ` , this will make an ordered list with each plate 's info in a separate item ."
collects all measures for each strain
collects basic stats on strains independent on plate ( if not part of strain info ) . and presents their basic statistics .
produces an array of the stats - measure over all strains .
instantiate the unscented kalman filter
check output of a method against true mean and covariances
: type capacity : int
: rtype : int
: type key : int : type value : int : rtype : nothing
": type board : list[list[str ] ] : rtype : void do not return anything , modify board in - place instead ."
: type num : int : rtype : str
: type nums : list[int ] : rtype : int
: type nums : list[int ] : type target : int : rtype : int
: type pattern : str : type str : str : rtype : bool
: type length : int : type updates : list[list[int ] ] : rtype : list[int ]
: type root : treenode : rtype : bool
: type head : listnode : rtype : listnode
: type head : listnode : type m : int : type n : int : rtype : listnode
the init fuction of our minmaxfloat : param min_value : the minimal value : type min_value : float : param max_value : the maximal value : type max_value : float : param args : the rest of the arguments to pass to the floatfield : param kwargs : the rest of the named arguments to pass to the floatfield
return list of faqs
accept new bindings and reconfigure with them
parse bindings and mangle into an appropriate form
parse an individual binding using gtk 's binding function
map modifier names to gtk values
translate a keyboard event into a mapped key
find our parent widget
handle keypress events
trap and re - emit the clicked signal
"search forwards and jump to the next result , if any"
jump back to the previous search
update the ui for a search hit
we have to have a callback for each character
get the range of a vte widget
trap and re - emit the end - search signal
return the currently set search term
"get static const tnimtype variable , should be available for every non trivial nim type"
select default layouts
exposes all the settings in cyclope.settings to the template .
exposes compress_enabled setting .
generic detail of an object .
generic list of objects .
"when uploading files , the file name has to bee slugified to ascii"
"this is how it is actually used today , however if we used group permissions instead this would have to be expanded ."
"if two files with the same name are uploaded , it should be overwritten . this is for url /media_widget / embed / create"
"same as above , but for /media_widget / pictures / create"
/media_widget / embed / new / none throws doesnotexist : contenttype matching query does not exist . i have not been able to identify when / why this happens
"widget should be refreshed after a succesful upload it can not stay with previously uploaded file state mostly when an error was raised ( 500 ) , it goes unusable ."
same as above for pictures widget .
handles a user joining a room : param message : the websocket message : param kwargs : route kwargs : return :
handles when a user leaves the room
handles when the client sends a message
serializes values into a string representation .
parses string into a dictionary of values .
simulate initiating an interaction event .
wait for and validate an interaction event .
validate a value .
generage a valid value .
create a copy of first argument and update with second argument 's value .
generates t trajectories of the markov jump process .
perform a direct ssa time step and pre - generate m random numbers
print time simulation output for each generated trajectory
print a time series of the propensities each generated trajectory
print obtained distributions for each generated trajectory
print obtained distributions for each generated trajectory
print obtained waiting times
print the means ( 3 decimals ) of each species for the selected trajectory
print the standard deviations ( 3 decimals ) of each species for the selected trajectory
print the means of each propensity for the selected trajectory
print the standard deviations of each propensity for the selected trajectory
print the waiting time means for the selected trajectory
print the waiting time standard deviations for the selected trajectory
analyze the average output over all generated trajectories
analyze the average output over all generated trajectories
: param name : name of the object : param username : ssh login username : param password : ssh login password : param hostname : ssh server ip : param port : ssh server port : param status_command : command to make sure target is alive : param restart_command : command to restart the target in case it is deadore : param logger : logger for this object ( default : none )
"nothing is done here , so we use a sleep for now ."
: param interface : name of interface to listen to : param dir_path : path to store captured pcaps : param name : name of the monitor : param logger : logger for the monitor instance
open the l2socket .
clean the packet list .
store the pcap .
close the l2socket .
called in a loop .
: param name : name of the monitor object : param dev_name : serial device : param baudrate : serial baudrate : param capture_dir : where to store the captured serial output : param logger : logger for the monitor object
"add a pattern to search for on the serial output , and the callback that will be called when the pattern is found ."
set a pattern that declares the test successful if received
set a pattern that declares the test as failed if received
called in a loop .
generate an hid report container from a hid report string
wrap a lego with template
return a list of all mutations for the template
: param value : default value : type encoder : : class:`~kitty.model.low_levele.encoder . enc_str_default ` : param encoder : encoder for the field : param fuzzable : is field fuzzable ( default : true ) : param name : name of the object ( default : none ) : param fuzz_count : fuzz count ( default : 1000 ) : param seed : random seed for generating radamsa seeds ( default : 123456 ) : param bin_path : path to the radamsa binary ( default : none )
: return : number of mutations this field will perform
check whether we can run radamsa .
return a json string in jsonrpc 2.0 format .
": error must be an object { "" code "" : 200 , "" message "" : "" blah "" , "" data "" : "" optional "" }"
create a new quiz but does n't create any ' card ' models . card models will only be used for cardbox in future .
process module .
process module .
initialize module .
process module .
"adds a system user that preferably does n't have a home directory , password , or shell in the distribution - appropriate method . assign it to a group with the same name ."
retrieves the set of users from /etc / passwd
copies the ona service files to the init system - appropriate locations .
sets the ona service directory to be owned by the ona user and group . raises runtimeerror if something fails .
adds the ona user to a group ( adm or wheel ) that lets it read the system logs .
"allows the ona user to execute certain commands as root , sans password . raises runtimeerror if something fails"
write an identifier for the ona to the local configuration file .
start the service given by ` service_name ` with the proper init system call . optionally specify an ` instance ` tuple to stop a service with multiple instances . returns runtimeerror if the service fails to start .
stop the service given by ` service_name ` with the proper init system call . optionally specify an ` instance ` tuple to stop a service with multiple instances . returns the return code from the stopping command .
"appends "" .service "" to ` service_name ` if ` instance ` is none . appends "" -@value.service "" if an ` instance ` tuple ( key , value ) is specified ."
"calls sudo systemctl action service_name key = value ` action ` is "" start "" or "" stop "" ` service_name ` is the name of an ona service . returns the return code from systemctl ."
"calls sudo initctl action service_name key = value ` action ` is "" start "" or "" stop "" ` service_name ` is the name of an ona service ` instance ` is a ( key , value ) tuple like ( "" eth "" , "" eth1 "" ) returns the return code from initctl ."
"allows the ona user to execute certain commands as root , sans password . this is crazy dangerous , so we use visudo to ensure that the changes we make are valid ."
"given strings like ' 0 - 5,7 - 10 ' , return a string of comma - separated integers that span the range . integers must be between 0 and 65535 inclusive ."
generates a safe filename that is unlikely to collide with existing objects in google cloud storage .
uploads a file to a given cloud storage bucket and returns the public url to the new object .
testing main function for multiprocessing purpose : testing import without exception
create admin account
change admin account 's password
apply multiple mangling rules ( both sed - like and handlers ) in order
convert pv to my_pv if needed
zero_value identify the value that represents 0 when standardizing
"learn the occurrences . good for frequency / count data parameters ---------- x : { array - like , sparse matrix } , shape ( n_samples , n_features ) sample vectors from which to compute variances . y : any ignored . this parameter exists only for compatibility with sklearn.pipeline . pipeline . returns ------- self"
loads specified features from file
method for combining a feature table with an outcome table in a single dataframe
"returns untraned version model used for image tracking img_edge : number of pixels for images ( height and width are same ) backend_id : either "" tf "" or "" th """
fits and returns model using image / box pairs from my_gen
parse an individual ` .ann ` file and output the relevant elements .
add the necessary filepaths for saving and later accessing .
copy over the files given by the attributes in the dataframe .
associate the correct bounding box coords with the right variables .
add columns denoting the relevant info for the current and previous frame .
gets parsed command - line arguments .
constructs the simulator .
initializes the world .
adds polydata to the simulation .
adds a robot to the simulation .
adds an obstacle to the simulation .
updates moving object 's state .
updates sensor 's rays .
updates cell locator .
launches and displays the simulator .
update simulation clock .
make sure that replay.get_file_name generates a valid json file path .
test that stdout logs use info format and level .
test that stdout logs use debug format and level .
test that logging to stdout uses a different format and level than the the file handler .
return true if value is a repository url .
return true if value is a zip file .
expand abbreviations in a template name .
determine if ` repo_directory ` contains a ` cookiecutter.json ` file .
locate the repository directory from a template reference .
make sure that the systems preferred encoding is not ` ascii ` .
"returns : - none ( not buildable ) , - task ( depends implicitly on another task ; i.e. a symlink ) - target ( buildable )"
run in a child process
overloaded constructor to create the genometricspace object from memory data and meta variables . the indexes of the data and meta dataframes should be the same .
parses and loads the data into instance attributes . the indexes of the data and meta dataframes should be the same .
sets one axis of the 2d multi - indexed dataframe index to the selected meta data .
creates a 2d multi - indexed matrix representation of the data . this representation allows the data to be sent to the machine learning algorithms .
retrieves the selected metadata values of the given set
provides statistics of a group based on the meta data selected .
creates a bag of genomes representation for data mining purposes each document ( genome ) in the representation is a set of metadata key and value pairs belonging to the same cluster . the bag of genomes are saved under ./bag_of_genomes/ directory
creates a term - document matrix which is a mathematical matrix that describes the frequency of terms that occur in a collection of documents ( in our case a collection of genomes ) .
computes the term frequency and stores it as a dictionary
returns true if the string is a uuid code
computes the importance of each metadata by using tf * coverage ( the percentage of the term occuring in a cluster )
renders the cloud of words representation for a given dictionary of frequencies
draws the cloud of words representation
make required directories to hold logfile .
humanize byte size figures
": param d : : return : ( read_bytes , wrote_bytes ) , ints"
": param d : : return : ( received_bytes , transceived_bytes ) , ints"
repeat call x - times : docker api is just awesome
get rid of tback : ` attributeerror : ' text ' object has no attribute ' keypress ' `
": param network_name : str : param network_data : dict : return : dict : { "" ip_address4 "" : "" 12.34.56.78 "" "" ip_address6 "" : "" ff : fa : ... "" }"
": return : dict { # container - > host "" 1234 "" : "" 2345 "" }"
": return : dict : { "" default "" : { "" ip_address4 "" : "" 12.34.56.78 "" "" ip_address6 "" : "" ff : fa : ... "" } "" other "" : { ... } }"
return key not yet used in data .
omit printing on console .
create a noresultserror
create new pdc client instance .
"try to obtain token from all end - points that were ever used to serve the token . if the request returns 404 not found , retry with older version of the url ."
"this call is equivalent to ` ` res(**kwargs ) ` ` , only it retrieves all pages and returns the results joined into a single iterable . the advantage over retrieving everything at once is that the result can be consumed immediately ."
"if the first attribute / endpoint with "" - "" , just replace with "" _ "" in name ."
set pdc change comment to be stored on the server .
return an iterator with all pages of data . return noresultserror with response if there is unexpected data .
create new client instance with page prarameter . other params are all used for base class . : param page : the page number of the data .
"re - write the ge_paged here , and add the self.page check . this call is equivalent to ` ` res(**kwargs ) ` ` , if there is no self.page parameter , only it retrieves all pages and returns the results joined into a single iterable . the advantage over retrieving everything at once is that the result can be consumed immediately ."
tests making migrations with django 's migration framework
overriden in order to access the command line arguments .
overriden in order to send emails on unhandled exception .
send email notifications .
return the set of logging methods for the ' name ' logger .
decorator for functions returning previous result when args are unchanged .
escape special characters in string .
quote ' msg ' and escape special characters .
"return the list of whitespace separated tokens from ' msg ' , handling double quoted substrings as a token ."
remove escape on special characters in quoted string .
remove escapes from escaped characters in a quoted string .
"return a dictionary built from a string of ' key=""value "" ' pairs ."
"return the smallest prefix of ' word ' , not prefix of ' other ' ."
return the smallest prefix of ' word ' that allows completion in ' strlist ' .
unlink a file .
return an iterator over the offsets of the beginning of lines .
return a closed file object to a new temporary file .
call ' handle_cb ' for each line in buff + data .
format a python object into a pretty - printed representation .
return the list of indexes of ' sub ' in ' txt ' .
match the first opening matches[0 ] with a closing matches[1 ] .
split ' txt ' into matching matches[0 ] with matches[1 ] at the same level .
run the doctests .
format un object .
create the single instance .
override in subclass .
set flush mode .
write to the stringio buffer .
flush to stderr when enabled .
close the handler .
update the key map files for each debugger .
build the vimball .
base - class for all sb emulators exceptions raised by this module .
a sb emulator node connection error .
a sb emulator build error .
a sb emulator cleanup error .
mtcbench fail to run error .
fail generate configuration file for multinet
fail parsing multinet handler output .
fail to deploy multinet workers .
fail to initialize multinet topology . : param additional_error_info : the general error message . : param err_code : the specific error code . : type str : type int
fail to start multinet topology .
fail to get number of switches of multinet topology .
fail to get total number of flows of multinet topology .
error while generating traffic in multinet topology .
fail to stop multinet topology
fail to cleanup multinet workers
base - class for all nb generator exceptions raised by this module .
a nb generator node connection error .
nb generator build failure .
nb generator clean failure .
nb generator run failure .
generates the test html report
gets a dictionary with tables specifications and generates the corresponded html code .
"gets a list of dictionaries that describes the plots of the report , and generates the corresponded html code ."
used for self testing purposes
the helper method start a server process that listens to a predefined port
runs as a separate child process . it takes as argument a socket object .
initializes the testing environment parameters . starts the server process
"checks the getpid_listeningonport ( ) function of util / process.py module . checks the equality between the known process i d of the initializes server , with the one returned from the function ."
"checks the getpid_listeningonport ( ) function of util / process.py module . in this scenario we check the result in case we give as input to the function , a port number on which a process that the user not owns is listening ."
checks the getpid_listeningonport ( ) function of util / process.py module . in this scenario we check the result in case we give as input to the function something that is not a port number .
checks the is_process_running ( ) function of util / process.py module . in this scenario we check the result in case we give as input to the function a valid process i d.
checks the is_process_running ( ) function of util / process.py module . in this scenario we check the result in case we give as input to the function a invalid process i d.
checks the is_process_running ( ) function of util / process.py module . in this scenario we check the result in case we give as input to the function a invalid process i d.
cleans the testing environment parameters . stops the server process we started
"sets axis labels , title and subtitle of a plot ."
configures the plots axis and saves the figure to file
draws a single errorbar .
creates a single errorbar figure .
creates a multiple errorbars figure .
produces a single scatter plot with a specific color .
creates a single scatter plot figure .
creates a multiple scatter plots figure
reads a json file and returns the contents of the file as a dictionary as well as a dictionary that maps y_axis_keys to x_axis_keys
reads a json file and returns the contents of the file as a dictionary as well as a dictionary that maps y_axis_keys to x_axis_keys that in turn map to z_axis_keys
attributes of a plot .
iterate over ` ` samtools pileup -c ` ` formatted file .
"encode genotypes like gg , ga into a one - letter code . the returned code is lower case if code[0 ] < code[1 ] , otherwise it is uppercase ."
"decode single letter genotypes like m , m into two letters . this is the reverse operation to : meth:`encodegenotype ` ."
translate indel from vcf to pileup format .
convert vcf record to pileup record .
iterate over a vcf - formatted file .
compare two headers a and b.
compare two headers a and b.
compare two headers a and b.
compare two headers a and b.
converts position and velocity body - centered frame to icrs .
converts position and velocity in icrs to body - centered frame .
converts position and velocity from inertial body - centered frame to perifocal frame .
provides rotational elements at epoch .
nonblocking prompt for a deprecation warning .
get and parse arguments .
"get configuration , get driver , and build handler and start it ."
"maps a string into an integer log level if none can be found , uses the default"
"define the tooltip messages for user mouse - over . depends on column . column is an integer with 0 index starting from left . no tooltip for the "" message "" column . parameters omitted as the"
constructor for logitem notes : ---------- timestamp initailzies to current system time msg is passed in by the user
function to perform filtering of a message based upon the loglevel passed
write to the lists outputlist as stdout or stderr .
write to the lists in outputlist from device or user space .
"append to a front of buffer , keeping overall size less than max_len"
clear all output_list buffers
copy items from unfiltered list into filtered list
swap buffers around when the paused boolean changes state .
processes messages .
convert the cel file with ccl or v3_4 to v3_4
build the uri used by the authenticating server to redirect the client back to the page originating the auth request . appends the _ next action to the generated url so the flows continues .
return the access token generated by the authenticating server .
get user data .
this method redirects the user to the authenticating form on authentication server if the authentication code and the authentication token are not available to the application yet .
"return the pylab figure object . data list of list for the data . xlabel what label to put on x axis . ylabel what label to put on y axis . title what label to put on title . box_label what to put in xticklabel . box_color color for the boxes.<""black','red'>,etc . whisker_color color for the whisker.<""black','red'>,etc . tick_size what font size of the tick label . left the left margin distance right the right margin distance top the top margin distance bottom the bottom margin distance"
"return the figure object . x1,x2 list of list for the two dimension data . xlabel what label to put on x axis . ylabel what label to put on y axis . title what label to put on title . left the left margin distance right the right margin distance top the top margin distance bottom the bottom margin distance label a list of label for each point color list of color for each point or a single color for all the points legend list of text for legend for each point"
"return the pylab figure object . line1 list of the ( x , y ) coordinates of the points . line2 ... xlabel what label to put on x axis . ylabel what label to put on y axis . title what label to put on title . box_label what to put in xticklabel . tick_size what font size of the tick label . left the left margin distance right the right margin distance top the top margin distance bottom the bottom margin distance legend list of legend , 1 for each line color list of colors , 1 for each line"
"return the pylab figure object . mean list of means for the data . std list of standard variation . xlabel what label to put on x axis . ylabel what label to put on y axis . title what label to put on title . box_label what to put in xticklabel . tick_size what font size of the tick label . left the left margin distance . right the right margin distance . top the top margin distance . bottom the bottom margin distance . xtick_rotation rotation the box_label in vertical . ylim ( min , max ) of the limit of y_axis . ytick_pos list of position to put yticks . yticks list of ticks to put in y_axis ."
convert signal file to pcl format
basic pdf test and sanity checks
return a storage value as a list .
return the first or only value when given a request.vars - style key .
returns the last or only single value when given a request.vars - style key .
"request.args(0,default=0,cast = int , otherwise='http://error_url ' ) request.args(0,default=0,cast = int , otherwise = lambda : ... )"
extract the fastq rna seq files
extract the files that are gpr format
merge three signal file to generate a joined signal file
initializes an eyetracker object .
update product quantity .
test manufacture mto with stock based on forecast quantity and no link between sub assemblies mo 's and main mo raw material
test manufacture mto with stock based on reservable stock and there is a link between sub assemblies mo 's and main mo raw materi al
read the version number out of a vmlinuz file .
"add the named section , raising duplicatesectionerror if the section exists and duplicate_ok is false ."
"set an option , creating the section if needed ."
"get an option , returning none if missing"
returns a schema generated for the given sample .
"iterates through the given samples , generating schemas and merging them , returning the resulting merged schema ."
read repository configuration from a yum config file .
read repository configuration from a directory containing yum configs .
see : createfile function http://msdn.microsoft.com/en-us/library/windows/desktop/aa363858(v=vs.85).aspx
see : createnamedpipe function https://msdn.microsoft.com/en-us/library/windows/desktop/aa365150(v=vs.85).aspx
see : connectnamedpipe function https://msdn.microsoft.com/en-us/library/windows/desktop/aa365146(v=vs.85).aspx
see : writefile function https://msdn.microsoft.com/en-us/library/windows/desktop/aa365747(v=vs.85).aspx
see : readfile function https://msdn.microsoft.com/en-us/library/windows/desktop/aa365467(v=vs.85).aspx
creates a quadcopter graphical representation with initial position and initial angles .
set the pitch ( rotation around the side - to - side axis ) of the 3d model
set the yaw ( rotation around the vertical axis ) of the 3d model
set the roll ( rotation around the front - to - back axis ) of the 3d model
set the position of the center of the 3d model .
"set roll , pitch and yaw of the 3d model ."
"elements on the numpy array ( 1d or 2d ) , that have an absolute value less than threshold are truncated to 0.0"
test deletion for anonymous users .
test deletion for account of volunteer .
test deletion for account of organization .
test deletion for account of admin .
fixtures for offer model unittests .
test offer model string reprezentation .
testing organization name field
testing organization name as onetoone relation
testing offer description field
testing offer requirements field
testing offer time commitment field
testing offer benefits field
testing offer location field
testing offer title field
testing offer time_period field
testing offer status field
return whether the user can edit an offer based on an id .
get main or first image from all offer images .
returns first n values of your column as a dataframe . this is executing : select < name_of_the_column > from < name_of_the_table > limit < n >
returns entire column as a dataframe . this is executing : select distinct < name_of_the_column > from < name_of_the_table >
returns all unique values as a dataframe . this is executing : select distinct < name_of_the_column > from < name_of_the_table >
returns random sample of n rows as a dataframe . this is executing : select < name_of_the_column > from < name_of_the_table > order by random ( ) limit < n >
serialize representation of the column for local caching .
serialize representation of the tableset for local caching .
"example image - reading function that tries to use freeimage , skimage , scipy or pygame to read in an image"
look up barcodes from a list of barcode results returned by zbar.scanner.scan
while not found seek hashname at < concurrency > peers try again
"create seek channel wait for see , and update dht"
updates the dataset instance from a text file according to the given params . used for sampling
builds ( or loads ) a dataset instance . : param params : parameters specifying dataset options : return : dataset object
keeps only n captions per image and stores the rest in dictionaries for a later evaluation : param ds : dataset object : param repeat : number of input samples per output : param n : number of outputs to keep . : param set_names : set name . : return :
initialize the manager of the api . should keep in memory the fallback_name : param fallback_name : name of the intent to return in fallback case .
should return the same name as written in settings file
"by applying fit function , the api must : - forget former intents & entities - update intents & entities - train its model - be available from http requests ( for predictions ) ( some apis like luis must be ' published ' here"
"given a list of sentences , this function must return the list of intents relative to the sentences . : param sentences_list : list list of the sentences you want to get the intent : return : list of the intents"
this class method must return the list of all the parameters the user can set . these parameters must be configurable from the constructor function
defines a decorator function for tests that passes a unique youcompleteme instance as a parameter . this instance is initialized with the default options ` default_client_options ` . use the optional parameter |custom_options| to give additional options and/or override the already existing ones .
return the /sys / class / rc directory behind a /dev / lirc or /dev / input / event * device .
check that device has ok permissions and possibly protocol .
middleware hook method called immediately after the view function returns a response .
override this method to override the login_url attribute .
override this method to override the permission_denied_message attribute .
override this method to override the redirect_field_name attribute .
override this method to use a different test_func method .
test that users can create community
test that public community is listed
test that fully - visible private community is listed
test that partially - visible private community is listed
accepts a intsance of user account and returns a reversible ' time - unique ' hash for it
accepts a unique hash string representing a user account and decodes it to return an actual intance of that account returns none if decoded user does not exits
check that leeway properties are properly read .
test the expected leeway left / right split .
check project is setup correctly django_settings_module exported in venv / bin / activate
converts ' package-name-1.2.3.tar.gz ' to ' package - name==1.2.3 '
gets a pypuppetdb node object given a certname
"for a puppetdb node object , return the latest report ."
convert an integer seconds into human - readable hms
return a textual marker for result states
words is a list of words to embedd . embeddings is a numpy array of same length . depth is the number of dimensions to keep . all further dimensions are considered part of the word .
cache the return value in the correct cache directory . set ' method ' to false for static methods .
download a file into the correct cache directory .
path that should be used for caching . different for all subclasses .
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the check digit . the number passed should not have the check digit included .
"check if the number provided is a valid dni number . this checks the length , formatting and check digit ."
"check if the number provided is a valid dni number . this checks the length , formatting and check digit ."
"check if the number provided is a valid pps number . this checks the length , formatting and check digit ."
"check if the number provided is a valid pps number . this checks the length , formatting and check digit ."
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the check digit . the number passed should not have the check digit included .
"check if the number is a valid national identification number . this checks the length , formatting , embedded date and check digit ."
check if the number is a valid national identification number .
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the check digit for the 10 - digit инн for organisations .
calculate the check digits for the 12 - digit personal инн .
"check if the number is a valid инн . this checks the length , formatting and check digit ."
check if the number is a valid инн .
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the checksum for legal entities .
calculate the check digit for personal codes . the number passed should not have the check digit included .
split the date parts from the number and return the birth date .
"check if the number is a valid vat number . this checks the length , formatting and check digit ."
check if the number is a valid vat number .
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the checksum . the checksum is only used for the 9 digits of the number and the result can either be 0 or 42 .
"check if the number is a valid vat number . this checks the length , formatting and check digit ."
reformat the number to the standard presentation format .
calculate a checksum over the number given the weights .
"check if the number provided is a valid ruc number . this checks the length , formatting , check digit and check sum ."
"check if the number provided is a valid ruc number . this checks the length , formatting and check digit ."
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
calculate the checksum .
"check if the number is a valid vat number . this checks the length , formatting and check digit ."
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
split the date parts from the number and return the birth date . note that in some cases it may return the registration date instead of the birth date and it may be a century off .
use the number to look up the place of birth of the person .
calculate the check digit . the number passed should have the check digit included .
"check if the number is a valid ric number . this checks the length , formatting and birth date and place ."
check if the number is a valid ric number .
reformat the number to the standard presentation format .
split the date parts from the number and return the birth date .
get the person 's birth gender ( ' m ' or ' f ' ) .
calculate the check digit for organisations . the number passed should not have the check digit included .
"check if the number is a valid national identification number . this checks the length , formatting and check digit ."
convert the number to the minimal representation . this strips the number of any valid separators and removes surrounding whitespace .
split the date parts from the number and return the birth date .
"check if the number is a valid birth number . this checks the length , formatting , embedded date and check digit ."
check if the number is a valid birth number .
reformat the number to the standard presentation format .
convert the number to the minimal representation . this strips the number of any surrounding whitespace .
calculate the check digit . the number passed should not have the check digit included .
check if the number is a valid routing number . this checks the length and check digit .
check if the number is a valid rtn .
normal run - 5 changes
test 4 inline changes
"test 3 inline changes , ignoring unversioned ( yolo )"
test no updates
test --include with --exclude
utility function to return a list of all words that are have a length greater than a specified number of characters . @param text the text that must be split in to words . @param min_word_return_size the minimum no of characters a word must have to be included .
utility function to return a list of sentences . @param text the text that must be split in to sentences .
runs the rake algorithm on ` text `
test real query
integration test for hits ( )
"arguments : | ` ` f ` ` -- a filename or a file - like object | ` ` units ` ` -- the units of the atom fields . the number of fields , their unit and their meaning depends on the input file of the lammps simulation ."
read and return the next time frame
skip the next time frame
arguments : | ` ` filename ` ` -- the formatted checkpoint file
read all the requested fields
convert a few elementary fields into a molecule object
return an array with the energy at each point in the optimization
get the final energy after optimization
return the index of the lowest energy during the optimization process
return the coordinates of the geometries at each point in the optimization
return a molecule object of the optimal geometry
return the energy gradients of all geometries during an optimization
return the energy gradient of the optimized geometry
return the hessian
arguments : | ` ` f ` ` -- a filename or a file - like object
read and return the next time frame
skip the next time frame
initialize a sectionfile object
get the label from the last line read
skip a section
read and return an entire section
get the next section with the given label
arguments : | ` ` f ` ` -- a filename or a file - like object | ` ` sub ` ` -- an optional slice object to select a subset of time frames
read the number of atoms from the first section
read a single frame from the trajectory
skip a single frame from the trajectory
generates a path for uploaded code . generating file names with this methods makes categorizing files easier and helps prevent file duplication problems .
check if user does n't have an avatar set the gravatar for it
generates a path for uploaded code . generating file names with this methods makes categorizing files easier and helps prevent file duplication problems .
app will be ready afterward
"take a value , determine if it matches one , and only one , of the member fields"
take a list ( or single value ) and bitwise - or all the values together
take a single number and split it out into all values that are present
take an input list and return a frozenset
test field formats that are valid elementbase elements .
test field formats that are not valid elementbase elements .
initialize a starstruct element object .
validation function to determine if a field tuple represents a valid enum element type .
ensure that the supplied message contains the required information for this element object to operate .
change the mode of the struct format
pack the provided values into the supplied buffer .
unpack data from the supplied buffer using the initialized format .
"return the "" transformed "" value for this element"
test field formats that are valid elementstring elements .
test field formats that are not valid elementstring elements .
test field formats that are valid elementstring elements .
test field formats that are valid elementstring elements .
test field formats that are valid elementstring elements .
helper function to return the number of bits for the format
helper function to get the right bytes once we 're done
helper function to get the integer portion of a fixed point value
initialize a starstruct element object .
validation function to determine if a field tuple represents a valid fixedpoint element type .
ensure that the supplied message contains the required information for this element object to operate .
pack the provided values into the specified buffer .
unpack data from the supplied buffer using the initialized format .
return bytes of the expected format
test invalid message names .
test invalid message modes .
test an empty message .
test pack the test formats .
test unpack the test formats .
test pack the test formats .
test unpack the test formats .
train using skipgram model .
override to supply own word frequencies .
load edges in csv format as numpy ndarray of strings .
checks if a key is valid and raises a valueerror if its not .
initialize new filesystemstore
initialize new webfilesystemstore .
"given two bases ` ` basis_a ` ` and ` ` basis_b ` ` of vector spaces : math:`u , w \subseteq v ` , computes bases of : math:`u + w ` and : math:`u \cap w ` using the zassenhaus algorithm ."
"given ` ` bases ` ` of different subspaces : math:`u_i \subseteq v ` , returns a basis of the intersection : math:`\bigcap_i u_i ` . the basis vectors must all have the same length ."
make attribute names globally unique so they can be used as sparql variables
"returns the expressions in the supplied exprs , ensuring that all attribute references are in the unnamed perspective . the expressions are resolved against the scheme of the supplied operator , but only if necessary ."
convert a reference to the unnamed perspective
convert a reference to the named perspective
convert all named column references to unnamed column references .
returns true if all attributerefs in the expression are unnamed .
return a list of all classes in the module
return all the classes that can be used to construct an aggregate expression
"return a list of all classes used to construct arithmetic , like plus , divide , etc ."
return a list of undefined variables in a udf .
bind variables to arguments in a function invocation .
convert references to state variables into namedstateattributeref references .
return a set of column indexes accessed by an expression .
subtract the given offset from each column access .
changes references to key columns to references to value columns in index_map .
return true if the expression contains an aggregate .
raise an exception if the provided expression contains an aggregate .
raise an exception if the expression contains a nested aggregate .
test that attributes are correct amid multiple conditions
test that attributes are correct amid multiple conditions and when the order of variables in the terms is the opposite of the explicit condition
builds tf - slim arg_scope for convolution ops based on the config .
builds a callable activation from config .
builds a tf - slim regularizer from config .
build a tf initializer from config .
build a dictionary of batch_norm params from config .
bipartite matches a collection rows and columns . a greedy bi - partite .
constructs a minibatch sampler .
returns subsampled minibatch .
convert xml derived dict to tf . example proto .
build losses based on the config .
builds a localization loss based on the loss config .
builds a classification loss based on the loss config .
create a tiled set of anchors strided along a grid in image space .
converts bbox center - size representation to corners representation .
constructs a gridanchorgenerator .
returns the number of anchors per spatial location .
generates a collection of bounding boxes to be used as anchors .
reads evaluation configuration from a pipeline_pb2.trainevalpipelineconfig .
reads evaluation configuration from multiple config files .
create * num_workers * worker objects with * input_tube * and an iterable of * output_tubes * . the worker reads a task from * input_tube * and writes the result to * output_tubes * .
return the tube class implementation .
"create , assemble and start workers . workers are created of class * cls * , initialized with * args * , and given task / result communication channels * input_tube * and * output_tubes * . the number of workers created is according to * size * parameter . * do_stop_task * indicates whether dotask ( ) will be called for "" stop "" request ."
"link the worker to the given next worker object , connecting the two workers with communication tubes ."
register the * result * by putting it on all the output tubes .
"implement this method in the subclass with work functionality to be executed on each * task * object . the implementation can publish the output result in one of two ways , either by 1 ) calling : meth:`putresult ` and returning ` ` none ` ` , or 2 ) returning the result ( other than ` ` none ` ` ) ."
"implement this method in the subclass in case there 's need for additional initialization after process startup . since this class inherits from : class:`multiprocessing . process ` , its constructor executes in the spawning process . this method allows additional code to be run in the forked process , before the worker begins processing input tasks ."
: type identifier_s : list
serve a get request .
"if index.mako is present in a directory , serve it instead of a directory listing"
test get_red_mask function from patty.segmentation.segredstick
"create a right rectangle , alinged with x and y axes , with x - side size sx and y - side size sy. triangle is offset by dx and dy."
"create a right rectangle triangular pyramid , alinged with x and y axes , with x - side at the base size of sx and y - side size at the base of sy. pyramid has high sz. it is offset by dx , dy and dz."
create the footprint of a pyramid created by make_tri_pyramid
"create a pyramid as per make_tri_pyramid , suroundeded by a triangular flat base ."
add noise to an array of 2d points
create a vector perpendicular to the original
return the rotation matrix associated with counterclockwise rotation about the given axis by theta radians .
make a hollow red - white - red - white stick
make a hollow red - white - red - white stick
add or remove objects from the environment . : param object_id : name of object to change the state of . : param state : have the object in the environment ?
": param offset : defined in the intel software development manual ; in a nutshell , it 's a unique number corresponding to each register . : param size : the size of a register in bytes . this alllowes to distinguish between registers that have the same offset . : return : the value of the requested register ."
: param offset : the same as above : param value : the value to be written to the register . its size determines the register to be used . : return : none
retrieve a specific bit of the eflags register : param bit : the number of the bit : return :
set a specific bit of the eflags register to some value : param bit : the number of the bit : param value : boolean : return : none
": return : ( a , b ) interval such that a<=b"
": return : bool true if x is in interval [ a , b ] or [ b , a ] ( tuple )"
: return : bool true if intervals [ t1 [ [ t2 [ intersect
": return : tuple intersection between 2 intervals ( tuples ) , or none if intervals do n't intersect"
": param t1 : interval 1 ( tuple ) : param t2 : interval 2 ( tuple ) : param none : value to return when t1 does not intersect t2 : return : len of intersection between 2 intervals ( tuples ) , or none if intervals do n't intersect"
"construct , start must be < = end ."
used in several methods below
": return : distance between self and other , negative if overlap"
: return : true iff self intersects other .
": return : intersection with other , or none if no intersection ."
expands self to contain other .
: return : new interval containing both self and other .
: return : true if x in self .
: return : true iff self is subset of other .
: return : true iff self is proper subset of other .
: return : true iff self is empty .
: return : true iff self.end - self.start = = 1 .
update the list by adding all elements from * iterable * .
returns intervals containing x
string representation : like a list of intervals
"return n - th corner of box 0 - th corner is "" start "" made of all minimal values of intervals -1.th corner is "" end "" , made of all maximal values of intervals"
: return : tuple of all intervals as tuples
enlarge box if required to contain specified point : param other : : class:`box ` or ( list of ) n - tuple point(s )
enlarge box if required to contain specified point : param other : : class:`box ` or ( list of ) n - tuple point(s ) : return : new box containing both
: return : true if x in self .
: return : true iff box is empty .
timeout for loops : param iterable : any iterable : param timeout : float max running time in seconds : yield : items in iterator until timeout occurs : raise : multiprocessing . timeouterror if timeout occured
"same as excel workday function . returns a date that is the indicated number of working days before or after the starting date . working days exclude weekends and any dates identified as holidays . use workday to exclude weekends or holidays when you calculate invoice due dates , expected delivery times , or the number of days of work performed ."
same as excel networkdays function . returns the number of whole working days between start_date and end_date ( inclusive of both start_date and end_date ) . working days exclude weekends and any dates identified in holidays . use networkdays to calculate employee benefits that accrue based on the number of days worked during a specific term
add day(s ) to to known holidays . dates with year==4 ( to allow feb 29th ) apply every year note : holidays set may contain weekends too .
@return true if day is a work day
@return true if you 're supposed to work at that time
@return next work day
@return previous work day
range of workdays between start ( included ) and end ( not included )
list of ndays workdays from start
"same as excel workday function . returns a date that is the indicated number of working days before or after the starting date . working days exclude weekends and any dates identified as holidays . use workday to exclude weekends or holidays when you calculate invoice due dates , expected delivery times , or the number of days of work performed ."
force time to be in workhours
@return interval of time worked a given day
@return interval of datetime worked a given day
@return timedelta worktime between t1 and t2 (= t2 - t1 )
@return fractional work hours between t1 and t2 (= t2 - t1 )
@return start time + t work time ( positive or negative )
@return start time - t work time ( positive or negative )
same as excel networkdays function . returns the number of whole working days between start_date and end_date ( inclusive of both start_date and end_date ) . working days exclude weekends and any dates identified in holidays . use networkdays to calculate employee benefits that accrue based on the number of days worked during a specific term
show the modifiers and colors
detect what color palettes are supported . it 'll return a valid color mode to use with colorful .
reads the current configuration
will handle both trades and orders . why not separate them ? because poloniex returns one message with both information embedded
"poloniex order book , this will provide a snapshot of the order book todo put format here"
"poloniex trade format : [ "" t"",""9394200"",1,""5545.00000000"",""0.00009541"",1508060546 ] which is a trade entry ( t ) and is defined as [ trade , tradeid , 0/1 ( sell / buy ) , price , amount , timestamp ]"
"poloniex order book format : [ 148,394056638,[[""o"",0,""0.07615527"",""0.34317849 "" ] ] ] which is [ currency pair , i d , o ( orderbook ) , 0/1 ( remove / modify ) price , quantity ]"
decompressed a binary object compressed with pickle from sqlite3 .
compressed binary object with highest pickle protocol for sqlite3 .
load value with key from sqlite3 stored at fname .
dump value with key in the sqlite3 database .
"replaces the underlined "" dash "" region of a setext header with a run of dashes or equal - signs that match the length of the header text ."
"given the string output from a ` git diff ` command , parse the string into hunks and , more granularly , meta - data and change information for each of those hunks ."
"given an array of lines from the output of a ` git - diff ` command , yield slices of the lines that correspond to the hunks in the diff ."
"given the ` @@ ... @@ ` header from the beginning of a hunk , return the start and length values from that header ."
"transform a list of ` + ` or ` - ` lines from a ` git diff ` output into tuples with the original raw line , the type of the change , the position of the head- and saved- versions at that line , and the text of the line with the ` + ` or ` - ` removed ."
parse out a gitlab http url from a remote uri :
"given a line of output from ` git remote -v ` , parse the string and return an object with original url , fqdn , owner , repo , and the token to use for this particular fqdn ( if available ) ."
open the url corresponding to the provided ` rel_path ` on ` remote ` .
"open the github repo in a new browser window , given the specified remote ."
"open the github issues in a new browser window , given the specified remote ."
"determine if the provided gitlab repo object refers to a hosted gitlab instance or to publically hosted gitlab.com , and indicate what base fqdn to use for api requests ."
"construct a gitlab url to query using the given url template string , and a gitlab . gitlabrepo instance , and optionally query parameters of given star - kwargs ."
"prepare ommon parameters for the request such as port , https and authentication headers"
"takes a url template that takes ` owner ` and ` repo ` template variables and as a gitlab repo object . do a get for the provided url and return the response payload , if successful . if unsuccessfuly raise an error ."
like ` query_gitlab ` but return a generator by repeatedly iterating until no link to next page .
add the provided relative path or pattern to the repo 's ` .gitignore ` file .
a dummy fitness function . find a solution with mean 15 .
"_ _ init _ _ : can identify ( in)valid input parameters , raise valueerror if detected"
_ _ init _ _ : respects argument mutual exclusivity
_ _ init _ _ : accepts valid inputs
bitmath.format context mgr sets and restores formatting
byte(3.0 ) prints out units in plural form
"byte(3.0 ) prints out units in plural form , setting the fmt str in the mgr"
"tib(1/3.0 ) prints out units in plural form , setting the fmt str in the mgr"
"tib(1/3.0 ) prints out units in singular form , setting the fmt str in the mgr"
"initializer , takes a callback that processes the received data in the original process ."
"send data , can be called from any process"
returns true if there are currently no pending callbacks
loops indefinitely receiving calls from the queue
redirects standard out to a buffer
redirect standard out and err to a buffer
creates a new sentinel
setup test fixture
teardown test fixture
test the most basic console logging at the debug level
test the most basic console logging at the fatal level
test the most basic console logging at the fatal level
test that logging before initializing the logger works
test logging to file writes something to the log file
test logging to file logs exception info
test timing code logs a message
test timing code and printing really prints a message
test timing code complains if there are no timings
test timing is about right
returns true if iterator 1 is shorter than iterator 2
true if the first iterator starts with the elements of the second
flatten nested sequence
process result submitted from any service to task dispatcher service .
callback for data coming in from a websocket
push json data to the browser via a websocket
unload data that has been placed on the message queue by the client
receive mavlink messages
callback for received mavlink messages
main loop of the module
"判断id对应的证券市场 匹配规则 [ ' 50 ' , ' 51 ' , ' 60 ' , ' 90 ' , ' 110 ' ] 为sh [ ' 00 ' , ' 13 ' , ' 18 ' , ' 15 ' , ' 16 ' , ' 18 ' , ' 20 ' , ' 30 ' , ' 39 ' , ' 115 ' ] 为sz [ ' 5 ' , ' 6 ' , ' 9 ' ] 开头的为sh ， 其余为sz"
判断是否为第三个周五（股指期货交割日，节假日除外 ） 参数 ： dt : datetime格式的数据
判断是否节假日 参数 ： day : 日期 ， 格式为 ' 20160404 ' return : bool
判断今天是否时节假日 return : bool
参数 rate : 滑点比率，如0.1，则买卖方向上各滑点0.1 %
"process pending events in libspotify . this method must be called for most callbacks to be called . without calling this method , you 'll only get the callbacks that are called from internal libspotify threads . when the pyspotify provides an : class:`~spotifyconnect . eventloop ` that you can use for processing events when needed ."
""" pr(kl(simulated data||original ) > kl(bootstrap original||bootstrap original ) )"
return the distinguished name of an x509 certificate
"build the path from node1 to node2 . the path is composed of all the nodes between node1 and node2 , node1 excluded . although if there is a loop starting from node1 , it will be included in the path ."
merge the inner class(es ) of a class : e.g class a { ... } class a$ foo { ... } class a$ bar { ... } = = > class a { class foo { ... } class bar { ... } ... }
return the number of register needed by the type @param
retrieve the java type of a descriptor ( e.g : i )
return the parameters type of a descriptor ( e.g ( ic)v )
thankfully copied from https://stackoverflow.com/a/377028/446140
method invoked by the cliff framework
method invoked by the cliff framework
: param str app_code : app code to use : param str app_secret : app secret to use : param dict common_args : args that will apply to every request : param bool use_test_env : whether use test version of components
change the value of use_test_env
get common args when request
"send request , will add "" signature "" parameter ."
inputs : - separator : 一行中元素的分隔符，默认空格
check that the displayed dialog text matches the regular expression ` ` pattern ` ` . : param pattern : regular expression that matches anywhere in the string
only applicable for radiolist dialogs : check that * there is a preselected item * its tag matches the regular expression ` ` pattern ` ` . : param pattern : regular expression that matches anywhere in the string
only applicable for inputbox dialogs : check that the initially given text matches the pattern ` ` text ` ` : param text : regular expression that matches anywhere in the string
": param actual_function_name : the dialog function that was called ( e.g. "" yesno "" ) : param kwds : a dictionary of all arguments to the function call : return : value that should be returned to the caller"
use ` ` return_value ` ` to compute the function return value . : param return_value : the return value or a callable that takes one argument ( a dictionary of all arguments to the function call ) and returns a value : return : self
add so - called checkers to the list of checkers . a checker is a function that takes one argument ( a dictionary of all arguments to the function call ) and makes some assertions . : return : self
"add an ` ` actionhandler ` ` that expects the function name ` ` function_name ` ` and return it . you should add a return value by invoking ` ` .result ( ... ) ` ` . : param function_name : e.g. "" yesno "" : return : an ` ` actionhandler ` `"
"expect a "" yesno "" dialog and answer it accordingly . : param answer : true if yes should be chosen , false if no should be chosen : return : an ` ` actionhandler ` `"
"expect a "" radiolist "" dialog and choose an item accordingly . : param answer : a regex that matches the item tag that should be selected or none if the dialog should be canceled : return : an ` ` actionhandler ` `"
"expect a "" menu "" dialog and choose an item accordingly . : param answer : a regex that matches the item tag that should be selected or none if the dialog should be canceled : return : an ` ` actionhandler ` `"
"expect an "" inputbox "" dialog and give an input accordingly . : param answer : text should be returned or none if the dialog should be canceled : return : an ` ` actionhandler ` `"
"expect an "" passwordbox "" dialog and give an input accordingly . : param answer : text should be returned or none if the dialog should be canceled : return : an ` ` actionhandler ` `"
context manager that activate all mocks and simulate the user behavior . example : :
"returns true when running with the native port of python for windows , false when running on any other platform ( including the cygwin port of python ) ."
"creates a symbolic link pointing to source named link_name . note : on windows , source must exist on disk , as the implementation needs to know whether to create a "" file "" or a "" directory "" symbolic link ."
"windows only : returns true if path is relative ( e.g. "" .\foo "" ) or is absolute including a drive letter ( e.g. "" c:\foo "" ) . returns false if path is ambiguous ( e.g. "" x : foo "" or "" \foo "" ) ."
"remove ( delete ) the file path . this is a replacement for os.remove , but allows deleting read - only files on windows ."
test whether a path is a symbolic link .
"return a string representing the path to which the symbolic link points . the result may be either an absolute or relative pathname ; if it is relative , it may be converted to an absolute pathname using os.path.join(os.path.dirname(path ) , result ) ."
"return the canonical path of the specified filename , eliminating any symbolic links encountered in the path ."
factory method : instantiates the concrete class according to the current platform .
wraps an existing file descriptor as a stream .
"removes a stream , when done with it ."
returns true when all streams have been processed .
"returns the set of streams that have data available to read . the returned streams each expose a read ( ) and a close ( ) method . when done with a stream , call the remove(stream ) method ."
creates a new stream wrapping an existing file descriptor .
tests that subclasses of plugin inherit the options from the parent class .
tests that conflicting options will raise an exception .
tests that plugins by default parse the passed in arguments .
tests that plugins properly parse the hostname option .
"tests that plugins can properly parse warning ranges from the command line via the "" -w "" option ."
"tests that plugins can properly parse critical ranges from the command line via the "" -c "" option ."
"tests that plugins can properly parse timeout from the command line via the "" -t "" option ."
tests that plugins can properly parse verbosity .
tests that the base plugin throws an exception for check since it is not implemented .
tests that the plugin can return a proper response for the given value .
tests that plugins can set a message when getting a response for a given value .
tests that if warning and critical are not set on the command line then the response is ok .
test that the default parameter to all_responses is working
test that the add_response and all_responses mechanism is working
creates a new object representing a single performance data item for a nagios response .
the value of this metric .
"the warning range of this metric . this return value of this will always be a : py : class:`~pynagios.range . range ` object , even if it was set with a string ."
"the critical range of this metric . this return value of this will always be a : py : class:`~pynagios.range . range ` object , even if it was set with a string ."
"the minimum value possible for this metric . this does n't make a lot of sense if the ` uom ` is ' % ' , since that is obviously going to be 0 , but this will return whatever was set ."
"the maximum value possible for this metric . this does n't make a lot of sense if the ` uom ` is ' % ' , since that is obviously going to be 100 , but this will return whatever was set ."
the unit of measure ( uom ) for this metric .
"returns the proper string format that should be outputted in the plugin response string . this format is documented in depth in the nagios developer guidelines , but in general looks like this :"
returns boolean noting whether a value is in the proper value format which certain values for the performance data must adhere to .
this handles single quoting the label if necessary . the reason that this is not done all the time is so that characters can be saved since nagios only reads 80 characters and one line of stdout .
"return a dictionary suitable for passing to matplotlib.colors . linearsegmentedcolormap html : a sequence of numbers and html style ( hex string ) colors . the numbers will be normalized . step : indicates whether the map should be smooth ( false , default ) or have hard steps ( true ) . name : a name for the custom gradient . defaults to ' customcolormap ' ."
"description : creates a most recent - oldest mosaic of the input dataset . if no clean mask is given , the ' cf_mask ' variable must be included in the input dataset , as it will be used to create a clean mask ----- inputs : dataset_in ( xarray . dataset ) - dataset retrieved from the data cube ; should contain coordinates : time , latitude , longitude variables : variables to be mosaicked if user does not provide a clean_mask , dataset_in must also include the cf_mask variable optional inputs : clean_mask ( nd numpy array with dtype boolean ) - true for values user considers clean ; if user does not provide a clean mask , one will be created using cfmask no_data ( int / float ) - no data pixel value ; default : -9999 output : dataset_out ( xarray . dataset ) - mosaicked data with coordinates : latitude , longitude variables : same as dataset_in"
description : method for calculating the median pixel value for a given dataset . ----- input : dataset_in ( xarray dataset ) - the set of data with clouds and no data removed . optional inputs : no_data ( int / float ) - no data value .
description : method for calculating the pixel value for the max ndvi value . ----- input : dataset_in ( xarray dataset ) - the set of data with clouds and no data removed . optional inputs : no_data ( int / float ) - no data value .
description : method for calculating the pixel value for the min ndvi value . ----- input : dataset_in ( xarray dataset ) - the set of data with clouds and no data removed . optional inputs : no_data ( int / float ) - no data value .
returns lists of lists when given tuples of tuples
: type nco : netcdf4.dataset : type name : str : type labels : numpy.array : type units : str : return : netcdf4.variable
: param nco : : param name : : type var : datacube.model . variable : param kwargs : : return :
takes post data from a request with a user i d and creates a model . todo : use form validation rather than doing it this way .
create output files and return a map of statistic name to writable netcdf dataset
parse a field spec document into objects .
get an sqlalchemy expression for accessing this field . : return :
: rtype : expression
: rtype : expression
parse the value from a string . may be overridden by subclasses .
: rtype : expression
: rtype : expression
: rtype : expression
: rtype : expression
"path_data : string , from an svg path tag 's 'd ' attribute , eg : ' m 46,74 l 35,12 l 53,-13 z ' returns the same data collected in a list of tuples , eg : [ ( ' m ' , 46 , 74 ) , ( ' l ' , 35 , 12 ) , ( ' l ' , 53 , -13 ) , ( ' z ' ) ] , the input data may have floats instead of ints , this will be reflected in the output . the input may have its whitespace stripped out , or its commas replaced by whitespace ."
"commands : list of tuples , as output from to_tuples ( ) method , eg : [ ( ' m ' , 1 , 2 ) , ( ' l ' , 3 , 4 ) , ( ' l ' , 5 , 6 ) , ( ' z ' ) ] interprets the command characters at the start of each tuple to return a list of loops , where each loop is a closed list of verts , and each vert is a pair of ints or floats , eg : [ [ 1 , 2 , 3 , 4 , 5 , 6 ] ] note that the final point of each loop is eliminated if it is equal to the first . svg defines commands : m x , y : move , start a new loop l x , y : line , draw boundary h x : move horizontal v y : move vertical z : close current loop - join to start point lower - case command letters ( eg ' m ' ) indicate a relative offset . see http://www.w3.org/tr/svg11/paths.html"
"color : string , eg : ' # rrggbb ' or ' none ' ( where rr , gg , bb are hex digits from 00 to ff ) returns a triple of unsigned bytes , eg : ( 0 , 128 , 255 )"
"style : string , eg : fill:#ff2a2a;fill - rule : evenodd;stroke : none;stroke - width:1px ; stroke - linecap : butt;stroke - linejoin : miter;stroke - opacity:1 returns color as a triple of unsigned bytes : ( r , g , b ) , or none"
"adds itself to the given batch , as as single primitive of indexed gl_triangles . note that batch will aggregate all such additions into a single large primitive ."
we can handle the request if it 's for a directory and the directory has a gophermap file .
return the fraction of time the ion is in each valence state .
return the time - averaged charge of the ion .
return the products of the acidity .
"return the effective acidity constant , ka , for each valence state ."
return the effective pka for the ion .
computes principal components for training vector set . uses first projection_count principal components for projections .
resets / initializes the hash for the specified dimension .
hashes the vector and returns the binary bucket key as string .
returns pickle - serializable configuration struct for storage .
keeps the configuration .
hashes vector v and stores it in all matching buckets in the storage . the data argument must be json - serializable . it is stored with the vector and will be returned in search results .
returns candidate count for nearest neighbour search for specified vector . the candidate count is the count of vectors taken from all buckets the specified vector is projected onto .
"hashes vector v , collects all candidate vectors from the matching buckets in storage , applys the ( optional ) distance function and finally the ( optional ) filter function to construct the returned list of either ( vector , data , distance ) tuples or ( vector , data ) tuples ."
collect candidates from all buckets from all hashes
apply vector filters if specified and return filtered list
apply distance implementation if specified
clears buckets in storage ( removes all vectors and their data ) .
clears buckets in storage ( removes all vectors and their data ) .
stores vector and json - serializable data in bucket with specified key .
"returns bucket content as list of tuples ( vector , data ) ."
removes all buckets and their content .
removes all buckets and their content .
stores hash configuration
loads and returns hash configuration
find a file in a search path
locate the cuda environment on the system
inject deep into distutils to customize how the dispatch to gcc / nvcc works .
get an imdb ( image database ) by name .
list all registered imdbs .
styleguidedetails - a model defined in swagger
gets the public_url of this styleguidedetails .
sets the public_url of this styleguidedetails .
gets the audience of this styleguidedetails .
sets the audience of this styleguidedetails .
gets the target_audience of this styleguidedetails .
sets the target_audience of this styleguidedetails .
gets the grammatical_person of this styleguidedetails .
sets the grammatical_person of this styleguidedetails .
gets the vocabulary_type of this styleguidedetails .
sets the vocabulary_type of this styleguidedetails .
gets the business of this styleguidedetails .
sets the business of this styleguidedetails .
gets the company_branding of this styleguidedetails .
sets the company_branding of this styleguidedetails .
gets the formatting of this styleguidedetails .
sets the formatting of this styleguidedetails .
gets the glossary_terms of this styleguidedetails .
sets the glossary_terms of this styleguidedetails .
gets the grammar_consistency of this styleguidedetails .
sets the grammar_consistency of this styleguidedetails .
gets the literal_translation of this styleguidedetails .
sets the literal_translation of this styleguidedetails .
gets the overall_tone of this styleguidedetails .
sets the overall_tone of this styleguidedetails .
gets the samples of this styleguidedetails .
sets the samples of this styleguidedetails .
returns true if both objects are equal
projectdetails - a model defined in swagger
gets the shares_translation_memory of this projectdetails .
sets the shares_translation_memory of this projectdetails .
returns true if both objects are equal
member - a model defined in swagger
gets the i d of this member .
sets the i d of this member .
gets the email of this member .
sets the email of this member .
gets the username of this member .
sets the username of this member .
gets the role of this member .
sets the role of this member .
returns true if both objects are equal
translationkey - a model defined in swagger
gets the i d of this translationkey .
sets the i d of this translationkey .
gets the name of this translationkey .
sets the name of this translationkey .
gets the description of this translationkey .
sets the description of this translationkey .
gets the name_hash of this translationkey .
sets the name_hash of this translationkey .
gets the plural of this translationkey .
sets the plural of this translationkey .
gets the data_type of this translationkey .
sets the data_type of this translationkey .
gets the created_at of this translationkey .
sets the created_at of this translationkey .
gets the updated_at of this translationkey .
sets the updated_at of this translationkey .
returns true if both objects are equal
locale - a model defined in swagger
gets the i d of this locale .
sets the i d of this locale .
gets the name of this locale .
sets the name of this locale .
gets the code of this locale .
sets the code of this locale .
gets the default of this locale .
sets the default of this locale .
gets the main of this locale .
sets the main of this locale .
gets the rtl of this locale .
sets the rtl of this locale .
gets the source_locale of this locale .
sets the source_locale of this locale .
gets the created_at of this locale .
sets the created_at of this locale .
gets the updated_at of this locale .
sets the updated_at of this locale .
returns true if both objects are equal
stores a function 's assumptions as an attribute .
stores what assumptions a function is overridden by as an attribute .
creates a decorator that adds a docstring to an equation function .
lex ` ` code ` ` with ` ` lexer ` ` and return an iterable of tokens .
format a tokenlist ` ` tokens ` ` with the formatter ` ` formatter ` ` .
lex ` ` code ` ` with ` ` lexer ` ` and format it with the formatter ` ` formatter ` ` .
special method return a string representation of the instance object .
public method to get the individual message data elements .
private method to restore the timing data from the timing cache .
public method to store the collected profile data .
public method to dump the statistics data .
public method to erase the collected timing data .
public method used to fixup the filename for a given frame .
public method used to trace functions calls .
private slot handling a change of the associated image .
public method to apply adblock rules to a web page .
special method to test equality .
public method to get the url as a string .
module function to create the configuration page .
public slot to save the viewmanager configuration .
private slot to handle the directory selection via dialog .
private slot to set the read only status of the repository url line edit .
public method to get the number of rows of the model .
public method to get the number of columns of the model .
public method to get data from the model .
public method to get flags from the model .
public method to get header data from the model .
public slot to set the number of bits .
public slot to set the value to show .
public slot to set the number of bits and the value to show .
public slot to get the current value .
public method to set the data of a node cell .
private method to format the various number inputs .
private slot to block some signals .
private slot handling a change of the bit size .
private slot to swap the byte order .
private slot to retrieve a binary number from the current editor .
private slot to handle input of a binary number .
private slot to send a binary number .
private slot to handle a change of the binary model value by the user .
private slot to retrieve an octal number from the current editor .
private slot to handle input of an octal number .
private slot to send an octal number .
private slot to retrieve a decimal number from the current editor .
private slot to handle input of a decimal number .
private slot to send a decimal number .
private slot to retrieve a hexadecimal number from the current editor .
private slot to handle input of a hexadecimal number .
private slot to send a hexadecimal number .
writes a report summarizing coverage statistics per module .
read a filename as utf-8 configuration data .
read a list of strings .
read a list of full - line strings .
initialize the configuration attributes to their defaults .
read configuration from the ` env_var ` environment variable .
read config values from ` kwargs ` .
read configuration from a .rc file .
set an attribute on self if it exists in the configparser .
function to create the main widget .
main entry point into the application .
return the absolute normalized form of ` filename ` .
is ` filename ` an absolute path on any os ?
prepare the file patterns for use in a ` fnmatchmatcher ` .
"find the path separator used in this string , or os.sep if none ."
"yield all of the importable python files in ` dirname ` , recursively ."
return the relative form of ` filename ` .
return a canonical filename for ` filename ` .
get data from ` filename ` if it is a zip file path .
a list of strings for displaying when dumping state .
add another directory to the list we match for .
does ` fpath ` indicate a file in one of our trees ?
a list of strings for displaying when dumping state .
does ` fpath ` match one of our filename patterns ?
add the ` pattern`/`result ` pair to the list of aliases .
map ` path ` through the aliases .
public slot to start the ericapi command .
private slot called by a button of the button box clicked .
private slot called when the process finished .
private slot to handle the readyreadstandardoutput signal .
private slot to handle the readyreadstandarderror signal .
module function to create the configuration page .
public slot to save the interface configuration .
private method to populate the style combo box .
private method to select the style sheet file via a dialog .
public slot to initialize the properties .
"public method to check , if a style is a comment style ."
"public method to check , if a style is a string style ."
public method to get the default keywords .
private slot to show security details .
private slot to show a preview of the selected image .
private slot to show a context menu for the images list .
private slot to copy the image url or the image name to the clipboard .
private slot to save the selected image to disk .
private slot to show data about the selected database .
module function to format the given time .
module function to generate a formatted size string .
private method to get the value to compare on for the first column .
"special method to check , if the item is less than the other one ."
private method to create an entry in the result list .
private method to create an entry in the summary list .
private method to resort the tree .
private method used to populate the listviews .
public slot to start the calculation of the profile data .
private slot called when the action finished or the user pressed the button .
private slot called to revert the effects of the _ _ finish slot .
private slot called by a button of the button box clicked .
private slot to show the context menu of the listview .
private slot to handle the erase profile context menu action .
private slot to handle the erase timing context menu action .
private slot to handle the erase all context menu action .
private slot to handle the exclude / include python library context menu action .
find the source for ` filename ` .
"the missing line numbers , formatted nicely ."
were arcs measured in this result ?
returns a sorted list of the arcs in the code .
returns a sorted list of the arcs actually executed in the code .
returns a sorted list of the arcs in the code not executed .
returns a sorted list of the executed arcs missing from the code .
returns a list of line numbers that have more than one exit .
how many total branches are there ?
return arcs that were n't executed from branch lines .
get stats about branches .
set the number of decimal places used to report percentages .
returns the number of executed statements .
returns the number of executed branches .
returns a single percentage value for coverage .
"returns the percent covered , as a string , without a percent sign ."
how many characters wide can pc_covered_str be ?
module function to create the configuration page .
public slot to save the editor highlighter associations configuration .
private slot to add the lexer association displayed to the list .
private slot to delete the currently selected lexer association of the list .
private slot to handle the clicked signal of the lexer association list .
private slot to handle the activated signal of the lexer association list .
private slot to handle the selection of a lexer .
public method to read and parse the xml document .
private method to read the remote debugger info .
private method to read the path translation info .
public method to get header data from the model .
public method to get data from the model .
public method to get the number of columns of the model .
public method to get the number of rows of the model .
public method to remove entries from the model .
public method to add an exception rule .
private method to add a host to an exception list .
public slot to handle the command sent by the client .
"private method used to handle the "" load form "" command ."
"private method used to handle the "" load translation "" command ."
public method to process the command line args passed to the ui .
public slot to perform some polishing actions .
public method to save the current state of the widget .
public method to set the state of the widget .
public method to initialize a colour selection button .
private slot to select a color .
public method to save the colour selections .
public method used by the font selection buttons .
main command line entry point .
module function to create the configuration page .
public slot to save the editorcalltips configuration .
module function to check for data to be written .
private method to check the mode .
private method to write a specific number of pending bytes .
public method that returns the number of bytes waiting to be written .
public method to close the file .
public method to write all pending bytes .
public method to indicate whether a tty interface is supported .
public method returning the file number .
"public method to check , if the stream is readable ."
public method to read bytes from this file .
public method to read bytes from this file .
public method to read a line from this file .
public method to read all lines from this file .
public method to read one line from this file .
"public method to check , if the stream is seekable ."
public method to move the filepointer .
public method to get the filepointer position .
public method to truncate the file .
"public method to check , if a stream is writable ."
public method to write a string to the file .
public method to write a list of strings to the file .
private slot to populate the menu .
private slot to set the default user agent .
private slot to set a custom user agent string .
private slot to change the user agent .
private slot to add the default user agent entries .
special method implementing equality .
special method determining less relation .
public method to check the history for an entry .
public method to get the row number of an entry in the source model .
public method to get data from the model .
public method to set the source model .
private slot to handle the change of data of the source model .
public method to get the header data .
public method to recalculate the frequencies .
private slot to handle a reset of the source model .
public method to determine the number of rows .
public method to get the number of columns .
public method to map an index to the source model index .
public method to map an index to the proxy model index .
public method to create an index .
public method to get the parent index .
private method to load the model data .
private slot to handle the insertion of data in the source model .
private slot to handle the removal of data in the source model .
public method to remove entries from the model .
private method to calculate the frequency score .
private method to restore the timing data from the timing cache .
public method to store the collected profile data .
public method used to fixup the filename for a given frame .
public method used to trace functions calls .
public method to initialize the object .
private method to build a dictionary of modules contained in the package .
public method to build the modules shapes of the diagram .
private method to add a module to the diagram .
private method to generate the associations between the module shapes .
public method to get a string for data to be persisted .
public method to parse persisted data .
read a javascript file and return a dictionary of functions and variables .
public method to parse the source .
private method implementing the visit logic delegating to interesting methods .
public method to ignore the given node .
public method to treat a function node .
public method to treat a property_init node .
public method to treat a variable node .
public method to treat a constant node .
public method to get the current column count .
public method to get the current row count .
public method to get the requested data .
public method to get item flags .
public method to get header data .
public method to create an index .
public method to check for the presence of child items .
public method to add a new watch expression to the list .
public method to set the values of a watch expression given by index .
public method to set the enabled state of a watch expression given by index .
public method to set the values of a watch expression given by index .
public method to delete a list of watch expressions given by their indexes .
public method to delete all watch expressions .
public method to get the values of a watch expression given by index .
public method to get the index of a watch expression given by expression .
private slot to handle the change of the selection .
private slot to delete the currently selected exception of the listbox .
private slot to delete all exceptions of the listbox .
private slot to handle the add button press .
private slot to handle the textchanged signal of exceptionedit .
public method to retrieve the list of exception types .
public method to retrieve the copy data .
private slot to handle the button press for selecting the target via a selection dialog .
private slot to handle changes of the target .
public method to remove entries from the model .
public method to get the number of rows of the model .
public method to get the number of columns of the model .
public method to get flags for a model cell .
public method to get data from the model .
public method to set the data of a model cell .
public method to get the header data .
private slot handling a change of the registered engines .
public method to set the key to be configured .
private slot to handle the ok button press .
private slot to handle the clear button press .
private slot to handle the change of the shortcuts type .
private method to set the text of a key edit .
public method called to filter the event queue .
protected method to handle a key press event .
module function to retrieve the class members .
public method to return the next possible completion for ' text ' .
public method to compute matches when text is a simple name .
public method to compute matches when text contains a dot .
public function to get the filename of the config file .
public function to prepare the given process .
public method to get data from the model .
public method to determine the number of rows .
private method to translate the top level date row into the offset where that date starts .
public method to map an index to the source model index .
public method to create an index .
public method to get the parent index .
"public method to check , if an entry has some children ."
public method to get the item flags .
public method to set the source model .
private slot to handle a reset of the source model .
private slot to handle the insertion of data in the source model .
public method to map an index to the proxy model index .
public method to remove entries from the model .
private slot to handle the removal of data in the source model .
private module function to show a modal message box .
function to show a modal critical message box .
function to show a modal information message box .
function to show a modal question message box .
function to show a modal warning message box .
function to show a model yes / no message box .
function to show a model abort / retry message box .
function to show a model message box to ask for clearing the data .
public method used to shutdown the purge interface .
private method to get a list of files / directories being purged .
public method to purge files and directories not tracked by mercurial .
public method to list files and directories not tracked by mercurial .
public method to write a user agent data file .
private method to write a user agent file .
module function to create the configuration page .
public slot to save the virustotal configuration .
private slot to handle changes of the service key .
private slot to test the entered service key .
private slot to receive the result of the service key check .
protected slot implementing a close event handler .
public slot to start the bookmarks command .
private slot called when the process finished or the user pressed the button .
private slot called by a button of the button box clicked .
private slot connected to the finished signal .
private method to resort the tree .
private method to resize the list columns .
private method to generate a bookmark item in the bookmarks list .
private slot to handle the readyreadstdout signal .
private method to process the lines of output .
private slot to handle the readyreadstderr signal .
private slot to show some error .
private slot to handle the password checkbox toggled .
private slot to send the input to the subversion process .
private slot to handle the press of the return key in the input field .
protected slot to handle a key press event .
protected slot implementing a close event handler .
public slot to start the svn status command .
private slot called when the process finished or the user pressed the button .
private method to resort the tree .
private method to resize the list columns .
private method to generate a tag item in the taglist .
private slot to handle the readyreadstdout signal .
private slot to handle the readyreadstderr signal .
protected slot to handle a key press event .
return a function to the ` name ` method on a singleton ` coverage ` object .
public method to store the entered / modified data .
public method to add an item with item data .
public method to retrieve the data associated with an item .
public method to retrieve the current index .
public method to convert a value to text .
public method to convert a text to a value .
private slot handling service errors .
public method handling service errors for python 2 .
public method handling service errors for python 2 .
public method handling service errors for javascript .
private slot to ( re)initialize the plugin .
private methode to determine the syntax check options .
private slot to translate the resulting messages .
public method to activate this plugin .
public method to deactivate this plugin .
"private slot called , when the the project menu or a submenu is about to be shown ."
"private slot called , when the the project browser menu or a submenu is about to be shown ."
private slot used to check the project files for syntax errors .
private method to handle the syntax check context menu action of the project sources browser .
"private slot called , when a new editor was opened ."
"private slot called , when an editor was closed ."
"private slot called , when the the editor context menu or a submenu is about to be shown ."
private slot to handle the syntax check context menu action of the editors .
public method to write the description of an engine .
private method to write the description of an engine .
public method to set the start and end points of the line .
public method to set the start point .
public method to set the end point .
public method to return the bounding rectangle .
public method to paint the item in local coordinates .
"return all physical tokens , even line continuations ."
"generate a series of lines , one for each line in ` source ` ."
"determine the encoding for ` source ` ( a string ) , according to pep 263 ."
public slot to initialize the properties .
"public method to check , if a style is a comment style ."
"public method to check , if a style is a string style ."
public method to get the default keywords .
converts phone number from ( 610 ) 838 - 2592 to 610 - 838 - 2592 : param phone_number : the phone number to convert : return :
"convert a dictionary of hours from ' fri ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' mon ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' sat ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' sun ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' thu ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' tue ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] , ' we d ' : [ [ ' 00:00 ' , ' 23:59 ' ] ] to mo - su : 24/7 and handle possible variants wafflehouse is open 24/7 at all locations but if sometime , this changes i want to assume this will capture it : param hours : : return :"
initial requests . gets the authorization token via a post request
makes requests for each state . puts the auth token in the headers for each request . callback for start_requests ( )
extracts data and yields geojsonpointitems . callback for handle_oauth_token ( )
"trys to return the hours for a store , some do not list all hours . store_data is a dict of the store data , pulled in via scraping ."
"compute a system 's hinfinity norm , using an lmi approach ."
fix malformed pdf files when data are present after ' % % eof '
"copy filename to a tempfile , write pages to filename except the teared one ."
check whether a given paper needs some pages to be teared or not .
tear some pages of the file if needed .
takes a qwidget that can be modified and must be returned .
load some default values based on system 's settings . is called anytime we open / create a project .
"load settings from ' string ' . ' string ' is the filename of the pickle dump . if fromstring = true , string is the data of the pickle dumps ."
create a new m2crypto public key . optionally load it from a string representation or using a public key .
convert a key in the pem format into a key in the binary format . @note : encrypted pem 's are not supported and will silently fail .
convert a key to the pem format .
get the ec from a public pem .
get the string representation of this key .
"returns the length , in bytes , of each signature made using ec ."
verify whether a given signature is correct for a message .
check if the required curves are available .
check if m2crypto backend keys can be generated correctly .
check if libnacl backend keys can be generated correctly .
check if a bogus curve produces a runtimeerror
check if eccrypto correctly detects an m2crypto key for bin .
check if eccrypto correctly detects an libnacl key for bin .
check if eccrypto correctly detects an m2crypto key for hash .
check if eccrypto correctly detects an libnacl key for hash .
check if eccrypto can detect a valid m2crypto private key .
check if eccrypto does n't detect a valid public m2crypto key as a private key .
check if eccrypto can detect a valid libnacl private key .
check if eccrypto does n't detect a valid public libnacl key as a private key .
check if eccrypto does n't detect a valid m2crypto private key as a public key .
check if eccrypto detects a valid public m2crypto key as a public key .
check if eccrypto does n't detect a valid libnacl private key as a public key .
check if eccrypto detects a valid public libnacl key as a public key .
check if we do n't remove reachable nodes .
check if we remove unreachable nodes .
nothing should happen if we have no nodes to check .
"do n't overload inactive nodes with pings , send it once within some timeout ."
"do n't overload inactive nodes with pings , send it again after some timeout ."
"check if weil pairing in e[4 ] mod 11 of ( 5 , 4 ) and ( 5x , 4 ) with s=(7 , 6 ) equals 9 + 7x"
"check if weil pairing in e[408 ] mod 1223 of ( 764 , 140 ) and ( 18x , 84 ) with s=(0 , 1222 ) equals 438 + 50x"
check if ec sum of the point of infinity with itself is the point at infinity .
check if ec sum of the point of infinity with another point equals the other point .
check if a block signed by one party is stored in the databases of both parties .
check if a double signed transaction is stored in the databases of both parties .
check if a both halves of a fully signed block link to each other .
check if a block can be crawled .
check if the default crawl strategy produces blocks .
check if blocks do n't magically appear .
check if a block can be crawled by negative range .
check if blocks created in parallel will properly be stored in the database .
check if missing blocks are retrieved through a crawl request .
check if we will walk to a random other node .
check if we will walk to an introduced node .
check if we drop an unreachable introduced node .
check if we do n't drop an introduced node immediately .
bind an interface to the www on a certain port ( and ip ) .
"check if the underlying socket is open , or raise an exception ."
check if the underlying socket is open .
get the address for this endpoint .
send a udp packet to a socket_address .
open this endpoint for sending and receiving packets .
close this endpoint for sending and receiving . : param timeout : the maximum amount of time to wait for the socket to close : return : whether closing occurred naturally
the loop handling sending and receiving messages over this endpoint .
send any outstanding / previously undeliverable messages .
the function create parser to arguments
"this function returns a dictionary , that contains information about the problem"
"note that this code compresses into a buffer held in memory , rather than a disk file . this is done through the use of cstringio.stringio ( ) ."
complements the compressbuffer function in cacheclient
get the max - age in seconds from the saved headers data
"returns a datetime instance from a str formatted as follows e.g. ' mon , 03 mar 2014 12:12:12 gmt '"
returns the gmt last - modified datetime or none
returns the gmt response datetime or none
returns true if cached object is still fresh
cleans up the reactor after running startservice on a twisted.application.service
"overrides the deploy functionality to test hendrix outside of the whole django lazysettings.configure ( ) thing . however , as the plugin does rely on ` from djanog.conf import settings ` we should test that flow path also ..."
use the hendrix test project to test the bash deployment flow path
"shows that we can put our protocol ( hey_joe._waydownsouth ) and factory ( hey_joe . websocketservice ) together , along with a transport , and properly open a websocket connection ."
return the persistent object with oid ' oid ' .
like contextlib.closing except hides errors raised by close
creates an object from fixture
implements validation of new user picture uploaded
disables ' add ' button in admin
verifies a string is a possible sha256 hash .
"verifies an rsa signature . args : public_key ( str ): public key with begin and end sections . signature ( str ): hex value of the signature with its leading 0x stripped . message ( str ): message that was signed , unhashed ."
verifies the hash matches the sha256'd message .
"verifies the starlog has all the required fields , and any hashes and signatures match up ."
"verifies the state of a star log has all the required fields , and any hashes and signatures match up ."
verifies the fields of an event .
verifies the rsa signature of the provided event json .
takes the integer form of difficulty and verifies that the hash is less than it .
takes the unpacked form of difficulty and verifies that the hash is less than it .
loads indexed data .
gets a batch of data .
"loads and parses the input file , runs all tests and reports results"
"runs a single test , comparing output and rc to expected output and rc ."
get named configuration option from git repository .
"retrieve pull request information from github . return none if no title can be found , or an error happens ."
modify the signature in vin 0 of the tx to fail cltv
"modify the signature in vin 0 of the tx to pass cltv prepends < height > cltv drop in the scriptsig , and sets the locktime to height"
write out a list of all rpc functions available in ` starwels - cli ` for coverage comparison . this will only happen once per coverage directory .
"delegates to authserviceproxy , then writes the particular rpc method called to a file ."
format keyboard /command field .
this function assumes you 're passing a path to a file and attempts to create the path leading to that file .
returns number of pages in a pdf file
retrieves a new pdf document with the page extracted from the source pdf file .
find whether a given a substring is contained in a list of substrings .
convert each row of matrix f to a string .
same as test_model but reads input file line by line predict class labels of given data using the model learned .
read ~/.viminfo from @filepath
return the dbus proxy object for our plugin
return true if it was running and was stopped
set up change monitor
change callback ; something changed
launch the represented application
"look up @string in the string map , and return the copy in the map ."
"return a list of info dictionaries for all songs in a rhythmbox library database file , with dictionary keys as given in @keys ."
sort album in track order
sort songs in order by album then by track number
@filepath is a filesystem byte string ` str `
set up localization with gettext
return a list of other application flags with -- * prefix included .
initialize an exported gobject .
create a new qfurl for object @obj
"> > > url = "" qpfer://mother / qfid#module_and_type_hint "" > > > qfurl.reduce_url(url ) ' qpfer://mother / qfid '"
"> > > murl = "" qpfer://mother / qfid#module_and_type_hint "" > > > qfurl._parts_mother_id_typename(murl ) ( ' mother ' , ' qfid ' , ' module_and_type_hint ' )"
resolve self in a catalog of sources
"replace the ` * ` placeholder in a format string ( fmt ) , so that struct.calcsize(fmt ) is equal to the given ` size ` using the format following the placeholder ."
read pre- or suffix of line at current position with given format ` fmt ` ( default ' i ' ) .
"return next unformatted "" line "" . if format is given , unpack content , otherwise return byte string ."
"return list strings , each a line from the file ."
skip the next line and returns position and size of line . raises ioerror if pre- and suffix of line do not match .
write ` line ` ( list of objects ) with given ` fmt ` to file . the ` line ` will be chained if object is iterable ( except for basestrings ) .
write ` lines ` with given ` format ` .
"recursively check elements of a sequence ( dict , list , tuple or any other ... which may itselfs encapsulate subsequences ) , given a reference sequence that contains the allowed types or classes , the allowed ( sub)sequences lengths and the allowed values for each element ."
create a : class:`vref ` object . encapsulate these objects in ` ref ` argument for checking an iterable using ` check_fromref ` .
decode the json web token in the data .
encode the response to the request as a json web token .
register node attributes for authorization .
register node attributes for external authorization
register node attributes for external authorization
docstring for _ _ init _ _
"connectes the transport , will callback when done"
"disconenctes the transport , will callback when done"
returns if the transport is connected
returns the uri for this transport
return the aproximate rtt for the transport
return the current coder used or none if none set
return the filtered coders on this transport can be a subset of the total in the system .
send data with a payload to the transport with a timepout
"as soon as any data is received , send it to callback"
"detect falling , rising or both edges"
true if edge has been detected
"set state of pin , 0/1 for state low / high"
get state of pin 0/1 for low / high
set pwm frequency
set pwm duty cycle
shift out data repeat number of times parameters : data - list of tuples with state and time in microseconds
use policies to return access decision for the request .
return authorization response including decision and obligations .
called when the system object is first created .
"captures an image returns : image as jpeg encoded binary string , none if no frame"
add a named section
"get value of option in named section , if section is none ' global ' section is implied ."
"get value of option in named section , if section is none ' global ' section is implied ."
set value of option in named section
append value ( list ) of option in named section
set value of option in named section
set complete config
return the case sensitive keys for ' secton ' and ' option ' ( or none if not present ) in ' conf ' .
"expand $ home , $ user etc . and resolve ' ./actors ' etc . relative to the config file ."
returns config or none if no config at path .
"update config using delta_config . if value in delta_config is list , prepend to value in config , otherwise replace value in config ."
return the ' installation dir ' .
return the list of paths to search for configs . if install dir is in the path from home folder to cwd it is not included a second time .
"allow environment variables on the form calvin_<section>_<option > to override options read from defaults or config files . < section > must be one of global , testing , or developer ."
called when the system object is first created .
play media file
issue bms command and return data as byte data
get data from bms board
all indexes are 0 - based into the the sequence .
generate a hash of the mean ipd for all candidate contexts
"compute the likelihood of the observed ipds at position , given the context"
test out lda model
"for each modification in the best scoring configuration , score a config excluding the current mod against the winning config use this value as the qmod for the deleted modification"
test modified fraction estimation in detection mode around a known modification in lambda
"a function to establish a pipeline through which we can read radar data . first it tries the mongodb , then it tries to find local files , and lastly it sftp 's over to the vt data server ."
a function to read a single record of radar data from a sddataptr object
a function to index radar data into dict from a sddataptr object
a function to read a large amount ( to the end of the request ) of radar data into a list from a sddataptr object
parameters ---------- iyd :
parses /visualization / textures/ and compares with /visualization / textable.json
returns a random texture for a specific name and buildingheight p between 1 and 100
"sets up the heightmap image from roadmap.conf entry heightmap_name , writes ./heightmaps / inuse.txt so other functions know which heightmap to load possible inputs : random : generates a new random map with randommap.py insert_name insert_name.png insert_name.txt"
makes all necessary setups in order to run the polygon - generator
"reads list of procedural_city_generation.polygons . polygon2d objects from file and constructs buildings on top of these . the buildings consist of polygon3d objects , which are saved to /outputs / polygons.txt . see merger module for more details ."
"input : list of vertices representing the roadmap output : list of all polygon2ds representing lots , list of all polygon2ds representing blocks list of all polygon2ds which are too large to be lots polygon2d representing the road - network"
encipher string using railfence cipher according to initialised key .
decipher string using railfence cipher according to initialised key .
encipher string using polybius square cipher according to initialised key .
decipher string using polybius square cipher according to initialised key .
encipher string using caesar cipher according to initialised key .
decipher string using caesar cipher according to initialised key .
encipher string using m209 cipher according to initialised key . punctuation and whitespace are removed from the input .
decipher string using m209 cipher according to initialised key . punctuation and whitespace are removed from the input . the encipher and decipher operations of the m209 are identical .
enigma ( test_decipher ): try deciphering a few known pairs
enigma ( test_encipher ): encipher operation is identical to decipher operation
encipher string using rot13 cipher .
decipher string using rot13 cipher . the deciphering and enciphering operations are identical .
tmin : before 6pm
tmin : after 6pm
tmin : before 6am
tmin : after 6am
calculating degree days
reading xls file with temperature as time serie and calculate degree days
decodes a card object from a string
needed for sorting the cards
needed for sorting the cards
helper function to subtract two lists and return the sorted result
"get the current players name including their username , if possible"
convert a color code to actual color name
convert a color code to actual color name
simple error handler
send a message asynchronously
answer an inline query asynchronously
returns a list of admin ids for a given chat . results are cached for 1 hour .
returns module_name.function_name for a given test
returns a function which either saves some data to a file or ( if that file exists already ) compares it to pre - existing data using a given comparison function .
turns a square matrix into a series of hopping terms .
deprecated method : use : meth:`fit ( ) < algobase.fit > ` instead .
train an algorithm on a given training set .
compute the rating prediction for given user and item .
"used when the ` ` predictionimpossible ` ` exception is raised during a call to : meth:`predict ( ) < surprise.prediction_algorithms.algo_base.algobase.predict > ` . by default , return the global mean of all ratings ( can be overridden in child classes ) ."
"test the algorithm on given testset , i.e. estimate all the ratings in the given testset ."
compute users and items baselines .
build the similarity matrix .
"return the ` ` k ` ` nearest neighbors of ` ` iid ` ` , which is the inner i d of a user or an item , depending on the ` ` user_based ` ` field of ` ` sim_options ` ` ( see : ref:`similarity_measures_configuration ` ) ."
return a qtextcharformat with the given attributes .
apply syntax highlighting to the given block of text .
"do highlighting of multi - line strings . ` ` delimiter ` ` should be a ` ` qregexp ` ` for triple - single - quotes or triple - double - quotes , and ` ` in_state ` ` should be a unique integer to represent the corresponding state changes when inside those strings . returns true if we 're still inside a multi - line string when this function is finished ."
revokes an individual access token . this prevents the access token from being used in any future requests .
revoke the authorization token and all tokens that were generated using it .
revokes the refresh token and all access tokens that were generated using it .
creates a single - variable bayesian model from the provided feature . the feature is an indicator created from a particular level of the original categorical feature .
create the treatment plan .
apply the treatment to the dataframe .
create and apply the treatment plan .
validates the parameters passed in during initialization .
deprecated . use info()['ping ' ] instead .
return a dict with server info and ping .
calculate the distance between two cities using the pythagorean theorem .
function to perform a crossover between two genotypes of the tsp problem .
command line interface for ` ` notify - send - headless ` ` .
python api for headless ` ` notify - send ` ` commands .
create a command execution context for the current graphical session .
reads the json contents from filepath and uses that to compose the engine launch command .
reads the json contents from filepath and uses that to compose the engine launch command .
initialize the ipyparallel pool . the initialization takes all relevant parameters via kwargs .
submits work to the thread pool .
scales out the number of active workers by 1 .
scale in the number of active workers by 1 .
returns the status of the executor via probing the execution providers .
"shutdown the executor , including all workers and controllers ."
test parallel workflows from docs on composing workflows
add a stream log handler .
add a stream log handler .
test parallel dataflow from docs on composing workflows
construct a file object from a url string .
return the resolved filepath on the side where it is called from .
transport file from the site of origin to local site .
transport file from local filesystem to origin site .
overriding the default pickling method .
overloading the default pickle method to reconstruct a file from serialized form
testing python memoization when func bodies differ
return object type name except for dict keys .
pretty - prints the data structure .
return the pretty printed data structure of * object * .
"process incoming request , and propagate it to corresponding services . requests to 3rd party services are made asynchronously . we send requests to all 3rd party services and as soon as a response is received it is added to a response object which aggregates the responses from all services . in the normal functioning mode ( wait_until_complete = false ) this method will immediately return a response right after all requests have been sent . this response will mainly include a response_id parameter that can be later used to pull the actual responses from the 3rd party services ( see responseaggregator.collect_response ) . if wait_until_complete is set to false , then this method will wait untill a response is received for all requests and only then will return an aggregated response including the contents of all 3rd party services individual responses ."
custom django rest framework exception handler that includes ' status_code ' field in the responses .
"every time a new request is made to the endpoints of the audio commons api ( e.g. search ) , a response dictionary is created and stored in a shared key - value store ( we use a redis backend ) . this dictionary is updated as soon as new responses from 3rd party services are received and can be consumed by clients using the /collect endpoint of the audio commons api ."
process iterable to store data . must return the number of inserted records ( even 0 if none )
определяет член предложения для имени существительного и притяжательного местоимепния по падежу
"определение члена предложения у признаков : прилагательного , наречия ,"
"устанавливает связи членов предложения . обстоятельства и определения спрятаны в тех , к кому они относятся . работаем лишь со сказуемым , подлежащим и дополнением ."
числительное в число
ensure a value is a positive integer
convert a list of strings to a text string
custom exception message
check parameters are allowed for a given endpoint
retrieve rest http parameters from an argparse namespace
send an http request to this instance
send a parameterized request to this instance
get information about this instance
get a collection of links ordered by creation date
create a new link or note
update an existing link or note
a posivite integer is a positive integer
a negative integer is not a positive integer
an alphanumeric string is not a positive integer
custom exception formatting
instantiate a new client
missing authentication secret
ensure trailing / are stripped
check parameters - none passed
check parameters - empty dict passed
check parameters - valid params passed
check parameters - invalid params passed
check parameters - valid & invalid params passed
ensure the proper endpoint uri is accessed
invalid uri format
ensure the proper endpoint uri is accessed
retrieve rest parameters from an argparse namespace - get /info
retrieve rest parameters from an argparse namespace - get /links
retrieve rest parameters from an argparse namespace - get /links
ensure the proper endpoint uri is accessed
retrieve rest parameters from an argparse namespace - post /links
retrieve rest parameters from an argparse namespace - post /links
ensure the proper endpoint uri is accessed
retrieve rest parameters from an argparse namespace - put /links
retrieve rest parameters from an argparse namespace - put /links
generate a subparser and arguments from an endpoint dictionary
generate all endpoints ' subparsers from an endpoints dict
"given a service name , return the provider class"
fetch a user or the authenticated user .
get a single github repo 's info .
list a repo 's branches or get a single branch ( in a list ) .
get link for archive download .
create a webhook .
delete a webhook .
url post - processor transforms specific ` /project/<pid > ` or ` /project/<pid>/node/<nid > ` urls into guid urls . ex : ` < nid>/wiki / home ` .
"reverse url lookup for api routes ( that use the jsonrenderer or xmlrenderer ) . takes the same arguments as flask 's url_for , with the addition of ` _ absolute ` , which will make an absolute url with the correct http scheme based on whether the app is in debug mode . the _ xml flag sets the renderer to use ."
convenience function for apiv2 usage : concatenates parts of the absolute api url based on arguments provided
"reverse url lookup for web routes ( those that use the osfwebrenderer ) . takes the same arguments as flask 's url_for , with the addition of ` _ absolute ` , which will make an absolute url with the correct http scheme based on whether the app is in debug mode ."
return true if the current request is a json / ajax request .
handles routing of celery tasks . see http://docs.celeryproject.org/en/latest/userguide/routing.html#routers
factory for mock github objects . example : : :
: param node node : root node to update : param str file_id : the _ i d field of a filenode : param int version_idx : zero - based version index
serialize revision for use in revisions table .
"build name for downloaded file , appending version date if not latest ."
"a small decorator factory for osfstoragefilenode . acts as a poor mans polymorphic inheritance , ensures that the given instance is of "" kind "" folder or file"
"copy the files from src to the target nodesettings : param osfstoragefilenode src : the source to copy children from : param nodesettings target_settings : the node settings of the project to copy files to : param osfstoragefilenode parent : the parent of to attach the clone of src to , if applicable"
recursively sort keys of input data and all its nested dictionaries . used to ensure consistent ordering of json payloads .
landing page for the prereg challenge
"the object "" type "" used in the osf v2 api . e.g. comment objects have the type ' comments ' ."
"the page type associated with the object / comment.root_target . e.g. for a wikipage , the page name is ' wiki ' ."
"check whether an object ( e.g. file , wiki , comment ) is attached to the specified node ."
"return extra data to pass as ` params ` to ` node.add_log ` when a new comment is created , edited , deleted or restored ."
flattens relationships dictionary which has information needed to create related resource objects .
"flattens data objects , making attributes and relationships fields the same level as i d and type ."
parses the incoming bytestream as json and returns the resulting data .
parses the incoming bytestream as json . validates the ' signature ' in the payload then returns the resulting data .
validates registration_metadata field .
handle cas institution authentication request .
"given a cookie value , return the ` session ` object or ` none ` ."
verify users ' status .
"if request bears an osf cookie , retrieve the session and verify the user ."
"overwrite basicauthentication to authenticate by email , password and two - factor code . ` authenticate_credentials ` handles email and password , ` authenticate_twofactor_credentials ` handles two - factor ."
authenticate the user by userid ( email ) and password .
authenticate the user 's two - factor one time password code .
"returns custom value other than "" basic "" to prevent basicauth dialog prompt when returning 401"
check whether the request provides a valid oauth2 bearer token . the ` user ` in ` cas_auth_response ` is the unique guid of the user . please do not use the primary key ` i d ` or the email ` username ` .
return an empty string .
"metadata received from waterbutler , is built incrementally via latent task calls to this endpoint ."
"collect file trees for all add - ons implementing hgrid views , then format data as appropriate ."
view that returns the formatted data for rubeus.js/hgrid
correctly formats both bulk and single post response
adds many = true to serializer if bulk operation .
correctly formats bulk put / patch response
retrieves resources in request body
ensures user has permission to bulk delete resources in request body . override if not deleting relationships .
"override on view if allowing bulk delete request to skip resources for which the user does not have permission to delete . method should return a dict in this format : { ' skipped ' : [ array of resources which should be skipped ] , ' allowed ' : [ array of resources which should be deleted ] }"
handles bulk destroy of resource objects .
"make any necessary modifications to the user settings object , e.g. setting access_token ."
initialize user settings object if requested by ` self . owners ` .
"initialize node settings object if requested by ` self . owners ` , additionally linking to user settings if requested by ` self . node_user_field ` ."
"adds object to collection , creates collectedguidmetadata reference performs type / metadata validation . user permissions checked in view ."
removes object from collection
mark collection as deleted
find pending emails and amalgamates them into a single email .
get all emails that need to be sent .
take list of notifications and group by node .
remove sent emails .
update instance with the validated data .
report object is spam or other abuse of osf
retract last report by user
must return is_spam
blinker listener for registration initiations . enqueqes a chain of archive tasks for the current node and its descendants
"blinker listener for updates to the archive task . when the tree of archivejob instances is complete , proceed to send success or failure mails"
"mimic as_view ( ) returned callable , but returns view instance"
mimic as_view and with forms to skip some of the context
this decorator is a temporary fix to prevent bingpreview from pre - fetching confirmation links .
require that user be logged in . modifies kwargs to include the current user .
"a generic function to get the archive provider for some node , user pair ."
"a generic function for checking whether or not some node , user pair has an attached provider for archiving"
"a generic function for linking some node , user pair with the configured archive provider"
recursively traverse the addon 's file tree and collect metadata in aggregatestatresult
"reduces a tree of folders and files into a list of ( < sha256 > , < file_metadata > ) pairs"
note : : file_map is injected implictly by the decorator ; this method is called like :
"returns the latest available version for the browsable api , otherwise rest_framework default version"
execute a local command
execute a remote command via ssh
"receives a string and returns i d , data . frame : string input ( e.g. 415#19e6d0f907fa07fa ) output i d ( hex ) , data ( [ hex ] )"
provision a phaxio fax number
derovision a phaxio fax number
webhook for phaxio receive faxes
view a fax
delete an incoming fax
serve the home page .
serve the image .
"serve the image , with advanced options ."
serve image with address balance .
"assumes that the pumps are xcaliburd pumps and returns a list of ( < serial port > , < instantiated xcaliburd > ) tuples"
configures the cache file .
initialize class .
main method .
returns a list of matching patterns from the cache .
returns data from cache that matches the pattern .
creates a dictionary of environment variables to use the assembler randomisation .
creates a new builder for a program block .
build the program block in parallel with at maximum ` thread_count ` threads in parallel .
creates a new builder thread
"queue fetch loop , that builds the fetched program block configurations ."
"return the name of the tag , without namespace ."
try to guess the simple type and convert the value to it .
return an otrs ticket .
return an otrs article .
initialize otrs object .
get an attribute for aan otrsobject .
create an otrs object from xml .
add a child object to an otrs object .
check that the list of fields is bound .
create an xml representation of an otrs object .
return the dynamic fields for an object ket as a list .
save the attachments of an article to the specified folder .
return the dynamic fields for an object ket as a list .
helper to construct xblock objects
helper to generate scope ids for an xblock
helper to make a request
: return text
parses values from the outcome service xml .
handler for outcome service requests .
returns a loop decorator with this button .
"subtracts the mean rgb value , and transposes rgb to bgr . the mean rgb was computed on the image set used to train the vgg model ."
downloads the imagenet classes index file and loads it to self.classes . the file is downloaded only if it not already in the cache .
predict the labels of a set of images using the vgg16 model .
"adds a specified number of zeropadding and covolution layers to the model , and a maxpooling layer at the very end ."
adds a fully connected layer of 4096 neurons to the model with a dropout of 0.5
creates the vgg16 network achitecture and loads the pretrained weights .
"takes the path to a directory , and generates batches of augmented / normalized data . yields batches indefinitely , in an infinite loop ."
replace the last layer of the model with a dense ( fully connected ) layer of num neurons . will also lock the weights of all layers except the new layer so that we only learn weights for the last layer in subsequent training .
modifies the original vgg16 network architecture and updates self.classes for new training data .
configures the model for training . see keras documentation : https://keras.io/models/model/
trains the model for a fixed number of epochs ( iterations on a dataset ) . see keras documentation : https://keras.io/models/model/
fits the model on data yielded batch - by - batch by a python generator . see keras documentation : https://keras.io/models/model/
predicts the classes using the trained model on data yielded batch - by - batch .
this function prints and plots the confusion matrix . normalization can be applied by setting ` normalize = true ` . ( this function is copied from the scikit docs . )
a command tool to download netease - music 's songs .
download a song by name or i d.
download a album 's songs by name or i d.
download a artist 's hot songs by name or i d.
download a playlist 's songs by i d.
download a user 's playlists by i d.
download my playlists .
helper function to resolve mni path based on mni_template prefs setting .
: type words : list[str ] : rtype : list[str ]
iterator function for python 3 .
makes sure messages are pythonic .
used exclusively as a thread which keeps the websocket alive .
connects and subscribes to the websocket feed .
disconnects from the websocket feed .
receive the next message in the sequence .
checks if we are connected to the websocket feed .
creates fully qualified endpoint uris .
makes sure we have proper iso 8601 time .
returns the given response or raises an apierror for non-2xx responses .
abstract method - must be overriden .
performs http get requests .
performs http post requests .
performs http post requests .
iterator function for python 3 .
checks if a next message is possible .
returns true if the direction is set to before .
returns true if the direction is set to after .
sets the direction to before .
sets the direction to after .
abstract method - must be overriden . performs the endpoint operation
acquires the before cursor .
acquires the after cursor .
preprocesses brainfuck sourcecode .
formats preprocessed code for pretty - printing .
"for an indicator_id , region_id , campaign_id , value try to figure out why the data is in correct ."
the current state of the state machine . writing to this attribute advances the state of the state machine .
rewind can be used as an exceptional way to roll back the state of a : class:`orderedstatemachine ` .
wait for an exact state ` new_state ` to be reached by the state machine .
wait for a state to be entered which is greater than or equal to ` new_state ` and return .
query the software version of an entity .
the operating system of this entity .
the software name of this entity .
the software version of this entity .
": param feature_var : : xep:`30 ` feature ` ` var ` ` of the required feature : type feature_var : : class:`str ` : param argname : optional argument name to pass the : class:`featureinfo ` to : type argname : : class:`str ` or : data:`none ` : param multiple : if true , all peers are returned instead of a random one . : type multiple : : class:`bool `"
: param quirk : the quirk to skip on : type quirk : : class:`quirks `
the decorated coroutine function is run using the : meth:`~asyncio . abstracteventloop.run_until_complete ` method of the current ( at the time of call ) event loop .
"like : func:`blocking_with_timeout ` , the decorated coroutine function is executed using : meth:`asyncio . abstracteventloop.run_until_complete ` with a timeout , but the timeout is configured in the end - to - end test configuration ( see : ref:`dg - end - to - end - tests ` ) ."
this is the configured : class:`.provision . provisioner ` instance .
return the boolean - not of the value of ` expr ` . a expression value is true if it contains at least one element and false otherwise .
return the toplevel object for the given ` class _ ` . only exact matches are returned .
set the toplevel object to return from : meth:`get_toplevel_object ` when asked for ` class _ ` to ` instance ` .
evaluate the expression ` expr ` and return the result .
evaluate the expression ` expr ` and return the truthness of its result . a result of an expression is said to be true if it contains at least one value . it has the same semantics as : func:`bool ` on sequences.s
retrieve the current toplevel instance of ` class _ ` from the : class:`evaluationcontext ` . `
return the file system path relative to the root of a file - system based caps database for this key .
verify whether the cache key maches a piece of service discovery information .
extract cache keys from a presence stanza .
insert cache keys into a presence stanza .
calculate the cache keys for a disco#info response .
return a query set which requests a specific page .
limit the result set to a given number of items .
return a query set which requests the page after this response .
return a query set which requests the page before this response .
return a query set which requests the last page .
returns true if a wrapper is ( optionally ) allowed to buffer log content from the current thread .
enable buffering by all supported wrappers for this thread until endbufferingforcurrentthread is called .
end buffering . this is idempotent and can be safely called even if it was not started .
"publishes the specified local path as an artifact , if supported by the configured output format ."
called to make a custom console formatter class available for use by xpybuild .
"publishes the specified local path ( e.g. a log file ) as an artifact , if supported by this formatter ."
give us an iterator that returns us a read ( and which bam it 's from ) until we run out of reads from every bam
": param bam_in_l : : param out_prefix : : param criterion : { ' d_err ' , ' mq ' , ' mapped ' , ' p_diff ' } : param threshold : : param simulated : : param sidecar_fname : return :"
compute partitions and the files that correspond to each partition
": param rl : a list of read objects [ 0 , 1 , 2 , ... ] : param x : threshold : return :"
": param rl : a list of read objects [ 0 , 1 , 2 , ... ] : param x : threshold : return :"
: param rl : : param x : mq threshold : return :
: param rl : : param args : rest are ignored : return :
"treating a as a gold standard , consider p_diff as the difference in alignment to a. reads that are unmapped in a are discarded . basically , modify the reads in place by filling out tag xd then simply call partition_by_d_err for mapped reads . for unmapped reads return none"
": param rl : a list of read objects [ 0 , 1 , 2 , ... ] : param scoring_function : a function that returns 0 or 1 to indicate if a read is out or in the partition : return : a number between 0 and 2^n-1 where n = len(rl ) indicating the partition"
correctly split c1 ( address ) records like foo ; bar ; baz
correctly split c1 ( address ) records like [ a ; b ] foo ; [ c ; d ] bar
generator for getting n of evenly distributed colors using hsv color and golden ratio . it always return same order of colors
"normalizes string , removes non - alpha characters , and converts spaces to hyphens ."
returns absolute path to given executable name if exists on path
": param ( str ) request_id : a request_id can be shared with dropbox support to pinpoint the exact request that returns an error . : param error : an instance of the error data type for the route . : param ( str ) user_message_text : a human - readable message that can be displayed to the end user . is none , if unavailable . : param ( str ) user_message_locale : the locale of ` ` user_message_text ` ` , if present ."
returns the subtitle of the menu
returns the todo list without the todo of the given index
returns the todo list without the given item
asks confirmation to delete the project
deletes the existing project
returns the project name
returns the typed command
returns the attributes of the command
returns all item titles typed by the user the user can type several titles separated by a comma
cancels the current command
exits the program if no project found
asks to create a new project if none found
updates the project file with the new data
creates a copy of the todo list with the new item
"7 tab delimited properties : domain - the domain that created and that can read the variable . flag - a true / false value indicating if all machines within a given domain can access the variable . this value is set automatically by the browser , depending on the value you set for domain . path - the path within the domain that the variable is valid for . secure - a true / false value indicating if a secure connection with the domain is needed to access the variable . expiration - the unix time that the variable will expire on . unix time is defined as the number of seconds since jan 1 , 1970 00:00:00 gmt . name - the name of the variable . value - the value of the variable ."
"general purpose function to add an html element tag to the given text with the optional attributes . tag parameter should be just the tag name without any brackets , etc ."
"given a string , transforms into a suitable html i d"
return a list of path elements .
removes namespace prefixes from elements of the supplied path .
removes the last path element and returns both parts .
plots a seasonal time - series for a proxy
"find the nearest point in [ lons , lats ] to ' point '"
find missing or mistyped geographic names in data files
"rpc , 微服务调用。post方法接收参数 , 1函数名 : func 2args : [ ] 3kwargs : { } : param namespace : 运行空间 : param fun_name : 运行函数名 : return : get : 返回函数参数格式 post : 返回微服务调用返回值"
update / install / restart，全参数post
callback for use when the broker connection status info is available .
callback for use when receiving a mqtt message .
callback for use when receiving a mqtt message .
update the gui
close the gui
initialize the vehicle simulator .
obtains a u2finterface for the first valid local u2fhid device found .
registers app_id with the security key .
authenticates app_id with the security key .
create reader for arrow streaming format
create reader for arrow file format
serialize a pandas dataframe into a buffer protocol compatible object .
deserialize a buffer protocol compatible object into a pandas dataframe .
read contents of stream and convert to pandas . dataframe using table.to_pandas
"normalizes b - vectors to be of unit length for the non - zero b - values . if the b - value is 0 , the vector is untouched ."
"given the desired location for atlases and the type of processing , ensure we have all the atlases and parcellations ."
"crawls the given bids organized directory for data pertaining to the given subject and session , and passes necessary files to ndmg_pipeline for processing ."
crawls the output directory from ndmg and computes qc metrics on the derivatives produced
creates a brain graph from mri data
"given a list of files , returns a dictionary of graphs"
function called by nose on module load
function called by nose after all tests in this module ran
prepare model test fixture .
finish model test fixture .
get model test dependencies .
model objects can be created
model objects can be queried
create and configure sqlalchemy extension
create and attach cache extension
create and attach babel extension
create and attach login extension
create and attach assets extension
this is the entry point
plots of the model and the acquisition function in 1d and 2d examples .
plots to evaluate the convergence of standard bayesian optimization algorithms
integrated expected improvement
integrated expected improvement and its derivative
test that acquisition function returns correct weighted acquisition
test that acquisition function with gradients returns correct weight acquisition and gradient
renders template ` ` text ` ` with widget_tweaks library loaded and myform instance available in context as ` ` form ` ` .
renders ` ` field ` ` of myform with filter ` ` template_filter ` ` applied . ` ` params ` ` are filter arguments .
renders myform 's field ` ` field ` ` with attributes passed as positional arguments .
get the numerical recording priority for a talk .
get a one line representation of a talk 's scheduled room .
return an ios8601 formatted start time .
filters a dat file based on a v 's recommended wiki page .
"показывает информацию о книге ( iterable - список книг , отдаваемый searchcatalog ) directory - папка с архивами"
parameters ---------- src_file format
load from pypit output
parameters ---------- version : int 1 : find extras from set of lowredux fits src_file : str plot
parameters ---------- id_lines u_lines spec wave
initialize the class and calculate the ` ` pmf ` ` and ` ` cdf ` ` .
calculate the probability mass function ` ` pmf ` ` for the input values .
calculate the cumulative distribution function for the input values .
return the p - values corresponding to the input numbers of successes .
return the values of the cumulative density function .
return the values of the variable ` ` xi ` ` .
return the values of ` ` chi ` ` for the specified indices .
assert that the input values ` ` number_successes ` ` are ok .
check whether all the ` ` xi``s have imaginary part equal to 0 .
"check that all the input probabilities are in the interval [ 0 , 1 ] ."
replace all uploaded file references in a content string with the results of rendering a template found under ` ` template_path ` ` with the ` ` fileupload ` ` instance and the key = value options found in the file reference .
"render a single ` ` fileupload ` ` model instance using the appropriate rendering template and the given keyword options , and return the rendered html ."
return the fraction of each species at a given ph.
return the fraction of each species at a given ph.
calculate the charge balance difference .
solve the ph of the system .
the locale for this champion .
a set of tags to return additonal information for this champion when it 's loaded .
the region for this rune .
the platform for this rune .
the version for this rune .
the locale for this rune .
a set of tags to return additonal information for this champion when it 's loaded .
the rune 's name .
the rune 's id .
the image information for this rune .
the ` coredata ` _ types that belongs to this core type .
updates ` self ` with ` kwargs ` and returns ` self ` .
clean all data in buffer
go to my window & execute command
initialize the config parser .
inspect the available configurations for the supplied key .
converts a list of bytes or an 8 - bit string to an integer .
converts a number to a string of bytes .
draw all windows onto supplied surface .
there are no application wide actions supported yet .
"per - key addition of two dictionaries , where values are additive ."
"per - key subtraction of two dictionaries , where values are additive ."
choose randomly from weighted choices
returns the greatest common divisor of p and q
converts a list of bytes or a string to an integer
converts a number to a string of bytes
calculates r = a^p mod n
reads a random integer of approximately nbits bits rounded up to whole bytes
ceil(x ) - > int(math.ceil(x ) )
returns a random integer x with minvalue < = x < = maxvalue
"returns 1 if p may be prime , and something else if p definitely is not prime"
calculates the value of the jacobi symbol ( a / b )
"returns false if n is an euler pseudo - prime with base x , and true otherwise ."
calculates whether n is composite ( which is always correct ) or prime ( which is incorrect with error probability 2**-k )
"returns true if the number is prime , and false otherwise ."
returns a prime number of max . ' math.ceil(nbits/8)*8 ' bits . in other words : nbits is rounded up to whole bytes .
"returns true if a and b are relatively prime , and false if they are not ."
returns a tuple of two different primes of nbits bits
"returns a tuple ( d , i , j ) such that d = gcd(a , b ) = ia + jb"
"calculates an encryption and a decryption key for p and q , and returns them as a tuple ( e , d )"
"generate rsa keys of nbits bits . returns ( p , q , e , d ) ."
"generates public and private keys , and returns them as ( pub , priv ) ."
"encrypts a message using encryption key ' ekey ' , working modulo n"
"decrypts a cypher text using the decryption key ' dkey ' , working modulo n"
"signs ' message ' using key ' dkey ' , working modulo n"
"verifies ' signed ' using key ' ekey ' , working modulo n"
pickles and base64encodes it 's argument chops
base64decodes and unpickes it 's argument string into chops
"splits ' message ' into chops that are at most as long as n , converts these into integers , and calls funcref(integer , key , n ) for each chop ."
"glues chops back together into a string . calls funcref(integer , key , n ) for each chop ."
encrypts a string ' message ' with the public key ' key '
signs a string ' message ' with the private key ' key '
decrypts a cypher with the private key ' key '
verifies a cypher with the public key ' key '
sets up the connection to the server ( max 6 attemps )
reads the configuration from the server
launches main threads
listens for inputs from the server
checks if there are messages to send to the server and sends them
interprets message from the server other than type url . ( ie : info )
takes url from the urltovisit queue and visits them
dispatches packets to the right packet queue
disconnects from the server
initialize the json backend .
save default settings for all the properties from orca.settings .
save minimal subset defined in the profile against current defaults .
load from config file all settings
get general settings from default settings and override with profile values .
get pronunciation settings from default settings and override with profile values .
get keybindings settings from default settings and override with profile values .
check if we 're in first start .
set firststart . this user - configurable settting is primarily intended to serve as an indication as to whether or not initial configuration is needed .
list available profiles .
creates an instance of the utilities class .
gets all of the children that have relation_node_child_of pointing to this expanded table cell . overridden here because the object which contains the relation is in a hidden column and thus does n't have a column number ( necessary for using getaccessibleat ( ) ) .
"determines the node level of this object if it is in a tree relation , with 0 being the top level node . if this object is not in a tree relation , then -1 will be returned . overridden here because the accessible we need is in a hidden column ."
"creates a script for the given application , if necessary . this method should not be called by anyone except the script manager ."
returns the braille generator for this script .
returns the speech generator for this script .
does nothing .
does nothing .
creates a new script for the given application .
returns true if the given accessible is the text object for associated with a chat room conversation .
called whenever text is inserted into one of ekiga 's text objects . overridden here so that we can present new messages to the user .
"called whenever an object 's value changes . overridden here because new chat windows are not issuing text - inserted events for the chat history until we "" tickle "" the hierarchy . however , we do seem to get object : property - change : accessible - value events on the split pane . so we 'll use that as our trigger to do the tickling ."
run go - pca and store the result in a ` pickle ` file .
save the current object to a pickle file .
read a run from a pickle file .
test if required data files were downloaded successfully .
test if the go - pca test run produced the correct results .
link existing benchmark countries to newly created countries .
link existing benchmark countries to newly created countries .
test that a non - logged - in user can view the sign - up form .
test that a non - logged - in user can view the sign - up form that has an invite link .
test that signup without email is rejected .
test that the user receives a confirmation email when they signup for an account with an email address .
test that a settings object is created when the user is created .
"create default usersettings for each user , if they do n't already have settings ."
remove all usersettings .
add two numbers together .
"return document metadata from open graph , meta , and title tags ."
fetch title and description metadata for the given source .
use a predicate to partition entries into false entries and true entries .
return list where subsequent occurrences of repeat elements have been removed .
"return a view for adding a hypothesis , or handle form submission ."
"return a view for editing a hypothesis , or handle board submission ."
[ a - za - z][a - za - z0 - 9 _ ] *
[ ^\n ]
reads the configuration from a yaml file .
generate all network definition files based on the config passed in .
generate one network definition file .
checks filter config and runs filters specified depending on type .
convert string into a list of texts and numbers in order to support a natural sorting .
update description and hwid from usb data
"item access : backwards compatible - > ( port , desc , hwid )"
get a buffer for a string
if backup_path is none = > no backup
"uses ifup to check interfaces file . if it is not in the default place , each interface must be checked one by one ."
write if applicable
write if applicable
construct and write the iface declaration . the addrfam clause needs a little more processing .
write the bridge information .
"write the up , down , pre - up , and post - down clauses ."
"write plugins options , currently hostapd ."
write unknowns options
backup interfaces file is the file exists
restore interfaces file is the file exists
all adapters should validate
all adapters should validate
all adapters should validate
returns the number of commits since version.yaml was changed .
write a signal as a wave file .
get the variables a string in var = value format .
test the attenuation of the resampler at the given frequency .
test the snr using a test tone at the given frequency .
"using the size of the y axis , return a fraction of that size ."
"hide tick values that are outside of [ min_tick_value , max_tick_value ]"
only show ticks from 0.0 to 1.0 .
add a p - value significance indicator .
overlay a stripplot on top of a boxplot .
perform a fisher 's exact test to compare to binary columns
create a box plot comparing a condition and perform a mann whitney test to compare the distribution in condition a v b
create a roc curve and compute the bootstrap auc for the given variable and outcome
compact string representation which does n't print any of the collection elements .
"create a string representation of this collection , showing up to ` limit ` items ."
"data is a map , errors a list"
"data is a map , errors a list"
data is the entire xml body / document
a helper method that does the actual sending .
n : normalized to [ 0 .. 1.0 ]
"b and a : orthogonal coordinates , normalize [ 0 .. 1.0 ] . return a new b given a and b."
all args are points .
gets a customized logger .
init a logging filehandler with file mode using formatter ` ` _ formatter ` ` .
init a logging streamhandler using formatter ` ` _ filematter ` ` .
function to merge two arrays
function to sort an array using merge sort algorithm
this function prints the text passed as argument to this function
this function finds the factorial of the number passed as argument
pose3d contructor . exits when it receives a exception diferent to ice . connectionrefusedexception
updates pose3d .
returns if proxy has ben created or not .
returns last pose3d .
translates from quaternion to yaw .
translates from quaternion to pitch .
translates from quaternion to roll .
pose3diceclient contructor .
"starts the client . if client is stopped you can not start again , threading . thread raised error"
"stops the client . if client is stopped you can not start again , threading . thread raised error"
returns last pose3d .
returns if proxy has ben created or not .
work out signal loss times for a log file
work out the struct format for a type
generate complete python implemenation
generate mavlink message formatters and parsers ( c and python ) using options and args where args are a list of xml files . this function allows python scripts under windows to control mavgen using the same interface as shell scripts under unix
generate the python code on the fly for a mavlink dialect
calculate some interesting datapoints of the file
ping ( ) pings device
pretty printing from a stack overflow answer : http://stackoverflow.com/questions/3229419/pretty-printing-nested-dictionaries-in-python#answer-26209900 .
this function fetches all philo_ids for div elements within a doc
fetches the current instance of flask - praetorian that is attached to the current flask app
adds a dictionary of jwt data ( presumably unpacked from a token ) to the top of the flask app 's context
fetches a dict of jwt token data from the top of the flask app 's context
removes the dict of jwt token data from the top of the flask app 's context
this method returns the user i d retrieved from jwt token data attached to the current flask app 's context
this method returns a user instance for jwt token data attached to the current flask app 's context
this method returns the names of all roles associated with the current user
enable can build . by doing this here we can auto - enable can in the build based on the presence of can pins in hwdef.dat
optionally load extra environment variables from env.py in the build directory
pre - build hook to change dynamic sources
"create a new : class:`connectionpool ` based on host , port and scheme ."
empty our store of pools and direct them all to close .
"get a : class:`connectionpool ` based on the host , port , and scheme ."
similar to : func:`urllib3.connectionpool.connection_from_url ` but does n't pass any additional parameters to the : class:`urllib3.connectionpool . connectionpool ` constructor .
same as : meth:`urllib3.connectionpool . httpconnectionpool.urlopen ` with custom cross - host redirect logic and only sends the request - uri portion of the ` ` url ` ` .
"sets headers needed by proxies : specifically , the accept and host headers . only sets headers not provided by the user ."
"same as http(s)connectionpool.urlopen , ` ` url ` ` must be absolute ."
"given a string and an iterable of delimiters , split on the first found delimiter . return two split parts and the matched delimiter ."
"given a url , return a parsed : class:` . url ` namedtuple . best - effort is performed to parse incomplete urls . fields not provided will be none ."
deprecated . use : func:`.parse_url ` instead .
for backwards - compatibility with urlparse . we 're nice like that .
absolute path including the query string .
network location including host and port
monkey - patch urllib3 with pyopenssl - backed ssl - support .
undo monkey - patching by : func:`inject_into_urllib3 ` .
"adds a ( name , value ) pair , does n't overwrite the value if it already exists ."
returns a list of all the values for the named field . returns an empty list if the key does n't exist .
takes a single incoming air stream and splits it into two separate ones based on a given mass flow for the fl_o1
indexes : class:`particle ` objects . it returns a regex pattern which matches to any particle morphs and a dictionary indexes the given particles by regex groups .
shortcut for : class:`particleregistry.parse ` of the default registry .
shortcut for : class:`particleregistry.pick ` of the default registry .
shortcut for : class:`particleregistry.postfix ` of the default registry .
shortcut for : class:`tossi . formatter.format ` of the default registry .
defines a singleton instance immediately when defining the class . the name of the class will refer the instance instead .
the tuple containing all the possible tolerant morphs .
gets a tolerant morph .
determines one of allomorphic morphs based on a coda .
determines one of allomorphic morphs based on a word .
the syntax sugar to determine one of allomorphic morphs based on a word : :
the tuple containing the given morphs and all the possible tolerant morphs . longer is first .
add a new handler for this event .
remove a previously defined handler for this event .
function decorator to add an handler .
return declared handler count .
default settings exists
default_logging is valid
execute an ansible adhoc command returning the results in a adhocresult object .
testing ' bin_allocation_integers '
testing ' bin_allocation_alphabet '
testing ' segmentation '
testing ' mean '
testing ' arange '
testing ' paa '
testing ' sax '
testing ' num_red '
testing ' vsm '
testing ' gaf '
testing ' mtf '
testing ' dtw '
testing ' fast_dtw '
testing ' recurrence_plot '
load clowder from yaml file
load clowder from base yaml file
load clowder from import yaml file
combine imported group with existing groups
combine imported project with existing projects
combine imported source with existing sources
load clowder projects from imported group
load clowder groups from imported yaml
load clowder projects from imported group
load clowder sources from imported yaml
check whether yaml file contains required value
clowder start command entry point
clowder start command private implementation
clowder start tracking command
clowder start branches command
projectreporecursive _ _ init _ _
discard changes for repo and submodules
repo has submodules
check whether submodule repo is dirty
update submodules recursively and initialize if not present
sync fork with upstream remote
validate repo state
clean all submodules
base submodule command
reset all submodules
update all submodules
clowder swift tests
clowder swift config versions tests
clowder swift configure remotes tests
clowder swift reset tests
private execute command
force symlink creation
remove directory at path
"returns target path if input is a symlink , otherwise returns original path"
clowder link command entry point
clowder link command private implementation
runs script in project directories specified
clowder forall command entry point
clowder forall command private implementation
save yaml file to disk
": param word2index : word2index dictionary : param embedding_file : a file contain word and its embedding : param trainded_model : ' google_w2v','polyglot ' : return :"
define a basic representation of the class object .
define a formatted string representation of the object 's content . in the interest of not overflowing 80 - character lines this does not print the value of ` pysmart.attribute . attribute.flags_hex ` .
get stuff from plexpy and handles errors
parameters ---------- table_name
parameters ---------- file
writes an image from a byte buffer
"adds an image to a table , also creating it if it does n't exist ."
adds the top n trending places to the database
fetches an image from the database and saves it on file
fetched records saved in a database
for any general query on the database
delete the specified table from the db
produce v2 manifest of type application / vnd.docker.distribution.manifest.v2+json
base58 - > base32 conversion . strips padding
"invoke "" ipfs -r "" on work . no error checking . returns a pullable string"
reads a file to string
produce v1 manifest
pretty - prints a jsn object
buils a full path and reads it as json
remove host / port part from an image name
"get the django paginator data object from the given * context * . the context is a dict - like object . if the context key ` ` endless ` ` is not found , a * paginationerror * is raised ."
"retrieve the current page number from * get * or * post * data . if the page does not exists in * request * , or is not a number , then * default * number is returned ."
default callable for page listing . produce a digg - style pagination .
return a querystring pointing to * page_number * .
"handle a negative * page_number * . return a positive page number contained in * page_range * . if the negative index is out of range , return the page number 1 ."
verify a root vcs directory can be found .
verify an error occurs when no vcs directory can be found .
verify a working copy can be created .
verify a working copy can be created .
resize the widget width to fit contents .
verify ' doorstop - gui ' launches the gui .
verify ' doorstop - gui ' treats false as an error .
verify ' doorstop - gui ' treats keyboardinterrupt as an error .
verify tkinter import errors are handled .
verify verbose level 1 can be set .
verify verbose level 2 can be set .
verify verbose level 1 can be set .
run targets for python .
run a command - line program and display the result .
show a user notification .
launch the coverage report .
verify a success can be captured .
verify a failure can be captured .
verify a failure can be left uncaught .
verify settings are parsed correctly .
verify a string can be evaluated as a python literal .
verify an invalid literal calls the error function .
verify an invalid literal logs an error .
verify a default output extension can be selected .
verify a default output extension can be overridden .
verify a path is required for a single document .
verify a specified file extension can be selected .
verify a specified file extension can be selected .
verify an extension is required on single file paths .
verify ' yes ' maps to true .
verify ' no ' maps to false .
verify a prompt can be interrupted .
verify a bad response re - prompts .
verify prints are enabled by default .
verify prints are hidden when verbosity is quiet .
verify a positive integer can be parsed .
verify a non - positive integer is rejected .
verify a non - integer is rejected .
build a tree from the current working directory or explicit root .
attempt to create and append a document from the specified path .
find a document without an explicitly building a tree .
find an item without an explicitly building a tree .
get a shared tree for convenience functions .
set the shared tree to a specific value ( for testing ) .
force the shared tree to be rebuilt .
get name of first active job queue
retrieve task statuses from ecs api
poll task status until stopped
"register a job definition with aws batch , using a json"
calculates the great circle distance between two points ( law of cosines ) .
return the logger name of a dns zone
fixme ! briefly describe function
populate parsing module per zone
locate the resolution modules list for this zone
the log messages bby default info messages . this method should e used when logging default messages .
log a debug message
helper function to dump the content of dns request + response
log a warning message .
return the current request dns zone
implematation of parsing request data and making it a parsed dns data
read data from input stream
send data to output stream
generate the dns response module which will be sent back to the client .
close the connection if needed
this function should be called when we encounter unexpected error . it will dump the stack trace for future debugging .
"process the data provided by the user , self.dns_request is assumed to be added byt other function"
the actual handling code
parse data for udp
closing connection in udp is doing nothing .
send udp packet to the requesting client
parses the node from a : py : class:`flattable ` directive 's body
round off the table definition .
handles signatures of function - like macros .
transform a c signature into rst nodes .
extract all archives in bin directory under src .
create the homebrew formula .
produce a digest of given file via given hashlib hasher .
read the content of [ package ] section from cargo.toml . : return : [ package ] section as dictionary
render a string . template with given substitutions .
list all resfi aps in direct communication range ( neighbors ) .
"send a message to a neighboring resfi ap identified by nodeid , messages are end - to - end encrypted using a unicast unidirectional symmetric aes session key . on first call , session key is transparently obtained from neighbor by utilizing the asymmetric rsa keys for symmetric key exchange . messages are signed using the ap 's private rsa key and are additionally encrypted using the group encryption session aes key . : param message : message to be sent to all direct neighbors : param nodeid : the unique node identifier"
"send a message to all direct neighboring resfi aps , messages are encrypted using the aps symmetric aes group encryption key and are signed using the aps private rsa key . : param message : message to be sent to all direct neighbors : param ttl : time to live value in hops"
register a new resfi application in the resfi agent . : param namespace : param app object
"some applications are interested in getting security credentials , i.e. key material . : param param , param==1 returns public ip of rrmu , if param==2 returns public rsa key"
"used for encryption of data using the private key . : param data , data to work : param mode enables to utilize the private key of the rrmu . if mode = = 1 , returns signature computed over data , if mode = = 2 , function decrypts data and returns plaintext ."
"resfi apps have the possibility to change the radio channel of the wireless interface running in ap mode . : param data , channel to switch"
"get the current radio channel of the wireless interface running in ap mode . : param data , returns currently used channel"
get a list of available radio channels for the wireless interface running in ap mode .
get the network load currently served by this ap .
returns the wired interface aka the network interface used to connect the ap to the internet .
"register a callback function to be called by the resfi framework on the reception of a probe response frame : param callback , the callback to be registred ."
"program the information element to be transmitted in the 802.11 probe responses . : param pubkeystr , hexadecimal representation of the public key encoded as string : param symkeystr , hexadecimal representation of the symmetric group encryption key encoded as string : param symivstr , hexadecimal representation of the symmetric group encryption iv encoded as string : param ipstr , hexadecimal representation of the public ip address of the ap 's rrmu encoded as string"
"perform an active scan using the wireless interface . : param fullscan , whether to perform a full scan or not : param ssid , whether to scan for a particular ssid : param freq , whether to scan on just the given frequency : param pubkeystr , hexadecimal representation of the public key encoded as string : param symkeystr , hexadecimal representation of the symmetric group encryption key encoded as string : param symivstr , hexadecimal representation of the symmetric group encryption iv encoded as string : param ipstr , hexadecimal representation of the public ip address of the ap 's rrmu encoded as string"
get information about associated stas served by wireless interface running in ap mode .
"setting the radio channel to be used by wireless interface running in ap mode . : param data , channel to switch"
"getting the radio channel used by wireless interface running in ap mode . : param data , returns currently used channel"
this routine is a truncated version of newcomb 's sun and is designed to give apparent angular coordinates ( t.e.d ) to a precision of one second of time .
"given a modified julian date , return the solar p - angle ( degrees ) , b0 - angle ( degrees ) , and solar radius ( arcmin , or if arcsec = true , return solar radius in arcsec )"
: type num : int : rtype : list[int ]
"returns a boolean indication that a field is a valid timestamp - a floating point number representing the time in seconds since the epoch ( so called posix time , see https://en.wikipedia.org/wiki/unix_time ) ."
check the port is an integer and within the valid range of allowed ports .
returns a boolean to indicate that a field is a string of some sort .
returns a boolean to indicate that a field is a dictionary of some sort .
returns a boolean to indicate if the passed in tuple conforms to a specification of another node within the dht . a valid node is a tuple with four items :
returns a boolean to indicate that a field is a tuple that may contain information about nodes .
"returns a boolean to indicate that a value stored in the dht is valid . currently * all * values are valid although in the future , size may be limited ."
instantiates the class with a reference to the asyncio eventloop to use to create connections to remote peers .
sends the message instance to the referenced contact .
receives a raw message from a sender . the details of what both the message and sender arguments represent will be different for each child class . the handler argument is always a reference to the local node in the dht .
returns a string representation of the version information of this project .
starts a local instance of the drogulus given the parsed arguments to use . the command falls back to sane defaults if none are given .
perform a spam test .
"representation , e.g. ' clay_shovel ( worn ) ' ."
initialise the proxy .
add resource .
get value of resource .
multiply resource by factor .
string representation of resources .
initialise the proxy .
iterate over items .
remove an item .
true if the proxy contains any items .
true if the proxy does not contain any items .
string representation of item proxy .
add a new item .
initialise an empty item .
load an item from dict representation .
string representation of the item .
override attribute setter for items with attached protobuf message .
override attribute getter for items with attached protobuf message .
initialise the factory .
get an item instance by name .
create a new unique item from a source .
return all items that are currently available .
return true if we have enough resources to create an item .
apply all effects of an item .
return true if the prerequisites for an item are met .
generate random mission .
save your api key to the global environment .
store the city that will be queried against .
return a list of available cities .
"use an endpoint and any additional keyword arguments rather than one of the pre - defined cities . similar to the ` city ` function , but useful for development ."
check a city 's open311 discovery endpoint .
send a post service request to a city 's open311 endpoint .
find a specific request in a city .
find service requests for a city .
find services for a given city .
find service request information for a specific token .
builds a set of valid english words .
builds a set of valid english abbreviations .
builds a set of names
return true if given string is a valid english abbreviation .
return true if given string is part of a contraction
return true if given string is a valid english word .
each slice frequency
frequency per day
frequency in days per year
once a month
six a month
every other hour
count per hour
small helper which converts twitter tzs to a datetime obj
determine a consensus annotation if annotation of reference sequences is conflicting . hypothetical protein annotations are avoided is possible
determine a consensus genename if genename of reference sequences is conflicting .
create json file for gene cluster table visualzition input : path to genecluster output output : genecluster.json
test a simple plot generated using a matrix from the following command :
1 . get read counts at different positions either all of same length or from genomic regions from the bed file
1 . get read counts at different positions either all of same length or from genomic regions from the bed file
register ` tensor ` to summary report as ` loss `
register ` tensor ` to summary report as ` metric `
register ` tensor ` to summary report as ` gradient `
register ` tensor ` to summary report as ` activation `
register ` tensor ` to summary report as ` parameters `
register ` tensor ` to summary report as ` image `
register ` tensor ` to summary report as audio
wrapper to implement profiling if requested .
"one strategy for balancing data is to under - sample the majority class until it is represented at the prescribed ` ` balance_ratio ` ` . this can be effective in cases where the training set is already quite large , and diminishing its size may not prove detrimental ."
swipe the keyboard down to hide it .
returns true if the keyboard is shown and ready to use .
waits for * timeout * for the keyboard to be ready and returns true . returns false if the keyboard fails to be considered ready within the alloted time .
tap on the key with the internal pointer
type the string * string * with a delay of * delay * between each key press
reconnect to the maliit process . this should be called by any tests which restart unity8 ( thus causing the maliit - server process to also be restarted ) .
returns the keypad state that key is found in .
returns the position of the key if it is found on that keypad or none if it is not .
get the label for a ' special key ' ( i.e. space ) so that it can be addressed and clicked .
gets to the login route retrieve the html page with the login form
posts to the login route are the actual login attempts
task : # 0 : training # 1 : validation # 2 : testing
calling ` expire ` on a lock should change the expiration on that object
calling ` expire ` on a lock should change the expiration in the database
` delete_expired ` method should delete expired locks
` lock.is_locked ` method should return true for unexpired locks
` lock.is_locked ` method should return false for expired locks
attempting to lock already locked object should raise ` objectlockederror `
attempting to lock object with expired lock should succeed
` lock_object_for_user ` method should create lock on object for correct user
force_lock_object_for_user should lock object even if it is locked by a different user
create or maintain a lock on an object if possible
"create lock on an object , even if it was already locked"
remove a lock from an object
locking api should require login for all methods
locking api should require correct permissions for all methods
get requests to api should return locks correctly
post requests to api should create a lock if it does already not exist
post request to api should extend expiration date of existing lock by that user
post from 2nd user to existing endpoint should not overwrite existing users lock
"put requests should always update lock , even if someone else owned it"
"put requests should always update lock , even if someone else owned it"
delete request to api should remove locks made by that user
calling delete on an already delete lock should not raise an exception
delete request to api should not remove lock made by other users
"if ` locking_delete_timeout_seconds ` is specified , locks are expired not deleted"
save full log on upgrade - diff - logs dir
just a wrapper to make mocking easier on tests
initializes context manager with satellite hostname
fetch current line count for satellite log files : return : loganalyzer
analyzes log files checking if some error occurred since last log_state update
update log_dct with adding delta from current number of lines of each item and the last provided by dct .
decorator which runs the wrapped function with hide('stdout ' ) if the ` ` silent ` ` keyword argument is provided .
disable repos passed as ` ` args ` ` using ` ` subscription - manager repos --disable ` ` .
delete repos files on ` ` /etc / yum.repos.d ` ` .
enable repos passed as ` ` args ` ` using ` ` subscription - manager repos --enable ` ` .
create custom repofiles .
enable repositories required to install satellite 6
disable beaker repositories
enable or disable custom repositories .
return the correct farmware api url according to farmbot os version .
send a message to the log .
"create a kind , args celery script node ."
"create a label , value celery script node ."
celery script to add a point to the database .
celery script to set an environment variable .
celery script to move to a location .
celery script to move relative to the current location .
celery script to signal that a sync is required .
celery script to send a message .
find home .
celery script if statement .
celery script to write a value to a pin .
celery script to read the value of a pin .
celery script to execute a sequence .
celery script to execute a farmware .
celery script to take a photo .
celery script to wait .
"performs a simple contrast stretch of the given image , from 5 - 95 % ."
"handles command - line interface , arguments & options ."
save metadata of image to a text file .
: param start_time : seconds since the epoch to start animation : param stop_time : seconds since the epoch to stop animation : param start_pos : number from 0 to 1 indicating start on strip : param stop_pos : number from 0 to 1 indicating stop on strip : param start_color : initial 24 - bit integer rgb color : param stop_color : final 24 - bit integer rgb color : param size : number from 0 to 1 indicating size of color1
: param time : current time as seconds since the epoch : param pos : position from 0 to 1 to get color for : return : 24 - bit integer rgb color
: param start_time : seconds since the epoch to start animation : param stop_time : seconds since the epoch to stop animation : param start_pos : number from 0 to 1 indicating start on strip : param epoch_pos : where the splash will start from : param stop_pos : number from 0 to 1 indicating stop on strip : param start_color : initial 24 - bit integer rgb color : param stop_color : final 24 - bit integer rgb color
: param time : current time as seconds since the epoch : param pos : position from 0 to 1 to get color for : return : 24 - bit integer rgb color
initializes the object . it can then be started with run ( ) . : param wlan_adapter : name of the wlan adapter ( i.e. ' wlan0 ' )
returns an instance of ` filelock ` that can be used in a with statement .
"produce all dates in a given year , month"
fetch potd thumbnail url for iso_date ( ' yyyy - mm - dd ' format )
produce picture names by fetching potd metadata
fetch and save image data for date and url
download up to max_count images for a given month
"get "" pictures of the day "" from english wikipedia for a given month"
return validated value or raise valueerror
the bar attribute
compute action delay using exponential distribution
yield to simulator issuing event at each state change
"initialize random generator , build procs and run simulation"
schedule and display events until time is up
simplest memoizing decorator
return text clipped at the last space before or after max_len
"build test fixture from wikipedia "" potd "" data"
convert an excel cell reference string in a1 notation to numeric row / col notation .
convert an excel cell reference string in a1 notation to numeric row / col notation .
convert numeric row / col notation to an excel cell reference string in a1 notation .
convert cell range string in a1 notation to numeric row / col pair .
pack row and column into the required 4 byte format
indent a string
extract a module - level docstring
initialize a : class:`statusinformation ` object .
"calculate the covariance matrix for the columns of x ( mxn ) , or optionally , the covariance matrix between the columns of x and and the columns of y ( mxp ) . ( in the language of statistics , the columns are variables , the rows are observations ) ."
write a gctoo object to a gct file .
write first two lines of gct file .
"write the top half of the gct file : top - left filler values , row metadata headers , and top - right column metadata ."
write the bottom half of the gct file : row metadata and data .
append dimensions and file extension to output filename . n.b. dimensions are cols x rows .
build argument parser .
separate method from main ( ) in order to make testing easier and to enable command - line access .
"if arg is a list with 1 element that corresponds to a valid file path , use set_io.grp to read the grp file . otherwise , check that arg is a list of strings ."
read a grp file at the path specified by in_path .
write a grp to a text file .
subsets a gctoo instance along either rows or columns to obtain a specified size .
primary method of script . reads in path to a gctx file and parses into gctoo object .
"makes sure that ( if entered ) i d inputs entered are of one type ( string i d or index ) input : - rid ( list or none ): if not none , a list of rids - ridx ( list or none ): if not none , a list of indexes - cid ( list or none ): if not none , a list of cids - cidx ( list or none ): if not none , a list of indexes output : - a tuple of the ordered ridx and cidx"
makes sure user did n't provide both ids and idx values to subset by .
"gets index values corresponding to ids to subset and orders them . input : - id_type ( str ): either "" i d "" , "" idx "" or none - id_list ( list ): either a list of indexes or i d names output : - a sorted list of indexes to subset a dimension by"
"reads in all metadata from .gctx file to pandas dataframe with proper gctoo specifications . input : - dim ( str ): dimension of metadata ; either "" row "" or "" column "" - meta_group ( hdf5 group ): group from which to read metadata values - convert_neg_666 ( bool ): whether to convert "" -666 "" values to np.nan or not output : - meta_df ( pandas dataframe ): data frame corresponding to metadata fields of dimension specified ."
"replace -666 , -666.0 , and optionally "" -666 "" . args : meta_df ( pandas df ): convert_neg_666 ( bool ): returns : out_df ( pandas df ): updated meta_df"
"sets index and column names to gctx convention . input : - dim ( str ): dimension of metadata to read . must be either "" row "" or "" col "" - meta_df ( pandas . dataframe ): data frame corresponding to metadata fields of dimension specified . output : none"
"parses in data_df from hdf5 , subsetting if specified ."
opens .gctx file and returns only column metadata
opens .gctx file and returns only row metadata
validate url only if present .
"returns the loss coefficient for a round edged wire screen or bar screen , as shown in [ 1 ] _ . angle of inclination may be specified as well ."
"returns the loss coefficient for a round edged open net / screen made of one of the following patterns , according to [ 1 ] _ :"
"returns the loss coefficient for a square wire screen or square bar screen or perforated plate with squared edges , as shown in [ 1 ] _ ."
"returns the loss coefficient for a square grill or square bar screen or perforated plate with squared edges of thickness l , as shown in [ 1 ] _ ."
"returns the loss coefficient for a rounded square grill or square bar screen or perforated plate with rounded edges of thickness l , as shown in [ 1 ] _ ."
calculates the sounders - brown ` k ` factor as used in determining maximum allowable gas velocity in a two - phase separator in either a horizontal or vertical orientation . this function approximates a graph published in [ 1 ] _ to determine ` k ` as used in the following equation :
"calculates the sounders brown ` k ` factor as used in determining maximum permissible gas velocity in a two - phase separator in either a horizontal or vertical orientation , * with a demister * . this function is a curve fit to [ 1 ] _ published in [ 2 ] _ and is widely used ."
"calculates the maximum allowable vapor velocity in a two - phase separator to permit separation between entrained droplets and the gas using an emperical ` k ` factor , named after sounders and brown [ 1 ] _ . this is a simplifying expression for terminal velocity and drag on particles ."
converts a known drag coefficient into a sounders - brown ` k ` factor for two - phase separator design . this factor is the traditional way for separator diameters to be obtained although it is unnecessary and the theoretical drag coefficient method can be used instead .
convert a set of parameters to the interpolation discretization scheme .
return constraint parameters .
compute the highest possible path velocity that is controllable .
render a simple prompt which reports the number of currently selected tests .
"sets up the command history , and starts regular autosaves ."
handle interactive exit . this method calls the ` ` ask_exit ` ` callback and if applicable prompts the user to verify the current test selection
evalutate line in the embedded ns and return result
add tests from a test set to the current selection .
"remove tests from the current selection using a slice syntax using a ' , ' delimiter instead of ' : ' ."
show all currently selected test by pretty printing to the console .
store a set of tests in the pytest cache for retrieval in another session .
plot a horizontal ( x ) scale bar into the axes .
plot a vertical ( y ) scale bar into the axes .
debug_divert_messages : @filename : a file to which to divert stdout and stderr or none to do nothing .
delete the account .
change the value of the parameters property .
"re - connect this account . if the account is currently disconnected and the requested presence is offline , or if the account is not enabled or not valid , this does nothing ."
this account has been removed .
"the values of one or more properties on this interface ( that do not specify that this signal does not apply to them ) may have changed . this does not cover properties of other interfaces , which must provide their own change notification if appropriate ."
"emitted when the imsi for the connection changes . this sort of thing is rare , but could happen on cellular phones that allow hot - swapping of sim cards . in the case of sim swapping , this signal would be emitted twice ; the first time while the sim is being ejected ( with an empty string ) , and the second time after a new sim has been inserted ( assuming that the imsi can be determined from the new sim ) ."
"request that the channel be closed . this is not the case until the closed signal has been emitted , and depending on the connection manager this may simply remove you from the channel on the server , rather than causing it to stop existing entirely . some channels such as contact list channels may not be closed ."
"returns the interface name for the type of this channel . clients should use the channeltype property instead , falling back to this method only if necessary ."
"returns the handle type and number if this channel represents a communication with a particular contact , room or server - stored list , or zero if it is transient and defined only by its contents . clients should use the targethandle and targethandletype properties instead , falling back to this method only if necessary ."
"get the optional interfaces implemented by the channel . clients should use the interfaces property instead , falling back to this method only if necessary ."
"emitted when the channel has been closed . method calls on the channel are no longer valid after this signal has been emitted , and the connection manager may then remove the object from the bus at any point ."
returns a new dictionary with the mapping of key to val
records event map statistics
"records statistics when we are unable to map data properly from a matching event mapping record . this indicates perhaps a bug , an aws inconsistency or breaking change ,"
"given some configuration details , set up flowlogs for a given vpc . this will allow us to profile and analyze traffic patterns for all parts of this network ."
this function does not work across accounts :-(
send a slack message using a mocked requests object
send a slack message using a mocked requests object
create an instance of a ready - made mock for working with the aws provider and all the cloud services it can interface with .
create a mock to wrap test data as if it was an sqs message object
construct a properly formatted sns message for testing .
create a gzipped archive of cloudtrail events .
a simple function used to load a dynamodb table from json file on disk . note : only use this for smallish tables . this is not suitable for large tables .
create a converter that will eat the input variable tdi data integers and create a single boolean string with all the data concatenated .
create a combiner function that will use the tdi_converter and the tdi_string to merge the constant and variable portions of the tdi data together .
"this function is somewhat complicated by support for things like the ftdi driver , where the input bits for a word might not be all together ."
define a function that will extract a list of integers from the tdo string from the driver .
"eat one utf-8 octet , and validate on the fly ."
reset validator to start new incremental utf-8 decode / validation .
incrementally validate a chunk of bytes provided as bytearray .
connect to pusher
disconnect from pusher
subscribe to a channel
unsubscribe from a channel
get an existing channel object by name
a websocket client that implements : rfc:`6455 ` and provides a simple interface to communicate with a websocket server .
initiate the closing handshake with the server .
connects this websocket and starts the upgrade handshake with the remote endpoint .
list of headers appropriate for the upgrade handshake .
prepare the request to be sent for the upgrade handshake .
ensure that we received a http ` 101 ` status code in response to our request and if not raises : exc:`handshakeerror ` .
read the upgrade handshake 's response headers and validate them against : rfc:`6455 ` .
fit model with coordinate descent .
decision function of the linear model
starts a subprocess with popenargs and returns it output
starts a subprocess with popenargs and returns the output as parsed json
wrapper around the list all functions pass . any circles or strongly connected components are listed alphabetically in nested lists
wrapper around the extract callgraph pass
wrapper around the encapsulate symbolic pass
wrapper around the prepend error pass
wrapper around the prepend error pass
internalize everything except entrypoint and remove unused code
"runs an llvm opt pass , that merges all globals with identical content"
extract all lines of code represented inside a bitcode file
extract all linecoverage information in an ordereddict
entry point to run this analysis stand alone
get the path of the corresponding klee directory
get the name of the corresponding klee directory
get the corresponding ktest file for a .err file
extract the reason for an error from a .err file
"extract the vulnerable instruction "" file : line "" from a .err file"
"exclude some error reasons , that are not helpful for further analysis"
get all informations about this error in an ordered dict
"one function , that calls all analysis functions and thereby generates multiple jsons inside a macke directory"
reload instance configuration
serve new connections into new threads
initialize the exception and pass the message to the log system .
return context variables with org permissions to the user .
simple context processor that automatically sets ' org ' on the context if it is present in the request .
"lookup by "" someapp "" or "" someapp.someperm "" in perms ."
"if we have tags set , then adds spaces before and after to allow for sql querying for them ."
"example : % li { class:""{% if_url ' contacts.contact_read ' ' active ' '' % } "" }"
initialize the object .
do the actual proposal and change the state of the model to contain the new parameters .
sample the proposal given the ` ` old_params ` ` and the gradient of the target probability with respect to them .
evaluate the proposal at the new parameters given the old parameters . : param new_params : the new parameters . : param old_params : the old parameters . we are assuming that we are conditioning on them . : param old_grad_params : the gradient of the target probability with respect to the parameters .
determine if a package in a dictionary satisfies given dependency spec
determine if a package in * repository * satisfies given dependency spec
determine if a package in * repository * satisfies given dependency spec
calculate if pkg name is installable currently which means it has to satisfy both install and runtime dependencies
determine if a package ver . satisfies given dependency spec
get set of doc ids given term
"get a union of all repository terms , not just the first repo in order . get only basic repo info from the first repo"
calculate if pkg is installable currently
read pspec file
merge tags from source in packages . some tags in packages merged with the tags from source . there is a more detailed description in documents .
override tags from source in packages . some tags in packages overrides the tags from source . there is a more detailed description in documents .
returns current work directory 's path
returns currently running kernel 's version
returns currently used python 's version
returns currently used perl 's version
returns any given environ variable
returns the path of binary packages
returns the path of binary packages
"custom negative log likelihood loss that returns loss per example , rather than for the entire batch ."
retrieves the likelihood of a given sequence
sample a batch of sequences
think about a windown sliding through s.
register a token 's whitespace prefix .
change the number of newlines before this token .
retains a token 's horizontal spacing .
split penalty attached to the pytree node of this token .
the number of newlines needed before this token .
return true if the token requires a split before it .
the original column number of the node in the source .
the original line number of the node in the source .
extra type information for directing formatting .
token is a binary operator .
a string representation of the node 's name .
format a single python file and return the formatted code .
format a string of python code .
read the contents of the file .
skip sections of code that we should n't reformat .
get a unified diff of the changes .
initialize attributes to describe a car .
return a neatly formatted descriptive name .
print a statement showing the car 's mileage .
set the odometer reading to the given value . reject the change if it attempts to roll the odometer back .
add the given amount to the odometer reading .
initialize the batteery 's attributes .
print a statement describing the battery size .
print a statement about the range this battery provides .
upgrade the battery if possible .
initialize attributes of the parent class . then initialize attributes specific to an electric car .
retrieve the specified file from storage .
"save new content to the file specified by name . the content should be a proper file object or any python file - like object , ready to be read from the beginning ."
"return a filename , based on the provided filename , that 's suitable for use in the target storage system ."
return a filename that 's free on the target storage system and available for new content to be written to .
validate the filename by calling get_valid_name ( ) and return a filename to be passed to the save ( ) method .
return a local filesystem path where the file can be retrieved using python 's built - in open ( ) function . storage systems that ca n't be accessed using open ( ) should * not * implement this method .
delete the specified file from the storage system .
"return true if a file referenced by the given name already exists in the storage system , or false if the name is available for a new file ."
"list the contents of the specified path . return a 2 - tuple of lists : the first item being directories , the second item being files ."
"return the total size , in bytes , of the file specified by name ."
return an absolute url where the file 's contents can be accessed directly by a web browser .
return the last accessed time ( as a datetime ) of the file specified by name . the datetime will be timezone - aware if use_tz = true .
return the creation time ( as a datetime ) of the file specified by name . the datetime will be timezone - aware if use_tz = true .
return the last modified time ( as a datetime ) of the file specified by name . the datetime will be timezone - aware if use_tz = true .
reset setting based property values .
"if timezone support is enabled , make an aware datetime object in utc ; otherwise make a naive one in the local timezone ."
check if the path should be handled . ignore the path if : * the host is provided as part of the base_url * the request 's path is n't under the media path ( or equal )
return the relative path to the media file on disk for the given url .
serve the request path .
recursively walk the storage directories yielding the paths of all files that should be copied .
check if the staticfiles settings have sane values .
turn any callable into a lazy evaluated callable . result classes or types is required -- at least one is needed so that the automatic forcing of the lazy evaluation code is triggered . results are not memoized ; the function is evaluated on every access .
shortcut for the common case of a lazy callable that returns str .
"a decorator that allows a function to be called with one or more lazy arguments . if none of the args are lazy , the function is evaluated immediately , otherwise a _ _ proxy _ _ is returned that will evaluate the function when needed ."
a decorator for functions that accept lazy arguments and return text .
"used to unpickle lazy objects . just return its argument , which will be the wrapped object ."
"split the values into two sets , based on the return value of the function ( true / false ) . e.g. :"
call the function and put the return value in instance.__dict _ _ so that subsequent attribute access on the instance returns the cached value instead of calling cached_property.__get _ _ ( ) .
must be implemented by subclasses to initialize the wrapped object .
pass in a callable that returns the object to be wrapped .
return a list of filenames referenced in sys.modules and translation files .
check for changed code using inotify . after being called it blocks until a change event has been fired .
a signal receiver which updates the last_login date for the user logging in .
a backend can raise ` permissiondenied ` to short - circuit permission checking .
a backend can raise ` permissiondenied ` to short - circuit permission checking .
"create and save a user with the given username , email , and password ."
"return a list of permission strings that this user has through their groups . query all available auth backends . if an object is passed in , return only permissions matching this object ."
"return true if the user has the specified permission . query all available auth backends , but return immediately if any backend returns true . thus , a user who has permission from a single auth backend is assumed to have permission in general . if an object is provided , check permissions for that object ."
"return true if the user has each of the specified permissions . if object is passed , check if the user has all required perms for it ."
"return true if the user has any permissions in the given app label . use simlar logic as has_perm ( ) , above ."
"return the first_name plus the last_name , with a space in between ."
return the short name for the user .
send an email to this user .
"create a test database , prompting the user for confirmation if the database already exists . return the name of the test database created ."
set this database up to be used in testing as a mirror of a primary database whose settings are given .
serialize all data in the database into a json string . designed only for test runner usage ; will not handle large amounts of data .
reload the database with data from a string generated by the serialize_db_to_string ( ) method .
internal implementation - return the name of the test db that will be created . only useful when called from create_test_db ( ) and _ create_test_db ( ) and when no external munging is done with the ' name ' settings .
internal implementation - create the test db tables .
clone a test database .
return a modified connection settings dict for the n - th clone of a db .
internal implementation - duplicate the test db tables .
"destroy a test database , prompting the user for confirmation if the database already exists ."
internal implementation - remove the test db tables .
return a tuple with elements of self.connection.settings_dict ( a databases setting value ) that uniquely identify a database accordingly to the rdbms particularities .
"split a sql identifier into a two element tuple of ( namespace , name ) ."
shorten a sql identifier to a repeatable mangled version with the given length .
format a number into a string with the requisite number of digits and decimal places .
"strip quotes off of quoted table names to make them safe for use in index names , sequence names , etc . for example ' "" user"" . ""table "" ' ( an oracle naming scheme ) becomes ' user"" . ""table ' ."
"return the static files serving handler wrapping the default handler , if static files should be served . otherwise return the default handler ."
return the correct stdcall function for certain osr routines on win32 platforms .
return only the gdal version number information .
return the full gdal version information .
initialize the user .
display a summary of the user 's information .
display a personalized greeting to the user .
increment the value of login_attempts .
reset login_attempts to 0 .
initialize the admin .
display the privileges this administrator has .
return the database column type for the geometry field on the spatial backend .
"return the distance parameters for the given geometry field , lookup value , and lookup type ."
"return the placeholder for the given geometry field with the given value . depending on the spatial backend , the placeholder may contain a stored procedure call to the transformation function of the spatial backend ."
mark a view function as being exempt from the csrf view protection .
"return ( codename , name ) for all permissions in the given opts ."
"return ( codename , name ) for all autogenerated permissions . by default , this is ( ' add ' , ' change ' , ' delete ' )"
"return the current system user 's username , or an empty string if the username could not be determined ."
try to determine the current system user 's username to use as a default .
return the string version of the geos library .
"return the geos version as a tuple ( major , minor , subminor ) ."
turn a setting value into a dependency .
take a projectstate and return a new one with the migration 's operations applied to it . preserve the original object state by default and return a mutated state from a copy .
take a project_state representing all migrations prior to this one and a schema_editor for a live database and apply the migration in a forwards order .
take a project_state representing all migrations prior to this one and a schema_editor for a live database and apply the migration in a reverse order .
"raise an exception if trying to pickle an unrendered response . pickle only rendered data , not the data used to construct the response ."
"accept a template object , path - to - template , or list of paths ."
return the freshly rendered content for the template and context described by the templateresponse .
add a new post - rendering callback .
render ( thereby finalizing ) the content of the response .
set the content for the response .
"force a value to be rendered as a localized value , regardless of the value of ` ` settings . use_l10n ` ` ."
"force a value to be rendered as a non - localized value , regardless of the value of ` ` settings . use_l10n ` ` ."
"force or prevents localization of values , regardless of the value of ` settings . use_l10n ` ."
parse a string and return a datetime.date .
parse a string and return a datetime.time .
parse a string and return a datetime.datetime .
parse a duration string and return a datetime.timedelta .
"return the ( width , height ) of an image , given an open file or a path . set ' close ' to true to close the file at the end if it is initially in an open state ."
check all registered staticfiles finders .
define a block that can be overridden by child templates .
convert a relative path ( starting with ' ./ ' or ' .. / ' ) to the full template name based on the current_template_name .
signal that this template extends a parent template .
load a template and render it with the current context . you can pass additional context using keyword arguments .
this is a wrapper around engine.find_template ( ) . a history is kept in the render_context attribute between successive extends calls and passed as the skip argument . this enables extends to work recursively without extending the same template twice .
render the specified template and context . cache the template object in render_context to avoid reparsing and loading when used in a for loop .
called when the observed object is modified . you call an observable object 's notifyobservers method to notify all the object 's observers of the change .
"if ' changed ' indicates that this object has changed , notify all its observers , then call clearchanged ( ) . each observer has its update ( ) called with two arguments : this observable object and the generic ' arg ' ."
return true if data differs from initial .
insert the given enity or driver into this entity .
is this pool the parent of the given entity
insert the given enity or driver into this entity .
insert the given enity or driver into this entity .
returns an iterable of iterables that each yield size items .
save simulation data
find data files
load simulation data files in order
load simulation data files concatenated into one
save dictionary data into csv file .
save dictonary of geometries to filename ( .json ) .
load dictonary of geometries from filename ( .json ) .
key transform function
keys of nearest blocks
add value to blocklist
get value in the same block as item
get values of neighbouring blocks
real number strategy that excludes nan and inf .
strategy that generates shapely points
strategy that generates shapely linestrings
strategy that generates shapely polygons
agent search strategy
load configuration from ini file .
import simulations callables
"breaking geometry object into continuous array where objects are separated by array of elements ( np.nan , flag )"
converts shapes to point pairs .
converts shape(s ) to array of linear obstacles .
draw geom to grid
union of geometries
truncated normal distribution with standard deviation of 3 .
sending a single sms with the minimum detail and no errors should work
sending a single sms with the full gsm character set ( apart from esc and form feed ) should work
sending a single sms with no message should fail
sending a single sms with no message should fail
sending multiple sms messages should work
"sending multiple sms messages , one of which has an invalid message should work"
function convert astra beam distribution to ocelot format - particlearray : type filename : str : return : particlearray
"function convert ocelot 's particlearray to astra beam distribution and save to "" filename "" . : param p_array : : param filename : : return :"
find the first intersection point of a ray with geometry
"tracing the ray , starting from last segment"
i 'm the ' x ' property .
can be used to redirect vtk related error messages to a file .
: return : a set of all the vtk classes .
: param : vtkclasses - the set of vtk classes : param : substr - the substring for the vtk class to match e.g readers : return : a set of all the vtk classes that are e.g. readers .
: param : vtkclasses - the set of vtk classes : param : filters - a list of substrings of classes to be removed : return : a set of all the vtk classes that do not have the substrings in their names .
test the named class looking for complementary set / get pairs to test .
test set / get pairs in each batch .
batch the classes into groups of batchsize .
check the python version .
"the arguments to expr in tcl are passed as individual arguments to this method . eg [ expr sin(20)*$a ] becomes expr.expr(""sin"",""("",""20 "" , "" ) "" , "" * "" , a )"
login with credentials implementing an interface inheriting from an interface registered with a checker ( but not itself registered ) .
replace l{pamauth.callintopam } with a dummy implementation with easily - controlled behavior .
this is called when the child terminates .
call processended on protocol after final cleanup .
callback to populate the request for current timestep
callback to do co - processing for current timestep
"sets up default numberofinputports , numberofoutputports , inputtype and outputtype that are used by various initialization methods ."
sets up number of input and output ports based on numberofinputports and numberofoutputports .
convenience method that returns an input data object given a vector of information objects and two indices .
convenience method that returns an output data object given an information object and an index .
overwritten by subclass to manage data object creation . there is not need to overwrite this class if the output can be created based on the outputtype data member .
overwritten by subclass to provide meta - data to downstream pipeline .
overwritten by subclass to modify data request going to upstream pipeline .
overwritten by subclass to execute the algorithm .
splits a request to requestxxx ( ) methods .
sets the required input type to inputtype .
sets the default output type to outputtype .
"sets up default numberofinputports , numberofoutputports , inputtype and outputtype that are used by various methods . make sure to call this method from any subclass ' _ _ init _ _"
sets the required input type to inputtype .
sets the default output type to outputtype .
splits a request to requestxxx ( ) methods .
overwritten by subclass to manage data object creation . there is not need to overwrite this class if the output can be created based on the outputtype data member .
overwritten by subclass to provide meta - data to downstream pipeline .
overwritten by subclass to modify data request going to upstream pipeline .
"pass string by value ... hard to find examples of this , because "" const char * "" methods shadow "" vtkstdstring "" methods ."
return a string by value .
pass a string by reference .
return a string by reference .
pass a unicode string by const reference
pass 8 - bit string when unicode is expected . should fail .
pass unicode where string is expected . should succeed .
pass 8 - bit string where string is expected . should succeed .
pass encoded 8 - bit strings .
"return the red , green and blue components for a color as doubles ."
testing if images can be imported to and from numeric arrays .
test if colored line plots can be built with python
: param url : the websocket url of the wamp router to connect to ( e.g. ` ws://somehost.com:8090/somepath ` ) : type url : str : param realm : the wamp realm to join the application session to . : type realm : str : param extra : optional extra configuration to forward to the application component . : type extra : dict : param debug : turn on low - level debugging . : type debug : bool : param debug_wamp : turn on wamp - level debugging . : type debug_wamp : bool : param debug_app : turn on app - level debugging . : type debug_app : bool
run the application component .
"linear map : sum_i(args[i ] * w[i ] ) , where w[i ] is a variable . args : args : a 2d tensor or a list of 2d , batch x n , tensors . output_size : int , second dimension of w[i ] . bias : boolean , whether to add a bias term or not . bias_start : starting value to initialize the bias ; 0 by default . scope : variablescope for the created subgraph ; defaults to "" linear "" . returns : a 2d tensor with shape [ batch x output_size ] equal to sum_i(args[i ] * w[i ] ) , where w[i]s are newly created matrices . raises : valueerror : if some of the arguments has unspecified or wrong shape ."
"initialize the parameters for an lstm cell . args : num_units : int , the number of units in the lstm cell . use_peepholes : bool , set true to enable diagonal / peephole connections . cell_clip : ( optional ) a float value , if provided the cell state is clipped by this value prior to the cell output activation . initializer : ( optional ) the initializer to use for the weight matrices . num_proj : ( optional ) int , the output dimensionality for the projection matrices . if none , no projection is performed . forget_bias : biases of the forget gate are initialized by default to 1 in order to reduce the scale of forgetting at the beginning of the training . activation : activation function of the inner states ."
smoke test : check if the change view renders for a django - parler model .
initialize the cclibdata object .
converts all attributes that are arrays or lists / dicts of arrays to lists .
converts appropriate attributes to arrays or lists / dicts of arrays .
returns a dictionary of existing data attributes .
sets data attributes given in a dictionary .
check the types of all attributes .
update the atomic positions
send a get request to hubspot
send a post request to hubspot
send a put request to hubspot
send a delete request to hubspot
loads all necessary objects for system operation from database configures system and returns system named tuple
check that the values extract by silan / cuepointanalyzer on our test audio files match what we expect . : param metadata : a metadata dictionary : return : nothing
set up nicely formatted logging and log rotation .
dump a stacktrace for all threads
special static method that 's automatically called by python when constructing a new instance of this class .
called while initializing this instance in _ _ new _ _
display the about page for ulauncher .
display the preferences window for ulauncher .
signal handler for closing the ulauncherwindow .
called when the ulauncherwindow is closed .
only affects gui
triggered by user input
add 2px to the window width if gtk+ > = 3.20 because of the bug in < 3.20 that does n't add css borders to the width
"from the pygtk reference manual say for example the preferences dialog is currently open , and the user chooses preferences from the menu a second time ; use the present ( ) method to move the already - open dialog where the user can see it ."
: param list result_items : list of resultitem instances
: param str basename : path to db file
create a new data base or open existing one
write the database to a file
: param str key : : type : bool : return : true if record was removed
: rtype : bool : returns : true if ulauncher window should remain open once all actions are done
"yields ` ( extension_id , extension_path ) ` tuples found in a given extensions dir"
create a new data base or open existing one
write the database to a file
": rtype dict : { ' last_commit ' : str , ' last_commit_time ' : str } : raises urllib2.httperror :"
> > > https://github.com/ulauncher/ulauncher-timer < < < https://github.com/ulauncher/ulauncher-timer/archive/master.zip
> > > https://github.com/ulauncher/ulauncher-timer < < < com.github.ulauncher.ulauncher - timer
> > > https://github.com/ulauncher/ulauncher-timer < < < ulauncher / ulauncher - timer
"search files in ` directory ` ` filter_fn ` takes two arguments : directory , filename . if return value is false , file will be ignored"
example ( assuming foo & bar do not exist ):
: returns : remaining part of the query that goes after : meth:`get_existing_dir `
iterate over all search modes and run first enabled . appsearchmode is always enabled
reference --------- [ 1 ] http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
compute the contrastive loss as in https://gitlab.idiap.ch/biometric/xfacereclib.cnn/blob/master/xfacereclib/cnn/scripts/experiment.py#l156 with y = [ -1 +1 ] -- > [ positive_pair negative_pair ] l = log ( m + exp ( y * d^2 ) ) / n * * parameters * * left_feature : first element of the pair right_feature : second element of the pair label : label of the pair ( 0 or 1 ) margin : contrastive margin * * returns * * return the loss operation
"parameters ---------- y_true : { tensor , ndarray } enrollment vectors , one sample per row ( i.e. shape=(nb_samples , nb_features ) ) y_pred : { tensor , ndarray } test vectors , one sample per row ( i.e. shape=(nb_samples , nb_features ) ) unit_norm : bool ( default : true ) if true , normalize length of each vector to 1 one_vs_all : bool ( default : true ) if true , calculate the similarity of one to all other samples , otherwise , it is ` one_vs_one `"
"computes the jacobian of the hidden layer with respect to the input , reshapes are necessary for broadcasting the element - wise product on the right axis"
note ---- origin implementation from seya : https://github.com/edersantana/seya/blob/master/seya/regularizers.py copyright ( c ) edersantana
kl - divergence between two gaussians . useful for variational autoencoders . use this as an activation regularizer
"this function query gpu information : ngpu [ device_name , device_compute_capability , device_total_memory ]"
calling this method will make sure you create only 1 session per graph .
auto - configure odin using os.environ['odin ' ] .
"return ------ the numpy randomstate as a "" randomness generator """
randomly generate and integer seed for any stochastic function .
return number of inter_op_parallelism_threads
return number of gpu
return number of intra_op_parallelism_threads
"in case using cpu , return number of cores if gpu is used , return number of graphics card ."
"device info contains : { "" n "" : ngpu , "" dev0 "" : [ device_name , device_compute_capability , device_total_memory ] , "" dev1 "" : [ device_name , device_compute_capability , device_total_memory ] , ... }"
use at&update to put modem in update mode
set air speed
print a string to stdout when debug is set to true .
print a string to stderr .
parse the galera.cnf configuration file .
convert an net - snmp string index to an oid .
"perform an snmp lookup of an oid on a host , return the result ."
look up the status of a certain host and return a string .
return the seqno of a certain host .
"attempt a number of times to ping mysqld , return result ."
join an existing cluster .
bootstrap a new cluster .
exit this script .
create a lock file in /var / lock/.
remove the lock file created by set_lock ( ) .
compare seqno of local node to that of available other nodes to determine eligibility to bootstrap a new cluster . return a boolean .
the main function .
"matches param to list entries , returns next entry after match"
"sees if list element matches regex , returns element"
close the mtdev converter
check state of kernel device
return true if the device has multitouch data .
return true if the device has slot information .
return true if the device has abs data .
return the maximum number of abs information available .
return the slot data .
return the abs data .
initialise the camera ( internal )
update the camera ( internal )
start the camera acquire
release the camera
copy the the buffer into the texture
draw the current image camera
reads in a datafile .
"all non - localhost environments need to install the "" production "" pip requirements , which typically includes the python database bindings ."
[ env ] development server environment
[ env ] staging server environment
[ env ] production servers . stricter requirements .
"[ env ] bootstrap the localhost - can be either dev , production or staging ."
[ env ] django development server environment
[ env ] django staging server environment
[ env ] django production server environment
return the fully - qualified domain names of the servers attached to an elastic load balancer .
attach the instance defined by the provided instance id ( e.g. i-34927a9 ) to the application 's elastic load balancer .
detach the instance defined by the provided instance id ( e.g. i-34927a9 ) to the application 's elastic load balancer .
download a file from s3 to the local machine . do n't re - download if the sha matches ( uses sha256 ) .
a shortcut to bootstrap or update a virtualenv with the dependencies for this project . installs the ` common.txt ` and ` dev.txt ` pip requirements and initializes / updates any git submodules .
toggles a value true . used in ' toggle ' commands such as maintenancemode ( ) .
toggles a value false . used in ' toggle ' commands such as maintenancemode ( ) .
"if using the maintenancemode app ( https://github.com/jezdez/django-maintenancemode ) , this command will toggle it on and off . it finds the ` maintenance_mode ` variable in your ` settings.py ` on the remote server , toggles its value and restarts the web server ."
swaps the deployed version of the app to the previous version .
restart the gunicorn application webserver .
run the latest chef cookbooks on all servers .
data to send to do a lasterror .
takes message data and adds a message header based on the operation .
get an * * insert * * message .
get an * * update * * message .
get a * * query * * message .
get a * * getmore * * message .
get a * * delete * * message .
get a * * killcursors * * message .
check if a logo is present
check if the tagline is present
set the name on the form
set the email on the form
set the phone on the form
set the gender on the form
click on ' click me ' button
accept the terms and conditions
check if we have been redirected to the redirect page
submit the form
get all required packages
post install commands
class to store a timezone / location database globaly
get utc offset ( taking dst into account )
are we in dst ?
get utc offset
get daylight saving time delta
handle file entries
handle a file entry
get location info
is dst on
get utc offset ( checks dst )
get utc offset
get object property ( see above )
set object property ( see above )
get timezone 's location
return all locations
get all required packages
post install commands
returns true if the driver is a proprietary one
"check that the user entered a valid boot device . @return true if the device is valid , false if it is not ."
check element value
check the correctness of a proposed user name .
check the correctness of a proposed host name .
check user password this function expects gtk widgets as parameters
displays pretty - printed package information .
get all required packages
adds [ xorg116 ] and [ catalyst - hd234k ] repos to pacman.conf
pre install commands
post install commands
returns true if the driver is a proprietary one
create a gitrepository instance .
create an instance of the singleton ` gitindexer ` .
retrieve metadata about newly cloned repositories and index them .
clone and index ( create and insert codeletes for ) a git repository .
create and insert a codelet for the files inside a git repository .
return a url for a filename from a git wrapper framework .
return a dictionary containing every valuable tracked file 's metadata .
heuristically determine whether a file is ascii text or binary .
create an instance of the singleton : class:`_gitcloner ` .
retrieve metadata about newly crawled repositories and clone them .
attempt cloning a git repository .
set up a conencted state
"needed because ping sets up a loopingcall , outside clock simulated calllater ( )"
go to connected state
simple module test - run function from web and see it matches expected value .
crawl several modules in the same directory .
"crawl recursively , so that subfolders ( submodules ) of the target are considered ."
see that we can execute stuff out from a pastebin raw link .
softmax operator . parameters ---------- a_np : numpy.ndarray 2 - d input data
log_softmax operator . parameters ---------- a_np : numpy.ndarray 2 - d input data
perform nearest neighbor upsampling on the data . bilinear upsampling is not supported .
perform nearest neighor upsampling on nchw layout input .
perform nearest neighor upsampling on nhwc layout input .
perform softmax activation on the data
perform log softmax activation on the data
create a runtime executor module given a graph and module .
set inputs to the module via kwargs
run forward execution of the graph
get index - th input to out
get index - th output to out
run graph upto node and get the output to out
load parameters from serialized byte array of parameter dict .
get internal module function
connect to rpc server
connect to a rpc tracker
get function from the session .
construct a remote context .
upload file to remote runtime temp folder
download file from remote temp folder .
"load a remote module , the file need to be uploaded first ."
construct cpu device .
construct gpu device .
construct opencl device .
construct metal device .
construct opengl device .
construct extension device .
close the tracker connection .
get the summary dict of the tracker .
get a text summary of the tracker .
request a new connection from the tracker .
request a resource from tracker and run the func .
create tarball containing all files in root .
unpack all tar files into the directory
schedule for dense operator .
convolution operator in hwcn layout .
schedule for softmax op .
flattens the input array into a 2 - d array by collapsing the higher dimensions .
customized cuda intrinsic lowering rule
customized log intrinsic function
cuda lowering rule for log
verify reorg operator by comparing outputs from tvm and numpy implementation
get the broadcasting info .
get the shape after binary broadcasting .
broadcast the src to the target shape
binary operands that will automatically broadcast the inputs
binary addition with auto - broadcasting
binary multiplication with auto - broadcasting
binary division with auto - broadcasting
binary subtraction with auto - broadcasting
take element - wise maximum of two tensors with auto - broadcasting
take element - wise minimum of two tensors with auto - broadcasting
create an extern op that compute matrix mult of a and rhs with crhslas
create an extern op that compute data * weight and return result in output
construct a tvm context with given device type and i d.
return a tvmarray representation of a numpy array .
create an empty array given shape and device
free c++ extension type handle
register a extension class to tvm .
shape of this array
type of this array
context of this array
context of this array
set ndarray value
peform an synchronize copy from the array .
convert this array to numpy array
copy array to target
this is a simple test function for mxnet bridge
create an extern op that compute matrix mult of a and rhs with rocblas
use nvcc compiler for better perf .
run the doxygen make command in the designated folder .
run the doxygen make commands if we 're on the readthedocs server
create a new irbuilder
pop sequence from stack
emit a statement to the end of current scope .
create an attrstmt at current scope .
create a for iteration scope .
create an if scope .
create an else scope .
"create new scope ,"
create a allocate statement .
create pointer variable with content type .
create pointer variable corresponds to buffer ptr .
add likely tag for expression . parameters ---------- expr : expr the expression . usually a condition expression . returns ------- expr : expr the expression will likely tag .
return the builded ir .
use the provisioner to destroy the instances .
execute the actions necessary to perform a ` molecule destroy ` and returns none .
sets up the requirements to execute ` ansible - playbook ` and returns none .
bake an ` ansible - playbook ` command so it 's ready to execute and returns none .
executes ` ansible - playbook ` and returns a string .
adds argument to cli passed to ansible - playbook and returns none .
adds argument to environment passed to ansible - playbook and returns none .
use the provisioner to configure the instances and parse the output to determine idempotence .
execute the actions necessary to perform a ` molecule idempotence ` and returns none .
parses the output of the provisioning for changed and returns a bool .
parses the output to identify the non idempotent tasks .
base initializer for all : ref:`driver ` classes .
name of the driver and returns a string .
driver name setter and returns none .
testinfra specific options and returns a dict .
the login command template to be populated by ` login_options ` and returns a string .
ssh client options and returns a list .
generated files to be preserved and returns a list .
options used in the login command and returns a dict .
ansible specific connection options supplied to inventory and returns a dict .
is the driver delegated and returns a bool .
is the driver is managed and returns a bool .
collects the instances state and returns a list .
sets up the requirements to execute ` flake8 ` and returns none .
bake a ` flake8 ` command so it 's ready to execute and returns none .
walk the verifier 's directory for tests and returns a list .
base initializer for all : ref:`provisioner ` classes .
default cli arguments provided to ` cmd ` and returns a dict .
default env variables provided to ` cmd ` and returns a dict .
name of the provisioner and returns a string .
write data to file .
caution : this method does not test for existing destination .
will be useful when we need to get content from url
initializes the interface for storing client sessions in mongodb .
set up timeoutprocess object
test a program that returns quickly
test a program that does not return quickly
merge _ _ form_options _ _ from parent class and child class
handle the front - page .
newsitem listing page
start the user login .
redirect the user to the initially requested page on successful authentication or redirect her back to the login page if login failed .
redirect the user to the initially requested page on logout and say goodbye as well .
the obj constructor must set the user name right
the obj constructor must set the email right
user objects should have no permission by default .
users should be fetcheable by their email addresses
display submission link button for assignments or sheets
context manager adding info to msg of exceptions raised within .
"return obj if obj is a vector , or [ obj ] in case obj is a scalar ."
raise typeerror if obj is not iterable .
raise typeerror if obj is no mapping .
raise valueerror if collection contains more than one of elements .
raise valueerror if collection is no subset of superset
"raise typeerror , if collection contains elements not of type cls ."
get the number of events for each year .
get the number of contributions for each year .
get the number of attachments in events in a category .
get category statistics .
get the global list of upcoming events
return the visibility options available for the category or event .
"compare two strings , ignoring white space and line breaks ."
return a query object filtering by the proxy 's module .
retrieve all settings .
retrieve the value of a single setting .
set a single setting .
set multiple settings at once .
delete settings .
delete all settings .
renders the videoconference room form : param kwargs : arguments passed to the template
renders the information shown in the expandable box of a vc room row : param vc_room : the vc room object : param event_vc_room : the association of an event and a vc room : param event : the event with the current vc room attached to it : param kwargs : arguments passed to the template
renders the information shown in the expandable box on a vc room in the management area
"renders a list of plugin specific buttons ( eg : join url , etc ) in the management area"
"renders a list of plugin specific buttons ( eg : join url , etc ) in the event page"
creates the videoconference room form
checks if a user can manage vc rooms on an event
checks if a user can manage a vc room
checks if a user has management rights on this vc system
returns a dict with keys representing event_id and the values containing data about the user rights for contributions within the event
serialize contributionpersonlink to json - like object
return a tuple consisting of spreadsheet columns and respective contribution values
extends the contribution wtform to add the extra fields .
get a list of contributions in which the ` user ` has submission rights
import timetable contributions from a csv file into an event .
the set of scopes the linked application has access to .
check if the current request is an ajax request related to a field in this form and execute the field 's ajax logic .
called after the form was successfully validated .
populates the given object with form data .
a list containing all fields that are not hidden .
"a list containing all errors , prefixed with the field 's label . '"
returns a dict containing all generated data
extends form.data with generated data from properties
checks if an attr may be retrieved from the object
the fields which are set as synced for the current request .
utility for the widget to get the entered value for an editable field
utility for the widget to get the unique value for a row
return the summary of answers submitted for this field .
process the form 's data imported from a dict .
the current set of colors or none if no colors are set
registers sqlalchemy events needed by this mixin .
a kwargs - style string suitable for the object 's repr
returns a dict containing information about the linked object suitable for the event log .
create a new user .
returns the template module for the reminder email .
clean up old static sites
gets a dict containing all field definitions
validates the request 's json payload using a json schema .
performs url normalization .
this method is called before _ check_access and url normalization and is a good place to fetch objects from the database based on variables from request params .
this method is called after _ process_args and is a good place to check if the user is permitted to perform some actions .
dispatch to a method named ` ` _ process_<verb > ` ` .
decorates a function to run within the rh 's framework
get a dict containing all contribution field types
render the template .
"allows you to put [ ? ] , the context help marker . help content passed as argument helpcontent ."
"allows you to put [ ? ] , the context help marker . help content is defined in < div id=""helpid""></div > ."
"purpose : avoid showing "" none "" to user ; show default value instead ."
return verbose date representation .
return verbose time representation .
adds helper methods to the dictionary . does it only if symbol does not exist - backward compatibility .
return a : class:` . template ` object corresponding to the given url .
check whether the title matches a search string .
"returns a dictionary containing the tpl variables that will be passed at the tpl formating time . for this class , it will return the configuration user defined variables . classes inheriting from this one will have to take care of adding their variables to the ones returned by this method ."
returns the html resulting of formating the text contained in the corresponding tpl file with the variables returned by the getvars method . params : params -- additional paramters received from the caller
returns a dict of request definitions
checks if the user manages any request types
create a new database connection .
"connect(dsn , ... ) - > new psycopg 1.1.x compatible connection object"
cursor ( ) - > new psycopg 1.1.x compatible cursor object
autocommit(on_off=1 ) - > switch autocommit on ( 1 ) or off ( 0 )
"this hook is called by the serializer instance , prior to the validation call being made ."
filter the queryset to all instances matching the given attribute .
"if an instance is being updated , then do not include that instance itself as a uniqueness conflict ."
"this hook is called by the serializer instance , prior to the validation call being made ."
the ` uniquetogethervalidator ` always forces an implied ' required ' state on the fields it applies to .
filter the queryset to all instances matching the given attributes .
"if an instance is being updated , then do not include that instance itself as a uniqueness conflict ."
"this hook is called by the serializer instance , prior to the validation call being made ."
the ` uniquefor < range > validator ` classes always force an implied ' required ' state on the fields they are applied to .
decorator that adds ` call in main thread ` tag attribute to decorated function .
test whether given function has ` call in main thread ` tag .
decorator that adds ` call with info ` tag attribute to decorated function .
test whether given function has ` call with info ` tag .
parse hotkey spec list into hotkey info list .
call all given functions .
set hotkey info . will be called by hotkey manager .
returns the url to the ` ` actstream_actor ` ` view for the current actor .
returns the url to the ` ` actstream_actor ` ` view for the current target .
returns the url to the ` ` actstream_action_object ` ` view for the current action object
shortcut for the ` ` django.utils.timesince.timesince ` ` function of the current timestamp .
returns a stream method to use .
returns the object ( eg user or actor ) that the stream is for .
returns a queryset of actions to use based on the stream method and object .
"returns an rfc3987 iri id for the given object , action and date ."
"returns an rfc3987 iri for a html representation of the given object , action . if domain is true , the current site 's domain will be added ."
returns a formatted dictionary for the given action .
returns a formatted dictionary for an individual item based on the action and item_type .
returns a formatted dictionary for the actor of the action .
returns a formatted dictionary for the target of the action .
returns a formatted dictionary for the action object of the action .
returns an extra keyword arguments dictionary that is used when initializing the feed generator .
"returns an extra keyword arguments dictionary that is used with the ` add_item ` call of the feed generator . add the ' content ' field of the ' entry ' item , to be used by the custom feed generator ."
: param client : client : type client : roblox . robloxsession
gets whether chat is enabled ( privacy setting )
gets conversation by i d
gets list of conversations the user has with others
returns all mutli user conversations
returns all one to one conversations
gets number of conversations with unread messages
gets list of conversations with unread messages .
starts conversation with user(s ) . returns existing conversation if it already exists .
: param client : client : type client : robloxchatmanager
user who started the conversation
recent messages in a conversation .
sends message to conversation
gets unread messages from conversation
shows typing indicator in conversation .
hides typing indicator in conversation
context manager to make the typing indicator easy to use . it will hide the typing indicator when the block is done .
waits for message and returns the meesage .
marks messages in conversation as read .
renames group conversation
adds users to the conversation .
removes user from conversation
: param conversation : c : type conversation : conversation
user who sent the message ( property )
main exploit function
setup about window for gitso
adds analytics code into auto generated documentation .
fetches timestamps for checkins from given mongodb collection .
groups given dataframe containing timestamps per month and produces a plot for visualizing the distribution .
counts total number of venues and checkins for each city in the database . : param venue_collection : mongodb collection that contains the venues : param checkin_collection : mongodb collection that contains the checkins : return : a tuple containing number of venues and checkins per each city and the total number of unique users
counts total number of unique categories . : param venue_collection : mongodb collection that contains the venues : return : a set of containing unique categories
returns a boolean of whether the raw_password was correct . handles encryption formats behind the scenes .
"> > > t = "" "" "" ... text ... < t : panel a=""b "" > ... < head > head</head > ... < /t : panel > ... end "" "" "" > > > print parse(t , loader ) < blankline > text < div a=""b "" class= "" panel "" > < div class=""panel - head "" > < h3 > head</h3 > < blankline > < /div > < /div > end"
"> > > t = ' < t : button class=""primary"">submit</t : button > ' > > > print parse(t , loader ) < button class=""btn btn - primary"">submit</button >"
"> > > t = ' < t : bs.button > submit</t : bs.button > ' > > > print parse_xml(t ) ordereddict([(u'bs.button ' , { ' _ text ' : u'submit ' , ' _ attrs ' : ordereddict ( ) } ) ] )"
"> > > t = ' < t : bs.button > submit</t : bs.button > ' > > > print parse(t , loader ) < button class=""btn"">submit</button > < blankline >"
"> > > t = "" "" "" < t : form_input_field name=""title "" label=""label "" required=""required "" > ... < input type=""text "" value=""value "" placeholder=""placeholder "" help=""help "" > ... < ! [ cdata [ ... < h3 > cdata</h3 > ... ] ] > ... < /input > ... < /t : form_input_field > ... "" "" "" > > > print parse_xml(t ) ordereddict([(u'form_input_field ' , { u'input ' : { ' _ text ' : u'<h3 > cdata</h3 > ' , ' _ attrs ' : ordereddict([(u'type ' , u'text ' ) , ( u'value ' , u'value ' ) , ( u'placeholder ' , u'placeholder ' ) , ( u'help ' , u'help ' ) ] ) } , ' _ text ' : u '' , ' _ attrs ' : ordereddict([(u'name ' , u'title ' ) , ( u'label ' , u'label ' ) , ( u'required ' , u'required ' ) ] ) } ) ] )"
"> > > t = "" "" "" < t : form_input_field name=""title "" label=""label "" required=""required "" > ... < input type=""text "" value=""value "" placeholder=""placeholder "" help=""help "" > ... < ! [ [ ... < h3 > cdata</h3 > ... ] ] > ... < /input > ... < /t : form_input_field > ... "" "" "" > > > print parse_xml(t ) ordereddict([(u'form_input_field ' , { u'input ' : { ' _ text ' : u'<h3 > cdata</h3 > ' , ' _ attrs ' : ordereddict([(u'type ' , u'text ' ) , ( u'value ' , u'value ' ) , ( u'placeholder ' , u'placeholder ' ) , ( u'help ' , u'help ' ) ] ) } , ' _ text ' : u '' , ' _ attrs ' : ordereddict([(u'name ' , u'title ' ) , ( u'label ' , u'label ' ) , ( u'required ' , u'required ' ) ] ) } ) ] )"
"> > > t = ' < t : bs.button class= "" { { < < 123}}"">submit</t : bs.button > ' > > > print parse(t , loader ) < button class=""btn btn- { { < < 123}}"">submit</button > < blankline >"
"> > > t = '' ' < t : bs.button class= "" { { < < 123}}"">submit ... < ! -- < a href=""#"">aaa</a > -- > ... < /t : bs.button > '' ' > > > print parse(t , loader ) < button class=""btn btn- { { < < 123}}"">submit</button > < blankline >"
hard memory limit
soft memory limit
: param workers : a list of workers : param log : log object : param check_point : time interval to check sub process status : return :
"> > > d = sorteddict ( ) > > > d[2 ] = { ' id':'a ' , ' name':'a2 ' } > > > d[4 ] = { ' id':'d ' , ' name':'a4 ' } > > > d[3 ] = { ' id':'c ' , ' name':'a3 ' } > > > d[1 ] = { ' id':'b ' , ' name':'a1 ' } > > > d.items ( ) [ ( 2 , { ' i d ' : ' a ' , ' name ' : ' a2 ' } ) , ( 4 , { ' i d ' : 'd ' , ' name ' : ' a4 ' } ) , ( 3 , { ' i d ' : ' c ' , ' name ' : ' a3 ' } ) , ( 1 , { ' i d ' : ' b ' , ' name ' : ' a1 ' } ) ]"
"> > > d = sorteddict({'a':'b ' , ' c':'d ' } ) > > > d[1 ] = ' e ' > > > d[2 ] = ' f ' > > > d.items ( ) [ ( ' a ' , ' b ' ) , ( ' c ' , 'd ' ) , ( 1 , ' e ' ) , ( 2 , ' f ' ) ]"
"> > > d = sorteddict(kvio = true ) > > > d[1 ] = ' e ' > > > d[2 ] = ' f ' > > > d.items ( ) [ ( 1 , ' e ' ) , ( 2 , ' f ' ) ] > > > repr(d ) "" < sorteddict { 1:'e ' , 2:'f ' } > "" > > > d[1 ] = ' c ' > > > d.keys ( ) [ 2 , 1 ]"
"> > > d = sorteddict ( ) > > > d[1 ] = ' e ' > > > d[2 ] = ' f ' > > > d.items ( ) [ ( 1 , ' e ' ) , ( 2 , ' f ' ) ] > > > d.__setitem__(1 , ' c ' , append = true ) > > > d.keys ( ) [ 2 , 1 ]"
> > > d = sorteddict ( ) > > > d.name = 1 > > > d.keys ( ) [ ' name ' ] > > > d.name 1 > > > d._name = 2 > > > d.keys ( ) [ ' name ' ] > > > d._name 2 > > > del d.name > > > d.keys ( ) [ ] > > > del d._name
"if no options defined , then it 'll use settings options"
get a distribute lock
force to set a distribute lock
check redis version
returns the number of queries .
returns the i - th example .
loads a learning to rank dataset from a text file source
saves the data set in txt format to given file
saves the data set in binary format to given file
loads the data set in binary format from given file
needed for pypy support even though nicfit.py support is 3.6 and above
get command regex string and completer dict .
get the start of this clip dv.filename generally looks like this : 2012 - 01 - 14/10:01:34.dv parse the dir and filename strings . or use the filesystem_create
find and process show
"given : uri - input uri png_name - output path and filename ( defaults to input.wav.png , munged if input is http )"
given : options.indir - dir to recurse from looking for .dv files options.outdir - dir to put results in ( keeps the same tree found ) uses lvlpng ( ) to create output files .
tests the gstreamer functionality : report levels from an input file .
"filenames = [ # "" /home / carl / videos / veyepar / test_client / test_show / mp4 / test_episode.mp4 "" , # "" /home / carl / temp / manageable_puppet_infrastructure.webm "" , # "" /home / carl / temp/15_57_39.ogv "" , # "" /home / carl / src / veyepar / tests/165275__blouhond__surround - test-1khz - tone.wav "" , # "" /home / carl / videos / veyepar / nodevember / nodevember15 / dv / swang_102/2015 - 11 - 14 / cam/10_51_03/00002.mts "" , "" /home / carl / videos / veyepar / nodevember / nodevember15 / dv / stowe_hall/2015 - 11 - 14 / graphics swang 11:14 / clip1gtk19.mov "" , "" /home / carl / videos / veyepar / nodevember / nodevember15 / dv / stowe_hall/2015 - 11 - 14 / video swang 11:14 / clip1atk1.mov "" , "" /home / carl / videos / veyepar / nodevember / nodevember15 / dv / collins_auditorium/2015 - 11 - 14 / saturday morning camera / sc1atk103.mov "" , "" /home / carl / videos / veyepar / nodevember / nodevember15 / dv / collins_auditorium/2015 - 11 - 14 / saturday morning gfx / clip1atk653.mov "" , ]"
parameters ---------- resource : ` resource ` a ` resource ` where this scheduler works on queue : str the name of the queue to be used for pilot creation runtime : int max runtime in minutes for the created pilot cores number of used cores to be used in the created pilot
return the path to the staging area used by this scheduler
return the generators of the attached project
get the schedulers representation of the path in ` location ` object
convert a staging location into an adaptivemd location
call a preparations to use a scheduler
check whether the scheduler is idle
shut down the scheduler
prepare files and folder for all generators
"submit a task in form of an event , a task or an task - like object"
trigger a check of state changes that leads to task execution
do a controlled shutdown . cancel all units and wait until they finish .
shortcut for creation and appending of a new event
wait until no more units are running and hence no more state changes
remove all pending events and stop them from further task execution
interprete adaptive paths and replace prefixes with real os paths
create a task that computes an msm using a given set of trajectories
remote analysis function to be called by the rpc python call
"we run the rp methods in a separate process because although the master process starts these methods , we do n't want to block the master process ."
method exposed to the master process to start all the rp components and processes . this is a non - blocking command .
method exposed to the master process to end all the rp components and processes . this is a blocking command .
batch source and target together
"check if data is a list , if it is not a list , it will return a list as [ data ]"
"data_file_name_queue args : file_name : txt file , file name or a list of file name shuffle : true or false"
batch data args : filename_queue : produced by file_queue data_classes : list of dataclass is_train : true or false batch_size : batch size
test if current pattern can resolve params
test if current pattern can match params .
creates a graph from saved graphdef file .
prepares inception net for batched usage and returns pool_3 layer .
calculates the activations of the pool_3 layer for all images .
"numpy implementation of the frechet distance . the frechet distance between two multivariate gaussians x_1 ~ n(mu_1 , c_1 ) and x_2 ~ n(mu_2 , c_2 ) is d^2 = ||mu_1 - mu_2||^2 + tr(c_1 + c_2 - 2*sqrt(c_1*c_2 ) ) . stable version by dougal j. sutherland ."
"calculation of the statistics used by the fid . params : -- images : numpy array of dimension ( n_images , hi , wi , 3 ) . the values must lie between 0 and 255 . -- sess : current session -- batch_size : the images numpy array is split into batches with batch size batch_size . a reasonable batch size depends on the available hardware . -- verbose : if set to true and parameter out_step is given , the number of calculated batches is reported . returns : -- mu : the mean over samples of the activations of the pool_3 layer of the incption model . -- sigma : the covariance matrix of the activations of the pool_3 layer of the incption model ."
"checks if the path to the inception file is valid , or downloads the file if it is not present ."
calculates the fid of two paths .
test that packrat parsing was enabled
test that pyparsing._trim_arity has been replaced
tests that arity trimming has been disabled and parse actions with the wrong number of arguments will raise typeerrors
: type nums : list[int ] : rtype : list[list[int ] ]
: type matrix : list[list[int ] ] : rtype : list[list[int ] ]
: type numcourses : int : type prerequisites : list[list[int ] ] : rtype : list[int ]
test the case when the application passes a string representation of the uuid . uuid data type to _ mssql .
test the case when the application passes an instance of the uuid . uuid data type to _ mssql to confirm it can handle it .
the uuid . uuid type is n't supported by the pyformat paramstyle ( that only supports ' % s ' and is the style supported by pymsql ) . test the case when the application passes a string representation of such data type to _ mssql .
the uuid . uuid type is n't supported by the pyformat paramstyle ( that only supports ' % s ' and is the style supported by pymsql ) . test the case when the application passes an instance of such data type to _ mssql to confirm it can handle it .
calculate an id for this object .
"creates an url opener that works with both jenkins auth and proxy auth if no values are provided for the jenkins or proxy vars , a regular opener is returned : param jenkinsuser : username for jenkins , str : param jenkinspass : password for jenkins , str : param jenkinsurl : jenkins url , str : param proxyhost : proxy hostname , str : param proxyport : proxy port , int : param proxyuser : proxy username , str : param proxypass : proxy password , str : return : urllib2.opener configured for auth"
"get a basic authentification handler for jenkins : param jenkinsuser : jenkins username , str : param jenkinspass : jenkins password , str : param jenkinsurl : jenkins base url , str : return : a list of handlers"
get a configured handler for a proxy
initialize the plugin . @type configuration : configuration object @param configuration : the configuration @type entity : l{tnarchipelentity } @param entity : the entity that owns the plugin @type entry_point_group : string @param entry_point_group : the group name of plugin entry_point
this method will be called by the plugin user when it will be necessary to register module for listening to stanza .
unregister the handlers .
return informations about the plugin . @rtype : dict @return : dictionary contaning plugin informations
handle create hook_vm_create . @type origin : l{tnarchipelentity } @param origin : the origin of the hook @type user_info : object @param user_info : random user info @type parameters : object @param parameters : runtim argument
handle create hook_vm_terminate . @type origin : l{tnarchipelentity } @param origin : the origin of the hook @type user_info : object @param user_info : random user info @type parameters : object @param parameters : runtim argument
handle create hook_vm_initialize . @type origin : l{tnarchipelentity } @param origin : the origin of the hook @type user_info : object @param user_info : random user info @type parameters : object @param parameters : runtim argument
get the oom info from file . @rtype : dict @return : dict contaning oom status
set the oom info both on file if exists and on file . @type adjust : int @param adjust : the value of adjust @type score : int @param score : the value of the score
this method is invoked when a archipel_ns_oom_killer iq is received . it understands iq of type : - do - something @type conn : xmpp . dispatcher @param conn : ths instance of the current connection that send the stanza @type iq : xmpp . protocol . iq @param iq : the received iq
return the value of the oom_adjust of the virtual machine . @type iq : xmpp . protocol . iq @param iq : the received iq @rtype : xmpp . protocol . iq @return : a ready to send iq containing the result of the action
set the adjust value of oom killer from -16:15 plus special -17 value that disable oom killer for the process the lower the value his the higher the likelihood of killing the process . @type iq : xmpp . protocol . iq @param iq : the received iq @rtype : xmpp . protocol . iq @return : a ready to send iq containing the result of the action
called after websockets server startup ( i.e. after daemonize )
called after a new websocket connection has been established .
"parses the path , extracts a token , and looks for a valid target for that token in the configuration file(s ) . sets target_host and target_port if successful"
proxy client websocket to normal target socket .
no missing residues
create a new instance of the graphitepicklehandler
returns the help text for the configuration options for this handler
return the default config for the handler
pickle the metrics into a form that can be understood by the graphite pickle connector .
returns the default collector settings
collect process stat data
return help text for collector configuration .
returns default settings for collector .
collect memory stats of lxcs .
read contents of given file .
create a new instance of the snmpcollector class
perform snmp get for a given oid
perform an snmp walk on a given oid
returns the default collector settings
returns the default collector settings
basic tests for properties conditioned on multiple other properties .
regression tests for properties conditioned on the toolset version subfeature and some additional properties .
"these files are created by the configuration logic in link.jam they may or may not exist , depending on the system ."
test creation of a single link
test merging two directories
test adding a link when a different symlink already exists
test merging several directories including common prefixes
test merging several directories including common prefixes .
make sure that the # include scanner finds the headers
make sure that files are replaced if needed when merging in a new directory
tests the behavior of updates when changing the link mode . the link needs to be updated iff the original was a copy .
test all nine possible combinations of two runs .
test that linking a single file from multiple sources causes a hard error .
launches the bot .
this manages the migrations and database creation system for you .
update the migration file with the newest schema .
runs an upgrade from a migration
runs an downgrade from a migration
this removes a database and all its migrations .
this migrates our older json files to postgresql
return a timezone .
return the class under test .
return the function under test .
mock jira issue .
fake jira instance .
test the required class instantiation values .
test what happens when the config is missing .
ensure we get a typeerror if the auth contains neither key .
ensure basic_auth kwargs are handeled .
ensure oauth kwargs are handled .
ensure extra_kwargs work .
ensure the jirafetcher fetch method returns issues .
ensure a converted issue has a key .
ensure a convereted issue has a title .
ensure a convereted issue has a title .
ensure created_at is populated .
ensure updated_at is populated .
ensure the changelog is converted as expected .
the type of ticket should be captured .
the type of ticket should be ticket if issuetype ca n't be found .
checks if a given migration is within its allowed parameters .
return a list of the schema numbers present in git .
analyse a log for errors .
extract a timestamp from a log line
return revision options .
a svn repository .
return revision for a file .
return the maximum revision for all files under a given location
implementation of method evaluate_solution ( ) for t1 function .
crossover of t1 solutions .
mutation of t1 solution .
matches anything .
append the string to the description .
"matches if sequence 's elements satisfy a given list of matchers , in order ."
matches if object is a string ending with a given string .
matches if any element of sequence satisfies a given matcher .
matches if all of the given matchers are satisfied by any elements of the sequence .
matches if any of the given matchers evaluate to ` ` true ` ` .
"return a nested dictionary snapshot of all metrics and their values at this time . example : { ' category ' : { ' metric1_name ' : 42.0 , ' metric2_name ' : ' foo ' } }"
return a string category for the metric .
a generator that can handle : - multi - line fasta - single - line fasta - standard fastq ( 4 lines per read )
returns the base64 representation of a string or bytes .
returns the bytes from a base64 representation .
returns the ( string ) hexadecimal representation of a string or bytes .
returns the bytes from a ( string ) hexadecimal representation .
returns the bytes representation of an arbitrary message .
returns the string representation of an arbitrary message .
pads a message with binary zeroes until a given length is reached .
pads a message with binary zeroes until the length is a desired multiple .
function to mark orders as active . argument : request return : activates an order
function to mark orders as inactive / cac ` . argument : request return : deactivates an order
"splits the query string in invidual keywords , getting rid of unecessary spaces and grouping quoted words together . example :"
"returns a query , that is a combination of q objects . that combination aims to search keywords within a model by testing the given search fields ."
displays the form for items purchased
loads training data and put them in queues
validator for dataset service endpoints
validator for spatial dataset service endpoints
validator for spatial dataset service endpoints
validator for persistent store service ports
retrives dataset service engine
retrives geoserver engine
activate a webprocessingservice object by calling getcapabilities ( ) on it and handle errors appropriately .
get the wps engine .
returns a persistent store engine
returns a persistent store url
javascript vendor libraries to be placed in the { % block global_scripts % } block
javascript vendor libraries to be placed in the { % block global_scripts % } block
javascript specific to gizmo to be placed in the { % block scripts % } block
add the current tethys app metadata to the template context .
load the initial settings
reverse the initial settings
get the namespace for the app or extension .
gets a list of all scheduler objects registered in the tethys portal
gets the scheduler associated with the given name
creates a new scheduler
this method is to be overridden by the custom test case classes that inherit from the tethystestcase class and is used to perform any set up that is applicable to every test function that is defined within the custom test class
"this method is to be overridden by the custom test case classes that inherit from the tethystestcase class and is used to perform any tear down that is applicable to every test function that is defined within the custom test class . it is often used in conjunction with the "" set_up "" function to tear down what was setup therein ."
creates temporary persistent store databases for this app to be used in testing .
destroys the temporary persistent store databases for this app that were used in testing .
creates and returns temporary user to be used in testing
creates and returns a temporary superuser to be used in testing
returns a client object to be used to mimic a browser in testing
validates that the old_password field is correct .
"/var / lib / munin / htmlconf.storable contains a copy of all informations required to build the graph ( limits , legend , types ... ) parsing it should be much easier and much faster than running munin - run config"
builds a munin dashboard structure ( domain / host / plugins ) by reading the html files rather than listing the cache folder because the later is likely to contain old data
"options : x , y , font , color , restricted , maxlength , prompt"
"set the position to x , y"
set the font for the input
draw the text input to a surface
update the input based on passed events
flatten one level of nesting
enum is an adapter to another field : it will just change its display attribute . it uses a dictionary to associate a value to another .
"compute image compression rate . skip size of color palette , focus on image pixels . original size is width x height x bpp . compressed size is an argument ( in bits ) ."
function for enumerating sub - domains and hosts by scrapping google . it returns a unique list if host name extracted from the href entries from the google search .
function to remove duplicates in an array . returns array with duplicates removed .
convert windows 64 - bit duration to string . the timestamp format is a 64 - bit number : number of 100ns . see also timestampwin64 ( ) .
format field value using humanfilesize ( )
convert an integer to hexadecimal in lower case . returns unicode string .
extend data using a length and an offset .
"build a huffman tree from a list of lengths . the ith entry of the input list is the length of the huffman code corresponding to integer i , or 0 if the integer i is unused ."
to use in conjunction with a testclass wrapped with @genty .
get the json payload to put into the queue
serve static files from root directory .
"returns the item if it is naturally hashable , otherwise it tries to use ub.hash_data to make it hashable . errors if it can not ."
transforms function args into a key that can be used by the cache
memoization decorator that respects args and kwargs
descriptor get method . called when the decorated method is accessed from an object instance .
the wrapped function call
indents a block of text
wraps multiline string blocks and returns unindented code . useful for templated code defined in indented parts of code .
horizontally concatenates strings preserving indentation
casts bytes into utf8 ( mostly for python2 compatibility )
splits the modpath into the dir that must be in pythonpath for the module to be imported and the modulepath relative to this directory .
determines importable name from file path
finds the path to a python module from its name .
imports a module from its string name ( _ _ name _ _ )
imports a module via its path
closes the cursor . no further operations are allowed once the cursor is closed .
read - only attribute specifying if the cursor is closed or not .
transforms a row into python values .
read - only attribute providing access to the : class:`connection < phoenixdb.connection . connection > ` object this cursor was created from .
read - only attribute specifying the number of rows affected by the last executed dml statement or -1 if the number can not be determined . note that this will always be set to -1 for select queries .
read - only attribute providing the current 0 - based index of the cursor in the result set or ` ` none ` ` if the index can not be determined .
constructor for yumlist
build the repoquery cmd options
format the package data into something that can be presented
gather and present the versions of each package
perform a repoquery
run the ansible idempotent code
"given a dict of labels / values , return list of key : < key > value : < value > pairs"
returns a mapping of filters to methods
return router options
return all options as a string
return hash as list of key value pairs
constructor for openshiftoc
return the self.router_parts
return a deploymentconfig by name
return all pods
create a deploymentconfig
run update for the router . this performs a delete and then create
check to see if we need to update
ansible module for gcloud deployment - manager manifests
constructor for ocvolume
property function service
setter function for yedit var
return whether a user exists
return user information
delete the object
make entries for user to the provided group list
create the object
update group membership
update the object
check if there are group membership changes
verify an update is needed
create a search_journalctl object with canned get_log_output method
dynamically import all check modules for the side effect of registering checks .
"the name of this check , usually derived from the class name ."
a list of tags that this check satisfy .
returns true if this check applies to the ansible - playbook run .
"executes a check , normally implemented as a module ."
returns a generator of subclasses of this class and its subclasses .
invoke an ansible module from a check .
run execute_module and retry on failure .
get deeply nested values from task_vars .
parse and return the deployed version of openshift as a tuple .
return the mount point for path from ansible_mounts .
constructor for openshiftoc
"add key , value pair to env array"
"return whether a key , value pair exists"
"return whether a key , value pair exists"
return a environment variables
delete a list of keys
place an env in the env var list
return whether a volume mount exists
return whether a volume exists
return the index of a volume
return replicas setting
return volume mount information
return volume mount information
delete a volume
add a volume or volume mount to the proper location
add a volume or volume mount to the proper location
update replicas value
place an env in the env var list
place an env in the env var list
verify a volume update is needed
verify whether a replica update is needed
ensure the given binary name exists and links to the expected binary .
ansible oc module for services
constructor for handling service options
return a service as a dict
get a list of ports
add a port object to the ports list
find a specific port
remove a port from a service
add cluster ip
add cluster ip
ansible git module for rebasing
"given a list of pvs , return a list of pvs in az from_az"
given a list of pvs and all snapshots in region return list of pvs that have snapshots available
returns a mapping of filters to methods
constructor for ocvolume
formulate the params and run oadm manage - node
perform oc get node
return pods for a node
run oadm manage - node --list - pods
oadm manage - node call for making nodes unschedulable
check various things and gather errors . returns : result as hash
"try to reach a url from the host . returns : success ( bool ) , reason ( for failure )"
try to reach a url from ansible control host . raise an openshiftcheckexception if anything goes wrong .
check to see if kibana is up and working . raises openshiftcheckexception if not .
get kibana route or report error . returns : url
check to see if kibana route is up and working . raises exception if not .
ansible oc module for project
constructs the object
processes all metrics provided by metric_manager
"check that fluentd has running pods , and that its logging config matches docker 's logging config ."
"ensure that the configured docker logging driver matches fluentd settings . this means that , at least for now , if the following condition is met :"
read and return the value of the ' use_journal ' environment variable on a fluentd pod .
return a list of running fluentd pods .
parse arguments to generate
generate a banner to wrap around file fragments
generate the source code for the ansible modules
return the path to the generate sources
verify if the generated code matches the library code
combine the necessary files to create the ansible module
create an elasticsearch check object with stubbed exec_oc method
validate value returned back from get_notafter ( )
validate value returned back form get_serialnumber ( )
validate the certificate subject
skip hosts that do not have package requirements .
return the correct open vswitch version for the current openshift version
skip hosts that do not have package requirements .
return the correct open vswitch version(s ) for the current openshift version .
"return received image tag as a normalized ( x , y ) minor version tuple ."
determine a boolean value given the multiple ways bools can be specified in ansible .
"retrieve a variable from hostvars and template it . if undefined , return none type ."
ensure a valid openshift_deployment_type is set
ensure python version is 3 for fedora and python 2 for others
ensure openshift_image_tag is formatted correctly
ensure we can determine what image version to use with origin fail when : - openshift_is_containerized - openshift_deployment_type = = ' origin ' - openshift_release is not defined - openshift_image_tag is not defined
ensure only one type of network plugin is enabled
checks to ensure openshift_hostname and openshift_public_hostname conform to the proper length of 63 characters or less
execute the hostvars validations against host
create a maintenace in zabbix
skip hosts that do not have package requirements .
check if key exists in content or the size of content[key ] > 0
put dependencies into the proper update format
put dependencies into the proper update format
determine the dependency type
fetch the service i d for an itservice
fetch the service i d for an itservice
determine the showsla paramter
determine which type algorithm
ansible zabbix module for zbx_itservice
ansible module for gcloud compute images
ansible oc module for route
constructor for oadm ca
get the current cert file
create a deploymentconfig
check whether the certificate exists and has the clusterip
ansible git module for pushing
constructor for gcloud resource
property for existing metadata
property for existing metadata
return whether the metadata that we are removing exists
return whether the keys exist in the metadata
return whether an we need to update
attempt to remove metadata
create an metadata
return most recent snapshot for source elb volume
"if a volume from the provided snapshot already exists in the target az , then return the volumeid , otherwise , return none"
return the ' name ' tag from a volume
create ebs volume in target az from provided snapshot
entry point for module
constructor for openshiftoc
return a secret by name
delete a secret by name
create a secret
run update secret
return what the secret would look like if created this is accomplished by passing -ojson . this will most likely change in the future
ansible oc module for approving certificate signing requests
ansible oc adm module for ca create - server - cert
check provided command
main module function
constructor for ocproject
property for project
setter function for project propeorty
return whether a project exists
delete the object
create a project
update a project
verify an update is needed
run the idempotent ansible code
constructor for gcp resource
property for resource description
property for resource target_tags
property for resource source_tags
property for resource source_ranges
property for resource allowed
property for resource network
return the resource representation
ensure the given binary name exists and links to the expected binary .
returns a list of variables whose name matches the given pattern
returns the names of the filters provided by this class
main upgrade method for 3.0 to 3.1 .
upgrade entry point .
constructor for ocscale
property function for resource var
setter function for resource var
return replicas information
update replicas into dc
verify whether an update is needed
perform a repoquery
updates a parsed yaml structure setting a key to a value .
"modify key ( supplied in jinja2 dot notation ) in yaml file , setting the key to the desired value ."
return a hash with the desired storage for the given es instance
return the minimum cpu value of the two values given
walk the sourch hash given the path and return the value or default if not found
returns a random word given the source of characters to pick from and resulting length
returns the entry in key given results provided by register_pairs
returns a dict given the source and delim delimited
returns the simple name from a fully qualified name
returns the namespace from a fully qualified name
this filter plugin will flatten a dict and its sublists into a single dict
returns the names of the filters provided by this class
"retrieve a variable from hostvars and template it . if undefined , return none type ."
checks that the ocp version supported
execute the hostvars validations against host
"chomp any "" + git.foo "" commit offset string from the given ` version ` and return the modified version string ."
"if containerized , see if we can determine the installed version via the systemd environment files ."
apply provider facts to supplied facts dict
get current version of openshift on the host .
run this module
this is a filter to see which pods in a project are running
returns a mapping of filters to methods
actually executes the command . this makes mocking easier .
constructor for repoquerycli
base command for repoquery
test for minimum required version
version verification is performed in _ _ init _ _ to catch the requirement early in the execution of ansible and fail gracefully
constructor for handling pvc options
return a service as a dict
storage_class_name property setter
volume_name property setter
selector property setter
access_modes property setter
volume_capacity property setter
return whether volume is bound
add an access_mode
remove an access_mode
update an access_mode
find a user
return timestamps as strings
ansible oc module for secrets
getter method for yaml_dict
setter method for yaml_dict
remove data at location key
get an item from a dictionary with key notation a.b.c d = { ' a ' : { ' b ' : ' c ' } } } key = a.b return c
get an item from a dictionary with key notation a.b.c d = { ' a ' : { ' b ' : ' c ' } } } key = a.b return c
write to file
write to file
return whether file exists
return yaml file
get a specified key
remove key from a dict
"put key , value into a dict"
create a yaml file
ansible oadm module for manage - node
initialize the class
returns a disctionary of all instances where the key is the instance name
property for verbs
setter for verbs
property for api_groups
setter for api_groups
property for resources
setter for resources
property for attribute_restrictions
setter for attribute_restrictions
add a verb to the verbs array
add an api_group to the api_groups array
add an resource to the resources array
add a verb to the verbs array
add a verb to the verbs array
add a verb to the verbs array
return whether rules are equal
create rules from an array
ansible oc module for labels
constructor for handling secret options
return a secret as a dict
secret property setter
update a secret
convert x ( in x_min .. x_max range ) to out_min .. out_max range
called very frequently from javascript to provide an update loop
called from javascript whenever a key is down ( note : can generate repeat calls if held down )
called from javascript whenever a key is released
called from javascript whenever headlight is toggled on / off
called from javascript whenever freeplay mode is toggled on / off
called on any key press or release holding a key down may result in repeated handle_key calls with is_key_down==true
try and execute the next queued action
the run method runs once cozmo is connected .
splice each numpy / cupy element to form a one numpy / cupy array it is used to construct twice size of the input : param lu : : param ru : : param ld : : param rd : : return :
extract all nodes with gated - grpc debug ops attached .
expand the base name if there are node names nested under the node .
pass ` pb ` 's ` tensorproto ` through a marshalling roundtrip .
"use both ` op ` and ` pb ` to get a summary , asserting equality ."
constructor of debuggerdatastreamhandler .
implementation of the core metadata - carrying event proto callback .
implementation of the graphdef - carrying event proto callback .
records the summary values based on an updated message from the debugger .
parses the session_run_index value from the event proto .
receives health pills from a debugger and writes them to disk .
starts the http server for receiving health pills at ` receive_port ` .
gets the name of the debugger events file currently being written to .
"handles the case in which we receive a bad value ( nan , -/+ inf ) ."
get a report of the numerics alerts that have occurred .
disposes of this object . call only after this is done being used .
obtain total number of elements from a tensor ( ndarray ) shape .
parse a string as time indices .
view a slice or the entirety of an ndarray .
convert an array into base64 - enoded png image .
"create a run with a text summary , metadata , and optionally a graph ."
tests that the plugin offers the correct routes .
"set up runs , then fetch and return the graph as a proto ."
instantiates scalarsplugin via tensorboard core .
the scalars plugin is active iff any run has at least one scalar tag .
"return { runname : { tagname : { displayname : ... , description : ... } } } ."
"result of the form ` ( body , mime_type ) ` ."
obtains value for scalar event given blob and dtype enum .
"given a tag and single run , return array of scalarevents ."
construct a werkzeug response .
deserializes byte content that is a json encoding .
tests that the plugin offers the correct routes .
tests that the /images routes returns correct old - style data .
tests that the /images routes returns correct new - style data .
tests fetching an individual image from an old - style summary .
tests fetching an individual image from a new - style summary .
tests that the /runs route offers the correct run to tag mapping .
"use both ` op ` and ` pb ` to get a summary , asserting validity ."
loads all new values from disk .
solo los artículos que estén actives .
obtener un numero de articulo ordenados por votos de articleratio .
vota un articulo con un positivo .
used when the entire index for model is updated .
saves trained paragraph vectors to a csv file in the * data * directory .
return string summarizing the gaintable
create gain table from visibility .
apply a gain table to a block visibility
append othergt to gt
copy a gaintable
create a gaintable from selected rows
assess the quality of a gaintable
convert earth location to string
convert earth location to string
convert direction to string
convert direction ( skycoord ) from string
: param config : : param f : : return :
: param config : : param f : : return :
convert visibility to hdf
convert hdf root to visibility
convert blockvisibility to hdf
convert hdf root to blockvisibility
export a visibility to hdf5 format
import a visibility from hdf5 format
export a blockvisibility to hdf5 format
import a visibility from hdf5 format
convert gaintable to hdf
convert hdf root to a gaintable
export a gaintable to hdf5 format
import gaintable(s ) from hdf5 format
convert skycomponent to hdf
convert hdf root to a gaintable
export a skycomponent to hdf5 format
import skycomponent(s ) from hdf5 format
convert image to hdf
convert hdf root to an image
export an image to hdf5 format
import image(s ) from hdf5 format
export a skymodel to hdf5 format
import a skymodel from hdf5 format
"test that "" botulinum "" data can be loaded ."
"test that "" chrom17 m "" data can be loaded ."
"test that "" rb_clinical_trial "" data can be loaded ."
"test that "" confocal "" data can be loaded ."
"test that "" germina "" data can be loaded ."
"test that "" kenya "" data can be loaded ."
"test that "" massaro_blair "" data can be loaded ."
"test that "" monachus "" data can be loaded ."
"test that "" mult "" data can be loaded ."
"test that "" perch "" data can be loaded ."
"test that "" rats "" data can be loaded ."
"test that "" setig "" data can be loaded ."
"test that "" urology "" data can be loaded ."
"test that "" washing_test "" data can be loaded ."
"test that "" waterfalls "" data can be loaded ."
"test that "" macnell2014 "" data can be loaded ."
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the test subject .
set up the joke sensor .
initialize the sensor .
return the state of the sensor .
return the state attributes .
get the latest data and updates the states .
initialize the data object .
get the latest data and updates the states .
"在growingstate类中定义函数update , 更新状态 ."
transliterate serbian cyrillic string of characters to latin string of characters . : param string_to_transliterate : the cyrillic string to transliterate into latin characters . : param lang_code : indicates the cyrillic language code we are translating from . defaults to serbian ( sr ) . : return : a string of latin characters transliterated from the given cyrillic string .
transliterate serbian latin string of characters to cyrillic string of characters . : param string_to_transliterate : the latin string to transliterate into cyrillic characters . : param lang_code : indicates the cyrillic language code we are translating to . defaults to serbian ( sr ) . : return : a string of cyrillic characters transliterated from the given latin string .
returns list of supported languages : return :
print tag key = value pairs .
switch between avg . event . touch and avg . event . track - source
returns scrsize aspect correct scaled to fit right into maxsize .
returns scrsize aspect correct scaled to completely fill minsize .
generator for v1 resnet models .
resnet-50 model of [ 1 ] . see resnet_v1 ( ) for arg and return description .
resnet-101 model of [ 1 ] . see resnet_v1 ( ) for arg and return description .
resnet-152 model of [ 1 ] . see resnet_v1 ( ) for arg and return description .
resnet-200 model of [ 2 ] . see resnet_v1 ( ) for arg and return description .
return a dictionary of settings .
look up the low - level qpol policy reference
factory function for creating attribute objects .
factory function for creating type objects .
factory function for creating type or attribute objects .
generator that expands this attribute into its member types .
generator that yields all attributes for this type .
generator that yields all aliases for this type .
( t / f ) the type is permissive .
generator that expands this into its member types .
generator that yields all attributes for this type .
generator that yields all aliases for this type .
generator that expands this attribute into its member types .
generator that yields all attributes for this type .
generator that yields all aliases for this type .
( t / f ) the type is permissive .
determine if this is a regular or mls constraint / validatetrans .
validate constraint rule types .
factory function for creating constraint objects .
the roles used in the expression .
object class for this constraint .
the types and type attributes used in the expression .
the users used in the expression .
the constraint 's expression in infix notation .
the constraint 's expression in postfix notation .
flatten the expression into a flat list .
internal generator for getting users / roles / types in a constraint expression . symbols will be yielded multiple times if they appear in the expression multiple times .
generate the string representation of the expression .
the constraint 's permission set .
create a dialog box for user details .
generator which yields all matching devicetreecons .
create a dialog box for common perm set details .
rangetransition factory lookup .
rangetransition valid rule types .
rangetransition valid rule types .
rangetransition rule type
rangetransition source type
rangetransition target type
rangetransition object class
rangetransition default range
rangetransition conditional expression
rangetransition statement .
sensitivity query with no criteria .
sensitivity query with exact name match .
sensitivity query with regex name match .
sensitivity query with exact alias match .
sensitivity query with regex alias match .
sensitivity query with sens equality .
sensitivity query with sens dominance .
sensitivity query with sens dominance ( equal ) .
sensitivity query with sens dominated - by .
sensitivity query with sens dominated - by ( equal ) .
create a dialog box for object class details .
generator which yields all matching pcidevicecons .
return a dictionary of settings .
run the query and update results .
fs_use _ * query with no criteria
fs_use _ * query with exact fs match
fs_use _ * query with regex fs match
fs_use _ * query with ruletype match
fs_use _ * query with context user exact match
fs_use _ * query with context user regex match
fs_use _ * query with context role exact match
fs_use _ * query with context role regex match
fs_use _ * query with context type exact match
fs_use _ * query with context type regex match
fs_use _ * query with context range exact match
fs_use _ * query with context range overlap match ( equal )
fs_use _ * query with context range overlap match ( subset )
fs_use _ * query with context range overlap match ( superset )
fs_use _ * query with context range overlap match ( overlap low level )
fs_use _ * query with context range overlap match ( overlap high level )
fs_use _ * query with context range subset match
fs_use _ * query with context range subset match ( equal )
fs_use _ * query with context range superset match
fs_use _ * query with context range superset match ( equal )
fs_use _ * query with context range proper subset match
fs_use _ * query with context range proper subset match ( equal )
fs_use _ * query with context range proper subset match ( equal low only )
fs_use _ * query with context range proper subset match ( equal high only )
fs_use _ * query with context range proper superset match
fs_use _ * query with context range proper superset match ( equal )
fs_use _ * query with context range proper superset match ( equal low )
fs_use _ * query with context range proper superset match ( equal high )
role query with no criteria .
role query with exact name match .
role query with regex name match .
role query with type set intersection .
role query with type set equality .
role query with type set match .
validate default _ * rule types .
factory generator for creating default _ * statement objects .
the object class .
common : factory policy lookup .
common : factory policy invalid lookup .
common : factory policy lookup of common object .
common : string representation
common : permissions
common : statement .
common : contains
objclass : factory policy lookup .
objclass : factory policy invalid lookup .
objclass : factory policy lookup of objclass object .
objclass : string representation
objclass : permissions
"objclass : statement , no common ."
"objclass : statement , with common ."
"objclass : statement , with common , no class perms ."
objclass : contains
"objclass : contains , with common"
generate the difference in types between the policies .
reset diff results on policy changes .
generate the difference in portcons between the policies .
reset diff results on policy changes .
generator which yields all matching nodecons .
devicetreecon query with no criteria
devicetreecon query with context user exact match
devicetreecon query with context user regex match
devicetreecon query with context role exact match
devicetreecon query with context role regex match
devicetreecon query with context type exact match
devicetreecon query with context type regex match
devicetreecon query with context range exact match
devicetreecon query with context range overlap match ( equal )
devicetreecon query with context range overlap match ( subset )
devicetreecon query with context range overlap match ( superset )
devicetreecon query with context range overlap match ( overlap low level )
devicetreecon query with context range overlap match ( overlap high level )
devicetreecon query with context range subset match
devicetreecon query with context range subset match ( equal )
devicetreecon query with context range superset match
devicetreecon query with context range superset match ( equal )
devicetreecon query with context range proper subset match
devicetreecon query with context range proper subset match ( equal )
devicetreecon query with context range proper subset match ( equal low only )
devicetreecon query with context range proper subset match ( equal high only )
devicetreecon query with context range proper superset match
devicetreecon query with context range proper superset match ( equal )
devicetreecon query with context range proper superset match ( equal low )
devicetreecon query with context range proper superset match ( equal high )
convert image sequence batch into image and diff batch .
read the tf . sequenceexample tfrecord files .
create directory if does n't exist : param dest_directory : : return : true if everything went well
download a set of files in temporary local folder : param directory : the directory where to download : return : a tuple of filepaths corresponding to the files given as input
"subtracts mean of image and divides by adjusted standard variance ( for stability ) . operations are per image but performed for the entire array . : param image : 4d array ( id , height , weight , channel ) : return : 4d array ( id , height , weight , channel )"
extract a matlab matrix into two numpy arrays with data and labels : param local_url : : return :
"helper function : unpickles a dictionary ( used for loading cifar ) : param file : filename of the pickle : return : tuple of ( images , labels )"
"extracts the cifar-10 dataset and return numpy arrays with the different sets : param local_url : where the tar.gz archive is located locally : param data_dir : where to extract the archive 's file : return : a tuple ( train data , train labels , test data , test labels )"
"extract the images into a 4d tensor [ image index , y , x , channels ] ."
extract the labels into a vector of int64 label ids .
load the original svhn data : param extended : include extended training data in the returned array : param test_only : disables loading of both train and extra - > large speed up : return : tuple of arrays which depend on the parameters
load the original cifar10 data : param extended : include extended training data in the returned array : param test_only : disables loading of both train and extra - > large speed up : return : tuple of arrays which depend on the parameters
load the mnist dataset : param extended : include extended training data in the returned array : param test_only : disables loading of both train and extra - > large speed up : return : tuple of arrays which depend on the parameters
simple partitioning algorithm that returns the right portion of the data needed by a given teacher out of a certain nb of teachers : param data : input data to be partitioned : param labels : output data to be partitioned : param nb_teachers : number of teachers in the ensemble ( affects size of each partition ) : param teacher_id : i d of partition to retrieve : return :
load the model from graphdef and checkpoint .
evaluate model perplexity using provided dataset .
predict next words using the given prefix words .
dump the softmax weights and word embeddings to files .
predict next words using the given prefix words .
construct an amortizedgaussiansanitizer .
set options for an individual tensor .
sanitize the given tensor .
"return the type of the activations , weights , and placeholder variables ."
"download the data from yann 's website , unless it 's already here ."
"extract the images into a 4d tensor [ image index , y , x , channels ] ."
extract the labels into a vector of int64 label ids .
generate a fake dataset that matches the dimensions of mnist .
return the error rate based on dense predictions and sparse labels .
adds ops for a recurrent neural network layer .
shape function for the variablelstm op .
gradient function for the variablelstm op .
adds ops for an lstm layer .
tests that the percent calculation works as expected .
tests that the error counter works as expected .
tests that the error counter works as expected .
get the name of the op that created a tensor .
build a network using the given parameters .
compute a linearly varying number .
clip an array of tensors by l2 norm .
soft - threshold a tensor by the mean value .
"add i.i.d . gaussian noise ( 0 , sigma^2 ) to every entry of t."
generate binomial table .
builds the model .
create input tfrecord tensors .
we use the user management implemented in the wiki of the openmod - community . new users must be created there . : param request : a http - request object sent by the django framework . : return : redirect to accountrequest - form on wiki.openmod-initiative.org
"load the user identified by user_id and is oauth - token . if latter does not exist yet , create one . : param request : a http - request object sent by the django framework . : param user_id : an user i d : return : profile renderer"
load and list the available groups by groupadmin . : param request : a http - request object sent by the django framework . : param user_id : an user i d : return : profile renderer
load the chosen action(create or edit ) for a group . : param request : a http - request object sent by the django framework . : param user_id : an user i d : param user_id : an group i d : return : profile renderer
"performs selected action(save or delete ) for a group . if a groupname already exists , then a error will be output . the selected users become members of this group . the groupadmin is already set . : param request : a http - request object sent by the django framework . : param user_id : an user i d : param user_id : an group i d : return : profile renderer"
load the chosen action(create or edit ) for a group . : param request : a http - request object sent by the django framework . : param user_id : an user i d : param user_id : an group i d : return : profile renderer
"performs selected action(save or delete ) for a group . if a groupname already exists , then a error will be output . the selected users become members of this group . the groupadmin is already set . : param request : a http - request object sent by the django framework . : param user_id : an user i d : param user_id : an group i d : return : profile renderer"
called when a websocket has been created successfully .
"attempt to upgrade the current environ into a websocket enabled connection . if successful , the environ dict with be updated with two new entries , ` wsgi.websocket ` and ` wsgi.websocket_version ` ."
validate and ' upgrade ' the http request to a websocket request .
called when the handler is ready to send a response back to the remote endpoint . a websocket connection may have not been created .
sets up the ` ` pywsgi . handler ` ` to work with a websocket response .
"i have n't seen this action type be sent from a tracker , but i 've left it here for the possibility ."
"acquire a lock . this method blocks until the lock is unlocked , then sets it to locked and returns true ."
wake up the first waiter who is n't cancelled .
close client connections .
true if connection is closed .
returns redis client to master redis server .
returns redis client to slave redis server .
execute sentinel command .
returns a dictionary containing the specified masters state .
"returns a ( host , port ) pair for the given ` ` name ` ` ."
returns a list of dictionaries containing each master 's state .
returns a list of slaves for ` ` name ` ` .
returns a list of sentinels for ` ` name ` ` .
add a new master to sentinel to be monitored .
remove a master from sentinel 's monitoring .
set sentinel monitoring parameters for a given master .
force a failover of a named master .
"check if the current sentinel configuration is able to reach the quorum needed to failover a master , and the majority needed to authorize the failover ."
create an object that contains the input expression in the cpe language ( a set of cpe names ) and the dom tree asociated with expression .
returns a human - readable representation of cpe language expression .
"accepts a set of known cpe names and an expression in the cpe language , and delivers the answer true if the expression matches with the set . otherwise , it returns false ."
"encode a numpy array as a base64 encoded string , to be json serialized ."
creates a python dictionary that has trace ids as keys and the corresponding trace objects as values .
"takes trace objects created by build_trace_dict ( ) and generates a list of python dictionaries that can be written to a file in json format , which in turn can be given to chrome tracing ( chrome://tracing ) ."
tests that a netsmap message can be created with a netdef message
tests that netdefs can be added to metanetdefs
test that passing net itself instead of proto works
test that passes intersecting parameters and input / output blobs
convert a hwc array to chw .
convert a chw array to hwc .
visualizes one single patch .
visualize multiple patches .
"similar to showmultiple , but always normalize the values between 0 and 1 for better visualization of image - type data ."
this function shows the channels of a patch .
gets the shape of a single patch .
net : the main net operator should be added to
retrieves blobs from step workspaces ( which contain intermediate recurrent network computation for each timestep ) and puts them in the global workspace . this allows access to the contents of this intermediate computation in python . returns the list of extracted blob names .
fill a queue with input data
test with is_test = true for a deterministic reference impl .
test with ratio=0 for a deterministic reference impl .
run the given runnable .
generates a ' code_verifier ' as described in section 4.1 of rfc 7636 .
creates a ' code_challenge ' as described in section 4.2 of rfc 7636 by taking the sha256 hash of the verifier and then urlsafe base64 - encoding it .
return a html row for stack item * i * ( which is represented by * text * )
display the stack
display named items
quotes a string as css string literal .
decode an ascii - art representation of a base feature .
"initialize stub with data , as if it just came from the instrument ( i.e. , reference must be provided in reverse - complemented form for reverse - strand reads ) ."
total length of reference / scaffold coordinate windows
predicate that determines whether the reference / scaffold windows are contiguous .
[ consensus ] - > consensus
"reads reference from fasta file , loading lookup tables that can be used any time later ."
enumerate the contiguous spans along this reference contig that are to be analyzed .
"enumerate all work chunks on this reference contig ( restricted to the windows , if provided ) ."
"enumerate chunks , creating chunks with hascoverage = false for coverage cutouts ."
termination is determined to be when the result collector has built consensus corresponding to the exact number of reference bases in the window under consideration .
"enumerate all refids ( subject to the referencewindows restriction , if provided ) ."
returns a list of files about to be commited .
check if the input file looks like a python script
parse the score out of pylint 's output as a float
"check the python file whether ignored if the file is ignored returns true , returns false otherwise"
stashes any changes on entry and restores them on exit .
a context manager that does nothing .
check if the file should be ignored
main function doing the checks
parse default data from 2 + field tsv with new para and lemma .
parse extra fields form > 3 fields of 2 + field tsv .
self test exmaple
construct formatter with given verbosity .
return copyright declaration in lexc format
return multichar declaration in lexc format
return root lexicon in lexc format
turn wordmap into lexc string valid for insides of lexicon
turn continuation record into lexc string valid for insides of lexicon
input : { ( pipeline ) - update pipeline with new values ( random_module ) - global random module ( to set global seed ) ck_kernel - ck kernel }
indeces[old_node_id ] = new_node_id
encode a byte string using base64 .
decode a base64 encoded byte string .
encode a byte string using the standard base64 alphabet .
decode a byte string encoded with the standard base64 alphabet .
encode a byte string using a url - safe base64 alphabet .
decode a byte string encoded with the standard base64 alphabet .
encode a byte string using base32 .
decode a base32 encoded byte string .
encode a byte string using base16 .
decode a base16 encoded byte string .
encode a file ; input and output are binary files .
decode a file ; input and output are binary files .
encode a bytestring into a bytestring containing multiple lines of base-64 data .
legacy alias of encodebytes ( ) .
decode a bytestring of base-64 data into a bytestring .
legacy alias of decodebytes ( ) .
small main program
"binhex(infilename , outfilename ): create binhex - encoded copy of a file"
"hexbin(infilename , outfilename ) - decode binhexed file"
read at least wtd bytes ( or until eof )
"new(name , data = b '' ) - return a new hashing object using the named algorithm ; optionally initialized with data ( which must be bytes ) ."
"new(name , data = b '' ) - return a new hashing object using the named algorithm ; optionally initialized with data ( which must be bytes ) ."
test seed ( ) and getstate()/setstate ( )
jumpahead will change the pseudo - number generator 's internal state
generate a random number list
"these lines are borrowed from python , they should n't cause any exception ."
these input to randrange ( ) should n't cause any exception .
"for any valid pair ( a , b ) , randint(a , b ) should lay between [ a , b ]"
"random.choice ( ) should be able to deal with string , list ."
"test random.shuffle ( ) on list . since string is not writable in - place , random.shuffle ( ) can not be applied on string . note : to copy items from a list to a new list , must use syntax like : newlist = oldlist [: ] if use syntax like : newlist = oldlist , newlist is just an alias of oldlist ."
this is a generator . returns the fully expanded filenames for all extracted files fails assertion if one of the files does n't exist .
asserts that each auto - generated file has been modified since ' extract ' was launched . intended to show that the file has been touched by ' extract ' .
verifies is_keystring predicate
verify all headers have been modified
verify all metadata has been modified
render widget .
test regex substitution .
test splitting message packets .
test joining message packets .
display fieldinfo representations
helper function to return path to the tests directory
static method to create a default logging instance for the loci . the default is a null handler ( no log ) .
"quick function to verify that a logger is really a logger , otherwise it raises a valueerror ."
default logger : param name : string used to give a name to the logger . : type name : str
"create a queue logger for a specific class , which * must * have a "" logging_queue "" property redirecting to a queue - like object . if the instance possesses a "" log_level "" attribute , the log level will be set to its value ; otherwise , the logger will be configured with a default level of "" warning "" ."
call ` ` sklearn.linear_model.enet_path ` ` using automatic mapping .
call ` ` sklearn.linear_model.lars_path ` ` using automatic mapping .
call ` ` sklearn.linear_model.lasso_path ` ` using automatic mapping .
call ` ` sklearn.linear_model.lasso_stability_path ` ` using automatic mapping .
call ` ` sklearn.linear_model.orthogonal_mp_gram ` ` using automatic mapping .
my define raise exception function
用sha1算法生成安全签名 @param token : 票据 @param timestamp : 时间戳 @param encrypt : 密文 @param nonce : 随机字符串 @return : 安全签名
提取出xml数据包中的加密消息 @param xmltext : 待提取的xml字符串 @return : 提取出的加密消息字符串
生成xml消息 @param encrypt : 加密后的消息密文 @param signature : 安全签名 @param timestamp : 时间戳 @param nonce : 随机字符串 @return : 生成的xml字符串
对需要加密的明文进行填充补位 @param text : 需要进行填充补位操作的明文 @return : 补齐明文字符串
删除解密后明文的补位字符 @param decrypted : 解密后的明文 @return : 删除补位字符后的明文
对明文进行加密 @param text : 需要加密的明文 @return : 加密得到的字符串
对解密后的明文进行补位删除 @param text : 密文 @return : 删除填充补位后的明文
随机生成16位字符串 @return : 16位字符串
return a list of values for the given key : param k : : param v : : param values : : return :
retrieve zip file from the given url .
creates an image and uploads it to the server .
creates a user identifier from the specified type and value .
retrieve the index of a given field in the api_error 's fieldpathelements .
formats the given datetime and timezone for use with adwords .
runs the example .
recursively display a node and each of its children .
creates a subdivision node .
creates a unit node .
returns the set of mutate operations needed to create the current tree .
creates an adgroupcriterionoperation for the given criterion .
remove cache files for testing
"tinymongo uses all collections in one file , clearing requires direct access"
parse test config file
check prosperdb for validation
compare dates between two data sets
"the average path length in a n_samples itree , which is equal to the average path length of an unsuccessful bst search since the latter has the same structure as an isolation tree . parameters ---------- n_samples_leaf : array - like of shape ( n_samples , n_estimators ) , or int . the number of training samples in each test sample leaf , for each estimators ."
fit estimator .
predict anomaly score of x with the isolationforest algorithm .
average of the decision functions of the base classifiers .
point all operations on dns models to ' bind '
"for the given message , if html is present , add bootstrap .alert - link class to all links"
create .dimacs file from w.txt
utility function to register a cinema 4d commanddata plugin . this function will read from several attributes of * cmd * to find the information required for registration .
"similar to : func:`register_command ` , this function registers a : class:`c4d.plugins . messagedata ` plugin to cinema 4d. * data * must be an instance or subclass of the messagedata class and provide the following attributes :"
"reloads * package * which must be a python module object . note that reloading modules can always lead to issues if things are still reference , because , for instance , class identities will change ."
removes * package * from : data:`sys.modules ` and all its sub packages and modules .
determines if the module * mod * with * name * is a module imported from the specified * path * or any subpath . * mod * can be none in which case the parent - module is checked ( determined from * name * ) .
replaces all non - ascii characters in the supplied unicode string with cinema 4d stringtable unicode escape sequences .
creates the object
"# todo - sha1hex create a superclass once tested called by servergateway to handle a url - passed the parts of the remainder of the url after the requested format ,"
"fetch the content , do nt pass to caller ( typically called by nameresolver.content ( ) todo - if needed can retrieve the torrent file here - look at hashstore for example of getting from self.url"
: returns : content - i.e. bytes
: param verbose : : return :
initializer for the class .
run the viterbi decoder .
create some random seeds .
the base experiment .
run the experiments .
read and import wow wmo object to blender scene
generate a request for communicationcontrol
populates the response ` ` service_data ` ` property with an instance of : class:`communicationcontrol . responsedata < udsoncan.services . communicationcontrol . responsedata > `
send data to the underlying transport protocol
wait for the reception of a frame of data from the underlying transport protocol
the implementation of the send method .
the implementation of the ` ` wait_frame ` ` method .
setup the connection object .
close the connection object
empty all unread data in the reception buffer .
"normalize scores to 1000 , for combined scores"
"string network factory from preprocessed edge file ( protein1 , protein2 , combined_score ) , scores are already normalized to 1000 . this is the standard factory method used for microbes ."
tests creating a network using the constructor
tests creating a network using the standard factory method
tests creating a network using the standard factory method no duplicate edge will be generated
tests creating a network
tests creating a network
tests the edges that have a source in the input
we take the safer route and assume that the input could be separated out into lines
create an rsatdatabase instance based on a mirror url
retrieve ncbi code from organism.tab file
returns the html page for the directory listing
returns the specified organism name file contents
returns the specified organism 's feature file contents note : the current version only tries to read from feature.tab while the original cmonkey will fall back to cds.tab if that fails
returns the specified organism 's feature name file contents
returns the specified contig sequence
creates a mock instance
mocked microbesonline operon prediction result
tests building an operon list from two name lists
test when all genes of the operon are on the forward strand
test when all genes of the operon are on the reverse strand
tests the make_edges_from_predictions function
test happy path
makes a mock organism with almost real data
returns reference operon pairs for comparison
test the make_operon_pairs ( ) function in integration
initialises the buy and hold strategy .
adds keys to the bought dictionary for all symbols and sets them to ' out ' .
generates a new set of signals based on the mac sma with the short window crossing the long window meaning a long entry and vice versa for a short entry .
standardizes the pipeline api data pull using the s&p500 's means and standard deviations for particular customfactors .
summarize standardized data in a single number .
"print "" long list "" log.info(context.long_set )"
9 filters : 1 . common stock 2 & 3 . not limited partnership - name and database check 4 . database has fundamental data 5 . not over the counter 6 . not when issued 7 . not depository receipts 8 . primary share 9 . high dollar volume check scott 's notebook for more details .
turn a boto http 400 into a badamazon
run any registered teardown function
we need to do some trickery with runtest so that it all works .
return a uuid1 value
make a temp file . record it so it can be cleaned up later
make a temp directory . record it so it can be cleaned up later
clean up any temporary things that were made during this test
yield a temporary file and ensure it 's deleted
yield a temporary directory and ensure it is deleted
"given a list of of [ < file_spec > , ... ] create the specified files under specified root ."
"setup hierarchy of folders in a temp directory so if heirarchy is { ' one ' : { ' two':{""six "" : '' } , ' three ' : '' , ' four':'contents ' } , ' five ' : { ' etc ' : '' } } then under a temp directory you 'll get one / two , one / three , one / four , five / etc"
get us a dictionary from a directory that can be used in setup_directory
make sure content of a tarfile matches what we expect
"yield ( identity , data , tarinfo ) for everything in archive at provided location"
make sure content of a tarfile matches what we expect
"yield ( identity , data , zipinfo ) for everything in archive at provided location"
@summary : constructor
retrieve text of a python enhancement proposal
"get the relative path to the source file with the specified filename : param source_id : i d of the source file : param filename : name of the file , will be sanitized : return : a path relative to the config.storedir where save that file"
"get the relative path to the output file with the specified filename : param output_id : i d of the output file : param filename : name of the file , will be sanitized : return : a path relative to the config.storedir where save that file"
get the relative path to the input file for the specified attempt on the specified task : param input_id : i d of the input file : param task_name : name of the task : param attempt : attempt on the task : return : a path relative to the config.storedir where that file is
get the size of the filename in bytes : param filename : relative path of the file to check : return : the number of bytes of the file
"store a file in the filesystem , creates the directories needed : param path : path of the file : param file_content : content of the file"
"moves a file in the filesystem , creates the directories needed : param src_path : relative path of the file : param dst_path : relative path where to put the file"
get the absolute path of a stored file : param relative_path : relative path of the file : return : the absolute path of the file
create a directory in the filesystem : param filename : absolute path of the file or its directory
"sanitize a filename , convert all the spaces to underscores and remove all invalid characters . the result string can only contain chars in [ a - za - z_- . ] . the filename is also truncated if it has more than max_length chars ( it tries to truncate the name and keep the extension ) : param filename : filename to sanitize : return : the sanitized file name"
generator function for decrypting / encrypting the binary file .
decrypts / encrypts the binary data .
verifies the contained data .
"turn everything off ( sleep ) , then ready"
turn all boolean outputs off
ready the panel
load experiment parameters from a json configuration file
save a dictionary of parameters to an experiment json config file
load experiment parameters from a yaml configuration file
save a dictionary of parameters to an experiment yaml config file
"store data that is specific to this experiment , and compute a wait time for an intertrial interval"
queue the sound and play it
"grouper(3 , ' abcdefg ' , ' x ' ) -- > abc def gxx"
generate a sine wave at a given frequency of infinite length .
generate random samples .
create a generator which computes the samples .
write samples to a wavefile .
write samples as raw pcm data .
: param addr : an ieee eui-48 ( mac ) address in string form .
: param addr : an ieee eui-48 ( mac ) address in string form .
: param int_val : an unsigned integer .
: param int_val : the integer to be packed .
: param packed_int : a packed string containing an unsigned integer . it is assumed that string is packed in network byte order .
tests an image to see whether it 's an animated gif
"compares the sizes of two files , and discards the larger one"
returns the next command to apply
"always keeps input , but still compares the sizes of two files"
"fit regressors parameters ---------- xs : list of { array - like , sparse matrix } , length = number of regressors list of matrices of training samples"
"predict class labels . parameters ---------- xs : list of { array - like , sparse matrix } , length = number of regressors list of matrices of training samples"
returns the r2 ( coefficient of determination ) score by default
"trains on the data . xs = [ [ ] , [ ] , [ ] ] ( one matrix for each mode ) ys = [ [ ] , [ ] , [ ] ]"
predicts new data instances
called when the dmp template engine is created by django
called from here as well as dmp_webpack.py
returns a provider instance for the given template
tself : ` self ` object from a mako template ( available during rendering ) . version_id : hash / unique number to place on links group : provider group to include ( defaults to all groups if none ) factories : list of provider factories to run on each template ( defaults to settings.py if none )
performs the run through the templates and their providers
provider instances use this to write to the buffer
returns the buffer string
returns the hash for the given arguments
formats the base64 string based on a user
creates the url request with the credentials
get the github api url
set the last url as a vim variable for later access
get the last url from vim and open it
open the url in the browser
get the last url from vim and open it
copies the given url to the yank register
returns the symbol for the current yank register
ask the user for a description of the gist
get the text from the files specified by the arguments if there is a visual selection just that text is used otherwise if all is passed all buffers are used
"return the text from the given buffer between the given lines this starts at a line before the given index to get all the text from the array of lines , joined by a newline"
return just the filename of the given buffer
return if the given buffer is a directory
post text to a given twitter account .
initialize a usagepacket from a binary string containing the udp packet contents .
return a values tuple which matches the parameters in the class 's insert_statement .
upload this packet to the database .
upload multiple usage packets of the same type . returns an array of packets which could not be uploaded
"parse an address in the binary usage packet 's sender address format . the address is a 16 byte array . if bytes 0 - 12 are   , then assume it 's an ipv4 address , otherwise , an ipv6 address ."
"unpack the next data from the usage packet body . accepts the format strings handled by struct.unpack , minus the leading endian indicator , which is determined by the packet header ."
extract keywords from text using the montemurro and zanette entropy algorithm . [ 1 ] _
calculates the logarithm of n!/m!(n - m ) !
get a single topic as a formatted string .
get the most significant topics ( alias for ` show_topics ( ) ` method ) .
get words x topics matrix .
test similarity_matrix returns expected results .
test most_similar returns expected results .
test most_similar returns correct results when ` topn ` is specified .
test most_similar raises keyerror when input is out of vocab .
test most_similar returns handles restrict_vocab correctly .
test most_similar returns expected results with an input vector instead of an input word .
test most_similar_to_given returns correct results .
test similar_by_word returns expected results .
test similar_by_word returns expected results .
test that distance returns expected values .
"test similarity returns expected value for two words , and for identical words ."
test words_closer_than returns expected value for distinct and identical nodes .
test rank returns expected value for distinct and identical nodes .
test that the deprecated ` wv ` property returns ` self ` . to be removed in v4.0.0 .
test that adding entity in a manual way works correctly .
test that adding a bulk of entities in a manual way works correctly .
test that _ _ setitem _ _ works correctly .
"perform e - step for each ( chunk_no , chunk , model ) 3 - tuple from the input queue , placing the resulting state into the result queue ."
"if given , start training from the iterable ` corpus ` straight away . if not given , the model is left untrained ( presumably because you want to call ` update ( ) ` manually ) ."
"train the model with new documents , by em - iterating over ` corpus ` until the topics converge ( or until the maximum number of allowed iterations is reached ) . ` corpus ` must be an iterable ( repeatable stream of documents ) ,"
test storing / loading the entire model .
"parameters ---------- min_count : int , optional terms with a count lower than this will be ignored threshold : float , optional only phrases scoring above this will be accepted , see ` scoring ` below . max_vocab_size : int , optional maximum size of the vocabulary . used to control pruning of less common words , to keep memory under control . the default of 40 m needs about 3.6 gb of ram . delimiter : str , optional character used to join collocation tokens , should be a byte string ( e.g. b ' _ ' ) . progress_per : int , optional training will report to the logger every that many phrases are learned . scoring : str or function , optional specifies how potential phrases are scored for comparison to the ` threshold ` setting . ` scoring ` can be set with either a string that refers to a built - in scoring function , or with a function with the expected parameter names . two built - in scoring functions are available by setting ` scoring ` to a string :"
fit the model according to the given training data .
transform the input documents into phrase tokens .
train model over a potentially incomplete set of sentences .
scrolls to the element and places cursor above it . useful when you want to click an element that is scrolled off the visible area of the screen .
basic test to verify stepping through the editor steps and saving works .
""" verify user can provide a custom background image url ."
verify that background image and zones get generated successfully .
test that autozone parameters are verified to be valid .
create the colorspace encoding and decoding dictionaries .
"given a sequence of nucleotides , convert them to colorspace . only uppercase characters are allowed . > > > encode(""acggtc "" ) "" a13012 """
"decode a sequence of colors to nucleotide space . the first character in s must be a nucleotide . only uppercase characters are allowed . > > > decode(""a13012 "" ) "" acggtc """
> > > _ nonnegativenumberformatter(-10 ) 0
"> > > _ integerlistformatter([.9 , 40.3 , 16.0001 ] ) [ 1 , 40 , 16 ]"
> > > _ opentypeos2widthclassformatter(-2 ) 1 > > > _ opentypeos2widthclassformatter(0 ) 1 > > > _ opentypeos2widthclassformatter(5.4 ) 5 > > > _ opentypeos2widthclassformatter(9.6 ) 9 > > > _ opentypeos2widthclassformatter(12 ) 9
> > > _ opentypeos2weightclassformatter(-20 ) 0 > > > _ opentypeos2weightclassformatter(0 ) 0 > > > _ opentypeos2weightclassformatter(50.4 ) 50 > > > _ opentypeos2weightclassformatter(90.6 ) 91 > > > _ opentypeos2weightclassformatter(120 ) 120
"> > > from fontmath.test.test_mathinfo import _ testinfoobject , _ testdata > > > from fontmath.mathfunctions import _ roundnumber > > > info1 = mathinfo(_testinfoobject ( ) ) > > > info2 = info1 * 2.5 > > > info3 = _ testinfoobject ( ) > > > info2.extractinfo(info3 ) > > > written = { } > > > expected = { } > > > for attr , value in _ testdata.items ( ): ... if value is none : ... continue ... written[attr ] = getattr(info2 , attr ) ... if isinstance(value , list ): ... expectedvalue = [ _ roundnumber(v * 2.5 ) for v in value ] ... elif isinstance(value , int ): ... expectedvalue = _ roundnumber(value * 2.5 ) ... else : ... expectedvalue = value * 2.5 ... expected[attr ] = expectedvalue > > > sorted(expected ) = = sorted(written ) true"
create signature for message taken from https://github.com/madeddie/python-bunq - thanks !
verify response from server taken from https://github.com/madeddie/python-bunq - thanks !
you can also run these commands manually to generate the pb file 1 . git clone https://github.com/tensorflow/models.git 2 . export pythonpath = path_to_your_model_folder 3 . python alexnet.py
run this command to generate the pb file 1 . mkdir model 2 . python rnn_lstm.py
"given a url , return a parsed : class:` . url ` namedtuple . best - effort is performed to parse incomplete urls . fields not provided will be none ."
deprecated . use : func:`parse_url ` instead .
convert self into a url
"plot vertical lines every ten bases , so we can orient ourselves"
get the coverage by base at each site in a set of reads
"work out if this should be get , post , put or delete"
cleans up a uri / url
cleans up a query
parse arguments for input params
"count of stddev outliers : what 's beyond ( mean - stddev , mean - stddev )"
tukey - style lowest datum within 1.5 iqr under q1 .
tukey - style highest datum within 1.5 iqr over q3 .
"count of tukey outliers : what 's beyond ( q1 - 1.5iqr , q3 + 1.5iqr )"
"given a local transition graph of a function , find all merge points inside , and then perform a quasi - topological sort of those merge points ."
"given a local transition graph of a function , find all widening points inside ."
sort a given set of nodes in reverse post ordering .
sort a given set of nodes from a graph based on the following rules :
append all nodes from a strongly connected component to a list of ordered nodes and ensure the topological order .
": param trip_counts : dictionary that stores trip counts for each loop . keys are address of loop headers . : param current_loop : list of currently running loops . each element is a tuple ( loop object , list of loop exits ) ."
": param trace : the basic block trace . : param crash_addr : if the input caused a crash , what address did it crash at ?"
grabs the concretized result so we can add the constraint ourselves .
"obnoxious way to handle this , should only be called from tracer ."
build a data flow grah ( dfg ) for every basic block of a cfg
"we want to build the type of dfg that 's used in "" automated ident . of crypto primitives in binary code with data flow graph isomorphisms . "" unlike that paper , however , we 're building it on vex ir instead of assembly instructions ."
process the expression in whatever ways are specified by the state options .
"translate a single irexpr , honoring mode and options and so forth . also updates state ..."
translates a sequence of irexprs into simirexprs .
returns a set of registers that this irexpr depends on .
returns a set of tmps that this irexpr depends on
initialize ptable for ctype
initialize ptable for ctype
initialize ptable for ctype
extract arguments and set them to
perform any initialization on this manager you might need to do .
"step this stash of this manager forward . should call ` ` simgr.step(stash , * * kwargs ) ` ` in order to do the actual processing ."
perform filtering on a state .
"return true , the state should be selected for stepping during the step ( ) process ."
perform the process of stepping a state forward .
return successors of the given state .
"return whether or not this manager has reached a "" completed "" state , i.e. ` ` simulationmanager.run ( ) ` ` should halt ."
"translates an integer , set , list or lambda into a lambda that checks a state address against the given addresses , and the other ones from the same basic block"
print string representation of the current version of django . should tally with tox 's opinion .
generate a unique username . keeps a set of previously generated usern
call ` full_clean ` on any created instance before saving
"create a username from faker 's profile generator , but ensure that it 's not in the database before using it . this is a pre - full_clean check ."
"assert that created user is "" clean "" in django 's opinion if build strategy is happening ."
gets the current date . wrapper function to make it easier to stub out in tests .
"gets the date from one year ago , which is the start of the contributions graph ."
"returns a long date string . example output : "" may 24 , 2015 "" ."
returns the previous day as a datetime.date object .
returns the next day as a datetime.date object .
"given a date in the past , return a human - readable string explaining how long ago it was ."
"returns a list of abbreviations for the days of the week , starting with sunday ."
return a list of valid partitions
: type g : list[int ] : type s : list[int ] : rtype : int
: type root : treenode : rtype : int
: type s : str : rtype : int
: type root : treenode : rtype : list[int ]
: type root : treenode : rtype : list[int ]
: type n : int : rtype : bool
: type root : treenode : type v : int : type d : int : rtype : treenode
: type s : str : rtype : bool
: type head : listnode : rtype : bool
check input url
parse page with beautifulsoup
grab each volume in the booklist
start the job using url
parse page with beautifulsoup
extract chapter links from page
extract volume 's basic info
get the formal chapter name
extract contents from each page
"add chapter chapter structure：a tuple ( chapter number , chapter name , content )"
add each chapter 's content to the epub instance
start extract every chapter in epub
get novel information
returns ext resources .
initialize enabled agent extensions .
this function sets the policy test rules to be exposed .
"parses ip link help output , and gets vf block"
validate vf capability support
gets the output of the ip link help command
return list of sg_log info for a port
return list of sg_log info for list of log_resources
returns none if it does n't exist .
load info from server for first query .
turns filters for a given rypte into a set of query ids .
find resources that match key : values in filters dict .
returns a list of all resources satisfying func matcher .
determines if a given resource update is safe to ignore .
takes in an ovo and generates an event on relevant changes .
returns changed fields excluding update time and revision .
get dvr serviced ports on given host and subnet .
get network info for dvr router ports .
get dvr serviced ports for given host and subnet .
get network info for dvr port .
notify dvr mac address updates .
callback for dvr_mac_addresses update .
builds an address pair from the first and last addresses .
"create the necessary pool and item allocator using ' , ' as the delimiter and linklocalallocator as the class type"
add agent extension for router .
handle agent extension for update .
delete router from agent extension .
change router state from agent extension .
prepare filters for the port .
apply port filter .
refresh security group rules from data store
stop filtering port .
defer application of filtering rule .
turn off deferral of rules and apply the rules now .
returns filtered ports .
defer apply context .
update group members in a security group .
update rules in a security group .
called when a security group is updated .
process ports that are trusted and should n't be filtered .
returns a new sa . table ( ) object for this test case .
push resource list into all registered callbacks for the event type .
returns extension resources .
apply optimisingtestsuite on a per - module basis .
this attribute is used by testresources for optimized sorting of tests .
add or update the provider configuration for the service type .
return the default provider for a given service type .
validate that the trunk can be managed .
prohibit the deletion of a port that 's used in a trunk .
validate that the port can be used in a trunk .
"return true if the port is bound , false otherwise ."
""" return true if a port can be trunked ."
raises portinuse for ports assigned for device purposes .
validate that subports can be used in a trunk .
utility method to parse subports in the request
"return mtu for the network where the given port belongs to . if the network or port can not be obtained , or if mtu is not defined , returns none ."
"update matching objects , if any . return number of updated objects ."
"delete matching objects , if any . return number of deleted objects ."
check the values passed in kwargs match the values of the trunk
returns ext resources .
test that get_service_providers filters correctly .
returns ids of all tenants depending on this db object .
"callback to handle rbac_policy , before_delete callback ."
"callback to handle rbac_policy , before_update callback ."
callback to validate rbac_policy changes .
returns extended resource for service type management .
prepares fdb_entries from json .
add flow for fdb
delete flow for fdb
setup an added tunnel port .
clean up a deleted tunnel port .
operate the arp respond information .
generator to yield port info .
call methods named ' _ fdb_<action > ' .
fdb update when an ip of a port is updated .
decorator to indicate flake8 extension .
n322 - try to detect unintended calls of nonexistent mock methods like : assert_called_once assertcalledoncewith assert_has_called called_once_with
"n328 - do n't use assertequal(true / false , observed ) ."
n330 - enforce using assertequal parameter ordering in case of empty objects .
n331 - enforce using assertisinstance .
n332 - enforce correct oredering for httpcode in assertequal .
n340 - check for neutron.i18n usage .
n341 - check usage of builtins gettext _ ( ) .
n334 - use unittest2 instead of unittest
n343 production code must not import from neutron.tests . *
n344 - use list comprehension instead of filter(lambda ) .
n346 - use neutron.db.api.sqla_listen instead of sqlalchemy event .
builds a namespace name from the given prefix and identifier
parses prefix from prefix - identifier
parses identifier from prefix - identifier
return create exceptions .
launch a process and monitor it asynchronously .
halt the process and watcher threads .
spawn a process and its watchers .
kill the process and the associated watcher greenthreads .
kill the async process and respawn if necessary .
"given a port_id , look up the router associated with that port in local namespace . returns a routerinfo object ( or none if the router is not found ) ."
"given a project_id , return a list of routers that are all in the given project . returns empty list if the project_id provided does n't evaluate to true ."
"given a router_id , make sure that the router is in a local namespace ."
return routerinfo for the given router i d.
test for debug mode
test with hipchat api mock
return a list of available trezor devices .
check if the device is still connected .
"apply a lock to the device in order to preform synchronous multistep "" conversations "" with the device . for example , before entering the transaction signing workflow , one begins a session . after the transaction is complete , the session may be ended ."
end a session . se session_begin for an in depth description of trezor sessions .
close the connection to the physical device or file descriptor represented by the transport .
write mesage to tansport . msg should be a member of a valid ` protobuf class < https://developers.google.com/protocol-buffers/docs/pythontutorial > ` _ with a serializetostring ( ) method .
"if there is data available to be read from the transport , reads the data and tries to parse it as a protobuf message . if the parsing succeeds , return a protobuf object . otherwise , returns none ."
"same as read , except blocks until data is available to be read ."
"returns true if there is data to be read from the transport . otherwise , false ."
generate string list for finding and writing
use autover to get up to date version .
generate ack logic for selected input
"resolve isselected signal flags for each input , when isselected flag signal is 1 it means input has clearance to make transaction"
: param hsintfcls : class of interface which should be used as interface of this unit
pack data of structure into words on axis interface
opposite of packaxisframe
": param structt : instance of hstruct which specifies data format to download : param tmpl : instance of transtmpl for this structt : param frames : list of frametmpl instances for this tmpl : note : if tmpl and frames are none they are resolved from structt parsetemplate : note : this unit can parse sequence of frames , if they are specified by "" frames "" : attention : interfaces for each field in struct will be dynamically created : attention : structt can not contain fields with variable size like hstream"
"generate reference requests and data data words are containing it 's indexes , baseaddresses are multiplies baseaddress : param spacevalues : is iterable of space values"
compute the message to a parent node .
maps the mask to the plates of a parent .
resolves the plate mapping to a parent .
resolve the plate mapping from a parent .
draw a random sample from the distribution .
returns the stochastic id list .
"fix moments , compute f and propagate mask ."
save the state of the node into a hdf5 file .
load the state of the node from a hdf5 file .
draw a random sample from the distribution .
print the distribution using standard parameterization .
compute the moments for a fixed value
return the shape of the moments for a fixed value .
returns the stochastic id list .
construct the linear state - space model with time - varying dynamics
run vb inference for linear state - space model with time - varying dynamics .
generate a signal with changing frequency
test the moments of tile node .
test the parent message of tile node .
test the mask message to parent of tile node .
to do : use something more suitable for static content to serve this
"clips a list of bounding boxes ( m,4 ) to be within an image region"
randomly crops ` image ` together with ` labels ` .
key function for sorting filenames
start the timer . ` name ` is the description of the current code snippet .
calculate the time costs of the current code snippet .
return the sum of overall time costs for each code snippet .
return the sum of average time costs for each code snippet .
return the overall time costs for each code snippet as string .
return the average time costs for each code snippet as string .
reset the time costs and counters .
tests the pmod devmode .
build the command word .
return a new instance of a devmode object .
start the microblaze processor .
put the microblaze processor into reset .
load the microblaze processor 's switch configuration .
returns the status of the microblaze processor .
send a write command to the mailbox .
send a read command to the mailbox .
check whether the command mailbox is idle .
"return a new instance of an grove_earhr object . parameters ---------- mb_info : dict a dictionary storing microblaze information , such as the ip name and the reset name . gr_pin : list a group of pins on pmod - grove adapter ."
read the heart rate from the sensor .
read the number of heart beats .
converts 32 - bit register value to floats in python .
return a new instance of an grove adc object .
read the adc raw value from the grove adc peripheral .
read the adc voltage from the grove adc peripheral .
set the length of the log for the grove adc peripheral .
start recording raw data in a log .
start recording multiple voltage values ( float ) in a log .
stop recording the raw values in the log .
stop recording the voltage values in the log .
return list of logged raw samples . returns ------- list list of valid raw samples from the adc sensor .
return list of logged samples . returns ------- list list of valid voltage samples ( floats ) from the adc sensor .
resets / initializes the adc . returns ------- none
create a new button object .
read the current value of the button .
wait for the button to be pressed or released
wait for the button to be pressed or released
create a new microblaze object .
this method write data into the mailbox of the microblaze .
this method reads mailbox data from the microblaze .
this method writes a blocking command to the microblaze .
this method writes a non - blocking command to the microblaze .
test whether the gpio class is working properly .
get menu of specific user * userid can be wechat account or openid
"additionaldict will be formatted to give full compacity to input thumb_media_id , thumbmediaid , thumbmediaid are all supported"
test that train and test do n't share sent ids .
return the given page as a png wand.image . image .
return the given page as a cropped png wand.image . image .
test to confirm that all the expected keys are returned from the api when data is requested .
gets all uploaded documents in this folder .
add flight time to a date record
work out flight time for a log file
set camera resolution
"scan a image directory , extracting frame_time and filename as a list of tuples"
process a set of files
"generator that yields lines from this book , chapter , url combination"
test that names of commands seem valid
test that frame ids seem valid
test that parameter descriptions seem valid
test that handler methods only have responses
"run a command , returning result callbacks as a list"
handle a received ezsp frame
"generated the string for the given child , which might be a list of lists ( ... of lists ... ) of nodes . for a single node , do n't append a semicolon , otherwise append semicolons and newlines to each statement if they require it ."
convert this template to a string .
convert this stringtemplate to a string .
convert this filetemplate to a string .
this method acts as a simulation of a specializer 's transform ( ) method . it 's the bare minimum required of a transform ( ) method by the specializer writer .
this method acts as a simulation of jit.py 's _ _ call _ _ ( ) method . the specializer writer does not have to write this method .
"this method tests the squaring lambda function , a one argument lambda function ."
"this method tests the adding lambda function , a two argument lambda function ."
return object name with leading module
"a string to provide useful information for visualization , debugging , etc ."
"removes a universe from the local machine . : param args : the command line arguments as parsed by argparse . this is expected to contain the following information : - universe : the name of the universe which should be removed . - verbose : true , for more verbose output ."
"removes a universe from the local machine . : param universe_name : the name of the universe which should be removed . : param verbose : true , for more verbose output ."
"runs a command on the local machine . the stdout / stderr is hidden , unless an error occurs . in that case , an error message containing the stderr is shown and a processfailedexception is raised . if the verbose flag is set to true , stdout and stderr are directly piped to this applications stdout . : param command : the command to run as list ( e.g. [ ' ls ' , ' -l ' , ' /etc ' ] ) : param phase_key : a message key which describes the current phase . this is used if something fails . : param verbose : true , if a more verbose output is desired . : param env : a dictionary of environment variables for the given command . : return : the process output of the command ."
"runs a command piped , so that it 's output is piped into another command . behaves like run_command otherwise . : param source_command : the command on the source side of the pipe as a list . : param sink_command : the command on the sink side of the pipe as a list . : param phase_key : a message key which describes the current phase . this is used if something fails . : param verbose : true , if a more verbose output is desired . : param env : a dictionary of environment variables for the given command . : return : the process output of the command ."
"runs a command on the local machine . the stdout / stderr is hidden , unless an error occurs . in that case , an error message containing the stderr is shown and a processfailedexception is raised . : param command : the command to run as list ( e.g. [ ' ls ' , ' -l ' , ' /etc ' ] ) : param phase_key : a message key which describes the current phase . this is used if something fails . : param env : a dictionary of environment variables for the given command . : return : the output of the command as a string ."
: param command : the failed command . : param result : the command result .
"gathers the variables defined in the given description . : param seed_dictionary : the seed universe file contents ( as a dictionary ) . : return : the retrieved user vars , the retrieved user secrets as dictionaries or none , none if no variables are defined in the description ."
creates the slingring vars dictionary from the given values . : param user_name : the user name : param user_group : the user 's primary group : param user_home : the user 's home directory within the chroot : param mirror : the debootstrap mirror : param universe_name : the universe name : param universe_version : the universe version : return : the slingring vars dictionary .
prints the text with a new line before and after it . : param text : the text .
reads a seed yaml configuration file and returns its content as dictionary . performs checks for mandatory attributes and throws an missingattributeserror if attributes are missing . : param path : the path to the configuration file : return : the file content as object
"reads the configuration file from the given path . raises a filenotfounderror , if the path does not exist . : param path : the location of the configuration file . : return : the contents of the configuration as a dictionary ."
reads a yaml configuration file and returns its content as dictionary . : param path : the path to the configuration file : return : the file content as object
reads a yaml configuration file and returns its content as dictionary . : param path : the path to the configuration file : return : the file content as object
gets the value from the configuration source with the highest priority . : param key : the key of the desired value . : return : the desired value .
sets a configuration value in the process configuration . : param key : the configuration key . : param value : the configuration value .
create a new group
get details to one of your groups
list your groups
update one of your groups
join a group
leave one of your groups
list all accepted timezones
get wall conversation id of this group
mark that the logged - in user is active in the group
add ( post ) or remove ( delete ) a membership role
add ( post ) or remove ( delete ) a notification type
: rtype : list
: rtype : dict
retrieve the validity time limit setting in seconds based on the verification code type .
true if the expiration date lies in the past or if the code has been invalidated .
accept the invitation
"creates and saves a user with the given username , email and password ."
"as we do n't allow sign - ups with similarly cased email addresses , we can allow users to login with case spelling mistakes"
the first argument is assumed to be the ` ` key ` ` for routing .
the first argument is assumed to be the ` ` key ` ` for routing .
"lots of points , do not overrun blob size limit"
this function returns the tax rate of a given zipcode ( no +4 extension ) in wa
разделение слова на слоги .
: param word : слово . : param language : язык . : return : ударения слова .
: param word : слово . : return : его слоги .
: param word : слово . : return : количество слогов в нём .
: param text : текст . : param language : язык . : return : его разметка по словарю .
": param text : текст . : param language : язык . : return : его разметка по словарю , классификатору метру и ml классификатору ."
: param text : текст . : param language : язык . : return : его метр .
генерация разметок по текстам .
: param word1 : первое слово . : param word2 : второе слово . : return : рифмуются ли слова .
сгенерировать стих по данным из разметок .
сгенерировать стих .
поиск рифмы для данного слова .
"построить wordformvocabulary , grammemevectorizer по корпусу"
определение ударения в слове по словарю . возможно несколько вариантов ударения .
obtain a a vo table from the heasarc archives and return it as a pandas table indexed by object / trigger names . the heasarc_table_name values are the ones referenced at :
"compute the likelihood ratio test by generating monte carlo datasets and fitting the current models on them . the fraction of synthetic datasets which have a value for the ts larger or equal to the observed one gives the null - hypothesis probability ( i.e. , the probability that the observed ts is obtained by chance from the null hypothesis )"
: param show_chi2 : : param scale : : param hist_kwargs : : return :
saves data sets for each plugin to phas for ogip data .
"returns a results set for each model . if there is more than one model , it will return a list of analysisresultsset instances , otherwise it will return one analysisresultsset instance"
"write the results to one file per model . if you need more control , get the results using the .results property then write each results set by itself ."
compute goodness of fit by generating monte carlo datasets and fitting the current model on them . the fraction of synthetic datasets which have a value for the likelihood larger or equal to the observed one is a measure of the goodness of fit
a wrapper to call the _ transform method for outputs of variates container class : param method : : return :
a generic 3ml fitted source post - processor . this should be sub - classed in general
the basics of adding are handled in the variatescontainer : param other : another fitted source handler : return : a variatescontainer with the summed values
dummy transform to be overridden in a subclass : param value : : return : transformed value
builds a propagated function using randomvariates propagation
calculate the best or mean fit of the new function or quantity
: return : the variatescontainer
: return : the raw samples of the variates
: return : the median of the variates
: return : the average of the variates
: return : the upper error of the variates
: return : the lower error of the variates
"a container to store an * list * of randomvariates and transform their outputs to the appropriate shape . this can not be done with normal numpy array operations because an array of randomvariates becomes a normal ndarray . therefore , we calculate the averages , errors , etc , and transform those ."
: return : the list of of randomvariates
: return : the transformed raw samples
: return : the transformed average
: return : the transformed median
: return : the transformed upper error
: return : the transformed lower error
: param other : : return :
a class that makes data / residual plots
: return : the figure instance
: return : the top or data axis
: return : the bottom or residual axis
add a model but use discontinuous steps for the plotting .
add a model and interpolate it across the energy span for the plotting .
add the data for the this model
: param xlabel : : param ylabel : : param xscale : : param yscale : : param show_legend : : return :
return the django endless pagination version as a string .
"given a prefix , generates 256 blocks of the form : aa .. aa|prefix| ? , and checks for a match against the observed cipher"
"authentification basic , upload pyshop repository access"
"decodeperson handle : 0x25 values[0 ] = 0x84 returns a dict for convenience : valid ( true , false ) person ( 1 .. 9 ) gender ( male|female ) age ( 0 .. 255 years ) size ( 0 .. 255 cm ) activity ( normal|high )"
"decodeweight handle : 0x1b byte[0 ] = 0x1d returns : valid ( true , false ) weight ( 5,0 .. 180,0 kg ) timestamp ( unix timestamp date and time of measurement ) person ( 1 .. 9 ) note : in python 2.7 to force results to be floats , devide by float ."
"decodebody handle : 0x1e byte[0 ] = 0x6f returns : valid ( true , false ) timestamp ( unix timestamp date and time of measurement ) person ( 1 .. 9 ) kcal = ( 0 .. 65025 kcal ) fat = ( 0 .. 100,0 % ) percentage of body fat tbw = ( 0 .. 100,0 % ) percentage of water muscle = ( 0 .. 100,0 % ) percentage of muscle bone = ( 0 .. 100,0 ) bone weight note : in python 2.7 to force results to be floats : devide by float ."
indication handler : receives indication and stores values into result dict ( see decode functions for dict definition ) handle : byte value : bytearray
same as parent except that we do not call self.sendkexinit ( ) because we do not want to send anything on the wire other than the banner after a connect ( ie . behave like a genuine openssh server ) .
"same as parent except that we need to call self.sendkexinit ( ) after checking the client version because i have seen ssh - bots based on early libssh versions ( 0.1 or 0.2 ) that expect us to initiate the key exchange init , otherwise they timeout and close the tcp connection ."
normalizes the arguments which uniquely specify an ensemblrelease genome .
"construct ensemblrelease if it 's never been made before , otherwise return an old instance ."
deserialize ensemblrelease without creating duplicate instances .
"if species name was "" homo sapiens "" then replace spaces with underscores and return "" homo_sapiens "" . also replace common names like "" human "" with "" homo_sapiens "" ."
search the dictionary of species - specific references to find a reference name that matches aside from capitalization .
helper for validating user supplied species names or objects .
create a species object from the given arguments and enter into all the dicts used to look the species up by its fields .
parameters ---------- latin_name : str
"test_exon_ids_of_gene_id : ensure that gene_id ensg00000141510 ( name = tp53 ) , has all the same exon ids found on the ensembl website ."
test_exon_ids_of_gene_name : ensure that tp53 has the same exon ids found on the ensembl website .
test_exon_ids_of_transcript_name : look up exon ids of transcript tp53 - 026 by name and ensure that the exon ids match what we find on ensembl 's website for release 77
exon_ids_of_transcript_id : look up exon ids of transcript enst00000610623 ( name : tp53 - 026 ) by its id and make sure they match what we find on the ensembl website .
return the canonical host as for the host http header specification .
set host and port from a canonical host string as for the host http header specification .
get a url representation of the service .
"this is a general method for getting a client : if present , it is pulled from the cache ; if not , a new one is instantiated and then put into the cache . this method should not be called directly , but rather by other client - specific methods ( e.g. , get_ec2_client ) ."
format time_tuple as a iso8601 time string .
"split the given url into the scheme , host , port , and path ."
the l{verifyingcontextfactory } properly allows to connect to the endpoint if the certificates match .
the l{verifyingcontextfactory } fails with a ssl error the certificates ca n't be checked .
"l{basequery } does n't use l{verifyingcontextfactory } if c{ssl_hostname_verification } is c{false } , thus allowing to connect to non - secure endpoints ."
l{verifyingcontextfactory } supports checking c{subjectaltname } in the certificate if it 's available .
"do not include the current directory if the txaws_certs_path environment variable ends with a "" : "" ."
usb device class matcher for pebble 's test automation dongles
should work as a class or instance method
"upon review saving , it will call this method , which allows us to update through the eventsource . i know , i know -- signals are awesome , but this is a little less magical and i do n't want events to have to ' know ' about the reviewer app ."
create an action for a thng .
read actions for a thng .
creates a seriallink object . : param links : a list of links that will constitute seriallink object . : param name : name property of the object . : param base : base transform applied to the seriallink object . : param stl_files : stl file names to associate with links . only works for pre - implemented models in model module . : param q : initial angles for link joints . : param colors : colors of stl files .
length property : return : int
"calculates forward kinematics for a list of joint angles . : param stance : stance is list of joint angles . : param unit : unit of input angles . : param apply_stance : if true , then applied tp actor_list . : param actor_list : passed to apply transformations computed by fkine . : param timer : internal use only ( for animation ) . : return : homogeneous transformation matrix ."
calculates inverse kinematics for homogeneous transformation matrix using numerical optimisation method . : param t : homogeneous transformation matrix . : param q0 : initial list of joint angles for optimisation . : param unit : preferred unit for returned joint angles . allowed values : ' rad ' or ' deg ' . : return : a list of 6 joint angles .
plots the seriallink object in a desired stance . : param stance : list of joint angles for seriallink object . : param unit : unit of input angles . : return : null .
"internal function to initialise vtk objects . : return : reader_list , actor_list , mapper_list"
"animates seriallink object over nx6 dimensional input matrix , with each row representing list of 6 joint angles . : param stances : nx6 dimensional input matrix . : param unit : unit of input angles . allowed values : ' rad ' or ' deg ' : param frame_rate : frame_rate for animation . could be any integer more than 1 . higher value runs through stances faster . : return : null"
initialises the link object . : param j : : param theta : : param d : : param a : : param alpha : : param offset : : param kind : ' r ' or ' p ' as input . ' r ' for revolute . ' p ' for prismatic . : param mdh : : param flip : : param qlim :
initialised revolute object . : param j : : param theta : : param d : : param a : : param alpha : : param offset : : param qlim :
initialises prismatic object . : param j : : param theta : : param d : : param a : : param alpha : : param offset : : param qlim :
property to return number of matrices in pose object : return : int
always returns a list containing the matrices of the pose object . : return : a list of matrices .
property to return the matrices of pose object . : return : returns np.matrix type if only one matrix is present . else returns a list of np.matrix .
checks if object is of type se2 or se3 or none of them . : return : bool
returns dimensions of first matrix in pose object . assumed that all matrices have same dimension . : return : tuple
"generates a url - safe token for the given user , action , time tuple ."
validates that the given token authorizes the user for the action .
gets all your transactions
gets one customer with the given transaction i d
gets transaction totals
initialize a transaction and returns the response
charges a customer and returns the response
verifies a transaction using the provided reference number
creates a new plan . returns the plan details created
updates an existing plan given a plan i d. returns the plan details updated .
gets all plans
gets one plan with the given plan i d requires : plan_id
tests ----- 1 . pseudoinput 2 . error : unequal number of peaks and troughs
tests the code to get the length of a query .
tests the iterator over individual results in the search response . includes testing the slicing behavior .
tests a query for silicon prototypes from icsd .
tests a live query with ordering .
returns the absolute path to the repo root directory on the current system .
loads the module specification and returns it as a python object .
tests the absolute path to the reporoot .
makes sure that an arbitrary code module can be loaded .
tests the test resetting .
tests operators and combinations of operators and the query strings that they produce relative to the aflux standard .
"tests inversion ( i.e. , negation ) of an operator ."
tests combinations of multiple conditions against the same keyword .
tests corner cases that are n't part of the previous tests .
walks over all the names imported in a dotted_as_names node .
"configure the runner args - the arguments to pass to the runner listeners - a list of listeners ( actually , mvc views ) runner - the command to start a test run"
start the test process
poll the running process for data on stdout and stderr
forward messages to each registered listener
"return int if text is all digits , otherwise return a string"
get the object of the currently selected item
add an editor_page to the list
remove an editor_page from the list
select an item in the list
called when the user selects an item from the tree
return the index for the item associated with the given editor_page
danger will robinson ! at the moment this is n't a proper refresh ; it does n't delete any existing data
run all rules against the given suite and its children
create / update profile
relative error between ` expected ` and ` actual ` : ` ` abs((a - e)/e ) ` ` .
initialize the cgpm .
record an observation for ` rowid ` into the dataset .
remove all incorporated observations of ` rowid ` from the dataset .
return the density of ` targets ` given ` constraints ` and ` inputs ` .
return n iid samples of ` targets ` given ` constraints ` and ` inputs ` .
return joint density of all observations and current latent state .
apply an inference operator transitioning the internal state of cgpm .
return the binary ( json - friendly ) representation of the cgpm .
load cgpm from its binary representation .
"generate 3 samples from 2 states 10 times , and ensure uniqueness ."
compute probability of customers in same table .
"compute the joint probability of crp assignment and data for the query rows , marginalizing over the assignment of the target row ."
compute the joint probability of crp assignment and data .
"retrieve observations for rowid , only considering variables in view ."
"return tables to iterate over when query , target in same table ."
"return tables to iterate over when query , target in different table ."
retrieve logpdf score restricted to the crp and specified clusters .
return marginal likelihood of cluster k in view ( 0 for fresh cluster ) .
"create submission --- tags : - submission parameters : - name : contest_id in : formdata type : string required : true description : if of contest - name : problem_id in : formdata type : string required : true description : if of problem - name : team_id in : formdata type : string required : false description : if of team - name : prog_lang in : formdata type : integer required : true description : programming language type ( 0 = cpp , 1 = cpp11 , 2 = python27 , 3 = python35 , 4 = java8 ) - name : code in : formdata type : file required : true description : code file ( max size is 16 m ) - name : access - token in : header type : string required : true description : token of current user responses : 201 : description : successfully submitted 400 : description : bad request 401 : description : token is invalid or has expired 403 : description : ( you are n't owner or member of the team ) ( you are n't owner or admin of the contest ) 404 : description : contest or problem or team does not exist 406 : description : ( contest has not started or has been finished ) ( you have too many pending submissions ) 413 : description : request entity too large . ( max size is 16 m ) 415 : description : supported file type is only text / plain"
"get all the team submissions in a contest --- tags : - submission parameters : - name : cid in : path type : string required : true description : i d of contest - name : tid in : path type : string required : false description : i d of team - name : access - token in : header type : string required : true description : token of current user responses : 200 : description : submissions list schema : i d : submissionlist type : object properties : i d : type : string description : submission i d filename : type : string description : the code file name prog_lang : type : string description : programming language submitted_at : type : integer description : submission submitted_at ( utc timestamp ) problem : schema : $ ref : "" # /definitions / api_1_contest_problem_list_get_problemabsinfo "" user : description : the member who submitted the code schema : $ ref : "" # /definitions / api_1_team_info_get_userabsinfo "" status : type : string description : submission status reason : type : string description : error reason ( is null when status is pending or accepted ) 400 : description : bad request 401 : description : token is invalid or has expired 403 : description : ( you are n't owner or member of the team ) ( you are n't owner or admin of the contest ) 404 : description : team or contest does not exist"
"get all the team submissions in a contest for a problem --- tags : - submission parameters : - name : cid in : path type : string required : true description : i d of contest - name : pid in : path type : string required : true description : i d of problem - name : tid in : path type : string required : false description : i d of team - name : access - token in : header type : string required : true description : token of current user responses : 200 : description : submissions list schema : $ ref : "" # /definitions / api_1_submission_list_get_submissionlist "" 400 : description : bad request 401 : description : token is invalid or has expired 403 : description : ( you are n't owner or member of the team ) ( you are n't owner or admin of the contest ) 404 : description : team or contest or problem does not exist"
download code file --- tags : - submission parameters : - name : sid in : path type : string required : true description : i d of submission - name : access - token in : header type : string required : true description : token of current user responses : 200 : description : code file 401 : description : token is invalid or has expired 403 : description : ( you are n't owner or member of the team ) ( you are n't owner or admin of the contest ) 404 : description : submission does not exist
loads all export plugins stored in boms_away / export_plugins which adhere to the following rules :
reads a com file and returns a map of label addresses and instructions
"takes an assembly instruction ( like "" mov ax , 1 "" ) and map of labels ( addr - > label ) . returns the corresponding battlestar code and a newly generated map of labels ( addr - > label ) . also takes and returns a labelcounter ."
pad a string with spaces on both sides until long enough
expands a statement line . executed when pressing < enter > .
check if its a simple statement . ( internal )
expands a statement with both shorthand property and value . ( internal )
expands a statement 's unit value . ( internal )
"splits a snippet into ` property ` , ` number ` and ` unit ` . property and unit are optional ."
expands a property . used to expand on ` : ` or ` ` .
expands a value of a given property ` prop ` . returns the expanded value .
finds the closest match to a ` value ` given a list of ` keywords ` .
"expands a single ` number ` + ` unit ` value . if the unit is absent ( blank string ) , the ` default_unit ` will be used instead ."
( private ) splits a line into its indentation and meat .
"checks if a line looks like a selector . this is used to prevent expansion on things that seem like rules , but are actually selectors ."
index ( ) should index the bray - curtis distances between terms .
"when a subset of terms is passed , just those terms should be indexed ."
"make people names as surname , firstnames or surname , initials . should eventually combine up the two ."
"split author field into a list of "" name , surname "" ."
turn the editor field into a dict composed of the original editor name and a editor i d ( without coma or blank ) .
separate pages by a double hyphen ( -- ) .
put the type into lower case .
turn the journal field into a dict composed of the original journal name and a journal i d ( without coma or blank ) .
split keyword field into a list .
: param record : the record . : type record : dict : returns : dict -- the modified record .
: param record : the record . : type record : dict : returns : dict -- the modified record .
convert accent from latex to unicode style .
homogeneize the latex enconding style for bibtex
checks to see if the request sent is of ajax type .
writes the metadata into the file passed as constructor parameter .
creates a new file name for a wpr archive file .
for modifying the metadata when we 're going to record a new archive .
finds all the desktop browsers available on this machine .
returns the out directory where the output binaries are built .
tests that with no selector seek action seeks first media element .
tests that seek action seeks video element matching selector .
tests that seek action seeks all video elements with selector='all ' .
tests that wait_for_seeked timeouts if video does not seek .
tests that seek action fails with no seek time .
"returns self[index ] if it exists , or ret if index is out of bounds ."
saves the browser object . called after the browser is started .
adds extra command - line options to the browser .
checks whether a page has the required ' endure ' property .
set - up before starting a new page .
takes a sample and adds a result if enough time has passed .
parses the --perf - stats - interval option that was passed in .
records information and add it to the results .
adds summary results ( single number for one test run ) .
test that gestureaction . runaction ( ) calls rungesture ( ) .
tests that with no selector play action plays first video element .
tests that play action plays video element matching selector .
tests that play action plays all video elements with selector='all ' .
tests that wait_for_playing timeouts if video does not play .
tests that wait_for_ended waits for video to end .
tests that wait_for_ended waits for video to end .
tests that action raises exception if timeout is reached .
"convert a |feautres| dictionary , and all ' children ' dictionaries , into lists recursively . sort lists first by ' level ' then by name ."
add level annotations to |features| . |features| and children lists must be sorted by ' level ' . annotations are added to the first item in a group of features of the same ' level ' .
"attempt to classify |node_name| in an api , determining whether |node_name| refers to a type , function , event , or property in |api| ."
"resolve $ ref |ref| in namespace |namespace| if not none , returning none if it can not be resolved ."
"resolve $ ref |ref| in namespace |namespace| , or globally if none . if it can not be resolved , pretend like it is a link to a type ."
this method will resolve all $ ref links in |text| using namespace |namespace| if not none . any links that can not be resolved will be replaced using the default link format that |safegetlink| uses . the links will be generated relative to |relative_to| .
generate a profile
waits for up to |timeout| secs for the function |condition| to return true .
returns an available port on the system .
yields all combination of chromium build output directories .
returns the path to the given binary name .
renders |template| using |request| .
gets the mapped c++ namespace name for the given namespace relative to the root namespace .
get opening self._default_namespace namespace declaration .
get closing self._default_namespace namespace declaration .
gets the enum value of the given model . property of the given type .
translates a model . property or model . type into its c++ type .
returns the forward declarations for self._default_namespace .
generates the code to display all value - containing properties .
clean temporary files built by a target .
make a target build even if it is up to date .
gets the full set of targets supported by this builder .
check if a target name is on the builder knows about .
returns a list of closest matching targets for a named target .
checks if the debugger is attaching or launching .
ask the debugger to restart .
kill the running debugger .
invoke the program within a debugger .
attach a debugger to a running program .
returns the canonical path for |path| .
creates a new linkertestrunner .
"if all pages fail , no summary is printed ."
"returns absolute path to an input file , given file name and another full file path in the same directory ."
memoize decorator . the refresh keyword is the keyword used to bypass the cache ( in the function call ) .
"parses arguments for convenience . argument can be a csv list ( ' a , b , c ' ) , a string , a list , a tuple ."
cleans a ticker for easier use throughout moneytree
maps clean_ticker over tickers .
formatting helper - percent
formatting helper - percent no % sign
formatting helper - float
"scale value from src range to dst range . if value outside bounds , it is clipped and set to the low or high bound of dst ."
map a format string over a pandas object .
returns a timestamp corresponding to the year / quarter in ` filename ` .
parse a faers demo file .
only run s3 sync once per day .
"callback function passed into transform_dict . takes a key / value tuple and either passes them through , does a transformation either or drops both ( by returning none ) ."
"takes several rows for the same report_number and merges them into a single report object , which is the final json representation , barring any anotation steps that may follow ."
group identical keys together .
"takes a list of ( name , value ) tuples , and ` pivots ` them , returning a dictionary from name - > [ values ] ."
called after all values have been reduced .
checks for a bug related to incorrect splitting of the pharm_class field .
test for correct tokenization of the exact field .
"sanity test generic drug counts . counts may change , but ordering should in general be consistent ."
verifies that we joined correctly for a specific report .
set new position of the window ( i.e. move the window ) .
set new size of the window .
default . override in derived
get printable string from activation function . : return : string
get output range of layer : return : output range as tuple
initialize class : param zmin : minimum depth : param zmax : maximum depth : param maxnumpoints : maximum number of points : return : none
"add point to point cloud , if more than maximum points are set , they are randomly subsampled : param point : 3d coordinates : return : none"
add points to the point cloud : param points : nx3 matrix with points : return : none
clear all points from the point cloud : return : none
transform point in 2d coordinates : param pt : point coordinates : param m : transformation matrix : return : transformed point
transform points in 2d coordinates : param pts : point coordinates : param m : transformation matrix : return : transformed points
"rotate a point in 2d around center : param p1 : point in 2d ( u , v , d ) : param center : 2d center of rotation : param angle : angle in deg : return : rotated point"
transform points in 2d coordinates : param pts : point coordinates : param center : 2d center of rotation : param angle : angle in deg : return : rotated points
get rotation matrix : param angle_x : angle around x - axis in deg : param angle_y : angle around y - axis in deg : param angle_z : angle around z - axis in deg : return : 4x4 rotation matrix
"rotate a point in 3d around center : param p1 : point in 3d ( x , y , z ) : param center : 3d center of rotation : param angle_x : angle around x - axis in deg : param angle_y : angle around y - axis in deg : param angle_z : angle around z - axis in deg : return : rotated point"
transform points in 3d coordinates : param pts : point coordinates : param center : 3d center of rotation : param angle_x : angle around x - axis in deg : param angle_y : angle around y - axis in deg : param angle_z : angle around z - axis in deg : return : rotated points
transform point in 3d coordinates : param pt : point coordinates : param m : transformation matrix : return : transformed point
"call a program with an optional timeout . if the program has a non - zero exit status , raises a calledprocesserror ."
"kill the process . if group = true , all sub - processes will also be killed ."
"wait for the process to terminate . returns returncode attribute . if timeout seconds are reached and the process has not terminated , it will be forcefully killed . if timeout is -1 , wait will not time out ."
"depending on what string is passed as ppa , return an appropriate yaml snippet , ready to inject in template ."
write an image building cloud - config file to a given location .
returns article that matches publish_id .
used in development environments to generate a user i d when logging in . this avoids having to connect to the ldap server ( which requires vpn externally ) in order to get an i d.
"this is the model for rest resources . actually it stores the data of resource in a dictionary . besides , a resource is linkable , which means it contains a list of links . : param raw_resource : the raw resource is a dictionary ."
initialize the links of a resource : return :
get the top level keys of a resource : return : top level keys
get the attribute value according to the key : param key : attribute key : return : attribute value
add the attribute key and value : param key : attribute key : param value : attribute value : return :
get all the links : return : links
get the link according to link relation and title : param link_rel : link relation : param title : link title : return : matched link
get count of the entries if the resource is a collection : return : count of entries
get an entry at position index : param index : entry index : return : entry
get the collection of entries : return : entries
check whether an attribute key exists : param key : the attribute key : return : true if existing
"get the raw resource , which is actually a dictionary : return : raw resource"
"get the representation of the raw resource , which is in json : param indent : indent of json representation : return : json representation"
"get the reference of a resource in json , like : { "" reference "" : "" http://localhost:8080 / dctm - rest / repositories / repo / objects/090000058000251a "" } : param indent : indent of json representation : return : reference in json"
generate instance of model . link from link in raw resource : param link_dict : the link in the raw resource : return : instance of model . link
check whether a link in raw resource is valid : param link_dict : link in raw resource : return : true if the link is valid
initialize the home resource : param resource : data in response of the entry url
get link from home resource according to link relation : param link_rel : link relation : return : matched link
get supported http methods for a link specified by the link relation : param rel : link relation : return : array of support http methods
get supported media types for a link specified by the link relation : param rel : link relation : return : array supported media types
calculates md5 hash from content of file with name='fname ' . also opens gzip files .
tests _ check_factor method .
tests _ check_start_end_times method .
check that get_ur outputs correct xml .
checks that the different time formats that we might have to parse are handled correctly . note that we convert into datetime objects with no timezone information for internal use .
iso2seconds should be able to parse most iso 8601 duration strings
returns the list of all contexts in the specified session .
retrieves the specified context .
creates a context .
updates the specified context .
deletes the specified context .
deletes all active contexts in the specified session .
returns the result of detect intent with texts as inputs .
com : - recipient_email = none quando : - enviamos notificações de confiração de email verificamos : - que ocorra uma exeção por causa do email inválido para recipient_email
com : - recipient_email = none quando : - enviamos notificações de resetar a senha verificamos : - que ocorra uma exeção por causa do email inválido para recipient_email
com : - recipient_email inválido quando : - enviamos notificações de confirmación de email verifcamos : - que ocorra uma exeção por causa do email inválido para recipient_email
com : - recipient_email inválido quando : - enviamos notificações de resetar a senha verifcamos : - que ocorra uma exeção por causa do email inválido para recipient_email
"quando : - current_app.config[""secret_key "" ] não tem valor verifcamos : - que ocorra uma exeção quando é criado um token com get_timed_serializer ao enviar a notificação de confirmação de email ."
"quando : - current_app.config[""secret_key "" ] não tem valor verifcamos : - que ocorra uma exeção qunado é criado um token com get_timed_serializer ao enviar a notificação de resetar a senha ."
"com : - um email válido para : recipient_email = ' foo@bar.baz ' quando : - enviamos a notificação de confirmação de email . verificamos : - que ` ` app.utils.send_email ` ` seja invocado como os parámetros : - recipient = ' foo@bar.baz ' - subject = "" confirmação de email "" - html = render_template('email / activate.html ' , confirm_url = confirm_url ) - que o valor de retorno da função : send_confirmation_email seja : ( true , '' )"
"com : - um email válido para : recipient_email = ' foo@bar.baz ' quando : - enviamos a notificação de resetar a senha . verificamos : - que ` ` app.utils.send_email ` ` seja invocado como os parámetros : - recipient = ' foo@bar.baz ' - subject = "" instruções para recuperar sua senha "" - html = render_template('email / recover.html ' , recover_url = recover_url ) - que o valor de retorno da função : send_confirmation_email seja : ( true , '' )"
context manager for temporarily switching real and effective uid and real and effective gid .
expand the tox.ini 's envlist into a fully expanded list .
takes string and returns list of options :
"usually an envlist is a comma seperated list of pyxx , however tox supports move advanced usage ."
"generator to split comma seperated string , but not split commas inside curly braces ."
if env matches the expanded factor then return value else return '' .
""" returns true if py{33 , 34 } expanded is contained in env.name ."
"split s by sep , unless it 's inside a quote ."
"makes tox substitutions to s , with respect to environment env ."
"given a match object , having matched something inside curly braces , replace the contents if matches one of the supported tox - substitutions ."
env : key or env : key : default
posargs : default
동시 접속 차단 로직
return the currently selected country or none .
select the country for the current thread .
remove the country for the current thread .
context manager that selects the country .
return a string describing a set of modifiers .
play a list of vnc_actions forward over the current keysyms state
returns the current state as keysyms
returns the current state as an index
used in the tests
"when an image is favorited , it should show up on the my lists page"
"when a favorite is removed , it should not appear on the my lists page"
"for a given version and license string , return the canonical human - readable deed"
"given a url , return the license as a license / version tuple"
"returns a dictionary of each partner with known licensing schemes , and their mapping of license key to their internal identifier ."
"given an array of licenses chosen by a user and a dictionary of handler- specific license values , find all matching items and return a comma - separated list of values . also handles special license group by expanding them into discrete licenses first . licenses are always returned in ascending order ."
the test database should be accessible
it should be possible to create an image record with a few basic fields
the identifier - creation function should return the same value for each iteration
it should be possible to create a tag with a few basic fields
it should be possible to associate a tag with an image
the ` tags_list ` field on the ` image ` table should contain an array of values
it should be possible to create an empty list
it should be possible to create a list and add an image to it
it should be possible to generate a url - safe identifier out of an arbitrary list of keywords
"when a list is created , a slug should be automatically generated"
creating two lists with the same title should not result in a duplicate slug
an image should be able to be synced with its source
the sync function should update the last - checked timestamp
the sync function should mark an image as removed if we get a non-200 response from the source
the sync function should not mark an image as removed if we get 200 response from the source
the generate_hash function should generate a perceptual hash from a byte stream
the generate_hash function should generate the same hash for the same image
images can be added as favorites by users
: param keep_recent : see ` tf.train . saver ` documentation . : param keep_freq : see ` tf.train . saver ` documentation .
maxpooling on images .
average pooling on images .
global average pooling as in ` network in network < http://arxiv.org/abs/1312.4400 > ` _ .
unpool the input with a fixed mat to perform kronecker product with .
non - parametric bilinear upsample the input images . : param x : input nhwc tensor : param shape : an integer
initialize a session
: param model_path : a model file or a ` ` checkpoint ` ` file . : param prefix : add a ` prefix/ ` for every variable in this checkpoint
"produce { var_name : var } dict that can be used by ` tf.train . saver ` , from a { var_name : [ vars ] } dict ."
return a set of strings
": param vars_available : varaible names available in the checkpoint , for existence checking : returns : a dict of { var_name : [ var , var ] } to restore"
: param param_dict : a dict of { name : value }
": params sess_inits : list of ` sessioninit ` instances . : params new_session : add a ` newsession ( ) ` and the beginning , if not there"
: param idx : index of the worker . the 0th worker will print log . : param config : a ` predictconfig `
"call _ init_runtime under different cuda_visible_devices , you 'll have workers that run on multigpus"
": param inqueue : input queue to get data point . elements are ( task_id , dp ) : param outqueue : output queue put result . elements are ( task_id , output )"
fetch a batch of data without waiting
: param predictors : a list of onlinepredictor
"dp must be non - batched , i.e. single instance"
returns all rows from a cursor as a dict
read an verify an intel hex file . return the data as an list of bytes .
serves files from the ./static/ subdirectory for every page .
run bigbuild 's custom context processors and return then as part of the provided dictionary .
returns a joined path with the front slash of the first argument always sliced off .
returns the page object being rendered by this view .
returns the template paths to use when rendering this object .
returns the context dictionary to use when rending this page .
builds an object 's static subdirectory .
build the provided object
returns the django - bakery build_dir where pages will be built .
returns the bigbuild_page_dir where dynamic pages are configured .
returns the bigbuild_archive_dir where archived pages are configured .
returns the name of the current git branch .
returns the base url for site .
what to use when this pagelist is used in a for loop .
returns the number of pages in this pagelist .
pull items either with a slug key or an integer index .
returns a list of page objects from the provided slug directory .
returns the list of slugged page modules in the provided directory .
returns a list of page objects ready to be built in this environment .
returns a list of archivedpage objects ready to be built in this environment .
parameters ---------- word_index : int the int index representing the word .
"given a dataset , this method decides which words ( which could be words or characters ) are given an index , and which ones are mapped to an oov token ( in this case "" @@unknown@@ "" ) ."
"adds ` word ` to the index , if it is not already present . either way , we return the index of the word ."
returns a list of the words in the index for a given namespace .
get the index of a word .
"get the word corresponding to an input index , for a given namespace ."
get the number of words in a namespace .
"lazy evaluated response cache ttl in seconds , corresponds to the cache - control 's max - age value and also used to evaluate expires header"
lazy evaluated value of last - modified header
lazy evaluated value of etag header
deliver error notifications from a form to a user .
list all of the pull requests for a repo
get a single pull request
create a pull request
update a pull request
list the commits for a pull request
list the files for a pull request
gets whether a pull request has been merged or not .
merge a pull request .
list your issues
list issues for a repo
get a single issue
create an issue
update an issue
return the location of a test file or directory given a path relative to the testdata directory .
read file at location and return a unicode .
return a list of text lines loaded from the location of a test file or directory given a path relative to the testdata directory .
"create directory or directory tree at location , ensuring it is readable and writeable ."
create and return a new unique empty directory created in base_dir .
return a unique new temporary file location to a non - existing temporary file that can safely be created without a risk of name collision .
create a unique new temporary directory location . create directories identified by sub_dir_path if provided in this temporary directory . return the location for this unique directory joined with the sub_dir_path if any .
extract a zip archive file at location in the target_dir directory .
"given an archive file identified by a path relative to a test files directory , return a new temp directory where the archive file has been extracted using extract_func ."
the function evaluates the yaml file and executes specifi commands
citim fisierul de configurare .
the method downloads a file to a custom location
the method creates a new hostname for the system
the method iterates through a user dictionary and creates users based on the properties
the method iterates through a dictionary of files and creates them at a custom path
the method runs a script based on the parameters specified in the config file
the method deletes a specified file
the method sends a command to reboot the system
the method send a command to shutdown the system
cauta si intoarce elementul unic din lista .
return cli arguments for validenting the html .
load the previous state of the repository .
save the current state of the repository .
compute sha1 hash for the received file .
helper method to shell out and execute a command through subprocess .
generator for all the scripts in the repository .
get the arguments from the cli .
get the script type of a path .
check if all the scripts meet the requirements .
shifts a letter by number places in letters
decrypts every line in < mesaj >
"have a main docstring , pylint"
verifica daca un punct se afla in imagine
"umple un punct daca poate , daca da merge si pe vecini lui , daca nu se opreste"
afiseaza o imagine
"funcția primește reprezentarea imaginii și coordonatele unui punct . în cazul în care punctul se află într - o formă închisă trebuie să umple forma respectivă cu caracterul "" * """
calculează distanța dintre origine și poziția curentă .
stabileste daca este instructiune .
calculeaza distanta fata de origine dupa mutari .
verifică validitatea expresiei primite .
funcția va primi calea către fișierul ce conține mesajul brut și va genera un fișier numit icao_intrare ce va conține mesajul inițial .
functie pentru cautarea indiferenta
functie pentru cautarea exacta
functie pentru cautarea si inlocuirea mesajului
functie pentru numarul de aparitii
apeleaza recursiv executia grep pe fisierele din director .
funcția primește o listă cu elemente numerice prin parametrul istoric și trebuie să returneze elementul care nu este duplicat .
funcția primește reprezentarea imaginii și coordonatele unui punct .
încercăm să rezolvăm problema fill .
"functia verifica daca punctul , descris de coordonatele sale - row si column , este pe imagine . returneaza true daca se afla pe imagine , false - in caz contrar ."
"functia primeste imaginea si coordonatele unui punct gol ( pe matrice , caracterul ' - ' ) , il coloreaza ( pe matrice , caracterul ' * ' ) dupa care verifica cele 4 puncte vecine . daca un punct vecin este gol , functia se autoapeleaza cu aceeasi imagine dar punctul fiind vecinul ."
funcția primește reprezentarea imaginii și coordonatele unui punct .
main function docstring
"read(addr , count , partial = false ) - > bytearray"
"readtype(gdb_type , addr ) - > int"
"write(addr , data )"
peek(address ) - > str
reads a null - terminated string from memory .
byte(addr ) - > int
uchar(addr ) - > int
ushort(addr ) - > int
uint(addr ) - > int
pvoid(addr ) - > int
u8(addr ) - > int
u16(addr ) - > int
u32(addr ) - > int
u64(addr ) - > int
"u(addr , size = none ) - > int"
s8(addr ) - > int
s16(addr ) - > int
s32(addr ) - > int
s64(addr ) - > int
poi(addr ) - > gdb . value
"round_down(address , align ) - > int"
"round_up(address , align ) - > int"
page_align(address ) - > int
"find_upper_boundary(addr , max_pages=1024 ) - > int"
"find_lower_boundary(addr , max_pages=1024 ) - > int"
mapping start address .
address beyond mapping . so the last effective address is self.end-1 it is the same as displayed in /proc/<pid>/maps
"recursively dereferences an address . for bare metal , it will stop when the address is not in any of vmmap pages to avoid redundant dereference ."
"recursively dereferences an address into string representation , or convert the list representation of address dereferences into string representation ."
"waring : if cursor not read all data , the connection next query is error"
return the rotation of the object as quaternion
"from 4x4 matrix , calculate camera location"
rotate around local y ( 180deg ) to move from z backward to z forward
rotate around local x ( 90deg ) to move from y up to -y forward
"execute the shell command ' cmd ' in a sub - process . if ' bufsize ' is specified , it sets the buffer size for the i / o pipes . the file objects ( child_stdout , child_stdin ) are returned ."
"execute the shell command ' cmd ' in a sub - process . if ' bufsize ' is specified , it sets the buffer size for the i / o pipes . the file objects ( child_stdout , child_stdin , child_stderr ) are returned ."
"run command with arguments . wait for command to complete , then return the status ."
"the parameter ' cmd ' is the shell command to execute in a sub - process . the ' capturestderr ' flag , if true , specifies that the object should capture standard error output of the child process . the default is false . if the ' bufsize ' parameter is specified , it specifies the size of the i / o buffers to / from the child process ."
"return the exit status of the child process if it has finished , or -1 if it has n't finished yet ."
wait for and return the exit status of the child process .
object representing a network device command
an object to represent xen devices like network and block @param domain : domain the device will be added to @param i d : device identifier @param devconfig : initial configuration dictionary for xendevice
convert device config to xenconfig node compatible string
"an object to represent xen network device @param domain : domain the device is being added to @param i d : network device identifier , interface name like eth0 @param devconfig : initial dictionary configuration for xennetdevice"
conversion of all key - value pairs of a map ( recursively ) to sxp . @param map_val : map ; if a value contains a list or dict it is also converted to sxp @type map_val : dict @return sxp expr @rtype : list
conversion of sxp to map . @param s : sxp expr @type s : list @return : map @rtype : dict
register a block device class with parser
turn a vm device dictionary into a blkdev object
only allow appending location information of vnc port into xenstore .
interpret the output of ` scp ' and create a suitable exception
dynamic choices so just return true for now
validates that the input is in self.choices .
"not a nice method . combining create / update mechanism , so one can post a patch without knowing i d."
create a base class with a metaclass .
handle the manager 's maintenance - mode
retrieve the current maintenance - mode status .
enter maintenance - mode on the manager rejecting further rest requests .
deactivate maintenance - mode on the manager to accept rest requests .
handle deployment workflows
retrieve information for a specific workflow of a specific deployment
list all workflows on the manager for a specific deployment
show events from workflow executions
display events for an execution
delete events attached to a deployment
factory to make an abstract dist object .
return a setuptools dist object .
ensure that we can get a dist for this requirement .
prepare a requirement that would be obtained from req.link
prepare an editable requirement
prepare an already - installed requirement
pack object ` o ` and write it to ` stream `
pack object ` o ` and return packed bytes
test for retrieving a permission instance given it 's name and owner ( user or org ) or if it 's available to all users .
test for retrieving owner of a permission object
test for retrieving the owner of a permission instance
test for adding permissions to permission instance given a user is its owner .
initialize a test db and call to make fixtures .
remove test session and tables .
setup for testing clientcredential model
test for clientcredential model 's new ( )
test for clientcredential model 's get ( )
test for checking if clientcredential 's secret is a sha256 string ( 64 characters ) prepended with ' sha256 $ '
test for verifying creation of resourceregistry instance
top main loop
docker_cpu main loop
"yields all the ports that memcached is listening to , according to ps ."
sends the ' stats ' command to the socket given in argument .
sends the ' stats slabs ' command to the socket given in argument .
collects and dumps stats from a memcache server .
"url - http location of jolokia auth - dict of username and password tags - dict of key value pairs monitors - list of dicts . - mbean - string , eg ' java.lang : type= * ' - metric - string , prefix to generated metric name , eg ' java.lang ' - tags - ( optional ) same as above , but specific for this mbean only - not_tags - ( optional ) list of autogenerated tags to remove , eg [ ' type ' ]"
take a dict of attributes and print out numerical metric strings recurse if necessary
"make request to jolokia , make sure we have valid data , print out the metrics for each mbean ."
"parse and order attribute text eg from : org.apache.cassandra.metrics : name = currentlyblockedtasks , path = request , scope = requestresponsestage , type = threadpools to : cassandra.metrics.threadpools.currentlyblockedtasks.count , [ path = request , scope = requestresponsestage ]"
test all check functions with test cases in docstrings .
initialize testing framework .
"report an error , according to options ."
run domain join to confirm it errors because we are already joined
"when it becomes complicated ( unlike flex ) , the old recipes work better ( cwd )"
return the index of sl in l or none
checks the ' set / show ' commands for the domain settings ( non - pso )
check that perl xml::twig module is installed . traffic summary depends on this module being installed .
remove possibly undeleted test users from previous test
this test should be enabled preferably against ms active directory . it takes quite the time against samba4 ( 1 - 2 days ) .
parse cmdline args and control build
retrieve the variables from a file
return linkflags for this lib
make it compareable with x.y.z versions ( y and z are optional )
return the complete uniqe linkflags that do not contain .la files anymore
check that the kcc generates graphs that pass its own verify option .
check that the kcc generates errors on a unconnected db
check that kcc writes dot_files when asked .
override this method to schedule the tasks in a particular order
override this method to schedule the tasks in a particular order
called to set the next group of tasks
the tasks that are put to execute are all collected using get_out
"by default , errors make the build stop ( not thread safe so be careful )"
execute the tasks
returns the expected password history for the dc
returns old passwords that fall outside the dc 's expected history
updates the user 's password history to reflect a password change
"returns the dn of the applicable pso , or none if none applies"
returns the user 's current password
attempts to change a user 's password
"updates what in the password history will take effect , to reflect changes on the dc . when the passwordhistorylength applied to a user changes from a low setting ( e.g. 2 ) to a higher setting ( e.g. 4 ) , passwords # 3 and # 4 wo n't actually have been stored on the dc , so we need to make sure they are removed them from our mirror pwd_history list ."
sets a user 's primarygroupid to be that of the specified group
returns a object representing the default password settings that will take effect ( i.e. when no other fine - grained password policy applies )
updates this password settings object to apply to a user or group
updates this pso to no longer apply to a user or group
transfer executable files to target
run a test on the target
ensure required members are not defaults .
serialize resource(s ) according to json - api spec .
renders a resource 's top level members based on json - api spec .
render the resources 's attributes .
render the resource 's relationships .
": param observable : string - the observable ( ipv4 address , ipv6 address , fqdn , url , hash ) : param otype : string - observable type ( ex : ipv4 , ipv6 , fqdn , url , email ) : param tlp : string - traffic light protocol ( ex : red , amber , green , white ) : param reporttime : string - timestamp ( format : yyyy - mm - ddthh : mm : ssz ) : param provider : string - provider ( ex : spamhaus.org ) : param group : string - group membership ( ex : everyone ) : param protocol : string - layer 4 protocol ( ex : icmp , tcp , udp ) : param portlist : string - list of ports ( ex : 1,2,445 - 446 ) : param tags : string - tags describing data ( ex : malware , botnet ) : param asn : int - asn number ( ex : 87 ) : param asn_desc : string - asn description ( ex : indiana university ) : param cc : string - country code ( ex : us ) : param application : string - application commonly associated to the port ( ex : http , ssh ) : param reference : string - reference text ( ex : https://www.spamhaus.org/drop/ ) : param reference_tlp : string - traffic light protocol ( ex : red , amber , green , white ) : param raw : : param confidence : int - number describing confidence in observable ( 0 - 100 ) : return : object"
send batch emails task .
send birthday greeting to members .
send birthdays list to select role members .
set the next group in the rotation weekly schedule .
send notification for the next group scheduled .
"uses the given function in the form of a lambda and produces a vectorized result if at least one of the items is an iterable value . otherwise , it evaluates it as normal . : param a : the first value for the function : param b : the second value for the function : param function : a 2 - arity lambda used for the function : param pre_function : a function that is called before vectorization ( optional ) : return : a value or array of values depending on a and b"
you must call close ( ) when you are removing the widget from the display . : return :
"as the mouse moves in the window , do stuff : - if it hits this widget , and - if it had not marked this widget as entered , - if it had not marked any widget as entered , , - we have moved over this widget ; dispatch on_motion_over - make this widget as entered else : ( it hit this widget , but it had marked another widget as entered ) ( this means it left that widget without dispatching on_motion_flee ) - dispatch on_motion_flee for the other widget - dispatch on_motion_over for this widget - mark this widget as entered . note : be careful if there 's a relativelayout involved in your widget heirarchy . collide_point may not intersect with the widget you expect , and so you 'll get false results ! remember that the x , y of the motion is in the parent coordinate system , and the parent coordinate system is lost on any widgets that are children of a relativelayout . ... but see the todo just below . : param top_level_window : the top level kivy window : param motion_xy_tuple : the coordinates of the mouse in the window 's coordinate system : return :"
: param x : x - value of a point in * window * coordinates : param y : y - value of a point in * window * coordinates : return : true or false
called when your touch point leaves a draggable item . : return :
"called when your touch point crosses into a dropdestination object . self is added as an argument because if you set this up in a .kv file , the self given there is always the self of the object created in the .kv file . for example , if you want to create a copy of the object in the python code , the self will still refer to the self of the original object ."
": param debug_flag : this is a normal argument . value : true or false . false will disable debug output . : param register : this is a keyword argument . set to a hexadecimal value , which would be considered a debug level . if during your debug.print ( ) call you give it a "" level "" keyword argument , the level will be and'ed against the register variable . if true , the debug.print ( ) will generate output ."
"if the debug_flag is false this will not print . however , this can be overridden by either : 1 . by setting the keyword "" definitely "" to "" true "" in the debug.print ( ) call , or 2 . by setting the keyword "" level "" to a hexadecimal flag value . if that value when and - ed with : param args : the stuff to be printed . : param kwargs : definitely , or level : return : nothing"
: param ssarun : the : class:`pism.invert.ssa . ssaforwardrun ` defining the forward problem . : param method : string describing the actual algorithm to use . must be a key in : attr:`tao_types ` .
add a listener to be called after each iteration . see : ref:`listeners ` .
add a listener to be called after each time the design variable is changed .
"given a parameterized design variable value : math:`\zeta ` , solve the ssa . see : cpp : class:`ip_taucparam ` for a discussion of parameterizations ."
executes the inversion algorithm .
"returns a tuple ` ` ( zeta , u ) ` ` of : cpp : class:`icemodelvec ` 's corresponding to the values of the design and state variables at the end of inversion ."
: param owner : the : class:`invssataucsolver_tikhonov ` that constructed us : param listener : the python - based listener .
called during ip_ssatauctaotikhonovproblemlcl iterations . gathers together the long list of arguments into a dictionary and passes it along in standard form to the python listener .
: param owner : the : class:`invssataucsolver_tikhonov ` that constructed us : param listener : the python - based listener .
called during ip_ssatauctaotikhonovproblem iterations . gathers together the long list of arguments into a dictionary and passes it along in a standard form to the python listener .
: param owner : the : class:`invssataucsolver_tikhonov ` that constructed us : param listener : the python - based listener .
create a dummy grid
create telium device instance : param str path : str path to serial emulated device : param int baudrate : set baud rate : param int timeout : maximum delai before hanging out . : param bool open_on_create : define if device has to be opened on instance creation : param bool debugging : enable print device < - > host com trace . ( stdout )
auto - create a new instance of telium . the device path will be infered based on most commom location . this wo n't be reliable if you have more than one emulated serial device plugged - in . wo n't work either on nt plateform . : param int baudrate : baudrate . : param int timeout : timeout for byte signal waiting . : param bool open_on_create : if device should be opened on instance creation . : param bool debugging : set it to true if you want to trace comm . between device and host . ( stdout ) : return : fresh new telium instance or none : rtype : telium . telium
get current timeout value from pyserial device instance : return : current timeout setting from device handled by pyserial : rtype : float
verify whenever the device is actually opened or not via pyserial main instance . : return : true if still opened . : rtype : bool
close the device if not already closed : return : true if device succesfuly closed : rtype : bool
open the device if not already opened : return : true if device succesfuly opened : rtype : bool
"send single signal to device like ' ack ' , ' nak ' , ' eot ' , etc .. . : param signal : str : return : true if signal was written to device : rtype : bool"
read one byte from serial device and compare to expected . : param signal : str : return : true if received signal match : rtype : bool
send data to terminal : param str data : string representation to convert and send : return : lenght of data actually sent : rtype : int
download raw answer and convert it to teliumresponse : return : teliumresponse : raise : terminalunexpectedanswerexception if data can not be converted into telium . teliumresponse : rtype : telium . teliumresponse
initialize payment to terminal : param telium . teliumask telium_ask : payment info : param bool raspberry_pi : set it to true if you'r running raspberry pi : return : true if device has accepted to begin a new transaction . : rtype : bool
"wait for answer and convert it for you . : param telium . teliumask telium_ask : payment info : param float waiting_timeout : custom waiting delay in seconds before giving up on waiting enq signal . : param bool raspberry_pi : set it to true if you'r running raspberry pi : return : teliumresponse , none or exception : rtype : telium . teliumresponse|none"
generate list of possible targets ordered by environment key .
generate targets list by opwsorks instance name
generate targets list by opwsorks stack name
aggregate all possible instance mappings
setup request to retrieve all breaches on a particular account
setup request to retrieve all breaches on a particular domain
setup request to retrieve a specific breach .
setup request to retrieve all breaches recorded on hibp.com so far .
setup request to retrieve all dataclasses on hibp .
execute a get request on hibp rest api service based on request object setup with one of the query services above .
spawns gevent / pool threads that will run the execute method on each hibp object .
asynchronously map the hibp execution job to multiple queries .
lazily + asynchronously map the hibp execution job to multiple queries .
patch cluster class to allow pickle to load old clusters
return the list of ipachar objects composing the ipa string
set the list of ipachar objects composing the ipa string
return ` ` true ` ` if the ipa string is equivalent to the ` ` other ` ` object .
"return a new ipastring , containing the canonical representation of the current string , that is , the one composed by the ( prefix ) minimum number of ipachar objects ."
"return a new ipastring , containing only the ipa characters specified by the ` ` chars ` ` string ."
"return a new ipastring , containing only the consonants in the current string ."
"return a new ipastring , containing only the vowels in the current string ."
"return a new ipastring , containing only the consonants and the vowels in the current string ."
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
"return a new ipastring , containing only :"
load the arpabet ascii ipa data from the built - in database .
print the given error message and exit .
"print unicode characterss that are not ipa valid , if requested by the user ."
print the canonical representation of the given string .
print a list of all ipa characters in the given string .
check if the given string is ipa valid .
"remove characters that are not ipa valid from the given string , and print the remaining string ."
print the arpabey ascii string corresponding to the given unicode ipa string .
print the kirshenbaum ascii string corresponding to the given unicode ipa string .
entry point .
open port with current settings . this may throw a serialexception if the port can not be opened .
set communication parameters on opened port . for the loop:// protocol all settings are ignored !
extract host and port from an url string
return the number of bytes currently in the input buffer .
read size bytes from the serial port . if a timeout is set it may return less characters as requested . with no timeout it will block until the requested number of bytes is read .
output the given byte string over the serial port . can block if the connection is blocked . may raise serialexception if the connection is closed .
"clear input buffer , discarding all that is in the buffer ."
"clear output buffer , aborting the current output and discarding all that is in the buffer ."
"set break : controls txd . when active , to transmitting is possible ."
set terminal status line : request to send
set terminal status line : data terminal ready
read terminal status line : clear to send
read terminal status line : data set ready
read terminal status line : ring indicator
read terminal status line : carrier detect
_ _ init _ _ .
_ _ init _ _ .
"@param cluster_unique : cluster unique string usually sent with bosco_cluster -l @return : ( cluster_entry , cluster_type )"
submit numsubmit glideins .
submit a single glidein job
returns value which is supposed to multiplied to weights of neural network to keep them small values as possible .
arguments --------- activation : activation . type name of activation function to use .
interface to get type of activation in string .
"interface to get f(x ) , where f(x ) is activation function ."
"interface to get df(x)/dx , where f(x ) is activation function ."
returns instance of selected activation function .
"dump a header , with possible extensions"
this dumps the file record to standard out notice how we can easily iterate over the extensions and tres
create the context used for running fixers
run fixer mode of each tool on each file return a diffcollection based on the parsed diff from the fixer changes .
apply the relevant changes from fixer_diff
add a workflow strategy used by different hosting environments to add new workflows
decorator for checking docker image existance . image existence is cached on first check .
see if the nodejs image exists
check if a file should be linted using eslint .
eslint has a fixer that can be enabled through configuration .
run code checks with eslint .
run eslint in the fixer mode .
run container command to install eslint plugins
get the persistent container name this is only used when we have to install custom plugins as that requires creating new temporary images .
remove the named container and temporary image
parse the output of ` git diff ` into a diffcollection and set of diff objects
rough check at whether or not a file diff is going to have additions at all .
get the names of all files that have changed
get all the changes for a given file independant of which commit changed them .
check whether or not a line has changed in a file .
find the line position for a given file + line
parse the diff data into a collection of hunks .
convert this diff object into a string that can be used with git apply . the generated diff will be lacking the ` index ` line as this object does n't track enough state to preserve that data because it is missing in some of the sources we interact with .
find out if a particular line changed in this commit 's diffs
get the line numbers of lines that were added
get the line numbers of lines that were deleted
find the line number position given a line number in the new file content .
get the intersecting or overlapping hunks that intersect with hunks in ` other `
check if a hunk contains the provided lineno in either its deletions or additions
check if a line was added
get the lines added in this hunk
get the lines deleted in this hunk
find the line position given a line number in the new file content .
see if ruby image exists
run code checks with puppet - lint
puppet - lint has a fixer that can be enabled through configuration .
run puppet - lint in fixer mode .
the proportion of observations that are matched in prediction .
the proportion of observations that are not matched .
the proportion of predictions that were right .
"the proportion of the target class that the classifier matches . aka "" true - positive rate "" and "" sensitivity "" ."
the inverse recall . the proportion of non - target class items that are not matched .
false - positive rate . the proportion of proportion of non - target class items that are not matched .
"the proportion of matched observations that are correctly matched . aka "" positive predictive value "" ."
"the proportion of non - matched observations that are correctly not matched . aka "" negative predictive value """
an information theoretic statistic that balances specificity with sensitivity .
the inverse f1 . the same information theoretic statistic applied to non - matched observations .
set up the class .
create a single node spark application .
stop the sparkcontext .
read data from database into spark dataframe .
transform dataframe into the format that can be used by spark ml .
rescale the data .
train kmeans on rescaled data and then label the rescaled data .
save results to hdfs .
invoke all the methods here .
try to open and read an url .
build the url to ask for threads and comments data .
format a string in a good way or returns an empty one if input is none .
format a date in the selected way .
process the data from a thread or a comment .
get all the comments and subcomments from a thread .
write the categorized data in a csv file .
main method .
checks that the ` ` post_invalidation ` ` signal is triggered only after the end of a transaction .
checks that the ` ` post_invalidation ` ` signal is triggered only after the end of a transaction .
scan a yaml stream and produce scanning tokens .
parse a yaml stream and produce parsing events .
parse the first yaml document in a stream and produce the corresponding representation tree .
parse all yaml documents in a stream and produce corresponding representation trees .
parse the first yaml document in a stream and produce the corresponding python object .
parse all yaml documents in a stream and produce corresponding python objects .
parse the first yaml document in a stream and produce the corresponding python object . resolve only basic yaml tags .
parse all yaml documents in a stream and produce corresponding python objects . resolve only basic yaml tags .
"emit yaml parsing events into a stream . if stream is none , return the produced string instead ."
"serialize a sequence of representation trees into a yaml stream . if stream is none , return the produced string instead ."
"serialize a representation tree into a yaml stream . if stream is none , return the produced string instead ."
"serialize a sequence of python objects into a yaml stream . if stream is none , return the produced string instead ."
"serialize a python object into a yaml stream . if stream is none , return the produced string instead ."
"serialize a sequence of python objects into a yaml stream . produce only basic yaml tags . if stream is none , return the produced string instead ."
"serialize a python object into a yaml stream . produce only basic yaml tags . if stream is none , return the produced string instead ."
"add an implicit scalar detector . if an implicit scalar value matches the given regexp , the corresponding tag is assigned to the scalar . first is a sequence of possible initial characters or none ."
"add a path based resolver for the given tag . a path is a list of keys that forms a path to a node in the representation tree . keys can be string values , integers , or none ."
add a constructor for the given tag . constructor is a function that accepts a loader instance and a node object and produces the corresponding python object .
"add a multi - constructor for the given tag prefix . multi - constructor is called for a node if its tag starts with tag_prefix . multi - constructor accepts a loader instance , a tag suffix , and a node object and produces the corresponding python object ."
add a representer for the given type . representer is a function accepting a dumper instance and an instance of the given data type and producing the corresponding representation node .
add a representer for the given type . multi - representer is a function accepting a dumper instance and an instance of the given data type or subtype and producing the corresponding representation node .
convert a representation node to a python object .
convert a python object to a representation node .
parameters ---------- hash_name : string the hash algorithm to be used coerce_mmap : boolean make no difference between np.memmap and np.ndarray objects .
"subclass the save method , to hash ndarray subclass , rather than pickling them . off course , this is a total abuse of the pickler class ."
@inputs : app_secret : secret key for application request_payload : request body hub_signature_header : x - hub - signature header sent with request @outputs : boolean indicated that hub signature is validated
@inputs : access_token : page access token app_secret_token : app secret key @outputs : appsecret_proof : hmac - sha256 hash of page access token using app_secret as the key
add error message
return the error
starts crontab jobs defined in this method .
stops crontab jobs containing job_comment_prepender in the job 's comment
locates a file and returns the absolute path
"perform a master login , which is what android does when you first add a google account ."
use a master token from master_login to perform oauth to a specific google service .
restart the timer
make a time stamp
render the given item
a shortcut for self._formatter.render ( )
pre - render fields before rendering the template .
validates a parsed json document against the provided schema . if an error is found a : class:`validationerror ` is raised .
redirect user to main page if the request is anything but post
"get the user that is making the request bound to this thread , and then raise an interrupt if he does not have the permission specified ."
return the username of the user making the request bound to this thread or < unknown > if not logged in . the result of this function can be trusted because it uses the authentication token .
setup the environ dictionary and add the ` ' ws4py.socket ' ` key . its associated value is the real socket underlying socket .
completes the response and performs the following tasks :
unfortunately the base class forces us to override the whole method to actually provide our wsgi handler .
call thos to start the underlying websockets manager . make sure to call it once your server is created .
the base class would close our socket if we did n't override it .
call this from your wsgi handler when a websocket has been created .
properly initiate closing handshakes on all websockets when the wsgi server terminates .
"given a string , evaluate escape sequences starting with backslashes as they would be evaluated in python source code . for a list of these sequences , see : https://docs.python.org/3/reference/lexical_analysis.html"
"trim text of common , leading whitespace ."
indent the given block of text by indent*4 spaces
"remove all items x where predicate(x , d[x ] )"
mark a test as a data - driven test
a convenience function for running tests in test modules
assert the error message contains / does not contain the phrases
fail a test for whatever reason .
load data in given context
thin plate spline spatial transformer layer tps control points are arranged in a regular grid .
request a snapshot of data from a streaming log .
subscribe a socket to log entries being published .
receive a log entry from the given socket .
execute a callback for each log entry .
stores log entries and sends them to clients upon request .
close the file object if possible .
"create new row , add widgets"
"create new vertical box , add widgets"
label creation function
create spinbutton with callback function
create switch button with callback
create horizontal gtk . box with label at start and widgets at the end .
unpacks values from a bigquery response object into a flat array . the array will contain dicts with the following fields : - ' case_id ' : patient barcode - ' sample_id ' : sample barcode - ' aliquot_id ' : aliquot barcode - ' value ' : value of the selected column from the clinical data table
unpacks values from a bigquery response object into a flat array . the array will contain dicts with the following fields : - ' case_id ' : patient barcode - ' sample_id ' : sample barcode - ' aliquot_id ' : aliquot barcode - ' value ' : value of the selected column from the mirna data table
creates a gnab v2 feature identifier that will be used to fetch data to be rendered in seqpeek .
"returns : true if given genomic build is valid , otherwise false ."
"returns : tuple ( query_body , run_query ) . the "" query_body "" value is the bigquery query string . the "" run_query "" is always true ."
unpacks values from a bigquery response object into a flat array . the array will contain dicts with the following fields : - ' case_id ' : patient barcode - ' sample_id ' : sample barcode - ' aliquot_id ' : aliquot barcode - ' value ' : value of the selected column from the protein data table
creates a gnab v2 feature identifier that will be used to fetch data to be rendered in oncoprint .
unpacks values from a bigquery response object into a flat array . the array will contain dicts with the following fields : - ' case_id ' : patient barcode - ' sample_id ' : sample barcode - ' aliquot_id ' : aliquot barcode - ' value ' : value of the selected column from the maf data table
update last activity time or logout .
"if ` ` request . get['idlefor ' ] ` ` is set , check if it refers to a more recent activity than ` ` request.session['_session_security ' ] ` ` and update it in this case ."
append sync chunks to sync dataframe append currents dataframes until search interval wo n't will be filled up
cross correlation and calculate offsets
"reset idx , drop excessive sync data , map sync events and make offset"
generate square reference signal
calculate cross - correlation with lag . take only first n lags
"return a tuple ( time_values , voltage_values , rate ) - voltage_values will contain the * num * most recently - collected samples as a 32bit float array . - time_values assumes samples are collected at 1ms / s - rate is the running average sample rate . if * downsample * is > 1 , then the number of values returned will be reduced by averaging that number of consecutive samples together . in this case , the voltage array will be returned as 32bit float ."
instruct the serial thread to exit .
fetch the messages from the channel .
fetch the messages
returns whether it supports archiving items on the fetch process .
returns whether it supports to resume the fetch process .
extracts the identifier from a slack item .
extracts and coverts the update time from a slack item .
extracts the category from a slack item .
parse a channel info json stream .
parse a channel history json stream .
parse a user 's info json stream .
fetch information about a channel .
fetch the history of a channel .
fetch user info .
sanitize payload of a http request by removing the token information before storing / retrieving archived items
fetch a resource .
returns the slack argument parser .
operations on access points .
list elements .
updates the attributes of a element .
get the sensors for an element .
generate and start a recorder using a helium . client .
return the helium . client object used by the current recorder .
returns the all known sensors for the active helium . client .
return the first of the known sensor for the active helium . client
yield a temporary label called ' temp - label ' .
returns the all known elements for the active helium . client .
return the first of the known elements for the active helium . client
returns the all known labels for the active helium . client .
return the first of the known labels for the active helium . client
returns the all known configurations for the active helium . client .
returns the first of the known configurations for the active client .
a temporary configuration for the active client .
"if we have a profile including default , but the users default in config is that the default is other , we have to change the include"
loads a file content
perform a singular spectrum analysis by computing the eigenvalues the lagged covariance matrix .
build the covariance matrix for singular spectrum analysis
compute the reconstructed component from the ssa decomposition
add linear gaussian cpd ( conditional probability distribution ) to the bayesian model .
returns the cpd of the node . if node is not specified returns all the cpds that have been added till now to the graph
removes the cpds that are provided in the argument .
the linear gaussian bayesian networks are an alternative representation for the class of multivariate gaussian distributions . this method returns an equivalent joint gaussian distribution .
checks the model for various errors . this method checks for the following error -
cardinality is not defined for continuous variables .
"for now , fit method has not been implemented for lineargaussianbayesiannetwork ."
"for now , predict method has not been implemented for lineargaussianbayesiannetwork ."
"for now , to_markov_model method has not been implemented for lineargaussianbayesiannetwork ."
"for now , is_imap method has not been implemented for lineargaussianbayesiannetwork ."
init method for the base class of elimination orders .
the cost function to compute the cost of elimination of each node . this method is just a dummy and returns 0 for all the nodes . actual cost functions are implemented in the classes inheriting baseeliminationorder .
returns the optimal elimination order based on the cost function . the node having the least cost is removed first .
return edges needed to be added to the graph if a node is removed .
"cost function for weightedminfill . the cost of eliminating a node is the sum of weights of the edges that need to be added to the graph due to its elimination , where a weight of an edge is the product of the weights , domain cardinality , of its constituent vertices ."
the cost of a eliminating a node is the number of neighbors it has in the current graph .
"the cost of a eliminating a node is the product of weights , domain cardinality , of its neighbors ."
the cost of a eliminating a node is the number of edges that need to be added ( fill in edges ) to the graph due to its elimination
"takes the specified items from collection c , creating a new collection : param c : the collection to take the items from : param items : the items to take : return : the new collection"
returns true if this is a list type . : param o : item to check if is list : return : true if is list
"transforms a list to a dict using key to determine what key to use : param l : list to transform : param key : if callable , gets call with item and should return key if list , zip together in a dict else , use index accessor with the value to get the key : return : dict created from list"
"transforms a dict to a list using the given keys : param keys : if empty , uses the sorted keys from the dict , else if list , takes the values of the keys from the list : param dicts : dicts to transform : return : dict created from list"
flattens the list recursively
"flatten the dictionary , concatenating the keys : param d : dictionary to flatten : param concat : if callable , takes key and new key and should return a new unique hashable object if else , concatenates using add operator : return : flattened dict"
runs the filter function on all items in a list of lists : param fn : filter function : param l : list of lists to filter : return : list of filtered lists
splits lists into multiple lists based on a function working against each item in the list .
transforms the keys in a dict .
: type s : str : rtype : str
: type s : str : rtype : str
: type g : list[int ] : type s : list[int ] : rtype : int
: type root : treenode : rtype : int
: type n : int : rtype : list[str ]
: type s : str : type t : str : rtype : str
"replace sys.std(out|err ) with a wrapper during execution , restored after ."
"if ` ` cc ` ` is given and is a file - like object or an iterable of same , it / they will be written to whenever this instance is written to ."
returns decorator for backoff and retry triggered by predicate .
returns decorator for backoff and retry triggered by exception .
jitter the value a random number of milliseconds .
jitter the value across the full range ( 0 to value ) .
정보제공 동의를 하지 않은 경우 동의페이지로 리다이렉션 시키는 메서드 .
getter for number if items in the column .
getter for the column values .
getter for the column name .
specify participant policy
specify participant policy
copy the license and contributing files to each folder repo generate covers if needed . dump the metadata .
analysis module file : param module_root : : param patterns : : param match_include_folder : match dir : return :
responds with a random greeting in response to user greetings .
implements hear to receive the messages and execute the plugin logic
this allows to execute the plugin in standalone mode
returns the menu array from the menu_file
return action class .
retuns the available menus .
returns the groups menu .
returns the meristation menu .
closes the menu .
return the main menu for the command ` show_menu ` .
returns the groups menu for the command shortcut ` groups ` .
returns the groups menu for the command shortcut ` groups ` .
this allows to execute the plugin in standalone mode
adds a empty element to the menu .
adds a new element to the menu .
get request body .
send reply to client .
check facebook for tagged public photos of myself
check facebook for uploaded photos
produce a vector whose values are : math:`v_i = start + increment * i ` .
"a setter for value , but using normalized values ."
the position of the knob in the bar computed by our value .
snaps the knob and value to a discrete value dictated by steps .
return a basic human readable version of the data .
return a raw data structure using only python built - in types .
patch a setuptools command to depend on ` prebuild `
"called for each test item ( class , individual tests ) . ensures that ' skip_t2 ' tests are skipped on t2 and ' skip_t1 ' tests are skipped on t1 ."
busts some moves !
old style dance .
optimize parameters for a model of the semivariogram
"input : ( h ) scalar or numpy ndarray ( a ) scalar representing the range parameter ( lta ) function to perfrom for values less than ( a ) ( gta ) function to perform for values greater than ( a ) output : scalar or array , depending on ( h )"
nugget model of the semivariogram
linear model of the semivariogram
spherical model of the semivariogram
exponential model of the semivariogram
gaussian model of the semivariogram
power model of the semivariogram
input : ( fct ) function that takes data and parameters ( param ) list or tuple of parameters output : ( inner ) function that only takes data as input parameters are set internally
input : ( fct ) function that takes data and parameters ( param ) list or tuple of parameters output : ( inner ) function that only takes data as input parameters are set internally
"input : ( p ) ndarray , data ( model ) modeling function - spherical - exponential - gaussian ( lags ) lag distances ( tol ) tolerance output : ( covfct ) function modeling the covariance"
writes a completed http request to the logs .
"test that values in generator are accesible via their index . values are cached , so we are actually testing that we can access the cached list ."
test that building a list works with generated and cached values
convert indicator vectors to lists of indices for bicluster ` i ` .
convert indices to indicator vectors
returns shape of bicluster from indicator vectors
returns the submatrix corresponding to bicluster ` i ` .
return a mask which is safe to use on x.
resample arrays or sparse matrices in a consistent way
shuffle arrays or sparse matrices in a consistent way
element wise squaring of array - likes and sparse matrices .
"generator to create slices containing batch_size elements , from 0 to n."
generator to create n_packs slices going up to n.
"cast iterable x to a sequence , avoiding a copy if possible ."
parameters ---------- extra : string to be added to the deprecation messages
decorate function fun
test meanshift algorithm
"non - regression : before fit , there should be not fitted attributes ."
test the bin seeding technique which can be used in the mean shift algorithm
test either above import has failed for some reason
load datasets in the svmlight / libsvm format into sparse csr matrix
load dataset from multiple files in svmlight format
dump the dataset in svmlight / libsvm file format .
fit the qda model according to the given training data and parameters .
apply decision function to an array of samples .
perform classification on an array of test vectors x.
return posterior probabilities of classification .
return posterior probabilities of classification .
compare gaussian kde results to scipy.stats.gaussian_kde
"compute information needed to center data to have mean zero along axis 0 . be aware that x will not be centered since it would break the sparsity , but will be normalized if asked so ."
centers data to have mean zero along axis 0 . this is here because nearly all linear models will want their data to be centered .
aux function used at beginning of fit in linear models
fit model .
decision function of the linear model .
predict using the linear model
set the intercept _
predict confidence scores for samples .
predict class labels for samples in x.
probability estimation for ovr logistic regression .
convert coefficient matrix to dense array format .
convert coefficient matrix to sparse format .
fit linear model .
compute score for random uniform cluster labelings
check that adjusted scores are almost zero on random labels
compute the adjusted mutual information and test against known values
check numerical stabability when information is exactly zero
"check relation between v_measure , entropy and mutual information"
fit the kernel density model on the data .
evaluate the density model on the data .
compute the log probability under the model .
generate random samples from the model .
download the 20 newsgroups data and stored it as a zipped pickle .
"given text in "" news "" format , strip the headers , by removing everything before the first blank line ."
"given text in "" news "" format , strip lines beginning with the quote characters > or | , plus lines that often introduce a quoted section ( for example , because they contain the string ' writes : ' . )"
"given text in "" news "" format , attempt to remove a signature block ."
load the filenames and data from the 20 newsgroups dataset .
load the 20 newsgroups dataset and transform it into tf - idf vectors .
get a wallet change address .
"convert a package ( as found by setuptools.find_packages ) e.g. "" foo.bar "" to usable path e.g. "" foo / bar """
get the subdirectories within a package this will include resources ( non - submodules ) and submodules
find all files in a subdirectory and return paths relative to dir
"for a list of packages , find the package_data"
converts string to srvec
converts srvec to string
calculates the distance between two points
returns first enveloping parent node for given title node : param html : page element : param article : element containing article : param title : element containing title : return :
gets article picture 's url
retrieving image 's parameters : param img_node : node of the img tag : param html_url : url of the source page : param headers : extra headers to request for images ' data
checks if given image is looking like banner : return : true or false
checks if real image url is a parameter given to some page : param image_url : initial url : return : resulting url
makes image path absolute if it is relative : param image_url : url of an image : param source_url : url of the source page : return : absolute url or none
detects format of the image and returns its width and height from meta : param img_url : url of the image : param headers : extra headers for url requests if needed : return : image 's width and height
command runner .
truncates html string .
expects a posted json blob in the form :
value can be either a string in the format xxx.xxx.xxx - xx or an 11 - digit number .
value can be either a string in the format xx.xxx.xxx / xxxx - xx or a group of 14 characters .
returns the url for this guitarist .
returns a token that can be used once to do a password reset for the given user .
check that a password reset token is correct for a given user .
check that users can be created and can set their password
check the properties of the anonymous user
check the creation and properties of a superuser
check the operation of the createsuperuser management command
returns a list of table names in the current database .
"returns a description of the table , with the db - api cursor.description interface ."
"returns a dictionary of { field_index : ( field_index_other_table , other_table ) } representing all relationships to the given table . indexes are 0 - based ."
"returns a dictionary of fieldname - > infodict for the given table , where each infodict is in the format : { ' primary_key ' : boolean representing whether it 's the primary key , ' unique ' : boolean representing whether it 's a unique index }"
generates the javascript necessary for displaying this google map .
returns html body tag for loading and unloading google maps javascript .
returns the ` onload ` html < body > attribute .
returns the < script > tag for the google maps api javascript .
returns only the generated google maps javascript ( no < script > tags ) .
returns all < script></script > tags required with google maps javascript .
returns additional css styling needed for google maps on ie .
returns xhtml information needed for ie vml overlays .
returns a sequence of gicon objects in this map .
a class for generating sets of google maps that will be shown on the same page together .
returns javascript containing all of the loading routines for each map in this set .
generates the javascript for the collection of google maps in this set .
returns the ` onload ` html < body > attribute .
returns a sequence of all icons in each map of the set .
helper to create a complete tree .
"normally , accessing fks does n't fill in related objects"
a select_related ( ) call will fill in those related objects without any extra queries
"select_related ( ) also of course applies to entire lists , not just items . this test verifies the expected behavior without select_related ."
"select_related ( ) also of course applies to entire lists , not just items . this test verifies the expected behavior with select_related ."
"the "" depth "" argument to select_related ( ) will stop the descent at a particular level ."
"the "" depth "" argument to select_related ( ) will stop the descent at a particular level . this tests a larger depth value ."
"the "" depth "" argument to select_related ( ) will stop the descent at a particular level . this can be used on lists as well ."
"the optional fields passed to select_related ( ) control which related models we pull in . this allows for smaller queries and can act as an alternative ( or , in addition to ) the depth parameter ."
"in this case , we explicitly say to select the ' genus ' and ' genus.family ' models , leading to the same number of queries as before ."
calculates a checksum with the provided algorithm .
calculates a checksum with the provided algorithm .
calculates a checksum with the provided algorithm .
calculates a checksum with the provided algorithm .
destroys this datastructure object .
allows for iteration over the layers in a data source .
allows use of the index [ ] operator to get a layer at the index .
returns the name of the data source .
"convert a dictionary of attributes to a single string . the returned string will contain a leading space followed by key=""value "" , xml - style pairs . it is assumed that the keys do not need to be xml - escaped . if the passed dictionary is empty , then return an empty string ."
test a middleware that implements process_view .
"test a middleware that implements process_view , operating on a callable class ."
test that all methods of middleware are called for normal httpresponses
test that all methods of middleware are called for templateresponses in the right sequence .
validates the input and returns a string that contains only numbers . returns an empty string for empty values .
displays the login form and handles the login action .
view that checks the hash in a password reset link and presents a form for entering a new password .
the flatpage admin form validates correctly validates urls
get the flag view : render a confirmation page .
post the flag view : actually flag the view ( nice for xhr )
users do n't get to flag comments more than once .
get / post the flag view while not logged in : redirect to log in .
test signals emitted by the comment flag view
the delete view should only be accessible to ' moderators '
posting the delete view should mark the comment as removed
the delete view should only be accessible to ' moderators '
posting the delete view should mark the comment as removed
tests a commentadmin where ' delete_selected ' has been disabled .
"given a first - choice name , adds an underscore to the name until it reaches a name that is n't claimed by any field in the form ."
displays the form
"validates the post data . if valid , displays the preview page . else , redisplays form ."
"validates the post data . if valid , calls done ( ) . else , redisplays form ."
hook to override the ` ` auto_id ` ` kwarg for the form . needed when rendering two form previews in the same template .
takes a request argument and returns a dictionary to pass to the form 's ` ` initial ` ` kwarg when the form is being created from an http get .
context for template rendering .
"given captured args and kwargs from the urlconf , saves something in self.state and/or raises http404 if necessary ."
"given a validated form , performs any extra processing before displaying the preview page , and saves any extra data in context ."
calculates the security hash for the given httprequest and form instances .
returns an httpresponse in the case of an invalid security hash .
does something with the cleaned_data and returns an httpresponseredirect .
shortens a string to a repeatable mangled version with the given length .
formats a number into a string with the requisite number of digits and decimal places .
test that the get_*_display ( ) methods are added to the model instances .
test that required mkmunicipalityfields throw appropriate errors .
test that umcnfields throw appropriate errors for invalid umcns .
test that mkidentitycardnumberfields throw appropriate errors for invalid values
test that the empty option is there .
"runs markdown over a given value , optionally using various extensions python - markdown supports ."
"get the comment app ( i.e. "" django.contrib.comments "" ) as defined in the settings"
"returns the name of the comment app ( either the setting value , if it exists , or the default ) ."
returns the comment model class .
returns the comment modelform class .
returns the target url for the comment form submission view .
"get the url for the "" flag this comment "" view ."
"get the url for the "" delete this comment "" view ."
"get the url for the "" approve this comment from moderation "" view ."
get all the inner text of a dom node ( recursively ) .
start serialization -- open the xml document and the root element .
end serialization -- end the document .
called as each object is handled .
called after handling all fields for an object .
called to handle each field on an object ( except for foreignkeys and manytomanyfields )
called to handle a foreignkey ( we need to treat them slightly differently from regular fields ) .
"called to handle a manytomanyfield . related objects are only serialized as references to the object 's pk ( i.e. the related * data * is not dumped , just the relation ) ."
helper to output the < field > element for relational fields
convert an < object > node to a deserializedobject .
handle a < field > node for a foreignkey
handle a < field > node for a manytomanyfield .
helper to look up a model from a < object model= ... > or a < field rel= ... to= ... > node .
a view that can only be visited by staff . non staff members get an exception
a view that parses and returns a json string as a file .
a view that is requested with get and accesses request.raw_post_data . refs # 14753 .
"returns the given html with ampersands , quotes and angle brackets encoded ."
hex encodes characters for use in javascript strings .
"similar to escape ( ) , except that it does n't operate on pre - escaped strings ."
converts newlines into < p > and < br />s .
returns the given html with all tags stripped .
returns the given html with spaces between tags removed .
returns the given html with all entities ( & something ;) stripped .
returns the given html with all unencoded ampersands encoded correctly .
converts any urls in text into clickable links .
"clean the given html . specifically , do the following : * convert < b > and < i > to < strong > and < em > . * encode all ampersands correctly . * remove all "" target "" attributes from < a > tags . * remove extraneous html , such as presentational tags that open and immediately close and < br clear=""all "" > . * convert hard - coded bullets into html unordered lists . * remove stuff like "" < p>&nbsp;&nbsp;</p > "" , but only if it 's at the bottom of the text ."
closes the connection to the email server .
sends one or more emailmessage objects and returns the number of email messages sent .
a helper method that does the actual sending .
creates a mock egg with a list of resources .
loading any template on an empty egg should fail
template loading fails if the template is not in the egg
a template can be loaded from an egg
loading an existent template from an egg not included in installed_apps should fail
check that the template directories form part of the template cache key . refs # 13573
builds a test suite for the geos tests .
runs the geos tests .
"verbose version of get_articles_from_same_day_1 , which does a custom database query for the sake of demonstration ."
rendering a template response triggers the post - render callbacks
test that update changes the right number of rows for a nonempty queryset
test that update changes the right number of rows for an empty queryset
test that update changes the right number of rows for an empty queryset when the update affects only a base table
test that update changes the right number of rows for an empty queryset when the update affects only a base table
we can update multiple objects at once .
multiple fields can be updated at once
"in the rare case you want to update every instance of a model , update ( ) is also a manager method ."
we do not support update on already sliced query sets .
the debug error template should be shown only if debug is true
check that the user 's name in the comment is populated for authenticated users without first_name and last_name .
prevent posting the exact same comment twice
test signals emitted by the comment posting view
test that the comment_will_be_posted signal can prevent the comment from actually getting saved
test that the comment_will_be_posted signal can modify a comment before it gets posted
"test the different "" next "" actions the comment view can take"
the ` next ` key needs to handle already having a query string ( # 10585 )
"tests that attempting to retrieve the location specified in the post redirect , after adding some invalid data to the expected querystring it ends with , does n't cause a server error ."
the ` next ` key needs to handle already having an anchor . refs # 13411 .
"retrieves a list of messages from the messages cookie . if the not_finished sentinel value is found at the end of the message list , remove it and return a result indicating that not all messages were retrieved by this storage ."
"either sets the cookie with the encoded data if there is any data to store , or deletes the cookie ."
"stores the messages to a cookie , returning a list of any messages which could not be stored ."
"creates an hmac / sha1 hash based on the value and the project setting 's secret_key , modified to make it unique for the present purpose ."
returns an encoded version of the messages list which can be stored as plain text .
safely decodes a encoded text stream back into a list of messages .
a version of python 's urllib.quote ( ) function that can operate on unicode strings . the url is first utf-8 encoded before quoting . the returned string can safely be used as part of an argument to a subsequent iri_to_uri ( ) call without double - quoting occurring .
a version of python 's urllib.quote_plus ( ) function that can operate on unicode strings . the url is first utf-8 encoded before quoting . the returned string can safely be used as part of an argument to a subsequent iri_to_uri ( ) call without double - quoting occurring .
a version of python 's urllib.urlencode ( ) function that can operate on unicode strings . the parameters are first case to utf-8 encoded strings and then encoded as per normal .
parses a date format as specified by http rfc2616 section 3.3.1 .
converts a base 36 string to an ` ` int ` ` . raises ` ` valueerror ` if the input wo n't fit into an int .
"parses a string with one or several etags passed in if - none - match and if - match headers by the rules in rfc 2616 . returns a list of etags without surrounding double quotes ( "" ) and unescaped from \<char > ."
wraps a string in double quotes escaping contents as necesary .
initializes on the geometry .
returns a properly quoted string for use in postgresql / postgis .
wrap a function so that results for any argument tuple are stored in ' cache ' . note that the args to the function must be usable as dictionary keys .
turns any callable into a lazy evaluated callable . you need to give result classes or types -- at least one is needed so that the automatic forcing of the lazy evaluation code is triggered . results are not memoized ; the function is evaluated on every access .
"a decorator that allows a function to be called with one or more lazy arguments . if none of the args are lazy , the function is evaluated immediately , otherwise a _ _ proxy _ _ is returned that will evaluate the function when needed ."
must be implemented by subclasses to initialise the wrapped object .
returns an extra keyword arguments dictionary that is used with the ` add_item ` call of the feed generator .
"returns a feedgenerator . defaultfeed object , fully populated , for this feed . raises feeddoesnotexist for invalid parameters ."
close the browser .
log in to instagram with the provided credentials .
return a list of links to the users profiles found .
open a specific dialog and identify the div containing the users list .
return the element linking to the users list dialog .
return all the list items included in the users list .
scroll a specific element one or more times with small delay between them .
keep asking for input until it 's empty .
keep asking for input until it 's empty or not in range .
args : app(flask ): the flask appliation instance . db(flywheel ): the flywheel object - database mapper instance .
add object to db session . only for session - centric object - database mappers .
retrieve object of type ` ` objectclass ` ` by ` ` i d ` ` .
"retrieve all objects of type ` ` objectclass ` ` , matching the filters specified in ` ` * * kwargs ` ` -- case sensitive ."
"retrieve the first object of type ` ` objectclass ` ` , matching the filters specified in ` ` * * kwargs ` ` -- case sensitive ."
"retrieve the first object of type ` ` objectclass ` ` , matching the specified filters in ` ` * * kwargs ` ` -- case insensitive ."
save object . only for non - session centric object - database mappers .
delete object specified by ` ` object ` ` .
this method does nothing for dynamodbadapter .
this method does nothing for dynamodbadapter .
drop all document collections of the database .
can we discover usernames ?
do we return a failure on bad pages ?
do we return a failure on failed pages ?
do we retrieve the right stats about a user ?
"for a given * sprite * , complete * progress * 's worth of this animation . basically , complete a step of the animation . returns a dictionary representing the changed property and its new value , e.g. : : code:`{""x "" : 100 } ` . typically , you will use the sprite 's animate function instead of calling this directly ."
removes all references to this view ; it must have previously been added to the layertree .
starts keeping track of this view in the layertree .
"set the layer that this view is on . behavior is undefined if that layer does not exist in the parent , so make sure you eventually add that layer to the parent ."
set the layers that will be available for this view or scene .
"from a list of numbers indicating the location of the view / layer within the current level , compute an absolute number in base max_layers that can quickly and easily compared ."
"runs through the entire layertree and calculates an absolute number for each possible view / layer , which can be easily compared ."
"for a given view , and the current depth in the layer heirarchy , compute what its relative depth chain should look like . sets this entry for layer_location to be a list of numbers indicating the relative depth . note that this is called in a recursive manner to move down the entire layertree ."
"for a given layer ( and also that layer 's parent / owner , since layer alone is ambiguous ) , identify what the absolute position value is from the precomputed cache , allowing for : above and : below modifiers ."
helper decorator for logging exceptions using the global gdbeventhandler instance .
"do nt execute the callback right now , instead defer the execution of the event and move it to the gdb event loop to be executed in some point in the future ."
"handle this event . if the target is running , defer the execution pushing this event into a queue to be executed later . if the target is stopped , then it should be safe to execute the event now , but before , execute all the queued events and then this current event ."
execute the callback associated to the particular event with those data .
"log to syslog and publish an event , with the defined severity and topic . the message will be ' message ' ."
"shortcut for logging errors . this method will log to syslog and publish an event using the publish method , with log_err severity . the final message will be the concatenation of the error_message and the current traceback ."
obtain the serializer with provided model class .
a shortcut to ` client.receive ` .
a shortcut to ` client.send_content ` .
a shortcut to ` client.connect ` .
a shortcut to ` client.disconnect ` .
a factory function to create new wsclient .
to reload config files and corresponding components when received sigusr1 signal .
"a proxy function for validation , which will find ` validate_<key > ` method in self and feed ` value ` to it if the method exists . the validation methods should return the validated value ."
validate and store configuration items specified by ` source ` ( a dict ) .
return a dict containing gathered configuration items .
biohub_plugins should not contains duplicated items .
configuration items should be protected .
returns a boolean indicating whether the settings is loaded .
resolves the path of config file .
"a function for testing , which saves current state of config file ."
"a function for testing , which restores the state in the last call of ` store_settings ` ."
load configuration from file specified by ` self.config_file_path ` .
write configuration back to file .
set the xml root .
add a conversion profile .
export a file with the conversion profiles .
import a conversion profile file .
return a _ profile objects .
return a dict of preset / params .
return a list of available qualities per conversion profile .
save xml tree .
return the path to the profiles file .
create a xml file with the conversion profiles .
returns the profiles.xml root .
class initializer .
set the target quality and other parameters needed to get it .
generate a tag from profile quality string .
get or create a connection to a broker
discover brokers and metadata for a set of topics . this method will recurse in the event of a retry .
generate a new correlation i d
attempt to send a broker - agnostic request to one of the available brokers . keep trying until you succeed .
group the requests
group a list of request payloads by topic+partition and send them to the leader broker for that partition using the supplied encode / decode functions
encode and send some producerequests
encode and send a fetchrequest
"as part of the kittler / illingworth method , compute j(t ) for a given t"
tries to compute an optimal histogram threshold using the kittler / illingworth method
"use "" cart "" method : classification and regression tree"
"use "" rifleserialclassifier "" method : a random forest technique"
"use "" pegasos "" method : primal estimated sub - gradient solver for svm"
retrieve _ i d value . @todo : it will be removed in future .
checks if value is an instance of dict
extracts a nested zip file . @param zip_path : zip path @param extract_path : where to extract @param password : zip password
"checks if the zip file contains another file with the same name , so it is going to be overwritten . @param zip_path : zip file path @return : comparison boolean"
get information from zip file . @param zip_path : zip file path @return : zipinfo class
extract into a list irc messages of a tcp streams . @buf : tcp stream data
get irc client commands of tcp streams . @buf : list of messages @return : dictionary of the client messages
get irc client commands of tcp streams . @buf : list of messages @return : dictionary of the client messages filtered
get irc server commands of tcp streams . @buf : list of messages @return : dictionary of server messages
get irc server commands of tcp streams . @buf : list of messages @return : dictionary of server messages filtered
check if there is irc messages in a stream tcp . @buf : stream data @return : boolean result
@param file_path : file path .
"gets filetype , uses libmagic if available . @param data : data to be analyzed . @return : file type or none ."
gets peid signatures . @return : matched signatures or none .
gets imported symbols . @return : imported symbols dict or none .
gets exported symbols . @return : exported symbols dict or none .
gets sections . @return : sections dict or none .
get resources . @return : resources dict or none .
get version info . @return : info dict or none .
gets imphash . @return : imphash string or none .
get compilation timestamp . @return : timestamp or none .
run analysis . @return : analysis results dict or none .
run analysis . @return : results dict .
run information gathering . @return : information dict .
generate associated markdown files for the notebook .
"call init , sign"
"call init , sign"
"' i have [ x , y , z ] , i want [ x , y , z ] , what do you have / want ' i : list of hashes , list of hashes o : list of hashes , list of hashes"
"' i have [ x , y , z ] , i want [ x , y , z ] , what do you have / want ' i : list of hashes , list of hashes o : list of hashes , list of hashes"
"' store blob [ blob ] of type [ type ] ' i : blob , type o : bool , ttl"
"' store blob [ blob ] of type [ type ] ' i : blob , type o : bool , ttl"
"' send blob [ blob ] of type [ type ] ' i : list of hashes , type o : list of blobs , ttl"
"' send blob [ blob ] of type [ type ] ' i : list of hashes , type o : list of blobs , ttl"
"' seek hashes key [ hash ] count [ number ] direction [ + /- ] ' i : hash , number , direction o : list of hashes"
' resolve [ hash ] ' i : hash o : blob
' resolve [ hash ] ' i : hash o : blob
"passphrase must be stored in server somewhere to recreate this object ( it 's possibly okay to use the redis database , which may be in common between multiple nodes )"
checking a jwt against passphrase and expiry
create a jwt based on utc time
"encrypt something , decrypt it"
"random objects encrypted - multiple renders , one reciever"
random objects encrypted - multiple senders / recievers
verify something that was signed
"backup and restore a key , ( assure equal ? )"
"a function to return the indicies of lat , lon within a bounding box . padding is leftover from old sciwms code , i believe it was to include triangles lying just outside the region of interest so that there are no holes in the rendered image ."
return row indicies into the nv data structure which have indicies inside the bounding box defined by lat_lon_subset_idx
return a transparent ( blank ) response used for tiles with no intersection with the current view or for some other error .
"assumes the size of lat / lon are equal ( ugrid variables ) . returns a boolean mask array of the indexes , suitable for slicing"
"execute all programs represented by ` ` program_output ` ` nodes in ` ` doctree ` ` . each ` ` program_output ` ` node in ` ` doctree ` ` is then replaced with a node , that represents the output of this program ."
"initialize the cache for program output at ` ` app.env.programoutput_cache ` ` , if not already present ( e.g. being loaded from a pickled environment ) ."
create a command from a : class:`program_output ` node .
execute this command .
get the output of this command .
"called , if a command was not found in the cache ."
summary and plot generation .
parse arguments .
set the active sub - window from index .
set the active sub - window .
closes sub - windows associated to the closed model items .
return the defaut workinhg directory .
return the resurce path .
return the full path of the program ( * cmd * ) or none .
check if a file is a script .
return the list of args for starting the script via subprocess .
normalize angles to fit expected range
parse arguments when running this as a script
"reads a raw bitstream , byte - swaps ( if desired ) , and writes to a binfile"
"process the fpga bit file at bitfilename , and write a bin file to binfilename"
must be overridden with the desired mathematical function
"must be overridden accoriding the desired mathematical function e.g. return base_unit + "" ^{}"".format(len(self.sink.input_streams ) )"
must be overridden depending on the desired mathematical function
test the fit_t1 experiment
test the fit_ramsey experiment
test the fit_single_qubit_rb experiement
collect token frequency statistics from trees
"this example sets up the kinetic solver and steady - state finder , on a bistable model . it looks for the fixed points 100 times , as follows : - set up the random initial condition that fits the conservation laws - run for 2 seconds . this should not be mathematically necessary , but for obscure numerical reasons it is much more likely that the steady state solver will succeed in finding a state . - find the fixed point - print out the fixed point vector and various diagnostics . - run for 10 seconds . this is completely unnecessary , and is done here just so that the resultant graph will show what kind of state has been found . after it does all this , the program runs for 100 more seconds on the last found fixed point ( which turns out to be a saddle node ) , then is hard - switched in the script to the first attractor basin from which it runs for another 100 seconds till it settles there , and then is hard - switched yet again to the second attractor and runs for 100 seconds . looking at the output you will see many features of note : - the first attractor ( stable point ) and the saddle point ( unstable fixed point ) are both found quite often . but the second attractor is found just once . has a very small basin of attraction . - the values found for each of the fixed points match well with the values found by running the system to steady - state at the end . - there are a large number of failures to find a fixed point . these are found and reported in the diagnostics . they show up on the plot as cases where the 10 - second runs are not flat ."
create a compartment at ` path ` with standard property values .
create a cable made of ` nump_comp ` identical compartments under ` path ` .
insert a constant conductance channel on compartment ` comp ` . set the channel reversal potential to ` ek `
insert a recorder for vm in compartment ` comp ` .
setup the model and recording for fig 6 experiment . this will insert channels in specific compartments for each cable .
do a simulation for fig6 and plot data .
create a single compartment squid model .
create spine of specified dimensions and index
a small compartmental model that demonstrates : : a ) how to set up a multicompartmental model using symcompartments b ) solving this with the default exponential euler ( ee ) method c ) solving this with the hsolver . d ) what happens at different timesteps .
this example illustrates how to run a model at different volumes . the key line is just to set the volume of the compartment : :
this function creates an ematrix of two pulsegen elements and another ematrix of two table elements .
this example shows that you can have two ematrix objects and connect individual elements using ` single ` message
"this example illustrates loading , and running a kinetic model for a bistable positive feedback system , defined in kkit format . this is based on bhalla , ram and iyengar , science 2002 ."
"get the document root . for i{document / literal } , this is the name of the wrapper element qualified by the schema 's target namespace . @param wrapper : the method name . @type wrapper : l{xsd.sxbase . schemaobject } @return : a root element . @rtype : l{element }"
expand list parameters into individual parameters each with the type information . this is because in document arrays are simply multi - occurrence elements .
get parameter definitions for document literal .
demonstration of medelling gap junction using moose .
"this example is to demonstrate , how gap junction can be modeled using moose ."
"this function setus up a simple chemical system in which ca input comes to the dend and to selected psds . there is diffusion between psd and spine head , and between dend and spine head ."
"this example illustrates and tests diffusion embedded in the branching pseudo-1 - dimensional geometry of a neuron . an input pattern of ca stimulus is applied in a periodic manner both on the dendrite and on the psds of the 13 spines . the ca levels in each of the dend , the spine head , and the spine psd are monitored . since the same molecule name is used for ca in the three compartments , these are automagially connected up for diffusion . the simulation shows the outcome of this diffusion . this example uses an external electrical model file with basal dendrite and three branches on the apical dendrite . one of those branches has the 13 spines . the model is set up to run using the ksolve for integration and the dsolve for handling diffusion . the timesteps here are not the defaults . it turns out that the chem reactions and diffusion in this example are sufficiently fast that the chemdt has to be smaller than default . note that this example uses rates quite close to those used in production models . the display has four parts :"
test plot function
demonstrates how to use vectors of moose elements
demonstration of voltage clamping in a neuron .
this snippet is to demonstrate modelling of voltage clamping .
loads and runs the pyloric rhythm generator from neuroml files .
run a given test
download and run tests .
get xml representation of the object . @return : the root node . @rtype : l{element }
@param username : a username . @type username : str @param password : a password . @type password : str
set i{nonce } which is an arbitrary set of bytes to prevent replay attacks . @param text : the nonce text value . generated when i{none } . @type text : str
set i{created } . @param dt : the created date & time . set as datetime.utc ( ) when i{none } . @type dt : l{datetime }
get xml representation of the object . @return : the root node . @rtype : l{element }
@param validity : the time in seconds . @type validity : int
in this example we demonstrate the use of pyrun objects to execute python statements from moose . here is a couple of fun things to indicate the power of moose - python integration .
"the pyrun class can take a double input through ` trigger ` field . whenever another object sends an input to this field , the ` runstring ` is executed ."
you can use the pyrun class to run python statements from moose at runtime . this opens up many possibilities of interleaving computing in python and moose . you can also use this for debugging simulations .
get a unicode safe string representation of an object
"returns a bytestring version of 's ' , encoded as specified in ' encoding ' ."
"return a dict of channel name , channel prototype pairs . if the channel prototypes have not been initialized , this functions initializes the same ."
"in this example we walk through creation of a vector of intfire elements and setting up synaptic connection between them . synapse on intfire elements is an example of elementfield - elements that do not exist on their own , but only as part of another element . this example also illustrates various operations on ` vec ` objects and elementfields ."
"set up two lif neurons and connect them by an stdpsynhandler . set up some tables , and reinit moose before simulation ."
call this between every pre - post pair to reset the neurons and make them settle to rest .
inject a brief current pulse to make a neuron spike
"connect two cells via a plastic synapse ( stdpsynhandler ) . induce spikes spearated by varying intervals , in the pre and post synaptic cells . plot the synaptic weight change for different intervals between the spike - pairs . this ia a pseudo - stdp protocol and we get the stdp rule ."
the default fucntion called when network receives something : param diction : dict
the default fucntion called when network receives no ack after sending something : param last_sent_diction : dict
the default fucntion called when network receives an ack after sending something . this function is essentially unnecessary .... mostly for debugging but maybe it will be useful someday to overwrite this with something : param last_sent_diction : dict
filters the image for candidate staff center lines .
shift the image vertically .
constructs a structure instance .
computes the structure .
flat maps ` fn ` on items unpacked from ` elems ` on dimension 0 .
labels contiguous true runs in segments .
labels consecutive runs of the same value .
labels peaks in values .
translates the image .
calculates the glyph y coordinate .
the knn k - means classifier model .
writes the knn saved model .
does nothing .
takes one argument and does nothing with it .
initializes the optimizer .
returns a step 's parameter update given a loss / gradient evaluation function .
rolls the optimizer 's internal state .
"sets params to the supplied array ( a possibly - resized or altered last non - averaged iterate ) , resampling the optimizer 's internal state if the shape has changed ."
take an l - bfgs step . returns the new parameters and the loss after the step .
updates the l - bfgs memory with a new curvature pair .
computes the product of a vector with an approximation of the inverse hessian .
rolls the optimizer 's internal state .
sets params to the supplied array and clears the l - bfgs memory .
"validate ` filename ` , print its errors , and return the number of errors ."
lint ( syntax - check ) a valohai.yaml file .
: rtype : ` ` cookie . simplecookie ` `
e.g. ` ` 200 ok ` `
"` ` get ` ` , ` ` post ` ` etc ."
the ` ` x - requested - with ` ` header equal to ` ` httprequest ` `
report a map into the state variable directory .
read a state variable map .
test existence of added methods
test existence of initial method
test execution of initial method
test self.readmap/self.report functionality
public main entry of this module . args : entities : a list of entities to be selected from tid : the type of these entities return : a single entity selected
select entities from a list of entities such that the name of the entity fully contain the query
select from a list of entities based on # of reviews
select a entity from a list of entities based on the release year assume that the entities are all film
return release year as int from the description of a film
start next conversation with a random entity
pick a random comment args : flow : the flow class decision : decision made by classifier return : void returns :
pick a random positive comment
pick a random negative comment
pick a random comment with opposite sentiment
pick a type set flow.tid
pick entities based on keywords
"give an overall review for an entity if curr_eid is none , set ' cur_percent ' to none if curr_eid is not none , set a ' cur_percent ' field in session to be a float of num_pos / num_all"
"narrow down the target list if the state is in rangeinitiative substep , set tid and return if the state is in typeselected substep , set eid and return"
get the details for a specific alarm .
get a list of alarms .
delete a specific alarm .
update a specific alarm .
patch a specific alarm .
history of a specific alarm .
history list of alarm state .
initialize a new http client for the monasca api .
create an alarm definition .
get the details for a specific alarm definition .
get a list of alarm definitions .
delete a specific alarm definition .
update a specific alarm definition .
patch a specific alarm definition .
run the unit tests .
post to this url to update this item 's state when the doorbell is pressed or released .
post to this url to update this entity_id when the doorbell is pressed or released .
"set the timeout , in seconds , after which we give up on trying to get a url ."
"set the timeout , in seconds , that must pass after an off press before we send openhab an off state change . prevents ' spamming ' openhab with tons of update events if someone pounds the doorbell relentlessly ."
post separate payloads to separate endpoints when the doorbell is pressed and released .
informs home automation whenever the doorbell is pressed or released .
reset can not be reverted
: rtype : lisp.layouts.cue_layout . cuelayout
: rtype : lisp.cues.cue_model . cuemodel
show the layout - selection dialog
save the current session into a file .
load a saved session from file
register a item for ref_class .
remove all the occurrences of the given item .
return an iterator over items registered with ref_class or subclasses .
remove all the items for ref_class .
return a view - like object of all the registered references .
: rtype : lisp.core.cue_model . cuemodel
: rtype : lisp.core.model_adapter . modeladapter
"return the current cue , or none ."
"return the current index , or -1 ."
set the current cue .
set the current cue by index
execute the current cue and go ahead .
destroy all the layout elements
"return the last cue in the context - menu scope , or none"
"return a list of all selected cues , filtered by cue_class"
select all the cues
deselect all the cues
search for files that match ` regex ` in ` directory ` .
hack to always set called_with to none
get private key from pem file .
encode public key to url - safe base64 format .
fill missing padding ( =) in base64 encoded string / bytes .
converts luminosity distance to redshift by solving the equation 'd - z=0 ' .
"converts log(nu / hz ) , log(nu lnu [ erg / s ] ) , error in log(nulnu ) to log(lambda / micron ) , log(fnu / mjy ) , error in log(fnu ) . the input units are cgs ."
"given the input angular size and distance to the object , computes the corresponding linear size in pc ."
convert array of periods in days to frequencies in hz .
convert array of frequencies to periods .
reads config file and gets parameters .
"given the directory where the results of an enrico analysis are located ( enrico_sed ) , this method plots the different count maps ( observed , model and residuals ) ."
this method plots some count map . inherited from the method plotmaps above .
from enrico / tsmap.py .
return the name of a file where the result of 1 pixel evaluation will be stored
converts from met fermi time to a python datetime tuple .
"fixes the start time of observations taken with lat . this assumes that the time array in your light curve is in days already , and the beginning of your analysis coincides with t0 for lat ."
script or widget should not crash if importing is cancelled and result is none which can not be iterable . gh-68
test seeing a first auth
test seeing a first auth b2b
test that we can get and set after auth
test that we can get and set after auth b2b
the original and still very useful way to generate a div elegant form / formset : :
renders only form errors the same way as django - crispy - forms : :
renders a form field like a django - crispy - forms field : :
write ' rootobject ' as a plist to pathname or return as a string .
search for near - matches of subsequence in sequence
a contract is a special transaction without the ` to ` argument .
sign this transaction with a private key .
returns the address of a contract created by this tx
run the text as python code .
save the text to disk .
get the object 's children .
standard menus for network nodes
inserts a new valueobject record into a table : param migration_vo : migrationvo
"fetches the most recent record from table by "" create_date "" : return : migrationvo"
checks if the migrations table is already exists : returns boolean
drops dbmake 's auxiliary migrations table : return : boolean
": param migration_file : full path to a migration file including the file 's name : raise attributeerror , ioerror"
"applies the migration 's "" migrate up "" statements on a database via db_adapter 's connection"
"applies the migration 's "" migrate down "" statements on a database via db_adapter 's connection"
returns migrationvo that represents a new migration record with the migration 's params
: param target_revision : migration revision to migrate to : return :
returns a sorted list of migrations instances representing migrations files within the manager 's migrations directory
returns a sorted list in ascending order of available migration revisions in the migration directory : return :
returns a value of the most recent migrations revision : return : int
initialize variables and start download speed test
start download speed thread
run speed test
test download speed by retrieving a file
return true if it is time to run a new download speed test
start a new download speed test if necessary and return the download speed
"return cpu temperature , load average and usage info as a dict"
return dict with overall cpu usage
return cpu load
get cpu temperature
"get cpu average load for the last one , five , and 10 minute periods"
selector que será atualizado ao finalizar execução
adiciona o model no context
"ao criar algum item , já relacionar seu content type baseado na url ."
retornar json com resposta valida
verificar se o submit foi para deletar
"generates a javascript function containing the rules defined in this map , to be used with a mapadapter 's generate_javascript method . if you do n't pass a name the returned javascript code is an expression that returns a function . otherwise it 's a standalone script that assigns the function with that name . dotted names are resolved ( so you an use a name like ' obj.url_for ' )"
generate a numpy array containing a disc .
generate a gaussian of the form g(x ) = height*exp(-(x - center)**2 / width**2 ) .
this function returns the best shape for computing a fft
cartesian to polar coordinates .
polar to cartesian coordinates .
polar to logpolar coordinates .
compute the projection indices from retina to colliculus
invoked to rank all the items for the user
sends a graph to the receiver service and returns the : mod:`requests ` response object
"retrieves a public network from pybel web . in the future , this function may be extended to support authentication ."
loads a bel graph from an iterable over the lines of a bel script
loads a bel graph from a file resource . this function is a thin wrapper around : func:`from_lines ` .
loads a bel graph from a url resource . this function is a thin wrapper around : func:`from_lines ` .
: param namespace : : return :
: param namespace : : param version : : return :
gets a bel namespace file from artifactory given the name and version
: param module_name : : return :
: param module_name : : param version : : return :
gets a bel annotation file from artifactory given the name and version
: param module_name : : return :
formats the module name and version for a bel script
gets a bel knowledge file from artifactory given the name and version
gets the right name for the next version of the namespace
gets the right name for the next version of the annotation
: param str module_name : : rtype : str
helps get the artifactory path for a certain module
gets the artifactory path for a namespace module
gets the artifactory path for an annotation module
gets the artifactory path for a knowledge module
helps get the latest path for a given bel module by paremetrizing the getter
"gets the latest path for this bel namespace module . for historical reasons , some of these are not the same as the keyword . for example , the module name for hgnc is ` ` hgnc - human - genes ` ` due to the selventa nomenclature . see https://arty.scai.fraunhofer.de/artifactory/bel/namespace/ for the entire manifest of available namespaces ."
gets the latest path for this bel annotation module
gets the latest path for this bel annotation module
"parses an iterable of lines into this graph . delegates to : func:`parse_document ` , : func:`parse_definitions ` , and : func:`parse_statements ` ."
parses the lines in the document section of a bel script .
parses the lines in the definitions section of a bel script .
parses a list of statements from a bel script .
logs simple information about a graph
converts this graph to a node - link json object
writes this graph to the given path as a node - link json
writes this graph as node - link json to a file
dumps this graph as a node - link json object to a string
builds a graph from node - link json object
builds a graph from a file containing node - link json
builds a graph from the node - link json contained in the given file
reads a bel graph from a node - link json string
looks up a node by the hash of a pybel node tuple
looks up a node by its data dictionary by hashing it then using : func:`get_node_by_hash `
looks up an edge by the hash of a pybel edge data dictionary
gets a citation object by its type and reference
gets a citation object by its pubmed identifier
gets a citation object by its hash
gets an author by name if they exist in the database
looks up evidence by its hash
adds the sialic acid subgraph for all query tests
tests a what happens with a named complex
gets the current iso 8601 date as a string
checks if a string is a valid url
"uses requests to download an url , maybe from a file"
builds a bel graph from edges
counts the number of nodes in the cache
looks up a node by the hash and returns the corresponding pybel node tuple
looks up a node by the pybel node tuple
builds and runs a query over all nodes in the pybel cache .
counts the number of edges in the cache
gets the edges with the given citation
gets the edges with the given citations
searches edges with the given evidence
searches edges with given bel
: param str annotation : : param str value : : rtype : list[edge ]
see usage in self.query_edges
builds and runs a query over all edges in the pybel cache .
builds and runs a query over all citations in the pybel cache .
gets all edges annotated to the given documents
: param list[int ] node_ids : a list of node identifiers
gets all edges between any of the given nodes
: param list[int ] node_ids : a list of node identifiers
gets all edges incident to any of the given nodes
change the values of * cshlib_pattern * and * cxxshlib_pattern * to remove the * lib * prefix from library names .
create : py : class:`waflib . tools.perl.xsubpp ` tasks to process * .xs * files
"check if perl is installed , and set the variable perl . minver is supposed to be a tuple"
check if specified perlmodule is installed .
check for configuration needed to build perl extensions .
add the ` ` --with - perl - archdir ` ` and ` ` --with - perl - binary ` ` command - line options .
builds the message to print on ` ` waf --help ` `
finds the optimal amount of cpu cores to use for parallel jobs . at runtime the options can be obtained from : py : const:`waflib . options.options ` : :
wraps ` ` optparse.add_option ` ` : :
wraps ` ` optparse.add_option_group ` ` : :
wraps ` ` optparse.get_option_group ` ` : :
parses arguments from a list which is not necesarily the command - line .
see : py : func:`waflib . context . context.execute `
detects a suitable d compiler
this is how to provide compiler preferences on the command - line : :
task generator customising the options etc . to call perl for running a script .
override the ' compiling ' default .
more useful output .
"compile * d * files . to get .di files as well as .o files , set the following : :"
see feature request # 104 : :
process the attribute ' header_lst ' to create the d header compilation tasks : :
"find a f # compiler , set the variable fsc for the compiler and fs_name ( mono or fsc )"
detects the aix c++ compiler
flags required for executing the aix c++ compiler
create : py : class:`rst ` or other rst - related task objects
try to find the rst programs .
a recursive regex - based scanner that finds rst dependencies .
check an exit status and raise an error with a particular message
runs the rst compilation using docutils
"finds the program clang++ , and executes it to ensure it really is clang++"
"replaces existing buildcontext methods to verify parameter names , for example ` ` bld(source= ) ` ` has no ending * s *"
modifies existing classes and methods to enable error verification
error verification can be enabled by default ( not just on ` ` waf -v ` ` ) by adding to the user script options
read and return the temperature of one ds18x20 device . pass the 8 - byte bytes object with the rom of the specific device you want to read . if only one ds18x20 device is attached to the bus you may omit the rom parameter .
read and return the temperatures of all attached ds18x20 devices .
convert the raw temperature data into degrees celsius and return as a float .
the main function
overridden from handler ; actually emit the log entry .
broadcasts telemetry data to all connected clients .
tests loading waypoints from a kml format file .
tests the current waypoint .
tests the raw waypoint .
tests waypoints being reached .
tests the next waypoint method .
tests the done method .
the generator should also support zipped kml files ( kmz ) .
returns a kml waypoint generator .
builds and returns an argument parser .
main function .
tests circle line intersection none case .
tests circle line intersection degenerate case .
tests circle line intersection two points case .
adds two points .
tests the tangent distance calculation .
tests the chase waypoint generation .
return package version as listed in ` _ _ version _ _ ` in ` init.py ` .
"overwrite the _ require_model_perm , to make sure that you can not modify a superuser as non superuser"
store the groups of the user .
add the has_permission as a filter
login the user
logout the user
"given a username , return matching user(s ) who should receive a reset ."
makes sure the username is always stored as a lowercase
"can be used to filter deleted users , or unfilter them ."
"allows the user to be soft deleted , and undeleted . what actually needs to be done on soft deletion can be implemented in"
"adds an endpoint to do a reset request . generates a token , and calls the _ send_reset_mail callback if the reset request is successful"
endpoint that can be used to send an activation mail for an user . calls the _ send_activation_email callback if the user is succesfully activated
adds an endpoint to activate an user . also logs in the user
resets the password from an reset code
helper function that actually resets the password for an user
change the password from an old password
adds an endpoint to check if an email exists or not
callback called after an user is softdeleted or softundeleted
callback to send the actual reset mail using the token .
callback to send a mail notifying that the user is activated .
returns information about the user
returns information about the group
maps a query to a function if the pattern matches and returns result
returns a streaminghttpresponse with the file
writes the uploaded file to path and returns the path
returns a directory listing of path ( as an array )
returns a list of all the systems available
replace an event 's uid with e41jrqx2db4p1aqzi86bat7nhpbhpriihqka .
: param rva : virtual address relative to owner 's object image base : type rva : int : param owner : the object owner address relates to : type owner : cle . backend
loads address translator with lva
loads address translator with mva
loads address translator with rva
loads address translator with raw address
va - > lva : rtype : int
rva - > mva : rtype : int
rva - > rva : rtype : int
rva - > raw : rtype : int
makes a copy of obj into cle 's tmp directory .
return the segment name at address ` addr ` ( ida ) .
locate the section ( e.g. .got ) that should be updated when relocating functions ( that 's where we want to write absolute addresses ) .
is ` addr ` in the proper section for this architecture ?
return the function name at address ` addr ` ( ida ) .
resolves a bunch of symbols denoted by the list ` symbols ` .
get the address of the symbol ` sym ` from ida .
get the binary exports names from ida and return a list .
extract imports from binary ( ida ) .
callback function for ida 's enum_import_names .
extract imports from the binary . this uses the exports we get from ida and then tries to find the got entries related to them .
get the min address of the binary ( ida ) .
get the max address of the binary ( ida ) .
"resolve import for symbol ` sym ` the dirty way , i.e. find all references to it in the code and replace it with the address ` new_val ` inline ( instead of updating got slots ) . do n't use this unless you really have to , use : func:`resolve_import_with ` instead ."
"resolve import ` name ` with address ` newaddr ` . that is , update the got entry for ` name ` with ` newaddr ` ."
is the address ` addr ` in thumb mode ? ( arm ) .
extract strings from binary ( ida ) .
returns whether a binary is statically or dynamically linked based on its imports .
"not documenting this since if you try calling it , you 're wrong ."
the address of this symbol in the global memory space
whether this symbol is a function
"the name of this symbol , run through a c++ demangler"
"if this symbol is a forwarding export , return the symbol the forwarding refers to , or none if it can not be found ."
make the reverse complement of a dna sequence . you can also just make the complement or the reverse strand ( see options ) .
count the kmers of length k in a string
initialize plots based off the length of the data array .
update the plots with new data x. assumes x is a one - dimensional array .
"constructs an actionpanel assuming actions_arr is an array of fully initialized actions . each action must have : key , name , func . each action can have : axis_pos , keyboard_binding , ps3_binding ."
transforms a string into bool args : user_input ( str ): the string parameter retuns : bool : a true or false value
send a message though websockets .
browser was connected
browser was disconnected
"try : self.tb.run ( ) except keyboardinterrupt , ex : self.tb.stop ( )"
"build the authentication variables emarsys ' authentication system asks for . : return : nonce , created , password_digest ."
build the headers emarsys ' authentication system asks for . : return : headers .
make an authenticated synchronous http call to the emarsys api using the requests library . : param method : http method . : param endpoint : emarsys ' api endpoint . : param headers : http headers . : param payload : http payload . : param params : http params . : return : dictionary with the result of the query .
define custom tag handler to join paths with the path of the marmot module
reproduce the problem in https://github.com/bigchaindb/bigchaindb/issues/617
get log location .
run the app .
main entry point .
get version and version_info without importing the entire module .
"given a todo item , return a new instance of a todo item with the dates shifted according to the recurrence rule ."
"returns height of the widget , with maximum set to 4 lines ."
returns margin for rendering the widget always glued to the cursor .
"creates proper urwid . text widgets for all completion candidates from p_completions list , and populates them into the items attribute ."
additional flags .
actions specific to this command .
the core operation on the todo itself . also used to operate on child / parent tasks .
test progress of task with no length
test progress of task with no length ( but with creation date ) .
test progress of task with no length
test progress of task with no length ( but with creation date ) .
test overdue tasks
test overdue tasks
due today ( 256 )
due tomorrow ( creation date )
due tomorrow ( creation date )
due tomorrow ( recurrence )
due tomorrow ( recurrence )
due tomorrow ( creation date + recurrence )
due tomorrow ( creation date + recurrence )
due tomorrow ( creation date + recurrence + start date )
due tomorrow ( creation date + recurrence + start date )
due tomorrow ( creation date + strict recurrence + start date )
due tomorrow ( creation date + strict recurrence + start date )
due tomorrow ( creation date + start date )
due tomorrow ( creation date + start date )
due tomorrow ( creation date + start date )
due tomorrow ( creation date + start date )
start date after due date
start date after due date
creation date after due date
progress color determined by parent
progress color determined by parent
progress color determined by parent
allow priority to be set including parentheses .
allow lowercase priority to be set .
do n't prioritize unrelevant todo items .
force prioritizing unrelevant items with additional -x flag .
throw an error with invalid argument containing special characters .
test that there 's only one capital surrounded by non - word characters that makes up a priority .
test that there 's only one capital surrounded by non - word characters that makes up a priority .
main entry point of the prompt interface .
reads the configured todo.txt file and loads it into the todo list instance .
main entry function .
applies the colors .
prepends the number to the todo string .
"returns a list of grepfilters , ordinaltagfilters or negationfilters based on the given filter expression ."
filters a list of todos . truncates the list after p_limit todo items ( or no maximum limit if omitted ) .
"perform just after the dependencyfilter , but before any other filters ."
returns true when there are no children that are uncompleted yet .
"perform early before any other items are filtered out , possibly breaking the dependency chain ."
returns true when p_todo appears in the list of given todos .
returns true when p_todo does n't have a tag to mark it as hidden .
returns true if conditional constructed from both operands and self.operator is valid . returns false otherwise .
performs a match on a key : value tag in the todo .
performs a match on a priority in the todo .
"do the curve conversion ahead of time , and run tests on results ."
"print stats from conversion , as determined during tests ."
tests that the results of conversion have n't changed since the time of this test 's writing . useful as a quick check whenever one modifies the conversion algorithm .
test that conversion results are unchanged for multiple curves .
test that conversion results do not exceed given error tolerance .
test that error tolerance is n't exceeded for multiple curves .
max distance between a bezier and quadratic spline at sampled points .
"export a gif from the input frames , scaled down to 720p"
export all input frames as pngs inside a zip
return package mentioned in the given file . args : requirements_file ( str ): path to the requirements file to be parsed . returns : ( list ): 3rd - party package dependencies contained in the file .
test ecdsa_to_hex ( ) .
test create command .
test create command .
test get command .
test list command .
获取当前使用浏览器名称 : returns : todo
property is a list of : unicode
property is a list of : unicode
property is of type : linedatatype
property is of type : linedatatype
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : long
property is of type : long
property is of type : timeunit
property is of type : timeunit
property is of type : unicode
property is of type : unicode
property is a dictionary with values of type : object
property is a dictionary with values of type : object
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is a list of : step
property is a list of : step
property is of type : bool
property is of type : bool
property is of type : bulkstatus
property is of type : bulkstatus
property is of type : bool
property is of type : bool
property is of type : bool
property is of type : bool
property is of type : unicode
property is of type : unicode
property is of type : int
property is of type : int
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is a list of : destination
property is a list of : destination
property is of type : binarycontent
property is of type : binarycontent
property is of type : bool
property is of type : bool
property is of type : language
property is of type : language
property is of type : unicode
property is of type : unicode
property is of type : bool
property is of type : bool
property is of type : bool
property is of type : bool
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : datetime
property is of type : datetime
property is of type : deliverytimewindow
property is of type : deliverytimewindow
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : unicode
property is of type : to
property is of type : to
return version number as specified in the version file .
construct an array by tiling a given array .
maxout activation function .
permutates a given variable along an axis .
declares that user is using an experimental feature .
2d spatial transformer sampler .
creates an array of pointers to matrices
computes the matrix multiplication of two arrays .
computes the batch matrix multiplications of two sets of arrays .
converts the given image to the numpy array for vgg models .
converts a pre - trained caffemodel to a chainer model .
"_ _ call__(self , x , layers=['prob ' ] )"
"extract(self , images , layers=['fc7 ' ] , size=(224 , 224 ) )"
computes all the probabilities of given images .
maximum of array elements over a given axis .
minimum of array elements over a given axis .
returns index which holds maximum of array elements over a given axis .
returns index which holds minimum of array elements over a given axis .
computes triplet loss .
builds a graph of functions and variables backward - reachable from outputs .
the text that represents properties of the node .
converts graph in dot format .
dumps graph as a text .
computes the determinant of a batch of square matrices .
computes the determinant of a single square matrix .
linear unit regularized by simplified dropconnect .
concatenated rectified linear unit function .
returns self .
returns the next batch .
python2 alternative of ` ` _ _ next _ _ ` ` .
finalizes the iterator and possibly releases the resources .
serializes the internal state of the iterator .
computes the sum - squared cross - covariance penalty between ` ` y ` ` and ` ` z ` `
l2 norm squared ( a.k.a.\ euclidean norm ) .
run current test cases of the file .
decorator for testing unary mathematical chainer functions .
inserts the new node at the beginning of the list .
inserts the new node after a given node in the list .
removes the first node ( if any ) in the list .
removes the node ( if any ) that follows the provided node in the list .
generates a random height ( between ` ` 2 ` ` & ` ` self.max_layers ` ` ) to fill in .
looks for a given value within the skiplist .
prints a representation of the skiplist 's structure .
run a landmark request on a single image
copy over all required resources .
a utility method used to create a list of qt frameworks linked into the argument .
copy the qt framework into the bundle .
file is expected to be the path as output from tool
file is expected to be the path as output from otool ' where ' is the path relative to the installdirectory
copies over and process all linked qt frameworks .
utility function to be called by processplugins ( ) . plugindirectoryname is the name of a plugins subdirectory to copy over .
copies over and process all qt plugins .
moves the binary to the correct location
create a dmg bundle
main expects three arguments :
run manage.py on development
run manage.py on production
run django 's dev server
run django 's standart shell or shell from django_extentions application if ` shell_plus = true `
"run django 's tests . argument can be application name , name of test class or method of test class"
"put remote fixtures to repository on production , get and load them on development"
callback function generator : return : callback function
mock data generator .
helper function to fix the first value .
convert a sequence ( slice of the corpus ) into a matrix ( numpy ) of one - hot vectors corresponding to indices in values_indices
compute softmax values for each sets of scores in x.
converts a label ( int or string ) into the corresponding emoji code ( string ) ready to be printed
"given x ( sentences ) and y ( emoji indices ) , predict emojis and compute the accuracy of your model over the given set ."
implements the sigmoid activation in numpy
implement the relu function .
implement the backward propagation for a single relu unit .
implement the backward propagation for a single sigmoid unit .
compute the sigmoid of x
compute the relu of x
arguments : layer_dims -- python array ( list ) containing the dimensions of each layer in our network
implement the cost function
implements the forward propagation ( and computes the loss ) presented in figure 2 .
implement the backward propagation presented in figure 2 .
this function is used to predict the results of a n - layer neural network .
used for plotting decision boundary .
"returns the next possible token , advancing the iterator to the next position to start processing from ."
"generator for latex tokens on text , ignoring comments ."
marker for a token
process command that augments or modifies punctuation .
"process command , but ignore line breaks . ( double backslash )"
process a line comment
process both optional and required arguments .
prevents math from being tokenized .
process a string of text
read next expression from buffer
read the item content .
read the environment from buffer .
read the environment from buffer .
read the argument from buffer .
runs the bot .
sends a message in the constant format .
sends an error message .
kills all sessions to reduce lag .
cleans and reports if an error occurred
fetches information from the config .
sets up the driver profile .
gets the webhook url .
gets the voyage link .
prints a line .
checks whether a given file - like object is closed .
asserts whether all headers have been successfully parsed . extracts encountered errors from the result of parsing headers .
checks whether the request of a response has been a head - request . handles the quirks of appengine .
returns a basic auth string .
"takes the given response and tries digest - auth , if needed ."
maps values to attributes only called if there * is not * an attribute with this name
maps attributes to values only if we are initialised
check that a timeout attribute is valid .
"returns the 1 - based byte index where the completion query should start . so if the user enters : foo.bar^ with the cursor being at the location of the caret ( so the character * after * ' r ' ) , then the starting column would be the index of the letter ' b ' ."
"returns the 1 - based codepoint index where the completion query should start . so if the user enters : ƒøø.∫å ® ^ with the cursor being at the location of the caret ( so the character * after * ' ® ' ) , then the starting column would be the index of the character ' ∫ ' ( i.e. 5 , not its byte index ) ."
returns a copy of the dictionary with the _ sre . sre_pattern instances in each set value replaced with the pattern strings . needed for equality test of two filetype trigger dictionaries .
determines whether or not the semantic completer should be called .
return comments which should be exported .
checks the given path for the last exported comment 's i d
saves the last_pk into the given state_file
analytic solution [ 1 ] of the general quartic equation . the solved equation takes the form :
dummy main function to enable multiprocessing on windows
get word index .
convert an iterable of word indices into words .
get imdb data for training and validation .
train a model for imdb sentiment classification .
how to run :
app.yaml never has to be version : default
requirements : - install pip with distribute ( http://packages.python.org/distribute/ ) - sudo pip install mock - sudo pip install webtest - sudo pip install pyquery
verify the number of plurals in the translation .
verify the format string placeholders in the translation .
test format string ` alternative ` against ` format ` . ` format ` can be the msgid of a message and ` alternative ` one of the ` msgstr`\s . the two arguments are not interchangeable as ` alternative ` may contain less placeholders if ` format ` uses named placeholders .
fill_none : if name / version is not detected respective key is still added to the result with value none
"- > ( os , browser ) # tuple of strings"
= > version string /none
update status bar with error .
show all errors .
error was selected - go to error .
do lint on file save if not denied in settings .
selection was modified : update status bar .
returns readme.rst contents as str
"parse a page of html , and yield items into the item pipeline"
"set the logger for the spider , different than the default scrapy one"
"purpose of this method is to reconstruct the headers dictionary that is normally passed in with a "" response "" object from scrapy ."
processes a vaild action info request
wrapper for purging the crawlid from the queues
actually purges the crawlid from the queue
we could intercept a special dataset and return different data providers
create an image structure for the driver
create a sentence structure for the driver
"return size of a split , either number of sentences or number of images"
sample image sentence pair from a split
arguments are passed onto ` pexpect.spawn `
sets up the members
retrieves the ids of the listeners that requested to handle this event
tests if the given properties match the given filter
"retrieves the reference and the service associated to the given id , or a ( none , none ) tuple if no service was found ."
notifies the handlers of an event
adds the eventadmin specific properties to the event
sends synchronously the given event
sends asynchronously the given event
aggregates all content makers
prints basic isolate information
prints ipopo components instances details
lists the bundles installed
lists the services registered
prepares the section about process threads
handles a get request
sets up members
returns supported kind of vote
returns the options available for this engine
analyzes the results of a vote
sets up the event
retrieves the modified bundle
retrieves the kind of event
sets up the event
"returns the previous values of the service properties , meaningless if the the event is not modified nor modified_endmatch ."
returns the reference to the service associated to this event
returns the kind of service event ( see the constants )
* * deprecated :* * use get_kind ( ) instead
recursively visits the class hierarchy to find all slots
returns the names of the fields of the given object
transforms the given object into a json - rpc compliant form . converts beans into dictionaries with a _ _ jsonclass _ _ entry . does n't change primitive types .
"if ' obj ' is a dictionary containing a _ _ jsonclass _ _ entry , converts the dictionary item into a bean of this class ."
returns the options available for this engine
analyzes the results of a vote
prepares arguments to run an executable
starts an isolate with the given configuration and its monitoring threads
normalizes the given list of values : it must only contain numbers or strings
appends the given code to the existing html code
prepare a list in html
makes a bar chart of the given results using nvd3
"counts the "" for "" and "" against "" ballots"
prepares the html code to draw a chart
makes a whole html page for the given vote content
sets up members
adds a topic listener
removes a topic listener
a new mqtt listener has been bound
a listener has been updated
an mqtt listener is gone
control loop to let each client check its messages
a message has been received from a server
notifies listeners of an mqtt message
subscribes to a topic in all servers
unsubscribes from the topic from all servers
publishes an mqtt message
sets up members
publishes an mqtt message
decorator for api using token based authentication
initialize the flask login manager
return assessment model as json object
print puppyscripts as a list of puppyscript ids .
print puppyscripts as a string of puppyscript ids .
return assessment model as json object
"given an object and optional parameters , returns a string identifying the object uniquely ."
this method is the opposite of ` ` get_identifier ` ` . it resolve the object 's identifier to an actual model .
"if raw_id = false : returns a list of ` ` similarity ` ` objects for given ` ` obj ` ` , ordered by score . else : returns a list of similar ` ` model ` ` ids[pk ] for given ` ` obj ` ` , ordered by score ."
"if raw_id = false : returns a list of ` ` recommendation ` ` objects for given ` ` user ` ` , ordered by score . else : returns a list of recommended ` ` model ` ` ids[pk ] for given ` ` user ` ` , ordered by score ."
stores all the recommendations .
deletes all recommendations for object ` ` obj ` ` .
deletes all similarities that have object ` ` obj ` ` as source or target .
acquire a storage - specific lock
release a storage - specific lock
constructor which also logs the exception .
json - rpc wrapper .
returns an ordereddict with the bitcoin server configuration .
constructor . parses rpc communication details from ` ` bitcoin.conf ` ` and opens a connection to the server .
attribute getter . assumes the attribute being fetched is the name of a json - rpc method .
performs a json - rpc command on the server and returns the result .
chech that the entered recaptcha data is correct
templatetags absolute_url use for get full url of the current request context it pass context and url and return full url
templatetags absolute_url use for get full url of the current request context it pass context and url it will return blank string when context is none
"templatetags auto_update_year_range pass string of start year and return itself when current year is equal to start year . if start year is provided and not current year it will return year range in format ' { start_year } - { current_year } ' . otherwise , it will return current year when start not provided"
calls self.write ( )
"write a string to file , stripping newlines and reformatting"
"write a string to file , preserving newlines fed in"
command line argument parser . parses the arguments
"return an array like [ 0 , 0 , ... , 1 , ... , 0 , 0 ]"
turns a row vector into a column vector
least squares multivariate polynomial fit
create a callable python function out of beta / powers from multipolyfit
: arg dim : number of cells : key peepholes : enable peephole connections ( from state to gates ) ?
tell wether the current offset is the maximum offset .
": key maxlines : number of plots to draw and so max id . : key autoscale : if set to a factor > 1 , axes are automatically expanded whenever out - range data points are added : var indexlist : the x - component of the data points : var datalist : the y - component of the data points"
set an offset that modifies all subsequent references to line ids
appends additional lines as necessary
the given data point or points is appended to the given line .
data series id0 is replaced by the given lists
writes the data series for all points to a file
set axis labels and title
hand parameters to the legend
"hand parameters to the specified line(s ) , and set them as default for new lines"
"updates the current plot , if necessary"
plots the data internally and saves an image of it to the plotting directory .
crowding distance - measure for multiple objectives .
return a subset of items from iterable which are not dominated by any other item in iterable .
return a subset of items from iterable which are not dominated by any other item in iterable .
return a subset of items from iterable which are not dominated by any other item in iterable .
return a list that is sorted in a non - dominating fashion . keys have to be n - tuple .
initialize an mdrnnlayer .
re - initialize the environment
is the current episode over ?
execute one action .
a filtered mapping towards performaction of the underlying environment .
return the accumulated reward since the start of the episode
"an episodic task can be used as an evaluation function of a module that produces actions from observations , or as an evaluator of an agent ."
"returns the state one step ( dt ) ahead in the future . stores the state in self.sensors because it is needed for the next calculation . the sensor return vector has 3 elements : theta1 , theta2 , s ( s being the distance from the origin ) ."
"auxiliary access to just the pole angle(s ) , to be used by balancetask"
"auxiliary access to just the cart position , to be used by balancetask"
build a url to display graphs for the given repo .
generic method to show graphs .
called to show every graphs
used to archive the given ` path ` .
main function called when start from command line .
fixed version of write supporting bitflag 0x08 to write crc and size at end of file .
run the notification and check if mails are sent
run the notification and check if mails are sent
check email template generation .
check if this convertion is working fine .
return the list of repositories .
crawl all the pages to find broken links .
return a single page .
called to add a new key to an authorized_keys file .
called for delete a key from an authorized_keys file .
check if relative path are resolved .
browse repository root .
browse root restore page .
browse to a sub directory being deleted .
browse to restore page of a deleted directory .
browse to a sub directory .
browse to a sub directory containing special chars .
browse to restore page of a sub directory containing special chars .
browse to sub directory with non - ascii .
browse to a directory with quoted path ' ; 090 ' .
browse to an invalid repository .
browse to an invalid path .
verify if rdiff - backup - data is not accessible .
verify if browsing ' /browse/ ' for a single repository is working .
check creation of user with non - ascii char .
verify failure trying to create user without username .
verify failure trying to add the same user .
verify failure to add a user with invalid root directory .
verify failure to delete invalid username .
verify failure to delete our self .
verify failure trying to update user with invalid path .
verify failure trying to update invalid user .
check if admin filter is working .
check if user search is working .
check if adding user is forbidden .
check if deleting user is forbidden .
check if editing user is forbidden .
check if listing user is forbidden .
return package version as listed in ` _ _ version _ _ ` in ` init.py ` .
this will be a lie for a while . i 'll have to fix it later .
initializes a new cache object for storing data between events .
update and return the datetime that a monster expires .
update and return the datetime that a stop expires .
update and return the datetime that an egg expires .
update and return the datetime that a raid expires .
update and return the team_id of a gym .
update and return the gym_name for a gym .
update and return the gym_desc for a gym .
update and return the gym_image for a gym .
update and return weather_id for a cell
update and return severity_id for a cell
update and return day_or_night_id for a cell
cleans the cache and saves the contents if capable .
export the data to a more permanent location .
clean expired objects to free up memory .
gl function called each time a frame is drawn
return the current scene as a pil image .
parse a card from an input string
parse a section in the input file denoted by parse_inpspec .
parse intrinsic reaction coordinate calculation . returns a dictionary containing :
parse a geometry string and return molecule object from it .
parse the ouput resulted of a geometry optimization . or a saddle point .
parse the output resulted from a tddft calculation .
"a selection is an object that keeps state of the selected status of a collection of entities , such as atoms or bonds ."
an array of values that belong to the current chemicalentity .
an array of values that connects items belonging to the same dimension
a single value that belongs to the current chemicalentity
return a sub - attribute
display the molecule * mol * with the default viewer .
display the system * sys * with the default viewer .
display the the system * sys * and instrument the trajectory viewer with frames information .
options passed by command line override all other configuration sources
options passed in system config override user config .
"if electrum is started with the "" portable "" flag , system configuration is completely ignored ."
"if no system - wide configuration and no command - line options are specified , the user configuration is used instead ."
"if the "" portable "" flag is set , the user can overwrite system configuration options ."
the user config does not contain command - line options or system options when saved .
"we pass a path but if does not contain a "" config "" file ."
return the ids of the requests that we sent
insert abbrpreprocessor before referencepreprocessor .
find and remove all abbreviation references from the text . each reference is set as a new abbrpattern in the markdown instance .
"given a string , returns an regex pattern to match that string ."
"view , code & submit problems directly from terminal ."
"view contests , problems and problem statement"
lists current and upcoming contests on a judge .
lists problems of a contest / category on the judge
display the termicoder contents in current / passed folder
"sets up problem , contests and login ."
creates & open code file with template code .
test code against the sample testcases .
submit a solution .
"launches custom debug interface ( in future ) where you can use testcase generator , launch debugger for the particular language and visualize the output"
create a sequence logo figure .
creates a folder if it does not exist .
load validation data produced by camv .
calculate channel levels using median channel levels .
i know this is correct .
"lambda iamb algorithm for learning the structure of a discrete bayesian network from data . this algorithm is similar to the iamb algorithm , except that it allows for a "" lambda "" coefficient that helps avoid false positives ."
max - min hill climbing algorithm for learning a bayesian network structure from data .
pretty self explanitory . goes through and generates mines and such
loads a dict of coord data onto the grid
dumps all coords on the grid
finds all points located around the radius
gets a coordinate from the grid
return the inertia matrix of a given dyadic for a specified reference frame .
return the integral for a vector integrand .
get user input
decode the byte data to a string if not none .
encode the parameter as a byte string .
join a sequence of strings together .
join a sequence of characters into a string .
"shuffle the data , called when one pass is over or at the beginning of training"
over write the ' run ' method of threading . thread
"find all internal bookmarks pointed to by hrefs in html , and make sure they are valid ."
run this action .
clean filename of problematic characters .
"get the project filename with the given extension ( .md , .htm , etc . ) ."
add mdepub argument structure to an instance of argumentparser .
a decorator to call check on item children
common checker for not and - operators
return true only if there are no error
list all errors
"if nothing matches the current node , visit children"
"on search field node , check nested fields logic"
"on phrase field , verify term is in a final search field"
"on term field , verify term is in a final search field"
run tests with pytest .
creates and trains ( using ' _ train ' ) a hmm to represent the given qtc sequences . main function to create and train the hmm . please override with special behaviour if necessary .
gnerating samples from the trained hmm given a maximum sample length and thee total number of samples .
computeed the loglikelihood for the given sample(s ) to be produced by the hmm .
transforms a list of qsr state chains to a list of lists of numbers according to the alphabet . needs to be overridden by the specific qsr to handle the correct symbols .
transforms a list of symbols to the corresponding qsr state chains . needs to be overridden by the specific qsr to handle the correct symbols .
method for the creation of the transition probability matrix . creates a uniformly distributed matrix . please override if special behaviour is necessary .
method for the creation of the emission probability matrix . creates a uniformly distributed matrix . please override if special behaviour is necessary .
extract qsr specific parameters from the qsrlib request call parameters .
return qsr value .
return qtcbs specific from qtccs .
terminates a python thread from another thread .
create a new : class:` . session ` with no automation enabled by default .
a synonym for : func:`relationship ` .
construct a dynamically - loading mapper property .
"create a back reference with explicit keyword arguments , which are the same arguments one can send to : func:`relationship ` ."
indicate a column - based mapped attribute that by default will not load unless accessed .
initialize the inter - mapper relationships of all mappers that have been defined .
remove all mappers from all classes .
a synonym for : func:`joinedload ( ) ` .
a synonym for : func:`joinedload_all ( ) `
"convert a mysql 's 64 bit , variable length binary string to a long ."
produce an inspection object for the given target .
"return true if this rule has been consumed , false if not ."
"return true if the last test of this rule passed , false if failed , none if no test was applied ."
return true if this rule has been consumed .
return an parser that handles all the arguments .
"test compilation of supply , use and elementary exchange tables , preserving traceability , from ecoinvent flow lists"
"test compilation of supply , use and elementary exchange tables , aggregating away traceability , from ecoinvent flow lists"
not technically a unit test ... more a it - runs - through - and - does - not - crash integration test
get command for pid from /proc
get pid from sender string using org.freedesktop . dbus . getconnectionunixprocessid
get user i d from sender string using org.freedesktop . dbus . getconnectionunixuser
get user for uid from pwd
get selinux context from sender string using org.freedesktop . dbus . getconnectionselinuxsecuritycontext
return command of d - bus sender
systemd_manager_interface.jobremoved signal handler
a dbus . interface object for systemd_manager_interface .
register a job to be followed to completion .
return a future for results of registered jobs .
"create a new model class . name - name of the new class to create bases - tuple of base classes . this defaults to ( models . model , ) . attrs - attributes that should be set on the new instance ( will be passed directly to the ` type ( ) ` call ) meta_attrs - extra attributes that should be set on the generated meta class ."
return the partition key for ' now ' . no need to implement this if you 're not using time - based partitioning .
return the partition key for ' next ' . no need to implement this if you 're not using time - based partitioning .
"return an iterable of tuples of name , manager pairs , which will be added to all partitions in the given order . order is important , as django regards the first manager as the default manager ."
"get the partition for this model for partition_key . by default , this will create the partition . pass create = false to prevent this ."
"populate the field cache attributes on model_meta using our own rules , skipping partition foreign keys ."
"store the args to the fk , and validate that what we are pointing to is a partitioned model ( todo )"
atomic transaction .
handle exception with transaction rollback .
change mode to guided .
change mode to nav .
move at specified velocity in meters / sec with absolute heading ( if already in guided mode )
convert incoming command into velocity
send a text message over a serial link max number of char for a gameboy screen is 18 truncate or pad with space when needed
thread running function
change auto2 mode to guided .
change auto2 mode to nav .
goto a local northeastdown position in meters ( if already in guided mode )
goto a local northeastdown position relative to current position in meters ( if already in guided mode )
goto to a position relative to current position and heading in meters ( if already in guided mode )
move at specified velocity in meters / sec with absolute heading ( if already in guided mode )
move at specified velocity in meters / sec with absolute heading ( if already in guided mode )
identify a remote player
send tcp packet to player for server interaction
send udp packet to player ( game logic interaction )
opens a fontchooser toplevel to allow the user to select a font : return : chooser.font result
: param master : master tk . tk instance : param kwargs : keyword arguments passed to toplevel initializer
puts all the child widgets in the correct position : return : none
callback if family is changed : param family : family name : return : none
callback if size is changed : param size : int size : return : none
"callback if properties are changed : param properties : ( bool bold , bool italic , bool underline , bool overstrike ) : return : none"
callback if any of the values are changed : return : none
"generate a font tuple for tkinter widgets based on the user 's entries : return : font tuple ( family_name , size , * options )"
": return : font tuple ( family_name , size , * options ) , font object"
destroy the window : return : none
cancel font selection and destroy window : return : none
initialize zwave scene
the string representation of the scene .
the i d of the scene .
the label of the scene .
set the label of the scene .
"create a new zwave scene on the network and update the object_id field if label is set , also change the label of the scene"
add a value with data value_data to the zwave scene .
set a value data to value_data in the zwave scene .
get all the values of the scene
get all the values of the scene grouped by nodes
remove a value from the scene .
activate the zwave scene .
return a dict representation of the node .
ensure we have expected default parameters
search a given package on a given repository ( id ) .
format a logentry in correct json
build a readable log message from a radius log entry .
turn radius log entry information into a canonical form
delete the base including its subtree and create it .
return an ldapexporter from ldap and orm users
"request the logs , assert validity , and return the response ."
: param interval interval : : return :
fetch the users who should be synced
execute the ldap sync given a connection and state data .
construct an exporter instance with non - raw parameters
consolidate current and desired records into necessary actions
remove all the comments in the code ( from the # to eol ) . returns a new string with the comments removed . this improves the detection rates a lot removing most of the false positives .
try to detect if a source file is python 2 or 3 . it uses a combination of tests based on ast extraction and regular expressions .
"in py2 , does nothing . in py3 , converts to bytes , encoding to unicode ."
"in py2 , does nothing . in py3 , converts to string , guessing encoding ."
"when py2 str.encode is called , it often means bytes.encode in py3 . this does either ."
"translates a matrix by ( x , y ) ."
"equivalent to apply_matrix_pt(m , ( p , q ) ) - apply_matrix_pt(m , ( 0,0 ) )"
eliminates duplicated elements .
order - preserving sorting function .
split a list into two classes according to the predicate .
returns a discrete range .
compute a minimal rectangle that covers all the points .
picks the object obj where func(obj ) has the highest value .
groups every n elements of the list .
unpacks 1 to 4 or 8 byte integers ( big endian ) .
decodes a pdfdocencoding string to unicode .
encodes a string for sgml / xml / html
a distance function between two textboxes .
"read the configuration file and return the variables in json format . input : nothing output : all js . * variables of webinterface.cfg in json format begun by andres heinloo < andres@gfz-potsdam.de > , geofon team , june 2013"
"it returns the javascript code to load the loader.js file in the main page . begun by marcelo bianchi < mbianchi@gfz-potsdam.de > , geofon team , june 2013"
format string by interpolating known variable .
return a structure with all the keys set .
run the playbook generated by the plugin .
retrieve a dci context from the dciclient .
retrieve informations about the job to run .
fetch the different components and prepare a repo file .
return the topic and remoteci details .
run the tripleo - collect - logs role on the specified hosts .
upload configuration files .
add a custom admin view . can be used as a function or a decorator .
add our custom views to the admin urlconf .
make sure our list of custom views is on the index page .
lorentzian function x : frequency coordinate a : peak position b : half width c : area proportional parameter d : base line
asymmetric width term x : frequency coordinate a : peak position b : half width s : asymmetry parameter
lorentzian asymmetric function x : frequency coordinate a : peak position b : half width c : area proportional parameter d : base line s : asymmetry parameter
damped harmonic oscillator ps function x : frequency coordinate a : peak position b : half width c : area proportional parameter d : base line
gaussian pdf function x : coordinate a : peak position b : deviation ( sigma ) c : area proportional parameter d : base line
convert value to list if not
this function compute the external force acting on a single blob . it returns an array with shape ( 3 ) .
this function compute the force between two blobs with vector between blob centers r. in this example the force is derived from a yukawa potential
this function compute the force between two bodies with vector between locations r. in this example the torque is zero and the force is derived from an harmonic potential
load a chain instance from files .
the number of sites .
number of bands .
save a chain instance to files .
hamiltonian without interaction terms .
"transform a 2 x 2 matrix to a 4 dimensional vector , corresponding to s0,sx , sy , sz component ."
transform a vector of length 3 or 4 to a pauli matrix .
get green 's function g from hamiltonian h.
plot data by pauli components .
"linearly interplolate or extrapolate a curve , optimizing scipy.iterpolate.iterp1d to allow extrapolation ."
a log mesh can make low energy component of rho(w ) more accurate .
returns a list of primes < n. used robert william method of high speed prime generation .
"computes lcm between two integers p , q"
using the euclidian extended algorithm
perform rsa encryption algorithm
perform rsa decryption algorithm
checks for prism version updates every hour
"adds the site title , the logged in user , and the version to each site for use by the base template"
allows plugins to load files from their own static directories
returns the current line number in our program .
it adds the header fields used for ros topics
"return a set of struct types to be generated . it is not to be generated if it has a field external_ros_def , or if it is already in infos.ros_types ."
"the msgtogen is a mapping ( dict ) from the data structtype to the msg filename . the required extra msg fields ( radl__flags , instrumentation , etc ) are automatically added . @returns the list of message files generated ."
"generate all the message files required for the provided ast , all of them are flattened in the specified package folder and name ( instead of generating each messages in their respective origin package ) . @returns the list of message files generated ."
generate the messages defined in ast as being part of the provided package folder and name . @returns the list of message files generated .
assumes the time provided is in nanoseconds . returns 4 meaning full digits .
the provided time values need to be positive and increasing .
the provided time values need to be positive and increasing .
"@argument instruments_to_use is the list of instruments to use . @argument nodes_to_track is expected to be a list of node qualified names . if the empty list is provided , nodes will be discovered on the fly ."
": param io : io instance that can load items . : param lazy : lazy parameter with which the container object using the list was loaded . : param items : optional , initial list of items ."
"parse ' po ' format produced by xgettext . return a list of ( msgid , msgstr ) tuples ."
check if a variable is defined
contains no statements
local variable exists ?
add a variable definition to the scope
find a variable in this scope or any parent scope
add a called function to this scope and to all parent scopes . this ensures that the main scope ( module ) will contain a list of all called functions and only the called functions will be linked .
add a executable statement to this scope
pops out the last statement inserted . used by block commands to extract the block from the statement list
generate an if block after the return statement
print the list of variables for debugging and compiler stats
print the list of statements for debugging and compiler stats
print statistics of the scope
an argument is a variable inside this block
add an argument to the list
print for debugging and statistics
print statistics of the scope
return serialized agent object .
return build object data in serializeable format
return serialized job .
return test object data in serializeable format
return serialized test build object .
return serialized node object .
return serialized release object .
return serialized plugin object
return serialized dfg object
return serialized squad object
return serialized component object
return test object data in serializeable format
return serialized object of bug model .
returns argparse parser .
runs web application .
main entry for running the web server .
"data = [ { ' number ' : 10 , failure : 200 , ... } , { ' number ' : 11 } ]"
genrate graphs from result file
return a ctypeid - objpk string for value .
run the parent 's method for each value .
"set the attribute , for futuremodelform ."
"get the attribute , for futuremodelform ."
plot overlay histogram .
plot a pseudocolor .
plot scatter matrix of all pseudocolors .
"define a l2loss , useful for regularize , i.e. weight decay . args : tensor : tensor to regularize . weight : an optional weight to modulate the loss . scope : optional scope for op_scope . returns : the l2 loss op ."
"batch normalization on convolutional maps . args : x : tensor , 4d bhwd input maps n_out : integer , depth of input maps phase_train : boolean tf . variable , true indicates training phase scope : string , variable scope affn : whether to affn - transform outputs return : normed : batch - normalized maps ref : http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow/33950177"
helper for getting layer output tensor
normalize the image range for visualization
provide a transactional scope around a series of operations .
строка со сплитами . winorient передает её в закодированном бинарном формате формат : [ ssssssttttttcc ] * ssssss - номер чипа в 16 - чной системе tttttt - время в 16 - чной системе сс - номер кп в 16 - чной системе
return a backend instance .
return a backend instance from a request .
default constructor .
create a new event .
retrieve an even using its uid .
retrieve a list of event .
delete an event using its uid .
extra permissions .
add extra menu entries .
set path at creation .
set path at creation .
create a travel time weight network graph in units of minutes from openstreetmap nodes and edges
"an utility method to register the service the first time . it is usually not required to call this function , as windivert will register itself when opening a handle ."
check if the windivert service is currently installed on the system .
"unregisters the windivert service . this function only requests a service stop , which may not be processed immediately if there are still open handles ."
checks if the given packet filter string is valid with respect to the filter language .
"opens a windivert handle for the given filter . unless otherwise specified by flags , any packet that matches the filter will be diverted to the handle . diverted packets can be read by the application with receive ( ) ."
indicates if there is currently an open handle .
closes the handle opened by open ( ) .
receives a diverted packet that matched the filter .
injects a packet into the network stack . recalculates the checksum before sending unless recalculate_checksum = false is passed .
get a windivert parameter . see pydivert . param for the list of parameters .
set a windivert parameter . see pydivert . param for the list of parameters .
constructs a lambda that may be called to extract the timestamp field from a given event .
performs iterative dictionary search based upon the following conditions :
"looks up the location that the term maps to and sets it to the given value . : returns : true if the value was set successfully , false otherwise ."
performs iterative dictionary search for the given term . : returns : the value identified by term or none if it can not be found .
increment a timestamp by milliseconds .
"pretty - format the given timestamp ( to be printed or logged hereafter ) . if tz , the timestamp will be converted to local time . format : yyyy - mm - dd hh : mm tz"
allows a timedelta ( td ) add operation on a string timestamp ( ts )
"convert obj to a hashable obj . we use the value of some fields from elasticsearch as keys for dictionaries . this means that whatever elasticsearch returns must be hashable , and it sometimes returns a list or dict ."
"takes an index , specified using strftime format , start and end time timestamps , and outputs a wildcard based index string to match all possible timestamps ."
converts a ` datetime ` object ` d ` into a unix timestamp .
this method destructively modifies document by replacing any dots in field names with an underscore .
returns an elasticsearch instance configured using an es_conn_config
"given a conf dictionary w/ raw config properties ' use_ssl ' , ' es_host ' , ' es_port ' ' es_username ' and ' es_password ' , this will return a new dictionary with properly initialized values for ' es_host ' , ' es_port ' , ' use_ssl ' and ' http_auth ' which will be a basicauth username : password formatted string"
convert ` ` unit = num ` ` spec into a ` ` timedelta ` ` object .
convert ` ` unit = num ` ` spec into a ` ` datetime ` ` object .
"given a python string that may contain references to fields on the match dictionary , the strings are replaced using the corresponding values . however , if the referenced field is not found on the dictionary , it is replaced by a default string . strings can be formatted using the old - style format ( ' % ( field)s ' ) or the new - style format ( ' { match[field ] } ' ) ."
read list of training or validation examples .
recursively parses xml contents to python dict .
defines the vggish tensorflow model .
loads a pre - trained vggish - compatible checkpoint .
get inputs to network as single tensor .
"reshape inputs from [ time_length , batch_size , ... ] to [ time_length * batch_size , ... ] ."
get value estimates given input .
convert array into a sequence of successive possibly overlapping frames .
"calculate a "" periodic "" hann window ."
calculate the short - time fourier transform magnitude .
convert frequencies to mel scale using htk formula .
return a matrix that can post - multiply spectrogram rows to make mel .
convert waveform to a log magnitude mel - frequency spectrogram .
transforms the dragnn eval_res output to float accuracies of components .
write a summary for a certain evaluation .
annotate eval_corpus given a model .
creates a directory for writing summaries and returns a writer .
runs a single iteration of train_op on a randomly sampled batch .
runs multi - task dragnn training on a single corpus .
process a single xml file containing a bounding box .
return a particular component of the linear model .
creates a new instance of the model using the first ` ` len(weights ) ` ` components .
"projects the ` ` instance ` ` onto the model , retrieving the optimal linear weightings ."
projects a ` ` instance ` ` onto the linear space and rebuilds from the weights found .
returns a version of ` ` instance ` ` where all the basis of the model have been projected out .
"returns the jacobian of the linear model . in this case , simply the components of the model reshaped to have the standard jacobian shape :"
c - based interpolator that was designed to be identical when used in both python and matlab .
c - based interpolator that was designed to be identical when used in both python and matlab .
visualize the : class:`colouredtrimesh ` . only 3d objects are currently supported .
"parameters ---------- s : ( n , n ) ndarray covariance / scatter matrix"
apply pca on the data matrix x.
"updates the h_matrix , performing sanity checks ."
returns just the linear transform component of this affine transform .
returns just the translation component .
uses an svd to decompose this transform into discrete affine transforms .
a string representation explaining what this affine transform does . has to be implemented by base classes .
applies this transform to a new set of vectors .
` ` n_dims * ( n_dims + 1 ) ` ` parameters - every element of the matrix bar the homogeneous part .
"return the parameters of the transform as a 1d array . these parameters are parametrised as deltas from the identity warp . this does not include the homogeneous part of the warp . note that it flattens using fortran ordering , to stay consistent with matlab ."
updates this affine in - place from the new parameters . see from_vector for details of the parameter format
computes the jacobian of the transform w.r.t the parameters . this is constant for affine transforms .
computes the jacobian of the transform wrt the points to which the transform is applied to . this is constant for affine transforms .
returns the optimal alignment of source to target .
upon updating the h_matrix we must resync the target .
updates this affine in - place from the new parameters . see from_vector for details of the parameter format .
a : class:`discreteaffine ` is already maximally decomposed - return a copy of self in a list .
"return the list of partners to notify , based on their preferences ."
integrates a system of ordinary differential equations .
integrates a system of ordinary differential equations .
"chunks up an iterable for when you want to deal with batches . when ` return_partial = false ` , we only return chunks that can have ` chunk_size ` items ."
"indents a table by column . - rows : a sequence of sequences of items , one sequence per row . - hasheader : true if the first row consists of the columns ' names . - headerchar : character to be used for the row separator line ( if hasheader==true or separaterows==true ) . - delim : the column delimiter . - justify : determines how are data justified in their column . valid values are ' left','right ' and ' center ' . - separaterows : true if rows are to be separated by a line of ' headerchar 's . - prefix : a string prepended to each printed row . - postfix : a string appended to each printed row . - wrapfunc : a function f(text ) for wrapping text ; each element in the table is first wrapped by this function ."
a word - wrap function that preserves existing line breaks and most spaces in the text . expects that existing line breaks are posix newlines ( ) .
"similar to wrap_onspace , but enforces the width constraint : words longer than width are split ."
a simple word - wrap function that wraps text on exactly width characters .
* * purpose * * : test the attributes that the wfprocessor object accepts upon instantiation
* * purpose * * : test the functions to start and terminate the wfp process
* * purpose * * : test the functions to start and terminate the tmgr process
* * purpose * * : test the functions to start and terminate the heartbeat thread
"returns whether the given request was made by an open edx mobile app , either natively or through the mobile web view ."
returns whether the given request was made by an open edx mobile web view using a session cookie .
sets up the expandablefield with the collapsed and expanded versions of the serializer .
return a representation of the field that is either expanded or collapsed .
"verify that the eligiblecertificatemanager filters out certificates marked as ineligible , and that the default object manager for generatedcertificate does not filter them out ."
return the ccx that is active for this course .
"gets the value of the overridden field for the ` ccx ` . ` block ` and ` name ` specify the block and the name of the field . if the field is not overridden for the given ccx , returns ` default ` ."
returns a dictionary mapping field name to overriden value for any overrides set on this block for this ccx .
overrides a field for the ` ccx ` . ` block ` and ` name ` specify the block and the name of the field on that block to override . ` value ` is the value to set for the given field .
"clears a previously set field override for the ` ccx ` . ` block ` and ` name ` specify the block and the name of the field on that block to clear . this function is idempotent -- if no override is set , nothing action is performed ."
remove field information from ccx overrides mapping dictionary
bulk delete for ccxfieldoverride model
just call the get_override_for_ccx method if there is a ccx
ccx field overrides are enabled per - course
generate a new modulesystem that is minimally set up for testing
return item url with dispatch .
create a runtime that actually does html rendering
test pass proctoring tab is in the instructor dashboard
test pass proctoring tab is not in the instructor dashboard for non global staff users
special exams tab will not be visible if the user is not a staff member .
add default modes
"do nothing , assumptions too dangerous ."
test login -- the setup function does all the work .
test logout -- setup function does login .
test request object after logging out to see whether it has ' is_from_log_out ' attribute set to true .
assert that all pages in the course load correctly . ` course_id ` is the id of the course to check .
"assert that the url loads correctly . if expect_redirect , then also check that we were redirected . if check_content , then check that we do n't get an error message about unavailable modules ."
"set the cursor at "" position """
"read "" chunk_size "" bytes of data at position cursor and move the cursor"
"test staticcontentstream stream_data function , asserts that we get all the bytes"
"test staticcontentstream stream_data_in_range function , asserts that we get the requested number of bytes first_byte and last_byte are chosen to be simple but non trivial values and to have total_length > stream_data_chunk_size ( 1024 )"
test that only one filename starts with 000 .
assert content has all the bookmark info .
test the rendering of the student view .
test the rendering of the studio author view
returns a video component with parent ` ` parent ` ` that is intended to be displayed to group ` ` group ` ` .
returns a problem component with parent ` ` parent ` ` that is intended to be displayed to group ` ` group ` ` .
returns an html component with parent ` ` parent ` ` that is intended to be displayed to group ` ` group ` ` .
checks that the right compentents are rendered for user with ` ` user_tag ` `
internal helper method to manage asset compilation
todo : improve the following
"several conditions : different report types , different files , multiple files"
abstract method to get the response from the endpoint that is being tested .
logs in the test user .
options to configure the test course . intended to be overridden by subclasses .
helper method to create the course .
helper method to create the user .
"helper method that calls the endpoint , verifies the expected response code , and returns the response ."
"to verify that the removal of courseware chrome elements is working , we include this test here to make sure the chrome elements that should be removed actually exist in the full courseware page . if this test fails , it 's probably because the html template for courseware has changed and courseware_chrome_html_elements needs to be updated ."
dry helper .
ensures the receiver function is invoked when course_cert_awarded is sent .
ensures that the receiver function does nothing when the programs api configuration is not enabled .
ensures that the receiver function invokes the expected celery task when the programs api configuration is enabled .
disconnect course_published event .
"construct expected blocks . arguments : block_types ( list ): list of required block types . possible values include sequential , vertical , html , problem , video , and discussion . the type can also be the name of a custom type of block used for the course . get_parent ( bool ): if true then add child 's parent location else parent is set to none returns : dict : information about required block types ."
verify that course_structure returns info for entire course .
verify that course_structure returns info for required block_types only when specific block_types are requested .
verify that course_structure returns empty info for non - existed block_types .
add a student & teacher
create dummy course with ' coursefactory ' and enroll the student
reverse the setup
test getting courses
test the course list for regular staff when get_course returns an errordescriptor
"create good courses , courses that wo n't load , and deleted courses which still have roles . test course listing ."
creates four courses . enroll test user in all courses sets two of them as pre - requisites of another course . checks course where pre - requisite course is set has appropriate info .
returns the ` ` model ` ` instance with a primary key of ` ` instance_or_pk ` ` .
purges the cache keys for the instances of this model .
"returns the cache key for this ( model , instance ) pair ."
"delete content for the given location , as well as for content with run = none . it 's possible that the content could have been cached without knowing the course_key - and so without having the run ."
this method is deprecated . please use : func:`request_cache.get_cache ` .
this method is deprecated . please use : func:`request_cache.get_request ` .
empty the request cache .
test setup .
tests that theme footer is used rather than standard footer when comprehensive theme is enabled .
helper method to create a new request object for the lti launch .
verifies that the view returns forbidden if the lti oauth signature is incorrect .
overridable method to get the response from the endpoint that is being tested .
test that the xblocks data is calculated correctly .
test that the xblocks data is persisted correctly .
test that the xblocks data is persisted correctly with display_name = none .
test allow beta against list beta .
generate a url based on internal service url and api version number .
generate a url based on public service url and api version number .
"returns a named tuple containing information required for working with the programs authoring app , a backbone app hosted by the programs service ."
whether responses from the programs api will be cached .
indicates whether lms dashboard functionality related to programs should be enabled or not .
indicates whether studio functionality related to programs should be enabled or not .
indicates whether background tasks should be initiated to grant certificates for program completion .
update the certificates config data to certificate endpoint .
initial data setup
"helper method to compare the sequence with the stored exam , which should just be a single one"
"happy path testing to see that when a course is published which contains a proctored exam , it will also put an entry into the exam tables"
"make sure that if we publish and then unpublish a proctored exam , the exam record stays , but is marked as is_active = false"
make sure we filter out all dangling items
make sure the feature flag is honored
make sure the feature flag is honored
test delete student state .
negative test of trying to reset attempts with bad content_id
negative test of trying to reset attempts with bad user identifier
negative test of trying to reset attempts with bad user identifier
test to assert that the usrr is staff or not
returns true if ccx has been enabled and the specified user is a coach
setup components used by each refund test .
assert base case is refundable
assert that enrollment is not refundable if course mode has expired .
assert that courses without a verified mode are not refundable
assert that enrollment is not refundable once a certificat has been generated .
assert enrollment is refundable before cutoff and not refundable after .
assert that the later date is used with the configurable refund period in calculating the returned cutoff date .
assert that the none is returned when no order number attribute is found .
configure a configurationmodel exposed at ` api_base ` to have the configuration ` configuration ` .
configure the stub via http .
"log in as a staff user , then return the cookies for the session ( as a dict ) raises a ` configmodelfixureerror ` if the login fails ."
default http headers dict .
"log in as a staff user , then return a ` requests ` ` session ` object for the logged in user . raises a ` studioapiloginerror ` if the login fails ."
create a fake microsite site name
create a fake microsite site name
test to create a user form the microsite and see that it record has been saved in the usersignupsource table
test to create a user form the non - microsite . the record should not be saved in the usersignupsource table
test to create a user form the microsite but do n't provide any of the microsite specific profile information
test to create a user form the microsite but do n't provide any of the microsite specific profile information
install a course with no content using a fixture .
install a course fixture
populate the children of the test course fixture .
log in as the user that created the course . the user will be given instructor access to the course and enrolled in it . by default the user will not have staff access unless is_staff is passed as true .
create a unique identifier for the course used in this test .
go to the nested container page .
go to the test unit page .
perform the supplied action and then verify the resulting ordering .
install a library with no content using a fixture .
populate the children of the test course fixture .
log in as the user that created the library . by default the user will not have staff access unless is_staff is passed as true .
middleware entry point on every request processing . this will associate a request 's domain name with a ' university ' and any corresponding microsite configuration information
middleware entry point for request completion .
standard middleware entry point
create and enroll users with provided enrollment type .
adding the verification status for a user .
check that the user was assigned to a group .
helper method to iterate over all providers
returns list of providers that can be used to initiate logins currently
generator returning all enabled providers that use the specified backend .
set up the test data used in the specific tests
helper method to assert that all known redirect points do redirect as expected
helper method to asswer that all known conditionally redirect points do not redirect as expected
verifies that going to the courseware which does not have a survey does not redirect to a survey
"verifies that going to the courseware with an unanswered survey , redirects to the survey"
verifies that anonymous user going to the courseware info with an unanswered survey is not redirected to survery and info page renders without server error .
"verifies that going to the courseware with an answered survey , there is no redirect"
"assert that the course_id will be in the form fields , if available"
assert that a posted back course_id is stored in the database
"verifies that going to the courseware with a required , but non - existing survey , does not redirect"
"verifies that going to the courseware with a required , but non - existing survey , does not redirect"
"verifies that going to the courseware with a required , but non - existing survey , does not redirect"
test that course display names are correctly html - escaped .
create search page and course content to search
publish content on studio course page under specified section
edit chapter name on studio course page under specified section
add content on studio course page under specified section
reindex course content on studio course page
login and search for specific content
make sure that the page is accessible .
make sure that you can search for something .
make sure new content gets reindexed on button press .
returns status for a specific task .
view method that returns the status of a course - related task or tasks .
construct progress message from progress information in instructortask entry .
start the stub server .
returns a list of dummy notes .
returns a single dummy note .
verify the pagination information .
test paginated response of notes api
test next and previous urls of paginated response of notes api when number of pages are 1
test paginated response of notes api when there 's no note present
return a list of notes from the stub edxnotes service .
construt a url to the stub edxnotes service .
verifies the given serialized_block when basic fields are requested .
adds additional fields to the requested_fields context for the serializer .
verifies the given serialized_block when additional fields are requested .
creates a blockserializer
creates a blockdictserializer
"ensure that a user accessing a non - live course sees a redirect to the student dashboard , not a 404 ."
test that the last accessed courseware link is not shown if there is no course content .
test the info page on a course without any display _ * settings against one that does .
assert that when unenroll student tries to access ccx do not allow him self - register . redirect him to his student dashboard
"fetch the given course 's info page , asserting the number of sql and mongo queries ."
"although stored as compressed data , coursestructure.structure_json should always return the uncompressed string ."
"coursestructure.structure should return the uncompressed , json - parsed course structure ."
the generator should continue to operate on blocks / xmodule that do not have graded or format fields .
test the actual task that orchestrates data generation and updating the database .
test the progress.to_js_status_str ( ) method
test the progress.to_js_detail_str ( ) method
test the progress.add_counts ( ) method
test that comparing progress objects for equality works correctly .
"make sure default get_progress exists , returns none"
create course page and courses to find
logout and login with given credentials .
make sure that the page is accessible .
make sure you can search for courses .
"flatten a dict from cls - > [ fields , ... ] and yields values of the form ( cls , fields ) for each entry in the dictionary value ."
see documentation from : meth:`factory . factory._build `
see documentation from : meth:`factory . factory._build `
"when ` depth ` is specified as a factory parameter , creates a tree of children with that many levels ."
update the position attribute of the generated moduleruntime .
"when ` depth ` is specified as a factory parameter , creates a tree of children with that many levels ."
set the xmodule_runtime to make this xmoduledescriptor usable as an xmodule .
raise skiptest if this descriptor_cls should n't be tested .
execute assertions to verify that the property under test is true for the supplied descriptor .
assert that both student_view and get_html render the same .
assert that studio_view and get_html render the same .
"filter fields based on feature flag , i.e. enabled , disabled ."
fetch the key : value editable course details for the given course from persistence and return a coursemetadata model .
fetches all key : value pairs from persistence and returns a coursemetadata model .
decode the json into coursemetadata and save any changed attrs to the db .
validate the values in the json dict ( validated by xblock fields from_json method )
update metadata descriptor from key_values . saves to modulestore if save is true .
mock logging in to the dummy provider
fetch data from an api using provided api configuration and resource name .
"test dump_js_escaped_json properly escapes & , < , and > ."
"test dump_js_escaped_json first encodes with custom jsnoencoder before escaping & , < , and >"
"test dump_html_escaped_json properly escapes & , < , and > ."
"test dump_html_escaped_json first encodes with custom jsnoencoder before escaping & , < , and >"
"test js_escaped_string escapes & , < , and > , as well as returns a unicode type"
test js_escaped_string returns empty string for none
tests the full suite of mako best practices by running all of the combinations of types of data and types of escaping through a mako template .
"proves that the expectation string is a reasonable one , since it is not very human readable with all of the escaping ."
"proves that the expectation string is a reasonable one , since it is not very human readable with all of the escaping ."
this provider is enabled for self - paced courses only .
verify programs data can be retrieved using get_edx_api_data .
verify no data is retrieved if configuration is disabled .
"verify that when enabled , the cache is used ."
verify no data is retrieved and exception logged when api client fails to initialize .
verify exception is logged when data ca n't be retrieved from api .
verify that all data is retrieve for multiple page response .
converts uidb36 into uidb64
tests password reset behavior for user with password marked unusable_password_prefix
now test the exception cases with of reset_password called with invalid email .
try ( and fail ) resetting password 30 times in a row on an non - existant email address
"tests contents of reset password email , and that user is not active"
tests that the right url protocol is included in the reset password link
tests that the right url domain and platform name is included in the reset password email
tests that the right url domain and platform name is included in the reset password email
tests bad token and uidb36 in password reset
tests good token and uidb36 in password reset
tests password reset confirmation page for micro site
tests good token and uidb36 in password reset
set up the for the course header menu tests .
tests course header menu should not have ` certificates ` menu item if course has not web / html certificates enabled .
tests course header menu should have ` certificates ` menu item if course has web / html certificates enabled .
"update user partitions in the course descriptor , then reload the content ."
safely reload an item from the moduelstore .
return advanced component types which can be created .
"load an xblock by category name , and apply all defined mixins"
the restful handler for container xblock requests .
returns the applicable component templates that can be used by the specified course or library .
"helper method for getting the old location , containing course , item , lms_link , and preview_lms_link for a given locator ."
dispatch an ajax action to an xblock
"modifiers are full of junk we do nt care about , remove them"
return a list of actions needed before tasks can be generated
short cut to add a file to be staged
get a db instance : param db : database name : return : the motor db instance
get a collection instance : param db_name : database name : param collection : collection name : return : the motor collection instance
"assumes len(predictions ) = = len(ids ) , and that predictions[i ] is the index of the predicted class with the malware_classes list above for the executable corresponding to ids[i ] . outfile will be overwritten"
initialize the phase vocoder with the input and output hop sizes desired .
reset the phase accumulator and the previous phase stored to 0 .
send a single frame to the phase vocoder
a generator function for processing a group of frames .
performs a macd analysis on the historical data
performs momentum analysis on the historical data
initialize slacknotifier class
sends the message .
initializes strategyanalyzer class
returns a dictionary for dynamic anaylsis selector
returns a dictionary for dynamic informant selector
returns a pandas . dataframe for dynamic crossover selector
chunks message so that it meets max size of integration .
return line with only whitelist characters
remove sentences of length greater than max_input_length
"computes the rolling correlation along axis 0 of ` arr ` , in steps of size ` win ` returns a single value for each element along axis 0 of ` arr ` this value is the mean of the triangle of the correlation matrix ( coefficient if elements are 2xn , else average coefficient )"
generate sliding window version of an array
gap : float order : list - like names : list - like cmap : mpl cmap stacked : bool binary_label : trues / falses of same shape as data
"labels : true , false / none , or list of labels , one for each column in data"
remove a resource .
into helper function
normalize a regular expression by ensuring that it is wrapped with : ' ^ ' and ' $ '
register a new handler in this regex dispatcher .
extend the base method ` ` update ` ` .
deactivate the game buttons ; show error message ` ` message ` ` if pressed .
draw the stone symbols onto the buttons
"highlight the buttons with the coordinates ` ` ( y , x ) ` ` ( see board.py ) passed via ` ` positions ` `"
highlight the button with the coordinates of the last move .
run a game of gomoku
return the indices of the desired white and black player .
this method creates the required sections if they do not exist
"load ptb raw data from data directory "" data_path "" . reads ptb text files , converts strings to integer ids , and performs mini - batching of the inputs . the ptb dataset comes from tomas mikolov 's webpage : http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz args : data_path : string path to the directory where simple-examples.tgz has been extracted . returns : tuple ( train_data , valid_data , test_data , vocabulary ) where each of the data objects can be passed to ptbiterator ."
"iterate on the raw ptb data . this chunks up raw_data into batches of examples and returns tensors that are drawn from these batches . args : raw_data : one of the raw data outputs from ptb_raw_data . batch_size : int , the batch size . num_steps : int , the number of unrolls . name : the name of this operation ( optional ) . returns : a pair of tensors , each shaped [ batch_size , num_steps ] . the second element of the tuple is the same data time - shifted to the right by one . raises : tf.errors . invalidargumenterror : if batch_size or num_steps are too high ."
"iterate on the raw ptb data . this generates batch_size pointers into the raw ptb data , and allows minibatch iteration along these pointers . args : raw_data : one of the raw data outputs from ptb_raw_data . batch_size : int , the batch size . num_steps : int , the number of unrolls . yields : pairs of the batched data , each a matrix of shape [ batch_size , num_steps ] . the second element of the tuple is the same data time - shifted to the right by one . raises : valueerror : if batch_size or num_steps are too high ."
test anonymoususer hit
"test multiple anonymoususer hit , not counted"
"test multiple anonymoususer hit , counted because of filter active"
test anonymoususer hit
"test multiple anonymoususer hit , not counted"
"test multiple anonymoususer hit , counted because of filter active"
test ` hitcount_hits_per_ip_limit ` setting . should allow multiple hits from the same ip until the limit is reached from that ip .
exclude user by adding a group setting .
test black listed ips .
test black listed user agents .
test require ajax request or raise 404
test require post request or raise 404
test a valid request .
test a valid request with an invalid hitcount pk .
test a valid request .
increment a hit and then get the response .
increment a hit and then get the response .
custom callback for the hit.delete ( ) method .
returns hit count for an object during a given time period .
"the first time the object is created and saved , we increment the associated hitcount object by one . the opposite applies if the hit is deleted ."
"if a hit is deleted and save_hitcount = true , it will preserve the hitcount object 's total . however , under normal circumstances , a delete ( ) will trigger a subtraction from the hitcount object 's total ."
the name of the current module
if the mimetype is ` application / json ` this will contain the parsed json data .
execute tests in the passed module ( defaults to _ _ main _ _ ) with pytest .
center crop image .
load image from file and crop / resize as necessary .
save an image .
save images .
use the platform name to get which browsers can be tested .
parse the given arguments .
decide what browsers we should use .
build a command and send it to karma for execution .
"contruye lotes de imagenes args : dataset : un objeto de la clase reconobookdata batch_size : cantidad de imagenes que tiene el lote train : boolean , indice si las imagenes son para entrenamiento o para evaluación returns : images : 4 - d float tensor labels : 1 - d integer tensor raises : valueerror : si no hay dataset ."
"decodifica una imagen jpg en string en un 3 - d float image tensor . args : image_buffer : scalar string tensor . returns : 3 - d float tensor con valores entre [ 0 , 1 ) ."
"distorsiona el color de una imagen cada distorción de color no es conmutativa , por lo que el orden importa . idealmente el orden de aplicación de las distorciones de color debería ser aleatoria . pero es suficientemente buena solución si alteramos el orden de aplicación de las distorciones en función del hilo que ejecuta este preprocesado . args : image : tensor conteniendo una sola imagen . thread_id : preprocessing thread id . returns : imagen distorcionada"
distorciona la imagen para el entrenamiento de la red el distorsionado de imagen es una forma efectiva de generar más imagenes distintas y evitar el sobre ajuste de nuestra red neuronal args : image : 3 - d float tensor height : integer width : integer returns : 3 - d float tensor
prepara una imagen para la evaluación . dependiendo de lo configurado puede distorsionarse o no . args : image : 3 - d float tensor height : integer width : integer returns : 3 - d float tensor
defodifica y preprocesa una imagen para evaluación o entrenamiento args : image_buffer : jpeg encoded string tensor train : boolean thread_id : el número de hilo de preprocesado returns : 3 - d float tensor
parsea una linea del dataset que contiene una solo imagen la salida del script build_datasets.py es un conjunto de objetos proto . args : example_serialized : string leido del dataset . returns : image_buffer : tensor tf.string label : tensor tf.int32 text : tensor tf.string coneniendo el label leible por humanos
construct the xml cpu feature snippet < feature policy='disable ' name='lahf_lm'/ >
support instance methods .
prepare setup for networks removal
prepare networks for creation
"report the interfaces that have been added to networks , either by add or edit actions , including ifaces that have been removed and re - added to a different network ."
return an iterator over all dom elements with given ` tag ` .
find the first dom element with the given tag .
find ` attribute ` value of the first dom element with ` tag ` .
return tag of the given dom element .
return attribute values of ` element ` .
set ` attribute ` of ` element ` to ` value ` .
return text of the given dom element .
return direct subelements of ` element ` .
add child element to ` element ` .
remove child element from ` element ` .
replace the first child of ` element ` with ` new_child ` .
obtain device 's address from libvirt
"parse address to create proper dictionary . libvirt device 's address definition is : pci = { ' type':'pci ' , ' domain':'0x0000 ' , ' bus':'0x00 ' , ' slot':'0x0c ' , ' function':'0x0 ' } ide = { ' type':'drive ' , ' controller':'0 ' , ' bus':'0 ' , ' unit':'0 ' }"
create domxml device element according to passed in params
"< disk device=""disk "" type=""file "" snapshot=""no "" > < source file=""/net / myhost / myimage.img""/ > < target bus=""virtio "" dev=""vda""/ > < driver cache=""none "" error_policy=""stop "" name=""qemu "" type=""qcow2""/ > < /disk >"
add key = value unless key is already in the file . all pairs are added in a comment wrapped section .
add ' section ' in the beginning of the file . section is added in a comment wrapped section .
add self.prefix to the beginning of each line . no editing is done on new content added by this config file .
remove self.prefix from each line starting with it . no editing is done on new content added by this config file .
notice this method can be called out of context since it is read only
during finalize we distunguish between leaf merge and internal merge .
returns an open netlink socket . callback_function : modify the callback handler associated with the socket . callback function requires two arguments : nl_message : netlink message passed by the socket args : optional argument defined by _ nl_socket_modify_cb ( ) callback_arg : optional argument passed to the callback function
closes and frees the resources of the passed netlink socket .
provides a cache using cache_allocator and frees it and its links upon exit .
returns a socket from the pool ( creating it when needed ) .
"options having symbolic values , e.g. ' mode ' , are presented by sysfs in the order symbolic name , numeric value , e.g. ' balance - rr 0 ' . choose the numeric value from a list given by bondopts ( ) ."
"pci_path is a string looking similar to "" 0000:00:19.0 """
"some drivers forbid resetting vf mac address back to 00:00:00:00:00:00 , which was its original value . by setting the mac addresses to a valid value , upon restoration the valid address will be accepted ."
"given an old sriov pf configuration ( containing numvfs per device ) , convert it to the new device configuration and return it ."
reads the persisted sriov vfs old configuration and returns a dict where the device pci is the key and the number of vf / s is the value .
various formats are legal for pci address representation ; see : https://wiki.xen.org/wiki/bus:device.function_%28bdf%29_notation
positive test - libvirtmock does not raise any errors
libvirtmock will raise an error when nodedevicelookupbyname is called . when getlibversion is called ( used by libvirtconnection to recognize disconnections ) it will not raise an error - > in that case an error should be raised ( ' unknown libvirterror ' ) .
libvirtmock will raise an error when nodedevicelookupbyname is called . when getlibversion is called ( used by libvirtconnection to recognize disconnections ) it will also raise an error - > in that case os.kill should be called ( ' connection to libvirt broken . ' ) .
subscribe to a queue and listen for messages .
unsubscribe and stop recieving messages .
"jsonrpcclient notify method , sends an event on a spesific queue"
return drive configuration updated from * * kw
this function returns lvs output in lvm.getlv ( ) format .
starts application memory profiling
stops application memory profiling
generator that yields an information dictionary for each network address in the system .
returns a dictionary with the address information .
split an addr dict from iter_addrs
returns the textual representation of the address flags
": param vm : vm undergoing power - down action : param delay : graceful timeout for the user to close his applications ( in seconds ) . during this time no action is taken . : param message : message to show the user . : param timeout : timeout for each power - down method ( guest agents , acpi ) until it is considered unsuccessful and the callback chain should try another alternative . : param force : use forceful power - down if all graceful methods fail ? : param event : event object used to detect successful power - down ."
run shell command and assert success exit code .
test installing argweaver program .
test installing argweaver python lib .
test installing argweaver from a sdist .
calculates ancestral sequence for a local tree using parsimony
calculates emissions for all states at positions ' pos '
returns true if tag contains of the valid tags .
convert wiki formatting to markdown formatting .
makes sure filenames are valid by replacing illegal characters
"decorator for a view that makes sure that the user has * all * permissions , redirects to the log - in page if not logged in ."
returns a dummy api endpoint that returns true . this endpoint will be protected with the @oauth_scope decorator -- see that function 's signature for a description of the parameters that may be passed .
"test that secure requests succeed when the backend requires all accesstoken - authenticated requests to be secure , as recommended by http://tools.ietf.org/html/rfc6750#section-1 and http://tools.ietf.org/html/rfc6750#section-5.3 ."
"test that insecure requests fail when the backend requires all accesstoken - authenticated requests to be secure , as recommended by http://tools.ietf.org/html/rfc6750#section-1 and http://tools.ietf.org/html/rfc6750#section-5.3 ."
test that secure requests succeed when the backend does not require accesstoken - authenticated requests to be secure .
test that insecure requests succeed when the backend does not require accesstoken - authenticated requests to be secure .
"if an api request is made without a www - authenticate header containing an access token , it sould receive a response with status code 400 and no further error information . from http://tools.ietf.org/html/rfc6750#section-3.1 :"
"only bearer authentication is supported . if a client tries to authenticate via any other method , the response should fail with status code of 400 and no futher error information , as recommended by http://tools.ietf.org/html/rfc6750#section-3.1 :"
"api requests with malformed authentication headers can not be authenticated correctly , and should fail ."
api requests that attempt to authenticate with nonexistent accesstokens should fail .
"if a request is made with an expired token , the endpoint should respond with status code 401 ."
a client with access to a given scope should have access to all api resources protected by that scope .
requests from a client with access to multiple scopes should succeed when made to an api resource protected by a subset of the client 's granted scopes .
a client without access to the scope protecting an endpoint should receive a 403 error when making requests to said endpoint .
"runs cmd via subprocess . popen ; and if that fails , puts it into the shell ( /bin / sh ) . it seems that 's what executing things in bash does , and even execve . also , all so - far released versions of gitolite get the shebang line wrong ."
reads a config file that may have options outside of any section .
creates a repository from a section of the git - mirror configuration file
setup the environment to work with this repository
update the < ref > from < oldsha > to < newsha > on all mirrors . the update must already have happened locally .
update the local version of this < ref > to what 's currently on the given < mirror > . < oldsha > and < newsha > are checked . then update all the other mirrors .
reference . just computes the time
sets the implementation of this module
"compute p ( obs | a , b , pi ) and all forward coefficients ."
compute all backward coefficients . with scaling !
"calculate the ( t , n)-probabilty matrix for being in state i at time t."
sum the probabilities of being in state i to time t
sum for all t the probability to transition from state i to state j.
estimate the hidden pathway of maximum likelihood using the viterbi algorithm .
"sample the hidden pathway s from the conditional distribution p ( s | parameters , observations )"
computes the mean and alpha - confidence interval of the given sample set
returns the list of all indexes of the given array . currently works for one and two - dimensional arrays
returns a column with given indexes from a deep array
computes element - wise confidence intervals from a sample of ndarrays
create a 1d gaussian output model .
"string representation of this output model > > > output_model = gaussianoutputmodel(nstates=3 , means=[-1 , 0 , 1 ] , sigmas=[0.5 , 1 , 2 ] ) > > > print(repr(output_model ) ) gaussianoutputmodel(3 , means = array([-1 . , 0 . , 1 . ] ) , sigmas = array ( [ 0.5 , 1 . , 2 . ] ) )"
"human - readable string representation of this output model > > > output_model = gaussianoutputmodel(nstates=3 , means=[-1 , 0 , 1 ] , sigmas=[0.5 , 1 , 2 ] ) > > > print(str(output_model ) ) -------------------------------------------------------------------------------- gaussianoutputmodel nstates : 3 means : [ -1 . 0 . 1 . ] sigmas : [ 0.5 1 . 2 . ] --------------------------------------------------------------------------------"
model type . returns ' gaussian '
dimension of the gaussian output model ( currently 1 )
mean values of gaussians output densities
standard deviations of gaussian output densities
returns the output probability for symbol o from all hidden states
returns the output probabilities for an entire trajectory and all hidden states
fits the output model given the observations and weights
sample a new set of distribution parameters given a sample of observations from the given state .
generate a single synthetic observation data from a given state .
generate synthetic observation data from a given state .
generate synthetic observation data from a given state sequence .
unix double - fork magic .
start the daemon .
stop the daemon .
restart the daemon .
override this method .
testing for pipeline
testing for item
build decision tree
recursive method which builds out the decision tree and splits x and respective y on the feature of x which ( based on impurity ) best separates the data
do a recursive search down the tree and make a prediction of the data sample by the value of the leaf that we end up at
classify samples one by one and return the set of labels
recursively print the decision tree
y contains y_true in left half of the middle column and y_pred in the right half . split and return the two matrices
initialize the centroids as k random samples of x
return the index of the closest centroid to the sample
assign the samples to the closest centroids to create clusters
calculate new centroids as the means of the samples in each cluster
classify samples as the index of their clusters
do k - means clustering and return cluster indices
return a loaded elf header object pointing to the ehdr of the main executable .
return the address of the entry point for the main executable .
search the nearest page which contains the elf headers by comparing the elf magic with first 4 bytes .
returns an ehdr object for the elf pointer points into .
"returns a tuple containing ( phnum , phentsize , gdb . value ) , where the gdb . value object is an elf program header with the architecture - appropriate structure type ."
"given a pointer into an elf module , return a list of all loaded sections in the elf ."
retrieve the debug file directory path .
retrieve the textual name for a symbol
synchronize ida 's cursor with gdb
select and print stack frame that called this one . an argument says how many frames up to go .
select and print stack frame called by this one . an argument says how many frames down to go .
save the ida database
evaluate ida . locbyname ( ) on the supplied value .
"genesis block'u oluşturup , chain'in ilk block'u olarak ekler ."
"chain'deki block'lar değiştirilmiş mi kontrolü yapar . bunu , her block'un previous_hash değeri , bir önceki block'un blockhash'i ile aynı mı diye bakarak yapar ."
"ağa eklenecek transaction'ların merkle root hash'ini hesaplamak için kullanılır . her bir ikili transaction'un , hash'ini alır ve bunları tek bir hash olarak birleştirir . ve çıkan hash_list'i , tekrar aynı işleme tabi tutmak için yine bu metoda parametre olarak geçer . bu sayede tüm transacation'ların hash'leri , tek bir hash olana kadar bu fonksiyon çalıştırılmış olunur ."
"eklenmek istenen block'un merkle root hash'ini alıp , * son block'un hash'i , * eklenecek olan block'un id'si , * ve nonce değerini alarak hash'ler ve problemi çözmeye çalışır . problemi çözdüğünde chain'e block'u ekler ve diğer node'ları haberdar eder ."
connect to the ble device .
disconnect from the ble device .
return a list of gattservice objects that have been discovered for this device .
wait up to timeout_sec for the specified services and characteristics to be discovered on the device . if the timeout is exceeded without discovering the services and characteristics then an exception is thrown .
return a list of uuids for services that are advertised by this device .
"return a unique identifier for this device . on supported platforms this will be the mac address of the device , however on unsupported platforms ( mac osx ) it will be a unique id like a uuid ."
return the name of this device .
"return true if the device is connected to the system , otherwise false ."
return the rssi signal strength in decibels .
return the first child service found that has the specified uuid . will return none if no service that matches is found .
test if this device is the same as the provided device .
test if this device is not the same as the provided device .
hash function implementation that allows device instances to be put inside dictionaries and other containers .
initialize device information from provided bluez device .
"set the red , green , blue color of the bulb ."
return process object representing the current process
return list of process objects corresponding to live child processes
"restore internal attribute current_exception , it may have been modified by the code inside functions of this module ."
new window or tab is not controllable on the client side . autoraise not available .
make sure sys.modules is the same object and has the same content when exiting the context as when entering .
save import state and sys.modules cache and restore it on exit . typical usage :
append this dom component to dom element element_id
test multiple tiers of iterators
generate all combinations of k elements from list x.
return 3 random integers between 0 and 9
displays a running average across lists of integers sent to it
produces a set of values and forwards them to the pre - defined consumer function
"permutations(range(3 ) , 2 ) -- > ( 0,1 ) ( 0,2 ) ( 1,0 ) ( 1,2 ) ( 2,0 ) ( 2,1 )"
n - queens solver .
get the day position in the year starting from 1
get the week position in the year starting from 0 . all days in a new year preceding the first monday are considered to be in week 0 . parameters ---------- arg : tuple
check if data has daylight saving time
"check if timezone is available , if not return a tuple of empty str"
"javascript ca n't block execution for a given time , expect by an infinite loop that freezes the browser . it 's better to raise an exception"
"run the given benchmark , print results to stdout ."
greatest common divisor using euclid 's algorithm .
test whether an object is an instance of int .
test whether an object is an instance of a built - in numeric type .
test wheter an object is an instance of the rat class .
return the sequence of operations that results from applying the operation ` op ` to instances of the given classes .
"constructor : rat([num [ , den ] ] ) ."
accessor function for read - only ' num ' attribute of rat .
accessor function for read - only ' den ' attribute of rat .
convert a rat to an string resembling a rat constructor call .
convert a rat to a string resembling a decimal numeric value .
convert a rat to a float .
convert a rat to an int ; self.den must be 1 .
"add two rats , or a rat and a number ."
"subtract two rats , or a rat and a number ."
"subtract two rats , or a rat and a number ( reversed args ) ."
"multiply two rats , or a rat and a number ."
"divide two rats , or a rat and a number ."
"divide two rats , or a rat and a number ( reversed args ) ."
"divide two rats , returning the floored result ."
"divide two rats , returning the floored result ( reversed args ) ."
"divide two rats , returning quotient and remainder ."
"divide two rats , returning quotient and remainder ( reversed args ) ."
take one rat modulo another .
take one rat modulo another ( reversed args ) .
compare two rats for equality .
compare two rats for inequality .
pretty - print a python object to a stream [ default is sys.stdout ] .
format a python object into a pretty - printed representation .
version of repr ( ) which can handle recursive data structures .
determine if saferepr(object ) is readable by eval ( ) .
determine if object requires a recursive representation .
helper function for comparing 2 - tuples
handle pretty printing operations onto a stream using a set of configured parameters .
"format object for a specific context , returning a string and flags indicating whether the representation is ' readable ' and whether the object represents a recursive construct ."
create a new buildqueue . ` status_dir ` is a path to a directory that will contain job statusses . ` job_changed_handler ` is a callback that will be called when a job has changed to ' failed ' or ' passed ' . the callback will receive two parameters : the current job ( job instance ) and the previous job .
start the buildqueue thread .
create required directories under the ` status_dir ` .
put a job in the queue for building . this can be called from outside the thread with a ` job ( ) ` instance to queue the job for building .
continuously read the build queue for jobs and build them .
build a job .
write the current job status as set in this object to job status dir and symlink them if needed .
return the ` status_dir ` where all job statusses are kept .
delete a specific job 's status .
return a dict with a specific jpb 's status .
return a list of all job statusses sorted by date ( youngest first ) .
return the last non - aborted job that was run .
get account balance between dates or on particular date
get subaccount balance between dates or on particular date
get common query for cashflows
check if given file size is less or equal as max allowed in config
get file size in bytes
does not raise an error on http 201 ( created ) response .
does not raise an error on http 202 ( accepted ) response .
default view for the root
sample the variable
return the number of samples
return the minimum sample
return the maximum sample
return the average of samples
return the average of samples
return a string suitable for output
caches the result of the computation based on the function parameters available . : param cache : cache : return cached value
simple evaluation of q function
this function will take the current state and choose what the q function believes to the best action and return it
apply update to q functions lookup table based on the q learning equation
this function will update the q function to respond the actions impact on state1 to state2 based on the given reward
test creation of a pvc snapshot
test deletion of a pvc snapshot
to plot the radiative losses vs temperature
lex the fortran format statement into tokens
select a filename using a wx gui dialog .
generic text drawing function .
create a new pylinac pdf template report .
add a new pylinac template page to an existing report ; for constructing multipage reports .
take in a buffered image and make it compatible with reportlab 's image functionality .
test that saving an image does something .
test that the demo image passed
test than the wobble radius is similar to what it has been shown to be ) .
test that the center of the wobble circle is close to what it 's shown to be .
test than the number of radiation lines found is what is expected .
test that the wobble stays roughly the same for all radii .
test that the demo runs without error .
"check that the demo image was actually inverted , as it needs to be ."
"test that even at a distance start point , the search algorithm recovers ."
handle any uncaught exceptions .
wrapper function to call scripts in the classify folder .
wrapper function to call script in the train folder .
wrapper function to call the features main function .
predict a list of inputs as either oncogene / tsg / other .
predicts oncogene / tsg / other by gene mutation counts .
the actual 20/20 rule logic to classify genes .
setter for percentage threshold for recurrent missense mutations to call it an oncogene .
setter for percentage threshold for deleterious mutations to call it a tsg .
setter for minimum count that can be classified for either a oncogene or tsg .
sets the mutation type attribute to a single label based on attribute flags .
set amino acid change and position .
"interpret the mutation type ( missense , etc . ) and set appropriate flags ."
sets the self.is_missense flag .
sets the self.is_lost_start flag .
check for frame shift and set the self.is_frame_shift flag .
check if the stop codon was mutated to something other than a stop codon .
set whether there is a premature stop codon .
sets flags related to the mutation being an indel .
sets a flag for unkown effect according to hgvs syntax . the cosmic database also uses unconventional questionmarks to denote missing information .
"set a flag for no protein expected . ( "" p.0 "" or "" p.0 ? "" )"
convert hgvs syntax for amino acid change into attributes .
check if message follows the ctcp format .
construct ctcp message .
strip and de - quote ctcp messages .
"callback called when the user received a ctcp message . client subclasses can override on_ctcp_<type > to be called when receiving a message of that specific ctcp type , in addition to this callback ."
"callback called when the user received a ctcp response . client subclasses can override on_ctcp_<type>_reply to be called when receiving a reply of that specific ctcp type , in addition to this callback ."
built - in ctcp version as some networks seem to require it .
send a ctcp request to a target .
send a ctcp reply to a target .
modify privmsg to redirect ctcp messages .
modify notice to redirect ctcp messages .
builds a bmpprotocol instance .
creates a sanic app and adds a graphql / graphiql endpoint
"create app , add graphql endpoint , and run it . never returns ."
makes the parameters to be inside the bounds
perform multi - dimensional catmull - rom cubic interpolation .
common function .
"calculation of levy stable distribution via numerical integration . this is used in the creation of the lookup table . notice that to compute it in a ' true ' x , the tangent must be applied . example : levy(2 , 1.5 , 0 ) = _ calculate_levy(np.tan(2 ) , 1.5 , 0 ) "" 0 "" parameterization as per http://academic2.americanp.edu/~jpnolan/stable/stable.html note : fails for alpha=1.0 ( so make sure alpha=1.0 is n't exactly on the interpolation grid )"
"generates the lookup tables , writes it to .npz files ."
interpolate densities of the levy stable distribution specified by alpha and beta .
"levy with the tail replaced by the analytical approximation . also , mu , sigma are parameters that shift and rescale the distribution . parametrization can be chosen according to nolan , par={0,1 } ."
interpolate negative log densities of the levy stable distribution specified by alpha and beta . small / negative densities are capped at 1e-100 to preserve sanity .
"estimate parameters of levy stable distribution given data x , using the maximum likelihood method ."
"generate random values sampled from an alpha - stable distribution . parametrization can be chosen according to nolan , par={0,1 } ."
rewrite type for ' ipadeskdata ' attribute to allow loading the content of json - formatted data from file
rewrite type for ' ipadeskdata ' attribute to allow loading the content of json - formatted data from file
"convert two bytes to signed integer ( big endian ) for little endian reverse msb , lsb arguments can be used in an interrupt handler"
read bytes to pre - allocated buffer caller traps oserror .
perform a memory write . caller should trap oserror .
wakes the device .
sets the device to sleep mode .
returns passthrough mode true or false
get sample rate as per register map document section 4.4 sample_rate= internal_sample_rate / ( 1 + rate ) default rate is zero i.e. sample at internal rate .
set sample rate as per register map document section 4.4
accelerometer range value : 0 1 2 3 for range + /- : 2 4 8 16 g
gyroscope range . pass : 0 1 2 3 for range + /- : 250 500 1000 2000 degrees / second
update accelerometer vector3d object
for use in interrupt handlers . sets self._accel._ivector [ ] to signed unscaled integer accelerometer values
update gyroscope vector3d object
for use in interrupt handlers . sets self._gyro._ivector [ ] to signed unscaled integer gyro values . error trapping disallowed .
"returns a next state , given a state and an action"
"rewarded for reaching goal state , penalized for all other states"
transitions to the next state and computes the reward
checks if the car reached the top of the mountain
runs a simulation using the provided dqn policy for nsteps
this is only called for local tests ( under tests / perf_runner/ ) .
this is called after collection ( of all tests ) has been performed .
add additional section in terminal summary reporting .
evaluate an expression using this environment as globals .
get a list of merchants and their configured rates
"build a chain of tasks , adding monitoring and maintenance tasks at the beginning and end of the chain"
parameters ---------- previous_task_results args
having a task for starting the job makes sure we measure the right time of running
having a task for stopping the job makes sure we measure the right time of completion ( previous task is obviously done )
parameters ---------- job_holder : jobholder or tuple args
default generic error page
"defined in admin module , so redirect there"
"defined in admin module , so redirect there"
"defined in admin module , so redirect there"
module 's home page
"restful crud controller list / add shelter types ( e.g. ngo - operated , government evacuation center , school , hospital -- see agasti opt_camp_type . )"
"restful crud controller list / add shelter services ( e.g. medical , housing , food , ... )"
restful crud controller
"if the "" is_school "" or "" is_hospital "" checkbox was checked , we use the corresponding field values , else we clear them so no attempt is made to validate them ."
"if the user checked is_school , but there is no school_code , add a form.error for that field , to fail the submission and get an error message into the page . likewise for is_hospital and hospital_id ."
"call an xmlrpc , jsonrpc or rss service"
initialize a customized google geocoder with location - specific address information and your google maps api key .
"parse a location name , latitude , and longitude from an xml response ."
"this parses javascript returned by queries the actual google maps interface and could thus break easily . however , this is desirable if the http geocoder does n't work for addresses in your country ( the uk , for example ) ."
"can raise ioerror , throws ioerror"
"can raise ioerror , throws ioerror"
this does bla bla
scan kext plist and exctract pciid data
human expected alnum sort
convert list of hex strings into list of ints
compares macos amd kext pci devices to online pciids db and return output in markdown format
write output to file
sends an html email .
sends an email .
returns the pytz timezone for a given profile .
generates a compressed url .
returns true if the input phrase has a negative sentiment .
returns true if the input phrase has a positive sentiment .
add comments to tag @type node : zennode @type i : int
updates the conda environment : return :
upadates the conda environment and stores it in the environment.yml file
runs unit tests via nose with coverage .
adds all files from the library to the sphinx api .
cleans and generates docs .
cleans the repo : return :
"test if content is gzipped by magic num . first two bytes of gzip stream should be 0x1f and 0x8b , the third byte represent for compress algorithm , always 8(deflate ) now"
decode deflate stream
judge if is http request by the first line
judge if is http response by http status line
run captipper @return : captipper dict .
yield index tuples covering the m - scaled d+1 simplex ( d+1 cube corner n^d with edge length m - 1 .
count points in the d - m simplex .
return an ordered forward and backward mapping of the points in the d - m simplex .
build index arrays for multiplication . see ` simplex_mul_i ` .
xy 2d fractional xy object coordinate ( object knows meaning ) pq 2d fractional sagittal / meridional pupil coordinate
"test the model hierarchy , setters and getters"
декодирование пользователя - инициатора платежа
кодирование пользователя - инициатора платежа
генератор номера платежа ( по умолчанию )
"получение данных , передаваемых с запросом"
one method to interface with different methods of visualizing missing data ..
convert abbreviations like ' 100 m ' or ' 10k ' to a number .
the exported plugin code for transitive_dependencies .
the exported plugin code for generate_vsprojeccts
creates a grpccalloptions value to be passed at rpc invocation .
identifies the peer that invoked the rpc being serviced .
disables compression of the next response passed by the application .
disables compression of the next request passed by the application .
reserves a port for insecure rpc service once this server becomes active .
reserves a port for secure rpc service after this server becomes active .
starts this server 's service of rpcs .
stops this server 's service of rpcs .
creates an io object to be used for writing .
extracts the text stored in the given bytes buffer and generates an unicode string .
checks that given an name and a value the ` write_string ` method generates the expected xml text .
checks that given the value ` true ` the ` write_boolean ` method generates the expected xml text .
checks that given the value ` false ` the ` write_boolean ` method generates the expected xml text .
checks that given the value ` 0 ` the ` write_integer ` method generates the expected xml text .
checks that given the value ` 0 ` the ` write_integer ` method generates the expected xml text .
checks that the generic ` write ` method does n't require an xml writer paramater .
checks that the generic ` write ` method uses the alternative root tag if provided .
checks that the generic ` write ` method accepts an xml writer as parameter .
checks that the generic ` write ` method raises an exception if it is given a list and no root tag .
checks that the generic ` write ` method accepts empty lists .
checks that the generic ` write ` method accets lists with one element .
checks that the generic ` write ` method accets lists with two elements .
checks that the generic ` write ` method accets lists containing elements of different types .
"reads a string value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of string values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
converts the given text to a boolean value .
"reads a boolean value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of boolean values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
converts the given text to an integer value .
"reads an integer value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of integer values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
converts the given text to a decimal value .
"reads a decimal value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of decimal values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
converts the given text to a date value .
"reads a date value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of date values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
converts the given text to an enum .
"reads a enum value , assuming that the cursor is positioned at the start element that contains the value ."
"reads a list of enum values , assuming that the cursor is positioned at the start element of the element that contains the first value ."
registers a read method .
"reads one object , determining the reader method to use based on the tag name of the first element . for example , if the first tag name is ` vm ` then it will create a ` vm ` object , if it the tag is ` vms ` it will create an array of ` vm ` objects , so on ."
check that reference to storage domains service is not none
test returning empty storage domains list
test returning empty storage domains list
test we do n't get null storage domain service for existing storage domain i d and correct object
find rootname from archive_olpath property . return none if not found .
find rootname given node
"return three tuple ( key , row ) whose elemens are key object for sorting table and dictionary which has following keywords : heading , closed , scheduled , effort , clocksum , rootname ."
add oddday key in each rows of key_table * in place * . note that key should be a ` ` datetime.date ` ` object .
get data for rendering jinja2 template . data is dictionary like this :
iterate over events in org nodes .
org date object .
org node object .
path to org - mode file .
: class:`eventgroup ` object .
return the index in event group .
number of event in this group
"supported tags : malware , botnet , spam , phishing , dnsbl , blacklist"
"supported tags : malware , botnet , spam , phishing , dnsbl , blacklist"
constructor for a feebackcontroller .
format a command into a message to be logged .
gets the current timestamp
set up logging : param start_time : the start time of the log : param path : the path to the log folder : return : the logger object
get a file handler for logging : param path : the log file path : param start_time : the start time : return : the file handler
get a colourful console handler : return : the console handler
constructor for a mongoclient
destructor for a mongoclient .
set the value(s ) for a single cell or a cell range .
returns a list of all sheet names in the workbook .
get the value of a single cell or a cell range from the server and return it or them .
save the spreadsheet in its current state on the server . the server determines where it is saved .
encode msg into json and then send it over the socket .
"receive a message from the client , convert the received utf-8 bytes into a string then decode if from json ."
receive length number of bytes from the client .
disconnect from the server .
convert a message to json and send it to the client .
"receive a message from the client , decode it from json and return ."
receive length number of bytes from the client .
handle first request to server and check that it adheres to the protocol .
unlock the spreadsheet and close the connection to the client .
"make a connection to the client , run the main protocol loop and close the connection ."
"given an array of antenna positions , generate an array of baseline - vectors ."
"when passed a subset of astropy table columns , turn them into a 2 - d ndarray ."
"read itrf data in ascii format and return ( antenna positions , labels ) ."
generate the baselines and baseline - labels
instantiate telescope model from itrf co - ordinates of antennae
calculate the local hour angle of a target - ra at a given time
calculate the local sidereal time at the telescope
wrapper around : py : func:`.time_of_next_transit `
transform baselines to uvw for source at given local - hour - angle and dec.
calculate the uvw - array towards pointing centre for each obs_time .
calculate the uvw - array towards pointing centre for all obs_times .
sanity check the calculations for oversampling of subpixel offsets
sanity check everything works ok when input is 2d array ( i.e. uv - coords )
"test generation of cached ( offset ) kernels , and demonstrate correct usage ."
integration test of the convolve_to_grid function with oversampling
convert angular separation to delta - ra ( dec - dependent ' inflated radius ' ) .
extract a local sky model from a given catalog
highlight a segment .
decorator that installs powerline prompt to the class
run module as a script
list all outputs in segment_info format
list all workspaces in segment_info format
list all tab pages in segment_info format
list all buffers in segment_info format
get client id given segment info
highlight a segment .
: type review_id : str
connect to a postgresql server using the module wide connection and set the isolation level .
return the backend process id of the postgresql server that this session is connected to .
"call a stored procedure on the server , returning the results in a : py : class:`queries . results ` instance ."
explicitly close the connection and remove it from the connection pool if pooling is enabled . if the connection is already closed
return the current open connection to postgresql .
"return the current , active cursor for the open connection ."
return the current client encoding value .
return a list of up to the last 50 server notices sent to the client .
return the pool id used for connection pooling .
"a generator to issue a query on the server , mogrifying the parameters against the sql statement . results are returned as a : py : class:`queries . results ` object which can act as an iterator and has multiple ways to access the result data ."
set the client encoding for the session if the value specified is different than the current client encoding .
"when deleting the context , ensure the instance is removed from caches , etc ."
"for use as a context manager , return a handle to this object instance ."
"when leaving the context , ensure the instance is removed from caches , etc ."
set the isolation level automatically to commit after every query
"remove the connection from the stack , closing out the cursor"
"connect to postgresql , either by reusing a connection from the pool if possible , or by creating the new connection ."
return a cursor for the given cursor_factory . specify a name to use server - side cursors .
increment the number of exceptions for the current connection .
increment the number of executions for the current connection .
return a psycopg2 connection for the specified kwargs . extend for use in async session adapters .
register the cursor to be able to receive unicode string .
register the uuid extension from the psycopg2.extra module
return the current connection status as an integer value .
get_current_user returns value from pwd.getpwuid
pypy flag is set properly
hostname should match expectation
port should match expectation
path should match expectation
username should match expectation
password should match expectation
hostname should match expectation
port should match expectation
dbname should match expectation
user should match expectation
password should match expectation
options should match expectation
keepalive should match expectation
invalid query argument should not be in kwargs
return the current username for the logged in user
return the parsed query string in a python2/3 agnostic fashion
return a postgresql connection uri for the specified values .
"return a uri as kwargs for connecting to postgresql with psycopg2 , applying default values for non - specified areas of the uri ."
parse the url in a python2/3 independent fashion .
finds kernel specs from conda environments
returns a list of path as given by ` conda env list --json ` .
returns all potential envs in a basedir
converts a list of paths to environments to env_data .
validates that this env contains an ipython kernel and returns info to start it
validates that this env contains an irkernel kernel and returns info to start it
finds a exe with that name in the environment path
used when the entire index for model is updated .
"https://github.com/django/django/blob/master/django/contrib/humanize/templatetags/humanize.py converts an integer to a string containing commas every three digits . for example , 3000 becomes ' 3,000 ' and 45000 becomes ' 45,000 ' ."
simplest request possible . company . getendpoint is not an authenticated method
request that requires authentication to make sure the auth is working
makes sure the suite properties can get the list of metrics
makes sure the suite properties can get the list of elements
make sure a basic report can be run
make sure reports can be generated from json objects
make sure the account are printing out in html correctly for ipython notebooks
make sure the custom str works
make sure the report suites are printing okay for ipython notebooks
make sure the str represntation is working
test suite for omnitue module
string : connector name .
string : connector description .
string : connector name .
string : connector info .
list : data_sources(reports )
split a complete path in a list of strings
"create a folder on google drive . it creates folders recursively . if the folder already exists , it retrieves only the unique identifier ."
check if a file with specific parameters exists in google drive .
"saves new content to the file specified by name . the content should be a proper file object or any python file - like object , ready to be read from the beginning ."
deletes the specified file from the storage system .
"returns true if a file referenced by the given name already exists in the storage system , or false if the name is available for a new file ."
"lists the contents of the specified path , returning a 2 - tuple of lists ; the first item being directories , the second item being files ."
"returns the total size , in bytes , of the file specified by name ."
returns an absolute url where the file 's contents can be accessed directly by a web browser .
returns the last accessed time ( as datetime object ) of the file specified by name .
returns the creation time ( as datetime object ) of the file specified by name .
returns the last modified time ( as datetime object ) of the file specified by name .
registers a new operator function in the test engine .
registers a new attribute only operator function in the test engine .
registers a new operator class in the test engine .
runs the current phase .
"runs searches on the agris engine , handles pagination and sends results links to other functions : param ag_str : agrovoc term ( str ) : param q : query ( str ) : return : result urls ( list )"
"scrapes the title , abstract and agrovoc codes from the given address : param address : ( str ) : return : title , abstract , terms ( list ) ( tuple )"
downloads the xml for the particular record in the address : param address : ( str ) : param file_location : ( str )
"returns a list of ranks or a single rank , if rank_id or only_one are specified ."
"create a new rank . returns the i d of the inserted rank ( a string ) if everything went well , false otherwise ."
"list all the documents , each has a name that identifies it , and an hash map ."
requires standard login credentials
"check the user rank , if the user has not the right rank is redirect to a 401 page ."
set the hashmap called inside the ' g ' global flask variable .
run the template from a specific directive
extract status and message from the given dictionary . the message is translated according to the hash map .
set status and message on the given dictionary . the message is translated according to the hash map .
"the overview shows the list of the users registered , can sort the users depending on the field want ."
the administrator can create a new user
returns filename without up to two extensions e.g. /users / alex / work / joint / src / isas - cc.csv.gz -- > isas - cc
convert similarity from scientific to normal format .
make sure that the string is in unicode .
returns a string representing a list
parses a string that supposed to contain a list ( or something that has len ) . returns a list .
"returns a random integer from 0 to 100,000"
make the directory .
yield successive n - sized chunks from l.
"reads vocabulary in the "" word "" format"
in case of conflict take the max of two .
takes as input a two symbol language code e.g. ' de ' and returns all words from the evaluation datasets for this language
initialize the database class
start discovery process
tangle non - code and code blocks .
load the configuration files and load the command plugins that they define .
load release information from the repository we came from .
"link packages to the target , and write indexes ."
"create compressed versions of indexes , and their hashes . also clear out zero - length files ."
write the toplevel release files as needed .
"write the repository , using the settings the object was constructed with ."
` recipient ` is a user instance .
automatically records a timestamp as well .
returns the actual ` user ` instance for the actor .
the primary link url for this activity item .
"setrefreshtimer(self , proc , timeout=1 )"
oncall(wx . event )
"read(name , default= "" "" , obj = none )"
"write(name , value , obj = none )"
delete(rows ) expects rows in reverse sorted order
: param callback : : return :
: param callback : : return :
: param args : : return :
save parameters into member variables . cumulative reward per task . the event manager is the controller that dispatches . changes in the environment ( like new inputs or state changes ) . to handler functions in the tasks that tell the environment how to react . intialize member variables . we hear to our own output .
main loop of the environment . receives one bit from the learner and produces a response ( also one bit ) . will be set while execution is inside this function or its child tree . make sure we have a task . if the task has not reached the end by either timeout or achieving the goal . check if a timeout occurred . process the input from the learner and raise events . record the input from the learner and deserialize it .
returns a dictonary that contains the cumulative reward for each task .
"checks if the reward is allowed within the limits of the`max_reward_per_task ` parameter , and resets it to 0 if not ."
tells if the environment is sending any information through the output channel .
: param sequence : : return :
send the current received message to the task
: param sequence : : return :
: param message : : return :
: return :
"the following two ifs prevent repeating the same feedback ad infinitum , which otherwise happens in mini - tasks in case of a repeated invalid input . self._result is set back to none every time a new task is switched . adds a final space to the final message of the task to separate the next task instructions"
sets the reward immediately '
: param event : : return :
"this rases a statechanged event , meaning that something in the state of the world or the tasks changed ( but we do n't keep track what ) state changed events can only be raised if the current task is started . tasks that have a world should also take the world state as an argument"
"asks the task scheduler for a new task , reset buffers and time , and registers the event handlers . deregister previous event managers . pick a new task . this is to check whether the user did n't mess up in instantiating the class . check if it has a world : if we had an ongoing world , end it . register new event handlers for the world . initialize the new world . reset state . register new event handlers . start the task , sending the current environment . so it can interact by sending back rewards and messages . self._register_task_triggers(self._current_task )"
"if the trigger was not registered , we do n't worry about it if the trigger was not registered , we do n't worry about it"
: param task : : return :
: param task : : param trigger : : return :
this coroutine performs reset to fifo
this coroutine performs a write of the fifo
this coroutine performs a read of the fifo and returns a value
try writing values into the fifo and reading back
return entire set of matches
test if a single mgi is in the set of matches
generates an absolute cosine time series with the amplitude exponentially decreasing
the clear method clears the current document of all its content . syntax
the document.close ( ) method finishes writing to the open document . syntax
"creates an element of the type specified . note that the instance returned implements the element interface , so attributes can be specified directly on the returned object ."
focus sets focus on the current document . syntax
returns the element whose id is specified . syntax
returns a list of elements of a given name in the document . syntax
returns a list of elements of a given name in the document . syntax
writes a string of text to a document stream . syntax
writes a string of text followed by a newline character to a document . syntax
method to update droplet ( primarily used to update ip information and state changes )
method to update droplet
convenience method to return the percentage of event completion
this method renames the droplet to the specified name .
this method allows you to reinstall a droplet with a default image . this is useful if you want to start again but retain the same ip address for your droplet .
this method allows you to restore a droplet with a previous image or snapshot . this will be a mirror copy of the image or snapshot to your droplet . be sure you have backed up any necessary information prior to restore .
this method enables / disables automatic backups which run in the background daily to backup your droplet 's data .
this method destroys one of your droplets - this is irreversible .
this method allows you to reboot a droplet . this is the preferred method to use if a server is not responding .
this method allows you to shutdown a droplet . the droplet will remain in your account .
this method allows you to power cycle a droplet . this will turn off the droplet and then turn it back on .
this method allows you to power off a droplet . this will turn off the droplet and then turn it back on .
this method allows you to power on a previously powered off droplet .
this method will reset the root password for a droplet . please be aware that this will reboot the droplet to allow resetting the password .
this method allows you to resize a specific droplet to a different size . this will affect the number of processors and memory allocated to the droplet .
"this method allows you to take a snapshot of the droplet once it has been powered off , which can later be restored or used to create a new droplet from the same image . please be aware this may cause a reboot ."
creates an axes for displaying fits images . the axes uses the fits header information for ticks and grids appropriate for sky coordinate .
select wcs related cards
draw an arrows pointing the directions of e & n
return a list with the command to execute .
return the components of the match .
return true if ` matched_file ` is logically the same file as ` self.filename ` .
return the filename of the crate root .
return the class of the implementation that carries that name .
run the single hook specified by resolving all its prerequisites .
hooks which only want to be run once .
hooks that can be called more than once .
create flow throttler object .
enforce dailyflowrequestlimit and flowduplicateinterval .
test we handle when pam ssh service does n't require an account .
test we find when pam ssh service allows an unconditional auth permit .
test we detect when pam ssh service does n't deny auth by default .
test we find when pam ssh service allows an unconditional auth permit .
test we detect when pam ssh service does n't deny auth by default .
test we detect when pam ssh service does n't deny auth by default .
ensure check detects pam config files that non - root users can edit .
check that the rdfproto is the same as the sample .
make a sample pathspec instance .
test we can pop arbitrary elements from the pathspec .
test that pathspec works .
test that we can manipulate paths in unicode .
set up some vars for the directories we use .
clean the build environment .
use gsutil to copy sdists from cloud storage .
installs grr .
builds the client templates .
repack templates with a dummy config .
cleanup from any previous installer enough for _ checkinstallsuccess .
checks if the installer installed correctly .
install the installer built by repacktemplates .
build templates .
reads results for one hunt and process them .
filter the cron job approvals in the given timerange .
filter the hunt actions in the given timerange .
filter the hunt approvals in the given timerange .
filter the last week of user actions .
filter the last week of user actions .
only used in tests and will rerun all the hooks to create a clean state .
streams chunks of a given file starting at given offset .
streams chunks of a file located at given path starting at given offset .
streams chunks of memory of a given process starting at given offset .
streams chunks of a given file starting at given offset .
yields spans occurrences of a given pattern within the chunk .
an integer representing current position within the source .
an abstract method for reading byte segments .
whether the condition applies to external data .
"whether the conditions applies , modulo host data ."
whether the condition contains the specified values .
map functions that should be called if the condition applies .
add criteria for a check .
"adds existing triggers to this set , optionally rebuilding the registry ."
test if host data should trigger a check .
find the host attributes that trigger data collection .
find the artifacts that correspond with other trigger conditions .
find the methods that evaluate data that meets this condition .
test it does nothing if the first component is not ' rundll ' .
test it returns second out of 2 components if the first is ' rundll ' .
test it returns second out of 2 components if the first is ' rundll ' .
test it returns all components except for the first ' rundll ' .
test it returns 3rd out of 2 components if the first two are rundll .
test it strips the function name .
test it ignores a path without executable extensions .
test it returns a path if executable extension is found .
test the extraction is case insensitive .
test it does nothing if the mapping is empty .
test it correctly replaces one variable .
test it correctly replaces two variables .
test variable replacement is case insensitive .
test it generates multiple replacements if replacement is a list .
test it keeps variable value stable in a single path .
test it generates a product if two replacements have multiple values .
test it replaces system root prefix with a system root variable .
test it replaces system32 prefix with a system root variable .
test it extracts paths from non - rundll strings .
test it extracts paths from rundll strings .
test it replaces environment variables .
test it replaces environment variables with multiple mappings .
very simple emulator of the worker .
check that arrays with a forced type are enforced .
checks access to the given client .
checks access to the given hunt .
checks access to a given cron job .
checks if the given flow can be started by the given user .
the main entry point for checking access to aff4 resources .
elevates this token to a supervisor token .
returns the real token ( without suid ) suitable for testing acls .
report file frequency by client count .
ensure we can extract users from a passwd file .
sign the csr from the client .
begins an enrollment flow for this client .
generate rdfs for the fully expanded configs .
return pamconfigentries it finds as it recursively follows pam configs .
run a search with the given settings and return the path found .
executes the search
callback to show speed .
converts and rounds a numpy.float * to python float
print scutum icon
this function parses all arguments
operates arptables directly and locks gateway mac addresses
parses configuration this function parses the configuration file and load the configurations into the program
test creation of collection .
test creation of collection .
test creation of collection .
test append .
test append .
test extend .
test extend .
test insert .
test insert .
test set .
test set .
test set slice .
test set slice .
test set slice .
test set slice .
test getting of item .
test getting of slice .
test getting of slice .
"multibox loss args : predictions ( tuple ): a tuple containing loc preds , conf preds , and prior boxes from ssd net . conf shape : torch.size(batch_size , num_priors , num_classes ) loc shape : torch.size(batch_size , num_priors,4 ) priors shape : torch.size(num_priors,4 )"
read a line from set_finder and convert it to a tuple of values .
evaluate an expression using the provided values and a set of metrics .
calculate the mean distance between binding sites on the bg genome .
score a set using the provided ` score_fun ` .
prints an error message to stderr and exits .
prints a warning message to stderr .
workspace should be initialized .
metadata getting and setting should use property attributes .
must add the reverse complement of a primer if requested .
return a string describing a set of modifiers .
return a string describing a key symbol .
return a string describing a text motion .
return a key symbol for a key not supported by pyglet .
simulate the passage of time like a real clock would
"pyglet 's clock will not make up for lost time . in this case , the interval scheduled for callback_[bcd ] is 1 , and 2 seconds have passed . since pyglet wo n't make up for lost time , they are only called once ."
"pyglet 's clock will not make up for lost time . in this case , the interval scheduled for callback_[bcd ] is 1 , and 2 seconds have passed . since pyglet wo n't make up for lost time , they are only called once . this test verifies that missed events are rescheduled and executed later"
"test that the soft scheduler is able to correctly soft - schedule several overlapping events . this test delves into implementation of the clock , and may break"
tween the values v1 and v2 by the factor 0 < t < 1 using the supplied function .
tween the triples p1 and p2 by the factor 0 < t < 1 using the supplied function .
return the drawstyle for this drawable .
convenience method .
modify some aspect of the style . if style.is_copy is false then .copy ( ) it . we do n't do that automatically because there 's a chance this method is a noop .
invoke to position the dialog in the middle of the parent ( presumably the window ) and make the dialog become modal .
implements table 2 of uax # 29 : grapheme cluster boundaries .
set metrics for this glyph .
debug method .
debug method .
not implemented .
set the opengl blend state for the glyphs in this texture .
place ` image ` within this texture .
add font data to the font loader .
determine if a font with the given name is installed .
create a glyph using the given image .
create and return a list of glyphs for ` text ` .
return a list of glyphs for ` text ` that fit within the given width .
read a gif file stream .
override for loading from archive / network etc .
create the object from the xml element and attach it to the parent .
select the correct image to render .
select the correct image to render .
find and load a library .
implements the dylib search as specified in apple documentation :
implement runtime framework search as described by :
make the window size just big enough to show the current video and the gui .
position and size video image .
"main method returns 0 on success , 1 on failure"
": param ev_tz : timezone for serializing the event timestamp : param dt_col_tz : timestamp and datetime columns in mysql also gives a naive datetime object , timezone info is also need for serializing : param indent : json dump indent"
create a statestore for each streamtask . * these statestores may exist in different threads . *
copied in part from mdtraj.formats.hdf5.topology setter .
copied in part from mdtraj.formats.hdf5 topology property .
"create a new action and assign callbacks , shortcuts , etc ."
repeatedy absorb lin ops .
if possible moves the top level lin op argument into the prox operator .
copy the optional parameters from src_prox to dst_prox .
"if not a variable , returns a shallow copy ."
absorb the constant offset into the b term and zero out constants in lin op .
x = v
evaluate the function on v ( ignoring parameters ) .
test absorb lin op operator .
test merging functions .
test function to merge all prox operators possible .
test obtaining the constant offset .
merge as many prox functions as possible .
can lh_prox and rh_prox be merged into a single function ?
merge the two functions into a single function .
return a list of the variables in the problem .
initialize temporary variables for _ prox method .
the prox function for a specific atom .
"wrapper on the prox function to handle alpha , etc . it is here the iteration for debug purposese etc ."
evaluate the function on v ( ignoring parameters ) .
evaluate the function on v.
default to string is name of class .
proxfn + proxfn(s ) .
called for list + proxfn .
proxfn * number .
called for number * proxfn .
called for proxfn / number .
proxfn / integer .
returns a shallow copy of the object .
returns info needed to reconstruct the object besides the args .
json can handle a native list type not only strings
max_length refers to number of characters used to store the encoded list of choices ( est . 2n - 1 )
"takes processed widget data as value , possibly a char string , and makes it into a python list"
prepares a string for use in serializer
"given a widget instance ( * not * a widget class ) , returns a dictionary of any html attributes that should be added to the widget , based on this field ."
this view should return a list of all the branching for the currently authenticated user .
this view should return a list of all the phonebooks for the currently authenticated user .
return all managers of the system
return agents which are belong to manager_id
return all agent of the system
this view should return a list of all the phonebooks for the currently authenticated user .
this view should return a list of all the dnc contacts for the currently authenticated user .
this shortcut function allows you to get events that have started recently .
agent login page
agent login page
agent login page
* * attributes * * :
user detail change on agent ui
user detail change on agent ui
agent list for the logged in manager
add new agent for the logged in manager
delete a agent for a logged in manager
update / delete agent for the logged in manager
filter survey field
survey section type name
modify survey result string for display
calculate branching count
create survey view link
run microsoft speak text2speech and return audio url
run acapela text2speech and return audio url
gets the cached clients dictionary in current context .
adds remote application and applies custom attributes on it .
creates and adds new remote application .
"since weibo is a rubbish server , it does not follow the standard , we need to change the authorization header for it ."
creates a remote app and registers it .
creates a remote app only .
sets a function to process kwargs before creating any app .
the uri returned from request.uri is not properly urlencoded ( sometimes it 's partially urldecoded ) this is a weird hack to get werkzeug to return the proper urlencoded string uri
extract request params .
make sure text is bytes type .
decode base64 string .
create response class for flask .
console script for house_prices
loads the fashion mnist dataset .
build the specified module with specified arguments .
"@type module : module @type task_name : string @param task_name : task name , exactly corresponds to function name ."
@type module : module @type logging : logger @type task : task @type completed_tasts : set task @rtype : set task @return : updated set of completed tasks after satisfying all dependencies .
@rtype : argparse . argumentparser
returns all functions marked as tasks .
returns the length of the longest task name .
@type module : module @rtype : logging . logger
@type func : 0 - ary function @type dependencies : list of task objects
returns true is an object is a build task .
target footnote generation .
"given an input string , returns a dictionary of html document parts ."
"given an input string , returns an html fragment as a string ."
"return the document tree and publisher , for exploring docutils internals ."
initial setup for in - place document transforms .
override to apply the transform to the document tree .
store a single transform . use ` priority ` to override the default . ` kwargs ` is a dictionary whose contents are passed as keyword arguments to the ` apply ` method of the transform . this can be used to pass application - specific data to the transform instance .
"store multiple transforms , with default priorities ."
store a transform with an associated ` pending ` node .
"return a string , ` priority ` combined with ` self.serialno ` ."
"store each component 's default transforms , with default priorities . also , store components by type name in a mapping for later lookup ."
"apply all of the stored transforms , in priority order ."
build the url with query string : return : url with query string
generate string which should be signed and setted in header while sending request @rtype : string @return : canonical string for netease storage service
get canoicalized resource /bucket / obj?upload
starting point when module is the main routine .
starting point when module is imported by another program .
starting point when module is the main routine .
starting point when module is imported by another program .
"creates a ttk frame with a given master , and use this new frame to place the scrollbars and the widget ."
hide and show scrollbar as needed .
starting point when module is the main routine .
starting point when module is imported by another program .
perform reciprocal best hits between the given maf files .
map names from translated rbh 's to original query and database names .
log scale the evalue column specified by name .
build the crbh model on the given rbh 's .
filter a dataframe of last best hits using the crbh model .
a simple method that runs a commandexecutor .
find the corresponding command in order to execute it
is used to execute the command corresponding to the passed argument .
"example 1.6.1 from book "" solar engineering of thermal processes by duffie and beckman , fourth edition , wiley 2013 """
import all actions related to netconf driver and call the driver utils to execute a keyword
constructor for defects driver
create a json file each failing keyword
"process the text and attributes of a node into a text , this text will be used in the defect json file"
"get test for arguemnt nod ein the form name=""name "" , value=""value """
gets the list of defect json files for the testcase execution
creates a warrior jira object
creates issues in jira
attach logs to jira issues
ftp(test both put and get).this keyword can be used to transfer file from source _ system to destination system or vice versa . it checks the size after transfer in both get and put .
sftp(test both put and get).this keyword can be used to transfer file from source _ system to destination system or vice versa . it checks the size after transfer in both get and put .
takes a list of systems as input and executes the testcases in parallel by creating separate process of testcase_driver for each of these systems
executes the list of testcases in parallel computes and returns the testsuite status
logs into the syncplay server after the tcp connection is established . also sends details about the current file loaded into mpv and sets the user as ready .
sends the current mpv file details to syncplay server . sends the filename raw .
sets the user ready status to value ( boolean ) .
"sends a message to the syncplay server . accepts a dictionary , which is turned into a json string before being converted to a byte - string and sent as a line ."
"given a list of ` ` saltnode``\s , returns a list of lists , where each list contains the indices of the nodes belonging to that sentence ."
extracts the primary text from an stextualds node .
return all nodes beloning to the given layer
creates a ` ` saltnode ` ` instance from the etree representation of an < nodes > element from a saltxmi file .
creates an etree element of a ` ` saltnode ` ` that mimicks a saltxmi < nodes > element
"returns the string representation of a ` ` saltnode ` ` , which contains the facts from ` ` saltelement ` ` plus the node 's layer and its features ."
creates a ` ` primarytextnode ` ` instance from the etree representation of a < nodes > element from a saltxmi file .
convert a pcc document into a gexf file .
convert a saltxmi file into a graph
create a saltdocument and derive a linguisticdocument from it
"return a board data structure wit htiles in the sovled state for example , if boardwidth and boardheight are both 3 , this function returns [ [ 1 , 4 , 7 ] , [ 2 , 5 , 8 ] , [ 3 , 6 , none ] ]"
apply syntax highlighting to the given block of text .
"do highlighting of multi - line strings . ` ` delimiter ` ` should be a ` ` qregexp ` ` for triple - single - quotes or triple - double - quotes , and ` ` in_state ` ` should be a unique integer to represent the corresponding state changes when inside those strings . returns true if we 're still inside a multi - line string when this function is finished ."
save a link check result for a resource .
return a list of up to ` ` n ` ` resource ids to be checked .
return true if the given link checker result represents a broken link .
get the latest link check result data for a resource .
a simple wrapper for ckan 's package_search api action .
return a datasets with broken links grouped by organization report .
return a report of datasets with broken links grouped by email .
"get the current governor for cpu0 , assuming all cpus use the same ."
non - buffered printing to stdout .
interrupted respecting reader for stdin .
return iterator over self.quantity of subsequent generated values
abstract method that shall return iterator to subsequent generated values
decorator marking container method as an action all marked method will be processed by containermeta
wait until algorithm scene is finished
generate a list of annotationtypes for a specified text file for parsing it as a column - delimited file
load a corpus from a column - delimited text file
load a featurematrix from a column - delimited text file
recursively parse transcription lists into strings for saving
save a corpus as a column - delimited text file
save a featurematrix as a column - delimited text file
generate a list of annotationtypes for a specified text file for parsing it as an orthographic text
loads a directory of orthographic texts
load a discourse from a text file containing running text of orthography
export an orthography discourse to a text file
add participants to the specified survey .
delete participants ( by token ) from the specified survey .
get participant properties ( by token ) from the specified survey .
get participant properties of a survey .
send invitation emails for the specified survey participants .
list participants in a survey .
given the head of a linked list finds and returns the node where a cycle begins . uses o(1 ) space and o(n ) time .
returns the max coins with an optimal popping strategy .
returns the max coins popping balloons[lo ... hi ] optimally .
"returns the maximum length of a wiggle subsequence . the problem boils down to finding the number of min / max inflection points in the sequence . for example , if we are looking for an "" up "" wiggle in the sequence it makes sense to go as high up as we can to increase the set of numbers that will allow us to come back in a "" down "" wiggle . similar logic holds when going "" down "" the wiggle ."
"given a list of line heights , finds the largest container between two lines . good explanation of the algorithm can be found at https://discuss.leetcode.com/topic/3462/yet-another-way-to-see-what-happens-in-the-o-n-algorith # nopep8"
finds the last index of target in range [ start ... end ] of array . returns -1 if the target does not exist . the array is expected to be sorted in ascending order and array[start ] must be the target for the search to continue .
removes duplicates from sorted array nums so that there are at most k duplicates .
"given tilegrid , segment name and tag , return fasm directive"
"return ( x1 , x2 ) , ( y1 , y2 ) from xray_roi , exclusive end ( for xrange )"
"when given keyword arguments , functools.partial only makes them defaults . the full signature is therefore not fully determined , since the user can replace wrapped and change the meaning of * args , * * kwargs ."
headertuple objects are tuples .
headertuple objects unpack like tuples .
headertuple objects can be indexed .
neverindexedheadertuple objects can not be indexed .
headertuples and neverindexedheadertuples are equal to equivalent tuples .
headertuples and neverindexedheadertuples are always equal when compared to the same class .
headertuples compare equal to equivalent neverindexedheadertuples .
call this method to get a bridge instead of a standalone accessory .
call this method to get a standalone accessory .
stores an accessory and then loads the stored state into another accessory . tests if the two accessories have the same property values .
test that _ set_services still works and has access to the info services
wait for password request on fifo and answer with password from self.db through fifo .
reload passwords during runtime .
search all profiles in config and collect passwords from keyring .
"based on profile settings return password from keyring , password_cache or by asking user ."
get password from system keyring ( seahorse ) . the keyring is only available if user is logged in .
get password from password_cache
ask user for password . this does even work when run as cronjob and user is logged in .
internal password cache . prevent to ask password several times during runtime .
store password to keyring and password_cache
attach a queue to a callable to check if it was called asynchronously .
parse an expression @param string : the expression text @returns : an l{expression } object
iterate page objects @implementation : must be implemented by subclases
"iterate path objects for template c{index ( ) } function , depth first @param namespace : the sub namespace to iterate or none to iterate toplevel"
list tasks @param parent : the parent task ( as returned by this method ) or c{none } to list all top level tasks @returns : a list of tasks at this level as sqlite row objects
list tasks @returns : a list of tasks as sqlite row objects
get the l{path } for the source of a task @param task : the task ( as returned by l{list_tasks ( ) } @returns : an l{indexpath } object
contructor @param notebook : the source l{notebook } for resolving links @param layout : the l{exportlayout } for resolving target files @param source : is the l{path } of the source page being exported @param output : is a l{file } object for the destination file @param usebase : if c{true } the format allows returning relative paths @param document_root_url : optional url for the document root
returns an url for a link in a zim page this method is used to translate links of any type .
returns an url for image file ' src '
return an url for template resources
"find the source file for an attachment used e.g. by the latex format to find files for equations to be inlined . do not use this method to resolve links , the file given here might be temporary and is not guaranteed to be available after the export . @returns : a l{file } object or c{none } if no file was found"
find the destination file for an attachment @returns : a l{file } object
turn a l{path } object in a relative link or uri
turn a l{file } object in a relative link or uri
"constructor @param list : a list of 3 - tuples giving path name , cursor position and scroll position . will be converted in a list with l{historypath}s"
serialize to string @returns : the list content as a json formatted string
constructor @param notebook : a l{notebook } object @param uistate : l{sectionedconfigdict } to store the history ( history will use the ' history ' section in configdict )
append a new page to the history . will drop the forward stack and make this page the latest page . @param path : l{path } for the current page @emits : changed
get current path @returns : a l{historypath } object
"set current path ( changes the pointer , does not change the list of pages ) @param path : a l{historypath } object @raises valueerror : when the path is not in the history list"
get the previous path @returns : a l{historypath } object or c{none } if current is already the first path in the list
get the next path @returns : a l{historypath } object or c{none } if current is already the last path in the list
"get the most recent path that is a direct child of the given path . if there is a recent grand - child of the given path in the history , that will be used as a bases to get a new l{path } object . used by the keybinding for navigating to child pages . @param path : a l{path } object @returns : a l{historypath } or l{path } object or c{none }"
get the deepest nested grand - child of a given path . used for the ' namespace ' pathbar to keep showing child pages when the user navigates up . @param path : a l{path } object @returns : a l{historypath } object or c{none }
"looks through the history and recent pages to the last known cursor position for a page . @param path : a l{path } object @returns : a tuple of cursor and scroll position for c{path } or c{(none , none ) }"
"generator function that yields history records , latest first @returns : yields l{historypath } objects"
generator function that yields recent pages @returns : yields l{recentpath } objects
encode a pagename to a filename
decodes a filename to a pagename
"constructor @param folder : a l{folder } object @param endofline : either "" dos "" or "" unix "" , default per os"
map a pagename to a ( default ) file @param pagename : a l{path } @returns : a 2 - tuple of a l{file } for the source and a l{folder } for the attachments . neither of these needs to exist .
"map a filepath to a pagename @param file : a l{file } or l{filepath } object @returns : a l{path } and a file type ( c{file_type_page_source } , f{file_type_attachment } )"
like l{map_file } but takes a string with relative path
decide which is the real page file when multiple files map to the same page . @param filepaths : 2 or more l{filepath } objects @returns : l{filepath } that should take precedent as te page source
convert a sublime view into an swidebugview
"takes a list of line numbers ( zero based ) , regions , or else uses the selection . returns regions , each covering one complete line , representing the lines included in the supplied input ."
takes one or more lines and returns the 0 - based line and column of the first character in the line .
"inserts the specified text and creates a clickable "" button "" around it ."
"removes a clickable "" button "" with the specified index ."
removes our clickable regions then erases the view
read arbitrary size content from memory .
read a byte from memory .
write arbitrary size content to memory .
write byte in memory .
return a list of memory addresses that contain the specified value .
try to read memory content at specified address .
try to read previous memory content at specified address .
read previous value for memory location .
write arbitrary size content to memory .
write byte in memory .
get accessed addresses .
get number of write operations performed on the memory .
find gadgets .
finds possible ' ret - ended ' gadgets .
finds possible ' ret - ended ' gadgets .
build gadgets recursively .
return a gadgets list .
build a gadgets from a gadgets tree .
check for instruction validity as a gadgets .
get node root .
add a child to the node .
get node 's children .
get maximum instruction mnemonic width
get basic block label .
set basic block label .
get basic block is_entry .
set basic block is_entry .
get basic block is_exit .
set basic block is_exit .
get basic block instructions .
get basic block start address .
get basic block start address .
get basic block end address .
get basic block size .
get basic block taken branch .
set basic block taken branch .
get basic block not taken branch .
set basic block not taken branch .
get basic block direct branch .
set basic block direct branch .
get basic block branches .
check if an address is within the range of a basic block .
check if a basic block is empty .
reset current state of the analyzer .
return a smt bit vector that represents a register ( architectural or temporal ) .
return a smt bit vector that represents an architectural ( native ) register .
return a smt bit vector that represents a memory location .
return a smt bit vector that represents a memory location .
add an instruction for analysis .
add constraint to the current set of formulas .
check if the instructions and restrictions added so far are satisfiable .
get a value for an expression .
get variable name for a register considering pre and post mode .
parse instruction operand .
parse instruction .
parse an ir instruction .
append new child .
returns parent entry .
set parent entry .
returns list of children .
try to find the obj in the entry .
history has tree structure and count them .
get specific entry by index .
hook to add global options .
area under the roc curve
area under the precision - recall curve
true positive rate ` tp / ( tp + fn ) `
true negative rate ` tn / ( tn + fp ) `
matthews correlation coefficient
"f1 score : ` 2 * ( p * r ) / ( p + r ) ` , where p = precision and r = recall ."
compute pearson correlation coefficient .
"kendall 's tau coefficient , kendall rank correlation coefficient"
median absolute deviation
root mean - squared error
1 - rmse
mean squared error
exponentiated root - mean - squared error
fraction of variance explained .
: type message : message
create a class object dynamically using the appropriate metaclass .
call the _ _ prepare _ _ method of the appropriate metaclass .
calculate the most derived metaclass .
shallow copy operation on arbitrary python objects .
deep copy operation on arbitrary python objects .
keeps a reference to the object x in the memo .
"return the currect comment nesting . at the start and end of the file , this value should be zero . inside c comments it should be 1 or ( possibly ) more ."
strip the provided line of c and c++ comments . stripping of multi - line c comments works as expected .
"given a line of c code , return a string where all literal c strings have been replaced with the empty string literal "" "" ."
return the current error count for this cstylechecker object .
run the style checker on all the specified files .
run the style checker on the specified file .
"run the style checker on provided line of text , but within the context of how the line fits within the file ."
print an error message and increment the error count .
print a warning message and increment the error count .
unfolding is accomplished by simply removing any crlf that is immediately followed by wsp . each header field should be treated in its unfolded form for further syntactic and semantic evaluation .
"takes a header value and returns a fully decoded unicode string . it differs from standard python 's mail.header.decode_header ( ) because : - it is higher level , i.e. returns a unicode string instead of an array of tuples - it accepts unicode and non - ascii strings as well"
"attempts to decode part , understands ' q ' - quoted encoding ' b ' - base64 mime encoding"
returns an event indicating a report was created .
returns an event indicating a report has been responded to .
returns an event indicating a report has had an attribute changed .
returns an event indicating a rule matched a report .
sends a webhook event to any configured webhook urls
"generate ` dilated u - net ' model where the convolutions in the encoding and bottleneck are replaced by dilated convolutions . the second convolution in pair at a given scale in the encoder is dilated by 2 . the number of dilation layers in the innermost bottleneck is controlled by the ` dilation_layers ' parameter -- this is the ` context module ' proposed by yu , koltun 2016 in "" multi - scale context aggregation by dilated convolutions """
minimal conversion from simple_utide_test .
masked values in time and/or time series .
"quick check that method='robust ' works ; no real checking of results , other than by using "" py.test -s "" and noting that the results are reasonable , and the weights for the outliers are very small . minimal conversion from simple_utide_test"
robust estimate of standard deviation based on medians .
"calculate leverage as the diagonal of the "" hat "" matrix of the model matrix , x."
normalized residuals from raw residuals and a multiplicative factor .
multiple linear regression via iteratively reweighted least squares .
script execution .
script execution .
migrate to the latest schema version .
add filedata to this pcap .
add filedata to this pcap .
"generate metadata from the file data . will add content - type , length , and md5 ."
queries gridfs for a matching binary to this pcap document .
generate the domain details page .
bulk add domains via a bulk upload form .
generate the domain listing page .
add a domain . should be an ajax post .
edit a domain . should be an ajax post .
search for domains .
update tlds . should be an ajax post .
migrate to the latest schema version .
migrate from schema 3 to 4 .
migrate from schema 2 to 3 .
migrate from schema 1 to 2 .
migrate from schema 0 to 1 .
returns true if ` value ` is a list .
create a list of dictionaries with identifier information which can be used for rendering in a template .
attribute an identifier .
update the aliases on an actor .
update the tags on an actor .
set the confidence level on an attribution .
remove attribution from this actor .
return an instantiated class object .
return an instantiated class object .
return a class object .
plot excitation distribution .
main function .
run a reblocking analysis on hande output and print to stdout .
parse command - line arguments .
run reblocking and data analysis on hande output .
get the valence band maximum and conduction band minimum from vasp outcar
: type document : wagtail.wagtaildocs.models . document ( or subclass ) : param document : the document : rtype : dict : return : the document size and extension
task decorator is applied successfully
task.apply ( ) is called successfully on eager mode
task.apply ( ) is called successfully
task.name is correct
task queue name is correct
runs the worker and consumes messages from rabbitmq . returns only after ` shutdown ( ) ` is called .
processes the message received from the queue .
logs the time spent while running the task .
pause consuming messages if lood goes above the allowed limit .
counts down from max_worker_run_time . when it reaches zero sutdown gracefully .
exits after the current task is finished .
shutdown after processing current task .
shutdown after processing current task .
used internally to fail the task when connection to rabbitmq is lost during the execution of the task .
print stacktrace .
drop current task .
"return resnet unit symbol for building resnet parameters ---------- data : str input data num_filter : int number of output channels bnf : int bottle neck channels factor with regard to num_filter stride : tupe stride used in convolution dim_match : boolen true means channel number between input and output is the same , otherwise means differ name : str base name of the operators workspace : int workspace used in convolution operator"
"return resnet symbol of parameters ---------- units : list number of units in each stage num_stages : int number of stage filter_list : list channel size of each stage num_classes : int ouput size of symbol dataset : str dataset type , only cifar10 and imagenet supports workspace : int workspace used in convolution operator"
adapted from https://github.com/tornadomeet/resnet/blob/master/train_resnet.py original author wei wu
test actual_agreement_linear .
test artstein_poesio_bias_linear .
test fleiss_kappa_linear .
test fleiss_pi_linear .
test precision .
test recall .
test fmeasure .
test boundary_statistics .
test boundary_edit_distance .
test compute_window_size .
test pk .
test window_diff .
test boundary_string_from_masses .
test convert_positions_to_masses .
test convert_masses_to_positions .
boundary similarity ( b ) .
test false negative .
test false negative .
test near miss .
test one minus .
test the nltk boundary format .
test clustered fps .
test position - format .
test using an int instead of a tuple ( common mistake )
test incorrect format exception .
test incorrect argument exception .
test transposition weighting .
test multiple boundary types with auto boundary type identification .
test multiple boundary types with manual boundary type identification .
test b upon two datasets .
tests population mean .
tests population mean .
tests population standard deviation .
tests population variance .
tests population standard error of the mean .
segmentation similarity ( s ) .
segmentation similarity ( s ) .
assert that expression evaluates to the given sql
assert that two expressions evaluate to the same sql
return sql for this instance
render name as identifier
wrap name in a function call wrapper
render a single case to sql
changes the condition on which to update based on the type of update ( 999 vs subtier code )
runs a sql query to get the count of transaction rows based on the type of update . sql statement will either be agency_code = ' 999 ' or sub_tier_agency_code = ' xxxx ' for awarding and funding
logs row count before and after and update
obligationsundeliveredordersunpaidtotal in file c = ussgl 4801 + 4881 in file c for the same date context ( fyb )
obligationsundeliveredordersunpaidtotal in file c ! = ussgl 4801 + 4881 in file c for the same date context ( fyb )
"tests success for when record type is required and can not be blank . it must be 1 , 2 , or 3"
"tests failure for when record type is required and can not be blank . it must be 1 , 2 , or 3"
"test legalentityaddressline2 is optional , but must be blank for aggregate and pii - redacted non - aggregate records ( i.e. , when recordtype = 1 or 3 ) . record type 2 does n't affect success ."
"test failure when legalentityaddressline2 is n't blank for aggregate and pii - redacted non - aggregate records ( i.e. , when recordtype = 1 or 3 )"
"test primaryplaceofperformanceforeignlocationdescription must be blank for domestic recipients ( i.e. , when primaryplaceofperformancecountrycode = usa ) . this test should n't care about content when country_code is not usa ( that is for another validation ) or for aggregate and pii - redacted non - aggregate records ( recordtype=1 or 3 ) ."
"test failure primaryplaceofperformanceforeignlocationdescription must be blank for domestic recipients ( i.e. , when primaryplaceofperformancecountrycode = usa ) or for aggregate and pii - redacted non - aggregate records ( recordtype=1 or 3 ) ."
"read a csv into a dataframe , then use a configured ` clean_data ` and return the results"
load tas data from the provided csv and replace / insert any taslookups
load tas file into broker database .
look up the ids of existing tases . use account_num as a non - unique identifier to help filter results
"check for a taslookup which matches this ` row ` in the ` existing ` data . args : row : row to check in existing : dict[account_num , list[taslookup ] ]"
"tests that sf 133 amount sum for lines 1540 , 1640 matches appropriation contract_authority_amount_cpe for the specified fiscal year and period"
"tests that sf 133 amount sum for lines 1540 , 1640 does not match appropriation contract_authority_amount_cpe for the specified fiscal year and period"
set up class - wide resources ( test data )
test set - up .
insert one submission into job tracker and get submission id back .
businessfundsindicator must contain one of the following values : rec or non . case does n't matter
businessfundsindicator must contain one of the following values : rec or non .
"test legalentityziplast4 is required for domestic recipients ( i.e. , when legalentitycountrycode = usa ) for non - aggregate records ( i.e. , when recordtype = 2 ) record type 1 and non - usa do n't affect success"
test failure when legalentityziplast4 is blank for domestic recipients for non - aggregate records
"if the record is not an aggregate record ( recordtype=1 ) or individual recipient ( businesstypes includes ' p ' ) and awardeeorrecipientuniqueidentifier is provided , it must be nine digits ."
"test failure for if the record is not an aggregate record ( recordtype=1 ) or individual recipient ( businesstypes includes ' p ' ) and awardeeorrecipientuniqueidentifier is provided , it must be nine digits ."
test getting sub tiers of agencies from the permissions provided
test getting all cgacs without any sub tier agencies
test listing all the agencies ( cgac and frec ) that are accessible based on permissions given
"test printing out all agencies , frecs only retrieved if they have a sub tier , cgacs always"
test organization of passed sub tier agencies
"when both are provided , periodofperformancestartdate must occur on or before periodofperformancecurrentenddate . null in either does n't affect success"
"when both are provided , periodofperformancestartdate must occur on or before periodofperformancecurrentenddate ."
set up resources to be shared within a test class
tear down class - level resources .
tear down broker unit tests .
insert submission and return i d.
upload file to s3 and return s3 filename
create validation tables from model metadata and do initial inserts .
insert static data .
create a concatenated tas string for insert into database .
"postgres ' is not distinct from is an equality check that accounts for nulls . unfortunately , it does n't make use of indexes . instead , we 'll imitate it here"
we frequently need to mass - update records to look up their cars history entry . this function creates a subquery to be used in that update call . we pass in the database session to avoid circular dependencies
we 'll often want to copy tas component fields ; this method returns a dictionary of field_name to value
"tests that sf 133 amount sum for lines 1020 , 1030 , 1040 matches appropriation adjustments_to_unobligated_cpe for the specified fiscal year and period"
"tests that sf 133 amount sum for lines 1020 , 1030 , 1040 does not match appropriation adjustments_to_unobligated_cpe for the specified fiscal year and period"
tests that sf 133 amount sum for line 2490 matches appropriation unobligated_balance_cpe for the specified fiscal year and period
tests that sf 133 amount sum for line 2490 does not match appropriation unobligated_balance_cpe for the specified fiscal year and period
test primaryplaceofperformancecongressionaldistrict exists in the state indicated by the primaryplaceofperformancecode or is 90 in a state with multiple districts or when primaryplaceofperformancecode is 00 * * * * * . districts that were created under the 2000 census or later are considered valid
test failure primaryplaceofperformancecongressionaldistrict exists in the state indicated by the primaryplaceofperformancecode or is 90 in a state with multiple districts or when primaryplaceofperformancecode is 00 * * * * * . districts that were created under the 2000 census or later are considered valid
does the config have the necessary bits for talking to the sam soap api
"hit the sam soap api , searching for the provided duns numbers . return the results as a list of suds objects"
convert a suds result object into a row tuple . this accounts for the presence / absence of top - paid officers
soup - to - nuts creates a list of row tuples from a set of duns numbers .
modify existing models or create new ones
"if there are models which match the tas ( with an undefined end date ) , they should be modified"
"if there are models which match the tas ( with an defined end date ) , they should be modified"
"if a tas does n't share fields , we do n't expect a match"
"if the relevant tas does not overlap the date of the submission , it should not be used"
"the unique combination of fain , awardmodificationamendmentnumber , uri , and awardingsubtieragencycode must exist as a currently published record when the record is a deletion ( i.e. , if correctiondeleteindicator = d ) . ignore all other correctiondeleteindicators in this rule ."
"the unique combination of fain , awardmodificationamendmentnumber , uri , and awardingsubtieragencycode must exist as a currently published record when the record is a deletion ( i.e. , if correctiondeleteindicator = d ) . ignore all other correctiondeleteindicators in this rule ."
verify that we can retrieve multiple flex fields from our data
verify that flex data gets included in the failure row info
tests that object class program activity gross_outlays_delivered_or_fyb + gross_outlays_undelivered_fyb equals gross_outlay_amount_by_pro_fyb
tests that object class program activity gross_outlays_delivered_or_fyb + gross_outlays_undelivered_fyb does n't equals gross_outlay_amount_by_pro_fyb
"returns a h x w x 3 rgb image in the range of [ 0,1 ] ."
"given a h x w x 3 rgb image it is clipped to the range [ 0,1 ] and written to an 8 - bit image file ."
s is a list of n rows . each row is a list of h x w x 3 images .
"given a sequence of images , concatenate them along the given axis , expanding the other axes as needed . if gravity is zero then the original data will be centered in the output domain . negative or positive gravity will cause it to be flush with the lower or upper bound , respectively ."
"test adding a spawn for an item , with a spawn point ' in room ' ."
helpfully inserts data into the player 's output queue .
gets raw input from the player and queues it for later processing .
sends all data from the player 's output queue to the player .
get a prompt for the player .
parses the lines in the player 's input buffer and then calls the appropriate commands ( if they exist )
what should happen to the player everytime the world ticks .
"returns the name of the mode the player is in , or empty string if the player is n't in a special mode ."
set the description for this player .
return a capitalized version of the player 's name .
return this player 's view of the room they are in .
add a list of character effects to the player .
remove an effect from this player .
"return true if this item has an item type t , false if it does not ."
create a new item .
set the description of this item .
set the title of this item .
set the weight for this object .
set the base currency value for this item .
set the keywords for this item . the argument keywords should be a string of words separated by commas .
set the carryable status for this item .
add a new item type to this item .
load a preset item type into an item . note : a regular load from the db will cause shinymud to load using a column / model . currently this method only needs to be used by loading from import .
"create a gameitem with the same attributes as this prototype item . spawn_id -- the i d of the spawn that is loading this item into a room , or none if this item is not being loaded by a spawn"
"resolve the script i d , area data into an actual script object ."
set the script object .
build a dictionary of this event 's attributes so that they can be passed as arguments to the event handler .
"import an object ( area , player character , etc . ) from an outside source into the mud ."
export an object from the mud to an outside source .
"import a batch of area files from a directory . import_list can either be a list of area - names to be imported , or the string ' all ' . if the string ' all ' is given , import_list will attempt to import all areas in the default import directory ."
"list the objects that are available for import . obj_type - the type of object to be imported format - ( optional ) filter results by this format transport - the transport by which the data will be obtained ( if not given , the default_transport will be used ) source_path - any extra data needed to locate the objects to be listed"
get a formatter by its file name . returns the formatter function if it can be found and raises a sporterror if it ca n't . format_file - the filename of the desired formatter ( without the .py extension )
get a transport by its file name . returns the transport function if it can be found and raises a sporterror if it ca n't . t_file - the filename of the desired transport ( without the .py extension )
"get a transport 's list function . return a transport 's list function if it exists , or raise a sporterror if it does not . transport - the name of the transport whose list function should be returned"
"start the connection - handler thread running . this thread will accept connections , create a player object for the player logging in , and then add that player object to the world ."
"start the connection - handler thread running . this thread will accept connections , create a player object for the player logging in , and then add that player object to the world ."
start the statsender thread running .
"returns an iterator of ( start_line , stop_line , indent ) for logical lines given the source blob ."
"a helper to construct a pythonfile from a triple - quoted string , for testing ."
the filename of this python file .
an iterator over tokens for this python file from the tokenize module .
"return an enumeration of line_number , line pairs ."
the parsed ast of this file .
returns an iterable of nit pertinent to the enclosed python file .
"uppercamel , allowinghttpabbrevations , _ withuptooneunderscoreallowable ."
"lower_snake_case , _ with , _ _ two_underscores_allowable ."
"for example , super _ , i d _ , type _"
"for example , _ _ foo _ _ or _ _ bar _ _ ."
move an existing element to the end ( or beginning if last==false ) .
"given a popen object , safely kill it without an unexpected exception ."
"create or retrieve a memoized ssh tunnel to the remote host & port , using tunnel_host : tunnel_port as the tunneling server ."
create or retrieve a memoized socks proxy using the specified proxy host : port
"cancel the ssh tunnel to ( remote_host , remote_port ) if it exists ."
"chroot_base = directory for the creation of the target chroot . name = if specified , create the chroot in a temporary directory underneath chroot_base with ' name ' as the prefix , otherwise create the chroot directly into chroot_base"
make all source paths relative to this root path .
the path of the chroot .
copy file from { root}/source to { chroot}/dest with optional label .
hard link file from { root}/source to { chroot}/dest with optional label .
write data to { chroot}/dest with optional label .
perform ' touch ' on { chroot}/dest with optional label .
get all files labeled with ' label '
get all files in the chroot .
"root = source directory for files chroot_base = directory for the creation of the target chroot . name = if specified , create the chroot in a temporary directory underneath chroot_base with ' name ' as the prefix , otherwise create the chroot directly into chroot_base"
"given a filelike - object and a set of line - derived parsers ( e.g. glogline , zooline ) , generate line objects from the stream . if infinite = true , continue after hitting eof ."
"takes a set of ( stream , label ) pairs ."
"returns ( label , line ) pairs as they 're available , none if nothing is available or stream . eof if all streams have terminated ."
creates and saves a user with the given email and password .
"returns the first_name plus the last_name , with a space in between ."
returns the short name for the user .
: type root : treenode
: rtype : bool
: rtype : int
: type n : int : rtype : list[str ]
: type obstaclegrid : list[list[int ] ] : rtype : int
: type root : treenode : rtype : list[int ]
: type s : str : rtype : int
: type n : int : rtype : int
: type board : list[list[str ] ] : type word : str : rtype : bool
: type root : treenode : rtype : int
: type nums : list[int ] : rtype : list[int ]
: type s : str : type t : str : rtype : str
: type root : treenode : rtype : list[int ]
: type root : treenode : type sum : int : rtype : list[list[int ] ]
: type root : treenode : rtype : bool
: type root : treenode : rtype : bool
creates a simple graph
validates adding edge to graph
validates removing edge from graph
validates graph deletion
validates sum aggregate function
validates avg aggregate function
validates max aggregate function
validates min aggregate function
validates count aggregate function
validates limited result - set
validates result - set order default is ascending
"validates result - set order , default is ascending"
validates result - set order
validates result - set order
validates distinct resultset
create environment .
test property : disk_used_size_in_gb case : if this property convert to gb from kb
test property : disk_used_size_in_gb case : when nfsaas_used_size_kb is null the property must return none
test property : disk_used_size_in_gb case : when nfsaas_used_size_kb is 0 the property must return 0
test property : per_database_size_bytes case : when engine type is redis the value must be from parameter table
test property : per_database_size_bytes case : when engine type is redis the value must be from configuration when not found on parameter table
test property : per_database_size_bytes case : when engine type not is redis the value must be from disk_offering
tests database infra capacity
test property : maxmemory from parameter case : validates when maxmemory from parameter table
test property : maxmemory from configuration case : validates maxmemory come from configuration when not found on parameter table
test validates return total and used size when has single instance
test validates return total and used size when has single instance
test validates return total and used size when has sentinel instance
test validates return total and used size when has cluster instances
returns a decorator that will validate the request for basic auth with the provided username and password . will return a 401 if the request can not be fullfilled .
generate a flask app that will serve meshes landmarks and templates to landmarker.io
generate a flask app that will serve meshes landmarks and templates to landmarker.io
"generate a flask app that will serve images , landmarks and templates to landmarker.io"
capture stdout and stderr output of the executed block
capture stdout and stderr combined output of the executed block
"the superclass constructor does not really need to be called , but it enables a few useful features ( like unified logging ) . if not called by the child , it just makes sure that repo class is not instantiated directly ."
return list of packages available in this repository .
"the superclass constructor does not really need to be called , but it enables a few useful features ( like unified logging ) . if not called by the child , it just makes sure that bugtracker class is not instantiated directly ."
list bugs by their ids . ` args ` and ` kwargs ` may be used for instance - specific filtering .
downloads the bug with given id into storage or updates it if it already exists in storage .
creates a new bug with given contents .
adds ` comment ` to a bug with given bug id .
adds ` attachment ` to a bug with given bug id . ` attachment ` may be string or file - like object .
attaches bug with given bug id to a given ` db_report ` .
clones the bug - creates the same bug reported against a different product and version .
split name-version-release.arch.rpm into dictionary .
return ` headers ` and ` data ` lists formatted as table .
return the most common crash function among all backtraces of this report
return quality metric for this problem which equals to the quality of its best report .
list of all reports assigned to this problem sorted by quality .
list of all backtraces assigned to this problem .
list of all backtraces assigned to this problem sorted by quality .
list of all comments assigned to this problem .
"return true if the problem has only tainted kernel oopses assigned . only works for kernel oopses , other types are always not tainted ."
list of list of all reporturls assigned to this problem .
"given a country code abbreviation , check to see if it matches the country table ."
"given a country code abbreviation , get the full name from the table ."
"desc is the entire desc , with ' ' replaced with ' ' . this output does n't attempt to shorten the desc string ."
"a helper function to determine whether this language matches one of the target languages , with a match score above a certain threshold ."
looks up the things we need to know about how to handle text in a given language . this will return a dictionary with the following fields :
checks that a netcdf file has the given variable defined
checks that a netcdf file has the given dimension defined
"checks that the variable , var_name , has the attribute , att_name"
"checks that the variable , var_name , as teh attribtes ( and values ) in the att_dict"
tests writing a netcdf file with depth data
tests writing a netcdf file with velocities on the faces
"tests writing a netcdf file with data on the edges ( fluxes , maybe ? )"
"tests writing a netcdf file with data on the boundaries suitable for boundary conditions , for example -- ( fluxes , maybe ? )"
"an example with all features enabled , and a less trivial grid"
test finding a single node
test finding multiple nodes at once
the nearest neighbor of the exact node locations had better be the nodes !
see what happens the point is equidistant to two nodes
returns the neighbors using a star topology .
returns the neighbors using a ring topology .
turns a mapping of ' option : arg ' to a list and prefix the options . arg can be a list of arguments .
"depends on the option 's length , prefix it with ' - ' or ' -- ' args : option ( str ): the option to prefix returns : str : prefixed option"
"args : name ( str ): the name of the vm this builder belongs disk_path ( str ): the path to the disk that needs to be customized paths ( lago.paths . paths ): the paths of the current prefix build_spec ( dict ): the build spec part , associated with the disk located at disk_path , from the init file ."
"convert a build spec into a list of command tuples . after running this command , self.build_cmds should hold all the commands that should be run on the disk in self.disk_path ."
return an handler for cmd . the handler and the command should have the same name . see class description for more info about handlers .
"handler for ' virt - customize ' note : if ' ssh - inject ' option was specified without a path to a key , the prefix ' key will be copied to the vm ."
run all the commands in self.build_cmds
"search if a module exists , and it is possible to try importing it"
"this script scans every post of sonovsite ( son , article , galery ) and checks two values : created_date and is_visible . if present time is more recent than created_date , is_visible becomes true ."
determine the scope of the passed in function .
determine whether the passed in function is within the passed in scope .
publish an event with arbitary arguments . all the subscriberes of the particular event will be invoked with the passed in arguments .
register a callback function for a specific event .
unregister a callback for a specific event type .
"returns a copy of the list of subscribers to a specific event type . the list is cloned only to protect from eventual attempts of manually modifying the list , as it would be possible if the reference to the orignal list were to be returned ."
batches of ` ` batch_size ` ` items ceated from ` ` data ` ` iterable .
return whether the provider supports read access to the underlying data or not .
return whether the provider supports write access to the underlying data or not .
return whether the current read operation is permitted or not .
return whether the current write operation is permitted or not .
return the timeout value for the data that 's about to be stored .
return the default value to be returned in case data was not set .
return data ( if possible ) that is managed by this provider .
store data ( if possible ) that is managed by this provider .
convenience helper method that subscribes the passed in ` callback ` to the : py : attr:`~statecontainer . state_changed_event ` event .
"factory for random fs and meta datasets . returns a tuple of lists ( fs_items , meta_items ) ."
"make a basic rhythm using ` ` time_signature_pairs ` ` , ` ` counts ` ` and ` ` denominator ` ` ."
clean up rhythms in ` ` music ` ` via ` ` time_signature_pairs ` ` .
add ` ` pitches ` ` to music .
add attachments to ` ` music ` ` .
start a pty - intended to run it a ( green)thread .
takes a directory containing genomic data in fasta format and converts it to a blast database in format expected by eating functions .
tests the get_version function .
op handler for strike op which activates this task
op handler for regular tick op
a method which gets the material to be consumed from the inventory & returns the consume operation
"the repair op is from the the character , to the structure that is getting repaired which we term the target ."
"this method is called repeatedly , each time a repair turn occurs . in this example the interval is fixed , but it can be varied ."
op handler for cut op which activates this task
op handler for regular tick op
op handler for sow op which activates this task
op handler for regular tick op
this is called when trigger even is received
op handler for strike op which activates this task
op handler for regular tick op
op handler for cut op which activates this task
op handler for regular tick op
op handler for cut op which activates this task
op handler for regular tick op
"strength : 6 * 3 random characters from a list of 62 , approx . 64 ^ 18 possible strings , or 2 ^ 100 . should be enough to prevent a successful bruteforce , as download links are only valid for 3 hours : return :"
"increment the refcount of obj , and return a pointer to it"
set the key to be used for en-/de - cryption and optionally specify an initialization vector ( aka seed / salt ) .
encrypt the given string using twofish cbc .
decrypt the given string using twofish cbc .
return the bitwise xor of two arbitrary - length blocks of data
"parse cli arguments to either list services , operations , queries or existing json files"
this is a ddahinstance
this function stores a command that is used to run a dhclient on dut . it specifies a lease file and a config file .
this small function stores in variable a path for leases file .
this small function stores in variable a path for config file .
"function that executes command on dut , which removes the old lease file and creates an empty , new one ."
function that stores in variable a template for config file that is being generated .
function creates a config file from previously specified template . it checks whether there are equal count of open / closing brackets .
"this function shut downs and later starts dhclient on dut . @step(""restart client . "" )"
this function destroys every running instance of dhclient on dut .
same as stop_clnt ( ) .
"function that executes a previously generated command with "" -r "" option , which results in sending by dhclient release repeatedly , until reply is received . there 's no need to execute it with delay like in dibbler - client 's case , since message will being retransmitted ."
"@step(""client is configured to include ( another ) ? ( \s+ ) option . "" )"
"@step(""setting up test . "" )"
"function creates a script file that will execute a previously created command with delay . execution will take place on dut . it is important to sniff first solicit message sent by client , hence the delay . see also more detailed description of it in dibbler_client / functions.py ."
"@step(""client must ( not ) ? use prefix with values given by server . "" )"
"@step(""client is started . "" )"
set counters which are being used to server configuration in kea
tests if there is only a spike if the potential hits the threshold from below
"if we rerun spikecheck with the same time , we should get the same results"
": param eta : learning rate : param w_in : : param w_out : : param tau : the tau parameter for the learning window . if you want an unsymmetric window , then also set tau2 . : param window_size : : param verbose : verbose output of the weight change . : param tau2 : if learning window is unsymmetric , then tau2 is the tau parameter for x - values greater than 0 . if not given , it defaults to tau . : return :"
return the sum of the learning windows of one neuron . : param t1 : current time : param t2_list : spiking times of neuron
return the sum of the learning windows of one neuron .
constant learning window
calculate the weight change at time t. changes the weights in place .
generate a poisson spike train for a single neuron using a homogenous poisson distribution .
generate a poisson spike train for a single neuron using an inhomogenous poisson distribution .
generates a spike train with a peak at * midpoint * .
parser for ` binder_transaction_received `
parser for ` binder_wait_for_work `
returns set of cluster names
return idle time for specified cluster [ including in lpm state ]
return time for specified cluster when in lpm . this is an approximation as we can exit lpm if cluster was in lpm for long time after tracing began .
return idle time for specified cluster when its not offline . todo : filter by task
return busy interval for specified cluster & interval when cluster is not idle ( in lpm ) state
return idle interval for specified cpu & interval when cluster is idle ( in lpm ) state
return interval for specified cluster & interval
handler function for cluster idle events
parse cluster idle intervals
first timestamp in list
last timestamp in list
interval for thie event list
duration of events in seconds
insert ( sorted ) object with timestamp attribute to timestamps list .
append new event to list
returns list of objects whose timestamps fall between the specified interval .
"contructor : param master : the master object the project is connected to : param project_path : the default project path : param test_mode : if true , the popup is opened in test mode , false by default"
"a callback method to be called when a project is saved : param path : the path to save the project to : param selection : a selection of files , not used : param savefilename : the name of the project file to be saved : return : none"
creates the visual widgets for the presentation elements in the import list .
adds slavevisualproperties to the slavepresentation object : param import_list : list of presentation elements ' filenames to be added to the presentation : return :
sorts the slavepresentation and its presentation object based on the x - coordinates of slavevisualproperty objects . : return : presentation object
"highlights the next visual , indicating it is the currently active visual"
resets the slavepresentation and its presentation object . : return :
checks if the tracked slaveconnection has updated ; updates the widget if needed
"toggles dragging for all slavevisualproperty objects , also updates the presentation object in case it has gone out of sync . : param draggable : boolean value . : return :"
sets the minimum drag distance before the element begins to move around . 1 < < 16 is a bitwise operation that equals 2 ^ 16 . : param draggable : boolean value : return :
keeps the object on the same y coordinate as its parent . : param largs : : return :
"called when you start dragging the object around . updates that the object is , in fact , being dragged which is used in the method on_x to determine whether updating is necessary . : param touch : : return :"
compares the object 's x coordinate with another object 's and for some reason returns if the object 's x is greater than rather than less than ; it just works this way : param other : another slavevisualproperty object : return : boolean whether the object is greater than other .
cleans up the list of visuals after you release a dragged presentation element . : param touch : : return :
determines if the button has been moved far enough that it would require rearrangement . caller on_x : return : boolean of whether the rearrangement is in order
"constructs a popup that supports the selection and importing of multiple files at once to a single or multiple presentations . if a file with the same name already exists in the media path , opens a popup to query the user for the desirable action . : param listener : the object to inform when a single file 's import is ready : param imported_files : a list to add the paths of the opened files : param presentations : all the presentations in the current project : param selected_presentations : the presentations to import to : param media_path : the default path to open the filechooser to : param test_mode : if true , the popup is opened in test mode , false by default"
imports one or multiple files from a path . : param path : the path to open files from : param selection : a list the selected files in the path : param savefilename : not used : return : none
"get the selected files from media folder . if the file does n't exists in the media folder , it will be copied there first ."
"copies the source file as the destination file and returns the file with complete path . if the destination file exists , it will not be overwritten ."
"prepares the content to be passed on to gui . if the element is a text file , the text is extracted into a string and referenced via self.content . otherwise , the content refers to the path of the source file ."
creates a serializable json representation of an coursewareaccessexception .
call function under test .
test no due date .
test due date without extension .
test due date with extension .
"test due date with extension , but due date is later than extension ."
test non - sensical extension without due date .
test due date with extension when node is a dict .
check the template for required tags .
validate the html template .
validate the plaintext template .
validate the name field . enforce uniqueness constraint on ' name ' field
validate the course i d
returns the course for the given course_key_string after verifying the requested access to the course by the given user .
"returns the user object corresponding to the request 's ' username ' parameter , or the current request.user if no ' username ' was provided ."
"ensures that the user is authenticated ( e.g. not an anonymoususer ) , unless debug mode is enabled ."
gets a course progress status .
run the management command to generate a fake cert .
"scenario : start time works for youtube video given we have a video in "" youtube "" mode with start_time set to 00:00:10 and i see video slider at "" 0:10 "" position and i click video button "" play "" then video starts playing at or after start_time(00:00:10 )"
"scenario : end time works for youtube video if starts playing from beginning . given we have a video in "" youtube "" mode with end time set to 00:00:05 and i click video button "" play "" and i wait until video stop playing then i see video slider at "" 0:05 "" position"
"scenario : start time and end time work together for youtube video . given we a video in "" youtube "" mode with start time set to 00:00:10 and end_time set to 00:00:15 and i see video slider at "" 0:10 "" position and i click video button "" play "" then i wait until video stop playing then i see video slider at "" 0:15 "" position"
"given the dotted name for a python object , performs any necessary imports and returns the object ."
"returns an iterator over all ancestors of the given block , starting with its immediate parent and ending at the root of the block tree ."
"a context manager which disables field overrides inside the context of a ` with ` statement , allowing code to get at the ` original ` value of a field ."
checks to see whether overrides are disabled in the current context . returns a boolean value . see ` disable_overrides ` .
look for an override value for the field named ` name ` in ` block ` . returns the overridden value or ` default ` if no override is found .
"return true if this provider should be enabled for a given course , and false otherwise ."
"will return a : class:`overridefielddata ` which wraps the field data given in ` wrapped ` for the given ` user ` , if override providers are configred . if no override providers are configured , using the django setting , ` field_override_providers ` , returns ` wrapped ` , eliminating any performance impact of this feature if no override providers are configured ."
return a filtered list of enabled providers based on the course passed in . cache this result per request to avoid needing to call the provider filter api hundreds of times .
checks for an override for the field identified by ` name ` in ` block ` . returns the overridden value or ` notset ` if no override is found .
"returns an instance of fielddata wrapped by fieldoverrideproviders which extend read - only functionality . if no modulestore_field_override_providers are configured , an unwrapped fielddata instance is returned ."
computes a list of enabled providers based on the given xblock . the result is cached per request to avoid the overhead incurred by filtering override providers hundreds of times .
verify that the username and password are returned when compliance is disabled
verify that the username and password are returned when compliance is enabled
verify that the username and password are returned when compliance is enabled despite a noncompliantpasswordwarning being thrown
verify that an exception is raised when enforce_compliance_on_login throws a noncompliantpasswordexception
"pytest fixture to create some basic states for testing . duplicates functionality of the django test runner in test_views.py unfortunately , but they 're not compatible ."
helper function to compare a newly created userretirementstatus object to expected values for the given user .
basic test to make sure default creation succeeds
confirm that if no states have been loaded we fail with a retirementstateerror
confirm the correct error bubbles up if the user already has a retirement row
ensure that retirement request record creation succeeds .
ensure that retirement request record is created upon retirement status creation .
ensure that retirement request record is deleted upon deletion of a pending retirement status .
ensure that retirement request record is not deleted upon deletion of a non - pending retirement status .
helper method to create and verify and update based on the message .
scenario : user can access course updates page given i have opened a new course in studio and i go to the course updates page when i visit the page then i should see any course updates and i should see the new update button
"scenario : users can add updates given i have opened a new course in studio and i go to the course updates page when i add a new update with the text "" hello "" then i should see the update "" hello "" and i see a "" saving "" notification"
"scenario : users can edit updates given i have opened a new course in studio and i go to the course updates page when i add a new update with the text "" hello "" and i modify the text to "" goodbye "" then i should see the update "" goodbye """
"scenario : users can delete updates given i have opened a new course in studio and i go to the course updates page and i add a new update with the text "" hello "" and i delete the update and i confirm the prompt then i should not see the update "" hello """
"scenario : users can edit update dates given i have opened a new course in studio and i go to the course updates page and i add a new update with the text "" hello "" when i edit the date to "" 06/01/13 "" then i should see the date "" june 1 , 2013 """
"scenario : text outside of tags is preserved given i have opened a new course in studio and i go to the course updates page when i add a new update with the text "" before < strong > middle</strong > after "" then i should see the update "" before < strong > middle</strong > after "" and when i reload the page then i should see the update "" before < strong > middle</strong > after """
"scenario : static links are rewritten when previewing a course update given i have opened a new course in studio and i go to the course updates page when i add a new update with the text "" < img src='/static / my_img.jpg'/ > "" # can only do partial text matches because of the quotes with in quotes ( and regexp step matching ) . then i should see the asset update to "" my_img.jpg "" and i change the update from "" /static / my_img.jpg "" to "" < img src='/static / modified.jpg'/ > "" then i should see the asset update to "" modified.jpg "" and when i reload the page then i should see the asset update to "" modified.jpg """
entry point for subclassed commands to add custom arguments .
"sets logging levels for this module and the block structure cache module , based on the given the options ."
generates course blocks for the given course_keys per the given options .
generates course blocks for the given course_key per the given options .
"returns true if harvard annotation tool is enabled for the course , false otherwise ."
returns true if the edx notes feature is enabled in the course .
"returns the coursegrade for the given user in the course . reads the value from storage . if not in storage , returns a zerograde if assume_zero_grade_if_absent . else if create_if_needed , computes and returns a new value . else , returns none ."
"computes , updates , and returns the coursegrade for the given user in the course ."
"given a course and an iterable of students ( user ) , yield a graderesult for every student enrolled in the course . graderesult is a named tuple of :"
returns a zerocoursegrade object for the given user and course .
returns a coursegrade object based on stored grade information for the given user and course .
"computes , saves , and returns a coursegrade object for the given user and course . sends a course_grade_changed signal to listeners and a course_grade_now_passed if learner has passed course ."
return the dictionary with the dummy data
log in as a valid lms user .
scenario : user accomplishment banner should be present if logged in user is the one who is awarded the certificate given there is a course with certificate configuration and i have passed the course and certificate is generated when i view the certificate web view page then i should see the accomplishment banner . banner should have linked - in and facebook share buttons and when i click on ` add to profile ` button ` edx.certificate.shared ` event should be emitted
enable notifications for a user . currently only used for daily forum digests .
a view that enables notifications for the authenticated user
a view that disables notifications for the authenticated user
a view that retrieves notifications status for the authenticated user .
a view that disables or re - enables notifications for a user who may not be authenticated
checks that the current run meets the following criteria for an entitlement
tests that courseoverview structures are actually getting cached .
"tests that when a course is published or deleted , the corresponding course_overview is removed from the cache ."
sets up the course anew .
fill in the slug field for each providerconfig class for backwards compatability .
renders parameters to template .
ensures that the user is authenticated ( e.g. not an anonymoususer )
kicks off an asynchronous course import and returns an id to be used to check the task 's status
check the status of the specified task
return a serialized representation of the course blocks .
ensure that the user 's session hash has n't changed . we check that sessionauthenticationmiddleware is enabled in order to match django 's behavior .
this view function renders the template sent without checking that it exists . do not expose template as a regex part of the url . the user should not be able to ender any arbitray template name . the correct usage would be :
"render a press release given a slug . similar to the "" render "" function above , but takes a slug and does a basic conversion to convert it to a template file . a ) all lower case , b ) convert dashes to underscores , and c ) appending "" .html """
"combines the rulesets from the provided template_linters into a single , aggregate ruleset ."
"for each linter , lints the provided file . this means finding and printing violations ."
calls out to lint each file in the passed list of files .
"for each linter , lints all the directories in the starting directory ."
"for each linter , lints the provided file or directory ."
used to execute the linter . use --help option for help .
stops the patcher for the get_week_highlights method if the patch is still in progress .
return a context suitable for testing the permissions module
checks to see if a course is properly configured for an entrance exam
checks all of the various override conditions for a user to skip an entrance exam begin by short - circuiting if the course does not have an entrance exam
checks to see if the user has attained a sufficient score to pass the exam begin by short - circuiting if the course does not have an entrance exam
"get the entrance exam content information ( ie , chapter module )"
push the data to the stub comments service .
return a dictionary with the fixture 's data serialized for putting to the stub server 's config endpoint .
generate a dict mapping each response / comment in the thread by its ` i d ` .
add responses to the thread
configures whether or not forums are enabled .
returns an i d to uniquely identify this tool in analytics events .
show this tool to all learners who are eligible to upgrade .
returns the title of this tool .
returns the icon classes needed to represent this tool .
returns the url for this tool for the specified course key .
"most test cases will use a single call to this manager , as they need to set the global setting and the course - specific setting for a single course ."
deletes student state for a problem . requesting_user may be kept as an audit trail .
returns true if the user is the course staff else returns false
"creates a zendesk ticket for an exam attempt review from the proctoring system . currently , it sends notifications for ' suspicious "" status , but additional statuses can be supported by adding to the notify_support_for_status list in edx_proctoring / backends / software_secure.py the notifications can be disabled by disabling the "" create zendesk tickets for suspicious proctored exam attempts "" setting in the course 's advanced settings ."
forces the generic tab to use bootstrap styling .
displays a generic tab for the specified course .
render out the bootstrap page .
returns the team that the commentable_id belongs to if it exists . returns none otherwise .
check whether or not the given condition applies for the given user and content .
"accepts a list of permissions and proceed if any of the permission is valid . note that [ "" can_view "" , "" can_edit "" ] will proceed if the user has either "" can_view "" or "" can_edit "" permission . to use and operator in between , wrap them in a list ."
test that if the config is disabled or nonexistent nothing is returned
verify that compliance does not need to be enforced if : * password is compliant * there is no compliance deadline
test that if the config is enabled : * returns true if the user has a compliant password * returns false if the user does not have a compliant password
test that we do n't annoy user about compliance failures that only affect password resets
test that the proper deadlines get returned for each user scenario * staff deadline returns staff_user_compliance_deadline * courseaccessrole users return elevated_privilege_user_compliance_deadline * everyone else gets general_user_compliance_deadline
"test that when some deadlines are n't specified , we cascade from general to specific ."
make sure that answer for incorrect request is error json
make sure that ajax request works correctly
return the md5 hash that ` update_hash ` makes us .
make two equal dicts with different key order .
"processes commentclientrequesterrors in ajax requests . if the request is an ajax request , returns a http response that encodes the error as json"
"create a test thread with the given number of responses , passing all keyword arguments through to the thread fixture , then invoke setup_thread_page ."
set up multiple threads on the page by passing ' thread_count ' .
"sets up the course to use cohorting with the given list of auto_cohort_groups . if auto_cohort_groups is none , no auto cohorts are set ."
enables cohorting for the specified course fixture .
"enables "" always_divide_inline_discussions "" ( but does not enabling cohorting ) ."
disables cohorting for the specified course fixture .
"adds a cohort by name , returning its id ."
adds a user to the specified cohort .
sets up a ` discussiontabsinglethreadpage ` for a given ` thread_id ` .
gets the value of the user 's course tag for the specified key in the specified course_id .
sets the value of the user 's course tag for the specified key in the specified course_id . overwrites any previous value .
prefetches the value of the course tags for the specified users for the specified course_id .
make the user eligible for credit in the course .
verify the message on dashboard with different number of providers .
log and overview of the results of the command .
check if the authorizer has a user . : param username : the username you want to check . : return : true if the authorizer has the user . otherwise false .
"check if the permissions are valid . if one is not valid , raise a valueerror . : param perm : the permissions you want to check . : return : none"
add a user to the virtual user table .
add an anonymous user to the virtual user table . : param homedir : the home directory of the virtual user . : param kwargs : : return : none
"check if the user has the permission over path . : param username : the username you want to check . : param perm : the permission you want to check . it should be one of these letters : "" elradfmwm "" . : param path : the path you want to check . : return : true if the user has the permission . otherwise return false ."
设置目标函数 / 损失函数类型 。
后向计算过程，依次将误差从后向前传播，并依次调用 每一层的backward方法来求目标函数objective对每一层 的参数的梯度 。 每一层的参数的梯度保存在每一层的grads列表中 。
根据数据集x及其标签y，评估模型的分类准确率以及损失函数值。对于大型数据集 支持批量计算 。
check the model before training .
检测columnize_x的形状是否与给定的参数kh / kw / ch / cw相符合
检测columnize_x的形状是否与给定的参数kh / kw / ch / cw相符合
"原生python实现的im2col_nchw , 其中im2col_hw使用了c语言编写的扩展"
checks if it is a null result
appends dpr to childlist
"converts a list of token into a list of token , asuming size = = 1"
register our callbacks .
validate our args .
handles the logic to final a version and update the target entity .
helper function that determines the date field type on a specified entity and returns the date formatted for that type .
add word to vocabulary and return its i d. return -1 if this word is exist .
"return true iff this key is in the map , or if self.allow_unknown is true"
get the id for this string .
get the word for this id .
get the word frequency for this id .
load the words and word_to_id .
load the words and word_to_id .
"write the word id map , passed as a parameter ."
cut all ties with parent .
remove client from parent .
set parent of client to none .
remove client from parent and give client to new parent .
"returns a flat list of all the coordinates that form this shape . this property is useful in computing some property of the shape based on all it 's points . e.g. , centroid , bounding box , etc ."
the function can take a list of _ hpglprimitives .
the function can take a list of _ hpglprimitives .
"constructs an ellipse with the given width , height , and number of segments ."
an empty string returns an empty list .
the first argument must be a string .
the function converts a string of hpgl commands into chiplotle - hpgl instances .
hpgl commands need not be separated by ; .
aa and ar are with only coordinates and angle are imported correctly .
aa and ar are with all parameters are imported correctly .
the function can take a list of hpgl commands to filter out from the result .
the ` filter_commands ' argument must be a list of two - letter hpgl strings .
"creates a symmetric polygon with ` count ` sides , all with the same given ` length ` ."
sr can be initialized empty .
"the function can take a tuple pair ( r , a )"
the function can not take two values r and a
three arguments throw a typeerror .
one numeric argument throws a typeerror .
one tuple argument with > 2 arguments throws a typeerror .
main program to handle command line parameters and then run what they want .
"attempts to parse a date with given formats first , then default formats"
returns a string representation of the current timestamp
wrapper around dateutil.relativedelta ( same construtor args ) and returns a humanized string representing the detla in a meaningful way .
"return a new string which is an unquoted version of str . if str ends and begins with double quotes , they are stripped off . likewise if str ends and begins with angle brackets , they are stripped off ."
decorator that times the execution of a function
computes a human readable file size for the given path
"return a property attribute for new - style classes that only calls its getter on the first access . the result is stored and on subsequent accesses is returned , preventing the need to call the getter any more . https://github.com/estebistec/python-memoized-property"
create the illusion of series subclasses in the dataframe .
time spent in an activity .
rolling mean by time .
"a pseudo - init method , used internally ."
try and get a required column from the data .
encode an integer into a symbol string .
decode an encoded symbol string .
normalize an encoded symbol string .
create database if it does n't exist .
connect to database before each request .
close database connection after each request .
"register new user . returns user database row . if fails , returns none ."
"login user . returns user database row . if fails , returns none ."
decorator to enforce login .
serve static files from multiple directories .
"data_x , data_y ( batch_size , channel , height , width ) data_x : ( 1000 , 1 , 128 , 128 ) data_y : ( 1000 , 1 , 256 , 256 )"
start and end are in iso8601 yyyymmddthh : mm : ss format
"populate a dictionary of account objects key is accountnumber - i.e. , ' 5pdxxxxx : return :"
return a list of account history objects : param userid : : param numtransactions : : param accountid : : param transactiontype : : param start : : param end : : return : trnasactionlist
create a new group with a list of accountids : param groupnametouse : : param accountids : list of account ids : return :
return a list of option chains for various strikes / expirations for a given symbol : param symbol : : return :
retrieve multiple quotes from trademonster : param symboltypedict : : return :
helper for parsing quotes : param item : : return :
convenience method for returning a dictionary of quote objects from various symbols : param symboltypedict : : return :
"try and retrieve the username and password from the encrypted user file - ' cred.dat ' if no file exists , prompt the user for a login / password and create a file with encrypted contents : return : user and pass tuple"
creates a global session to be used by all requests : param cookies : : return :
"make a request to a given url with given payload data and return a python object from a parsed xml response either qa or prod environment , as defined in constants : param url : : param payload : : return : python object created from parsed xml"
saves figure content to the file if it 's path is provided
setup axes grid : param axes : : return :
"first two values in lims are the minimum and the maximum values , while third value is a step . values starting from 4 are additional values which will be added to the grid : param lims : : return :"
setup subplot x and y axis titles
returns the name of the current snapshot : param vm : virtual machine to find current snapshot name : return : snapshot name : rtype str
"returns dictinary of snapshots of a given virtual machine key is full path to snapshot , for example rootsnapshot / childsnapshot / leadsnapshot value is an instance of snapshot : param vm : an instance of virtual machine : type vim.vm . virtualmachine : return :"
"recursively traverses child snapshots and returns dictinary of snapshots : param snapshots : list of snapshots to examine : param snapshot_location : current path of snapshots : return : dictinary of snapshot path and snapshot instances : rtype : dict(str , vim.vm . snapshot )"
combines snapshot path : param base_snapshot_location : : param snapshot_name : : return : combined snapshot path : rtype str
sets the vcenter parameters if not already set at the deployment option : param deploy_params : vcentervmfromtemplateresourcemodel or vcentervmfromimageresourcemodel : type vcenter_resource_model : vmwarevcenterresourcemodel
create qs logger for command context autoloadcommandcontext or resourcecommandcontext : param logger_name : : type logger_name : str : param context : : return :
will locate vm in vcenter and fill its uuid : type context : cloudshell.shell.core.context . resourcecommandcontext
add new vnic to vm : param nicspec : < vim.vm.device . virtualdevicespec > : param virtual_machine : : param logger : : return :
@see https://www.vmware.com/support/developer/vc-sdk/visdk41pubs/apireference/vim.virtualmachine.html#reconfigure : param filter_function : function that gets the device and decide if it should be deleted : param virtual_machine : < vim.vm object > : return : < list of vim.vm.device . virtualdevicespec > for ' reconfigvm_task ' applying
get a network connected to a particular device ( vnic ) @see https://github.com/vmware/pyvmomi/blob/master/docs/vim/dvs/portconnection.rst
checks if the device has a backing with of the right network name : param < vim.vm . device > device : instance of adapter : param < str > network_name : network name : return :
checks if the vnic has a backing with of the right network name
compose empty vnic for next attaching to a network : param device : < vim.vm.device . virtualvmxnet3 or none > device for this this ' spec ' will be composed . if ' none ' a new device will be composed . ' operation ' - edit / add ' depends on if device existed : return : < vim.vm.device . virtualdevicespec >
attach vnic to a ' usual ' network : param nicspec : < vim.vm.device . virtualdevicespec > : param network : < vim . network > : param logger : : return : updated ' nicspec '
attach vnic to a distributed port group network : param nicspec : < vim.vm.device . virtualdevicespec > : param port_group : < vim.dvs . distributedvirtualportgroup > : param logger : : return : updated ' nicspec '
attach vnic to network . : param nicspec : < vim.vm.device . virtualdevicespec > : param network : < vim network obj > : return : updated ' nicspec '
compose new vnic and attach it to network . : param nicspec : < vim.vm.device . virtualdevicespec > : param network : < vim network obj > : return : < vim.vm.device . virtualdevicespec > ready for inserting to vm
compose new vnic and attach it to vm & connect to network : param nicspec : < vim.vm . vm > : param network : < vim network obj > : return : < task >
maps the vnic on the vm by name : param vm : virtual machine : return : dictionary : { ' vnic_name ' : vnic }
"this function creates the device change spec , : param vnic : vnic : param set_connected : bool , set as connected or not , default : true : rtype : device_spec"
create device spec for existing device and the mode of edit for the vcenter to update : param device : : rtype : device spec
sets the device spec as connected or disconnected : param nic_spec : the specification : param to_connect : bool
receives ovf image parameters and deploy it on the designated vcenter : param vmwarevcenterresourcemodel vcenter_data_model : : type image_params : vcentershell.vm.ovf_image_params . ovfimageparams : param logger :
: type image_params : vcentershell.vm.ovf_image_params . ovfimageparams
set the natural frequency of the wood
get the natural frequency of the wood
get the moe of the wood
returns a pep 386 - compliant version number from version .
returns main version ( x.y[.z ] ) from version .
simple csp report view
returns a short error message to be displayed to the user
returns the numeric http status code
run through all combinations of compressions and mailbox formats
this test uses an example email that causes issue # 47
work around for https://github.com/celery/celery/issues/4298
fetch subject for obj
extra meta data to save db queries later
extra meta data to save db queries later
"get set for liberation , expects user object"
gather email ids
send off data mining tasks
take email from database and put on filesystem
convert maildir to mbox if needed
fetch user info and dump json to files
tar up and delete the dir
create email to send to user
user profile data
grab metadata from inboxes
: type root : treenode : rtype : bool
: param nums : list[int ] : return : set[tuple ]
: type prices : list[int ] : rtype : int
"input : [ 7 , 1 , 5 , 3 , 6 , 4 ] diff : [ x , -6 , 4 , -2 , 3 , -2 ] : type prices : list[int ] : rtype : int"
: type n : int : rtype : list[str ]
: type low : str : type high : str : rtype : int
"this is a suboptimal , hacky method using eval ( ) , which is not safe for user input . we guard against danger by ensuring k in an int"
"this is a brute force method where we keep a dict the size of the list then we check it for the value we need . if the key is not in the dict , our and statement will short circuit and return false"
this is an optimal method using iteration . we move p1 k steps ahead into the list . then we move p1 and p2 together until p1 hits the end .
: type nums : list[int ] : rtype : list[int ]
all_boxes is a list of length number - of - classes . each list element is a list of length number - of - images . each of those list elements is either an empty list [ ] or a numpy array of detection .
evaluate detection proposal recall metrics .
turn competition mode on or off .
unmap a subset of item ( data ) back to the original set of items ( of size count )
compute bounding - box regression targets for an image .
this layer does not propagate gradients .
reshaping happens during the call to forward .
get a network by name .
list all registered imdbs .
generate very fastly a random hexadecimal string . kudos to jcdryer http://stackoverflow.com/users/131084/jcdyer
return a list of all known objects excluding frame objects .
compute the total size of all elements in objects .
get the difference of both lists .
sort objects by size in bytes .
filter objects .
get all referents of an object up to a certain level .
test if more memory is used after the function has been called .
is the passed object a container object .
remove duplicate objects .
print a summary of all known objects .
convenience function to check if the current platform is supported by this module .
get a list of ` threadinfo ` objects .
get the id of the current thread .
refresh the information using platform instruments . returns true if this operation yields useful values on the current platform .
"get virtual and resident size of current process via ' ps ' . this should work for macos x , solaris , linux . returns true if it was successful ."
get virtual size of current process by reading the process ' stat file . this should work for linux .
initialize the tests by emptying the out directory
aux : test detection of next entry
aux : test si formatting
aux : test path2unix
aux : test is_file ( )
aux : test is_dir ( )
aux : test is_dir_or_file ( )
aux : test recwalk ( )
aux : test fullpath ( )
_ actions which are positional or possessing the ` required ` flag
_ actions not positional or possessing the ` required ` flag
action with choices supplied
"actions which are general "" store "" instructions . e.g. anything which has an argument style like : $ script.py -f myfilename.txt"
"_ actions which are either storeconst , store_bool , etc .."
_ actions which are of type _ countaction
return an iterator for all of the contained gui
"check if an allele is present in the database args : chrom : the chromosome , format matches [ 1 - 22xy ] pos : coordinate within a chromosome . position is a number and is 0 - based allele : any string of nucleotides a , c , t , g alternate : any string of nucleotides a , c , t , g reference : the human reference build that was used dataset : dataset to look in ( currently used to select mongo database ) returns : the string ' true ' if the allele was found , otherwise the string ' false '"
mockable point for creating s3connections .
opens a local copy of an s3 url .
"获取指定日期内的季节 @@parm : begin : 开始时间begin=(2016,1 ) @@parm : end : 结束时间end=(2017,1 )"
this is a decorator which can be used to mark functions as deprecated . it will result in a warning being emmitted when the function is used .
generate a challenge token based on a hardware property
import the : mod:`.settings ` module and check for folders to create .
set uppercase variables from the : mod:`.settings ` module as attributes on this instance .
context manager that overrides setting values for the duration of the context .
context manager that overrides a file setting by pointing it to an empty temporary file for the duration of the context .
"override ` name ` with ` value ` , after some checks ."
raises an error if a slow protobuf implementation is being used .
initializes a nativesamreader .
initializer for nativesamwriter .
replace the reads stored by this reader .
iterate over all records in the reads .
iterate over records overlapping a query region .
yields reference positions corresponding to read 's variations .
""" process candidate positions to determine windows for local assembly ."
""" process reads to determine candidate windows for local assembly ."
checks that we are using the fast cpp version of python protobufs .
end - to - end test of model_eval .
writes proto to the file .
"exit a ` with ` block . typically , this will close the file ."
returns a genomicswriter for writing the records ` natively ` .
hook for sub - classes to run code at the end of _ _ init _ _ .
add one protocol instance .
return the list of ids of all the protocol instances
return the index of the replica that belongs to the master protocol instance
return the list of replicas that do n't belong to the master protocol instance
- slow processing 3pc messages for all nodes - do view change
- slow processing 3pc messages for all nodes - do view change
"2 of 4 nodes go down , so pool can not process any more incoming requests . a new request comes in . after a while those 2 nodes come back alive . another request comes in . check that previously disconnected two nodes request missing prepares and preprepares and the pool successfully handles both transactions after that ."
returns spylog entry for most recent checkperformance executions for a set of nodes . : param nodes : an iterable of node : return : a dictionary of node names to the most recent checkperformance call
sends requests to client and check the ratio of throughput of master instance and backup instance must be greater than or equal to delta and verify no view change takes place .
serialize a message for signing .
reads config from the installation directory of plenum .
reads a file called config.py in the project directory
"returns a list of hashes with serial numbers between start and end , both inclusive ."
we do 4 view change . timeout for one view change usually 60 sec . test running time will excpect as 4 * 60 = 240 .
"test steps : 1 . collect domainledger data for primary node , such as : tree hashes , root hash , tree root hash , leaves store ( content of binary file ) , nodes store ( content of binary file ) , ledger txns 2 . restart primary node and ensure that view change done 3 . compare previous collected data with data from all other nodes after restart . we do n't sent any txns during restart , therefore domainledgers must be the same 4 . repeat steps 1 - 3 for all nodes in pool"
creates a default bls factory to instantiate bls bft classes .
: param dbdir : the directory where the file storing the data would be present : param dbname : the name of the file that is used to store the data : param islinenokey : if false then each line has the key followed by a delimiter followed by the value : param storecontenthash : whether to store a hash of the value or not . storing hash can make it really fast to compare the value for equality
make sure that requests sent before view change started are processed and replies are returned : - delay propogates ( to make sure that requests are not ordered before view change is started ) - send requests - check that requests are ordered despite of view change being in progress
"nodes discard any 3pc messages for already ordered 3pc keys ( view_no , pp_seq_no ) . delay all 3pc messages to a node so it can not respond to them unless the other nodes order them , now when the slow node will get them it will respond but other nodes will not process them and discard them"
"test that garbage collector compares the whole 3pc key ( viewno , ppseqno ) and does not remove messages from node 's queues that have higher viewno than last ordered one even if their ppseqno are less or equal"
test that we can recover after having more than f nodes disconnected : - send txns - stop current master primary - restart current master primary - send txns
"replicas should not accept pre - prepare for view "" v "" and prepare sequence number "" n "" if it has already accepted a request with view number "" v "" and sequence number "" n """
"test case : 1 . create pool of 4 nodes 2 . stop not primary node 3 . send some txns 4 . start stopped node 5 . ensure , that restarted node got all txns which was sent during restart 6 . do step 2 - 5 for other not primary node in pool"
updated with wrong bls key for 1st node ; expect that bls multi - sigs are applied since we have 3 correct signatures
updated with wrong bls key for 1st and 2d nodes ; do not expect that bls multi - sigs are applied ( we have less than n - f correct bls sigs )
updated with wrong bls keys 1 - 3 nodes ; do not expect that bls multi - sigs are applied ( we have less than n - f correct bls sigs )
updated with wrong bls keys all nodes ; do not expect that bls multi - sigs are applied ( we have less than n - f correct bls sigs )
motor is initialized with a status of stopped .
return the current status
set the status of the motor to the specified value if not already set .
is the status in status.ready ( ) ?
is the status in status.going ( ) ?
set the status to status.starting
set the status to status.stopping and also call ` onstopping ` with the provided args and kwargs .
perform some actions based on whether this node is ready or not .
a series of actions to be performed when stopping the motor .
checks that node can catchup large ledgers
- slow processing 3pc messages for all nodes randomly - do view change
- slow processing 3pc messages for all nodes randomly - do view change
checks whether the given port is available
a deterministic but more evenly distributed comparator than simple alphabetical . useful when comparing consecutive strings and an even distribution is needed . provides an even chance of returning true as often as false
create a map where every node is connected every other node . assume each key in the returned dictionary to be connected to each item in its value(list ) .
choose a schema for client request operation and validate the operation field . if the schema is not found skips validation . : param dct : an operation field from client request : return : raises exception if invalid request
view change does not occurs when backup 's primary is disconnected
testing ` help ` command
testing ` help new ` command
testing ` help new node ` command
testing ` help new client ` command
view change occurs when master 's primary is disconnected
check that view change is done when no txns in the ldegr
check that view change is done after processing some of txns
check that we can send more requests after view change
primary gets all prepares after commits
testing ` status ` command at the start of cli when no nodes or clients are created
testing ` status ` and ` status node < nodename > ` command after one node is created
from : the node is not raised to : the node is ready to connect
from : the node ready to send a message to : the message is received other node
from : the node ready to send a message to : the message is received by all other nodes
from : the pool is not raised to : the pool is ready to connect
from : the pool up to : the pool is fully connected
from : any time the pool ready for the consistency proof procedure to : each of the nodes finish the consistency proof procedure ( ready for catchup if it is needed )
from : the consistency proof procedure is finished to : each of the nodes finished the the catchup procedure
from : the pool is disconnected to : the pool ledger is equal across the nodes
from : a message is replied to client to : the message is stored in the ledger
from : the view_change is send to : the view is changed started ( before nominate )
from : the nominate is sent to : the nominate is received by each node in the pool
from : the pool ready for the view change procedure to : the pool changed the view
from : any time to : the performance check is finished across the pool
from : the client sent the requests to : the requests are propageted
from : the requests are propageted to : the requests are pre - prepared
from : the requests are pre - prepared to : the requests are prepared
from : the requests are prepared to : the requests are committed
from : the requests are committed to : the requests are ordered
from : the client is not connected to the pool to : the client is connected to the pool
from : the client is connected to the pool to : the client finished the consistency proof procedure
from : the client finished the consistency proof procedure to : the client finished the catchup procedure
from : the client send a request to : the request is delivered to f nodes
from : the requests are sent to : the propagation procedure finish
authenticate the client 's message with the signature provided .
: param msg : : param signatures : a mapping from identifiers to signatures . : param threshold : the number of successful signature verification required . by default all signatures are required to be verified . : return : returns the identifiers whose signature was matched and correct ; a signingexception is raised if threshold was not met
adding an identifier should be an auditable and authenticated action . robust implementations of clientauthnr would authenticate this operation .
get the verification key for a client based on the client 's identifier
prepares the data to be serialised for signing and then verifies the signature : param req_data : : param identifier : : param signature : : param verifier : : return :
"added this because i spent the better part of an evening troubleshooting an issue cause by double import . we were importing test.helper in one place , and test_helper in another , and python sees them as two different modules , and imported the same file twice . this caused genha to be loaded twice , which caused overlapping ports to be assigned . took a long time to track this down . i 'm sure there 's a better way to do this , but this seems to work for the basic testing i did ."
a is disconnected with b so a does not get any nomination / primary from b ( simulated by a large delay ) . a gets nominations delayed due to which is sends primary only after it has received primary from other 2 nodes . a should still be able to select a primary and the pool should function .
": param obj : : param method : method name or method : param compare_val_to : if provided , only returns values which are equal to the provided one . wo n't work if the provided value is none : return : a list of return vals"
dynamically modify a class that extends from ` rstack ` and introduce ` teststack ` in the class hierarchy : param stack : : return :
a node that sends multiple primary declarations must be blacklisted by other nodes
"all nodes have bad clocks but they eventaully get repaired , an example of nodes being cut off from ntp server for some time or ntp sync disabled then without node restart ntp sync enabled"
run the unit tests .
extract urls from the data .
find urls in a text file and then check those links .
find the urls in a text stream and then check those urls .
sort the results into categories and return or print them .
print out report .
make the logging output pretty .
return the indices of nodes in the tpm .
"return ` ` true ` ` if ` ` tpm ` ` is in state - by - state form , otherwise ` ` false ` ` ."
"return a tpm conditioned on the given fixed node indices , whose states are fixed according to the given state - tuple ."
broadcast a state - by - node tpm so that singleton dimensions are expanded over the full network .
marginalize out nodes from a tpm .
infer the presence or absence of an edge from node a to node b.
infer the connectivity matrix associated with a state - by - node tpm in multidimensional form .
normalize a distribution .
"return the uniform distribution for a set of binary nodes , indexed by state ( so there is one dimension per node , the size of which is the number of possible states for that node ) ."
return the marginal probability that the node is off .
get the marginal distribution for a node .
check whether the repertoire is independent .
the purview of the repertoire .
return the size of the purview of the repertoire .
return the shape a repertoire .
"flatten a repertoire , removing empty dimensions ."
return the maximum entropy distribution over a set of nodes .
reverse the bits of the ` ` n``-bit decimal number ` ` i ` ` .
convert nodes to a tuple of their indices .
convert nodes to a tuple of their states .
convert between big - endian and little - endian for indices in ` ` range(n ) ` ` .
convert a pyphi state - tuple to a decimal index according to the big - endian convention .
convert a pyphi state - tuple to a decimal index according to the little - endian convention .
convert a decimal integer to a pyphi state tuple with the little - endian convention .
convert a decimal integer to a pyphi state tuple using the big - endian convention that the most - significant bits correspond to low - index nodes .
convert a state - by - state tpm from big - endian to little - endian or vice versa .
reshape a state - by - node tpm to the multidimensional form .
reshape a state - by - node tpm to the 2 - dimensional form .
convert a state - by - state tpm to a state - by - node tpm .
convert a state - by - node tpm to a state - by - state tpm .
a dictionary of loadable pyphi models .
"return a json - encodable representation of an object , recursively using any available ` ` to_json ` ` methods , converting numpy arrays and datatypes to native lists and types along the way ."
update kwargs for ` dump ` and ` dumps ` to use the pyphi encoder .
serialize ` ` obj ` ` as json - formatted stream .
serialize ` ` obj ` ` as a json - formatted stream and write to ` ` fp ` ` ( a ` ` .write()``-supporting file - like object .
check whether the json version matches the pyphi version .
check if ` ` dct ` ` is a pyphi model serialization .
deserialize a json string to a python object .
deserialize a json stream to a python object .
encode the output of ` ` jsonify ` ` with the default encoder .
analog to ` encode ` used by json.dump .
recursively load a pyphi object .
load a serialized pyphi model .
create a new time frame .
get the service list
return a service .
create hashmap service .
delete the service and all the sub keys recursively .
get the field list .
return a field .
create a field .
delete the field and all the sub keys recursively .
return a list of rated resources for a time period and a tenant .
return a db api instance .
retrieve the current state .
store the state .
retrieve state metadata
store the state metadata .
retrieve the module priority .
set the module state .
retrieve the module state .
set the module state .
get a mapping .
set a mapping .
retrieve the list of every services mapped .
retrieve the list of every mappings .
remove a mapping .
reload the module 's configuration .
get the group attached to the threshold .
get the threshold list
return a threshold .
create a threshold .
update a threshold .
delete a threshold .
"asymmetric rounding function for adjusting prices to two places in a way that "" improves "" the price . for limit prices , this means preferring to round down on buys and preferring to round up on sells . for stop prices , it means the reverse ."
check to make sure the stop / limit prices are reasonable and raise a badorderparameters exception if not .
get the limit price for this order . returns either none or a numerical value > = 0 .
get the stop price for this order . returns either none or a numerical value > = 0 .
the exchange to which this order should be routed .
store the given price .
store the given price .
store the given prices
"utility method to generate fake minute - level csv data . : param first_day : first trading day : param last_day : last trading day : param starting_open : first open value , raw value . : param starting_volume : first volume value , raw value . : param multipliers_list : ordered list of pd . timestamp - > float , one per day in the range : param path : path to save the csv : return : none"
build a weight vector for an exponentially - weighted statistic .
convenience constructor for passing ` decay_rate ` in terms of ` span ` .
convenience constructor for passing ` ` decay_rate ` ` in terms of half life .
convenience constructor for passing ` decay_rate ` in terms of center of mass .
extra arguments to use when zipline 's automated tests run this example .
register the number of shares we held at this dividend 's ex date so that we can pay out the correct amount on the dividend 's pay date .
register the number of shares we held at this dividend 's ex date so that we can pay out the correct amount on the dividend 's pay date .
"update the position by the split ratio , and return the resulting fractional share that will be converted into cash ."
"a note about cost - basis in zipline : all positions are considered to share a cost basis , even if they were executed in different transactions with different commission costs , different prices , etc ."
creates a dictionary representing the state of this position . returns a dict object of the form :
get a series of benchmark returns from iex associated with ` symbol ` . default is ` spy ` .
"to resolve the symbol in the leveraged_etf list , the date on which the symbol was in effect is needed ."
"data : a nested dictionary : knowledge_date - > lookup_date - > { add : [ symbol list ] , ' delete ' : [ ] } , delete : [ symbol list ] } current_date_func : function taking no parameters , returning current datetime"
check the results of a non - callable object .
tests when a function does not have * args and it was expected .
tests when a function has * args and it was expected .
tests a function that unexpectedly accepts * args .
tests checking a function ignoring the presence of * args .
tests when a function does not have * * kwargs and it was expected .
tests when a function has * * kwargs and it was expected .
tests a function that unexpectedly accepts * * kwargs .
tests checking a function ignoring the presence of * * kwargs .
tests when the args are a subset of the expectations .
tests when an argument expects a default and it is not present .
tests when an argument expects a default and it is present .
tests that ignoring defaults works as intended .
tests the ignore argument list feature .
tests the case where arguments are not in the correct order .
"tests the case where a default is expected , but the default provided does not match the one expected ."
tests the any_default option .
tests ignoring a param name .
verify that the validate decorator does n't swallow typeerrors that would be raised when calling a function with invalid arguments
"creates trade_count trades for each sid in sids list . first trade will be on sim_params.start_session , and daily thereafter for each sid . thus , two sids should result in two trades per day ."
toggle the state of the flipper .
whether the flipper is ' open ' or ' closed ' .
set the flipper to be either 0 or 1 ' .
"the state of the flipper - should either be "" open "" or "" closed "" ."
return a graphical interface for the flipper .
create a dummy flipper object
toggle the state of the flipper
"return the state of the flipper , a string reading ' open ' or ' closed '"
set the state of the flipper ( to open or closed )
groups tokens that have beginning and end .
group together identifier and asc / desc token
groups together tokens that are joined by a middle token . i.e. x < y
: return : boolean
return true if platform is yun : return : boolean
return true if platform is rpi : return : boolean
return true if platform is win : return : boolean
: param err : exception handler : return : string
"save bridge to bridge_file , if success return true , else false : param bridge_file : string : return : boolean"
load data from bridge_file and return dictionary or none : param bridge_file : string : return : dictionary
return codeword from dictionary : param lcw : key : return : string
return codeword and default value from dictionary : param lcw : key : return : string
"try read from bridge , if key not there , save default value : param lcw : string , local codeword : param _ save : boolean , if not in bridge then save : return : various"
put value to the key in bridge_client : param key : key : param value : string : return : nothing
"get from bridge_client by key , key is expanded through cw : param key : key : return : string"
export bridge_client.json as json : return : json string
"return a tuple of ` ( session_id , sf_instance ) ` where ` session_id ` is the session id to use for authentication to salesforce and ` sf_instance ` is the domain of the instance of salesforce to use for the session ."
extracts an element value from an xml string .
returns an iso8601 string from a date
"sometimes file ids are not the file names on the device , but are instead generated by the api . these are not guaranteed to be valid file names so need hashing ."
decorator to make a task synchronous .
put some test messages to tarantool queue
: type self : async_task_processor . tarantooltask : type sleep_time : int : type word : str : return :
: type self : async_task_processor.primitives . tarantooltask : type tp : tarantoolprocessor : return :
return a pretty - printed xml string for the element .
return xml root
returns the given logs after unwraping the lines
returns the logs with error message in red ( html ) .
just an example api to check the dynamic part of the url is working correctly and is passed into the api function
example api to check multiple dynamic values are passed through to the function correctly from a url
example api for non dynamic urls
在请求上添加代理 : param request : : param spider : : return :
"make the signature in vin 0 of a tx non - der - compliant , by adding padding after the s - value ."
find all numbers in a string
calls the ' unit ' method of ` aclass ` with ` value ` .
stores ` value ` as the contents of the functor .
applies ` function ` to the contents of the functor and returns a new functor value .
the ' fmap ' operator . the following are equivalent :
returns an instance of the functor with ` value ` in a minimum context .
test case 01 : try instantiating an ssh api object by its * get_instance * class method .
test case 02 : try instantiating an ssh api object directly .
test case 03 : compare two : py : class:`~controlbeast.ssh.api . cbsshlib ` instances .
test case 01 : try instantiating a cbscmwrapper object .
test case 02 : try calling the ` ` init ` ` method .
test case 03 : try calling the ` ` commit ` ` method .
test case 04 : try calling the ` ` create_branch ` ` method .
test case 05 : try calling the ` ` checkout ` ` method .
test case 06 : try calling the ` ` get_branches ` ` method .
test case 07 : try calling the ` ` get_active_branch ` ` method .
test case 07 : try calling the ` ` get_root ` ` method .
test case 01 : try instantiating a cbsshsession object .
algorithm to be used for key generation . expected to be a string with the designator understood by * ssh - keygen *
list of valid algorithm names . this list depends on the available openssh version .
"key length in bytes to be used for key generation . expected to be an integer within the valid range for the selected algorithm ( for rsa e. g. [ 2¹¹ , 2¹² , 2¹³ , 2¹⁴ ] , for dsa e. g. [ 2¹⁰ ] ) ."
list of allowed key lengths for the currently chosen algorithm .
the version of the detected openssh installation as tuple .
"generate a public / private key pair and store them in ` ` filename ` ` , encrypted by ` ` passphrase ` `"
detects the version of the installed openssh client
test case 01 : create a key store with plaintext backend using a temporary file .
test case 02 : update data on a key store with plaintext backend using a temporary file .
test case 03 : delete data from a key store with plaintext backend using a temporary file .
test case 04 : destroy a : py : class:`~controlbeast.keystore . cbkeystore ` object after having used it .
test case 05 : initialise a key store with plaintext backend using a temporary file with initial data .
"test case 06 : create a key store with plaintext backend on a non - existing file , but at a writeable location ."
test case 07 : try creating a key store with plaintext backend on a non - existing file at a non - writeable location .
test case 08 : create a key store with plaintext backend on an existing file .
test case 09 : create a key store with crypto backend on a temporary file .
test case 10 : create a key store with crypto backend on a temporary file .
test case 11 : create a key store with plaintext backend on an existing file with invalid content .
test case 12 : try writing to a read - only key store .
test case 13 : try deleting from a read - only key store .
test case 14 : try force - syncing a read - only key store .
checks if a file system object can be accessed in a specific mode
"checks if a file does exist and is a regular file : param str filename : name of the file to be tested : return : true if the file exists , false if not : rtype : bool"
checks if a path exists and is a directory
run the command described by arguments and catch eventual exceptions .
the init method contains the actual code for the repository initialisation . this method needs to be implemented for each scm wrapper class
the commit method contains the actual code for committing updated content into the repository . this method needs to be implemented for each scm wrapper class
the create_branch method contains the actual code for creating a named branch within the repository . this method needs to be implemented for each scm wrapper class .
the checkout method contains the actual code for checking out a named branch from the repository . this method needs to be implemented for each scm wrapper class .
the get_branches method contains the actual code for retrieving a list of all named branches that exist within the repository . this method needs to be implemented for each scm wrapper class .
the get_active_branch method contains the actual code for retrieving the currently active branch of an existing repository . this method needs to be implemented for each scm wrapper class .
get the path to the root of the scm repository
converts stdout string to a list .
converts stderr string to a list .
converts traceback string to a list .
"returns if the result of the command was a success . true for success , false for failure ."
"returns if the result of the command was a failure . true for failure , false for succes ."
returns true if self.__traceback is not empty .
"prints the stdout to console - if there is any stdout , otherwise does nothing . : param always_print : print the stdout , even if there is nothing in the buffer ( default : false )"
"prints the stderr to console - if there is any stdout , otherwise does nothing . : param always_print : print the stderr , even if there is nothing in the buffer ( default : false )"
"prints the traceback to console - if there is any traceback , otherwise does nothing . : param always_print : print the traceback , even if there is nothing in the buffer ( default : false )"
call ` ` logging.basicconfig ` ` and override the formatter it creates .
modify a function to call ` ` basicconfig ` ` first if no handlers exist .
retrieves the script block alias and unicode category for a unicode character .
retrieves the script block alias for a unicode character .
retrieves the unicode category for a unicode character .
retrieves all unique script block aliases used in a unicode string .
currently it 's the same as multi - line doc mode .
generate repr for attrs of a category .
patch ` cliclient.execute ` method for unittest
get the test cli client
get the test vnx instance
converter for alu hlu map
convert following input to disk indices
convert a url to a host ( ip or domain )
"parse host address to get domain name or ipv4 / v6 address , cidr prefix and net mask code string if given a subnet address"
ipv4 cidr prefix to net mask
ipv6 cidr prefix to net mask
get the erodibility values for the surface based on underlying erosive stratigraphic layer .
this function writes the hdf5 file containing erosive layers information .
load different .cnv versions with fcnv
temporary solution to avoid # 37 & # 40
test that valid kwargs are stored as properties on the client .
test that unknown kwargs are ignored .
test that resources are turned into urls properly .
test that resource resolving works with different options .
test that getattr is doing right by us .
we should be able to set the host on the client .
we should be able to disable ssl verification when we are in dev mode
test that getattr raises an attributeerror if we give it garbage .
test that calling client.get ( ) results in a proper call to the get function in the requests module with the provided kwargs as the querystring .
test that calling client.post ( ) results in a proper call to the post function in the requests module .
test that providing a dictionary of proxy servers works .
"context manager and decorator to ignore warnings . note . using this ( in both variants ) will clear all warnings from all python modules loaded . in case you need to test cross - module - warning - logging this is not your tool of choice . parameters ---------- category : warning class , defaults to warning . the category to filter . if warning , all categories will be muted . examples -------- > > > with ignore_warnings ( ): ... warnings.warn('buhuhuhu ' ) > > > def nasty_warn ( ): ... warnings.warn('buhuhuhu ' ) ... print(42 ) > > > ignore_warnings(nasty_warn ) ( ) 42"
safe way to reset warnings .
parameters ---------- extra : string to be added to the deprecation messages
decorator to catch and hide warnings without visual nesting .
generate processing . r web reference .
modify the module search path .
allow or re - raise an import error .
clean up build files .
"strip trailing whitespace and clean up "" local "" names in c source ."
configures attributes on rules using a dictionary of the following form :
store a datastream to influxdb todo : this needs to be updated with the new structure : param datastream :
datastream object contains the list of datapoint objects and metadata linked to it . : param identifier : : param owner : : param name : : param data_descriptor : : param execution_context : : param annotations : : param stream_type : : param start_time : : param end_time : : param data : : param stream_timezone :
: param cc : cerebralcortex object reference
"returns all available buckets in minio storage : return : [ { bucket - name : str , last_modified : str } ] , in case of an error [ { "" error "" : str } ] : rtype : list"
"returns a list of all objects stored in the specified minio bucket : param bucket_name : : return:{object - name:{stat1 : str , stat2 , str } } , in case of an error [ { "" error "" : str } ] : rtype : dict"
"returns properties ( e.g. , object type , last modified etc . ) of an object stored in a specified bucket : param bucket_name : : param object_name : : return : { stat1 : str , stat2 , str } , in case of an error { "" error "" : str } : rtype : dict"
"returns stored object ( httpresponse ) : param bucket_name : : param object_name : : return : object ( httpresponse ) , in case of an error { "" error "" : str } : rtype : dict"
: param bucket_name : : return : true / false : rtype : bool
creates a new bucket : param bucket_name : : return : true / false : rtype : bool
"uploads an object to minio storage : param bucket_name : : param object_name : : param object_filepath : it shall contain full path of a file with file name ( e.g. , /home / nasir / obj.zip ) : return : true / false : rtype : bool"
"> > > parse_request ( "" -exclude%20=599%20include "" ) ( [ ' include ' ] , [ ' exclude ' ] , 599 )"
"searches words line by line in file , split them and check result with expect , excludes words that start with "" - "" symbol ."
"> > > parse_row ( "" \""first\"";\""second "" , 2 ) [ ' first ' , ' second ' ]"
"> > > make_magnet ( "" 329841348432213464 "" , "" torrent name "" , [ "" http://tracker1 "" , "" udp://tracker2 "" ] ) ' magnet:?xt = urn : btih:329841348432213464&dn = torrent%20name&tr = http%3a//tracker1&tr = udp%3a//tracker2 & '"
"> > > filter ( [ "" word1 "" , "" word2 "" ] , "" there is no such word1 word2 "" ) true"
loads configuration from a ` etcd store < https://github.com/coreos/etcd > ` _ .
"if your backend data is exposable as a python dict , you can subclass from this class to avoid implementing : py : meth:`has ` , : py : meth:`get ` , : py : meth:`keys ` , : py : meth:`subsection ` and : py : meth:`subsections ` . you only need to write : py : meth:`__init _ _ ` ( which should set ` ` self.source ` ` to that exposed dict ) , and possibly : py : meth:`typed ` and : py : meth:`save ` ."
"tells the scheduler to start program_id on station_id at start_time if operation is ' delete ' , scheduler will remove existing job if operation is ' update ' , scheduler will remove and re - add job"
tells the telephony_server to update the client about new station fields
this covers a bug that arose from a numerical stability issue in measurement on ec2 / mkl .
"this function can be used by the optimize to solve the sparse matrix a ( which will be j.t.dot(j ) , where j is the jacobian of the objective function ) . the structure of a is such that it is mostly sparse with a few dense rows and columns ( and also some columns with all zero ) . by explicitly spliting the matrix a into dense and sparse components , we can construct a basic preconditioner that makes linalg.cg much faster . ( a preconditioner matrix for a matrix a is a matrix that approximates the inverse of a. )"
"rotates points to the x - z plane . if the initial center of mass is not to within 1e-5 of the origin , we translate it to the origin ."
rotation matrix to rotate a mesh into a canonical reference frame . the result is a rotation matrix that will make up along + y and look along + z ( i.e. facing towards a default opengl camera ) .
find the most extreme point in the direction of the axis provided .
find the list of vertices that preceed inflection points in a curve . the curve is differentiated with respect to the coordinate system defined by axis and span .
"find the farthest point among the inputs , to the given point ."
"gets a string representation of the requested filename . checks for both ascii and unicode representations and returns a value if possible . if there are both ascii and unicode versions , then the parameter /prefer/ specifies which will be returned ."
"here all the workload happens . read the files , check if the ip is in there and report the results . if the lock file is found , which gets created when lists are getting updated , the script starts to sleep 10 seconds before checking again . also reads the source file date and checks , if its too old ( ignoreolderthandays parameter ) ."
prepares the http body for querying safebrowsing api . maybe the list need to get adjusted .
the actual query to safebrowsing api
computes the probability of the differential by iteratively summing up all characteristics of a specific weight using a sat solver .
search for the optimal differential or linear characteristics . works only for simon !
"find a characteristic of minimal weight for the cipher parameters = [ rounds , wordsize , sweight , isiterative , fixedvariables ]"
outputs all characteristics of a specific weight by excluding solutions iteratively .
searches for differential characteristics of minimal weight for an increasing number of rounds .
return true if the timelimit was reached .
count the number of solutions in a cryptominisat logfile
return cryptominisat process started with the given stp_file .
returns the solution for the given smt problem using stp .
returns the solution for the given smt problem using boolector .
check if a solution was found .
creates an stp file to find a characteristic for siphash with the given parameters .
returns a list of the parameters for siphash .
returns a string representing sipround in stp .
each cipher need to define how it creates an instance for the smt solver .
each cipher needs to specify the format it should be printed .
returns the print format .
creates an stp file to find a characteristic for chacha with the given parameters .
"chacha quarter round : ( c0 , c1 , c2 , c3 ) = quarterround(a0 , a1 , a2 , a3 )"
creates an stp file to find a characteristic for salsa with the given parameters .
"salsa quarter round : ( c0 , c1 , c2 , c3 ) = quarterround(a0 , a1 , a2 , a3 ) b0 , b1 , b2 and b3 are used for the modular addition ."
": param repos_and_branch : list(tuple(str , str ) )"
": param repos_and_branch : list(tuple(str , str ) )"
test config search search works for the usual case up where the file is at the root of the repository .
test config dir search finds .mu_repo file in sub - directories .
update the left and right values in the table
a dummy placeholder ( the image is already in gpu ) to be consistent with other providers .
"grab current frame ( thread - safe , minimal overhead )"
decode image data from grabbed frame .
grab and decode frame in one call
get the number of available cameras .
.. versionadded : : 1.9.0
function to capture the images and give them the names according to their captured time and date .
"open the dropdown list and attach it to a specific widget . depending on the position of the widget within the window and the height of the dropdown , the dropdown might be above or below that widget ."
remove the dropdown widget from the window and detach it from the attached widget .
call this method to trigger the ` on_select ` event with the ` data ` selection . the ` data ` can be anything you want .
search for a resource in the list of paths . use resource_add_path to add a custom path to the search .
add a custom path to search in .
remove a search path .
build and return the root widget .
set the default values for the configs sections .
add our custom section to the default configuration object .
respond to changes in the configuration .
the settings panel has been closed .
provides a thread - safe entry point for interactive launching .
provides a thread - safe exit point for interactive launching .
register a input provider in the database
get a list of all available providers
get a provider class from the provider i d
compute link impurity of vertex - labeled graph .
compute entropy of label vector .
load graph from an ascii file containing adjacency information .
compute graph feature vector(s ) .
run ( f)ine-(s)tructure ( a)nalysis .
estimate a gaussian mixture model .
learn a codebook .
compute a ( normalized ) bow histogram .
compute the posterior probability of x under a set of gmm models .
read a binary file .
write a binary file .
returns the center point of an object .
errormiddleware returns hard - coded content - type text / html . here we force it to be application / json .
create a wsgi application and return it
converts an iterable of permutation matrices given as numpy arrays into a list of lists .
tests for computing the birkhoff decomposition of a scaled doubly stochastic matrix .
parse config from ' git - config ' cache .
return package version as listed in ` _ _ version _ _ ` in ` init.py ` .
"return all files under the root package , that are not in a package themselves ."
if you add elements after the iteration query they should not compare in the results
instantiate proxy to the database
create all tables in the given database
create user admin and grant him all permission
initialize users database
check for required packages
create a new user
create a new group
will not be added
desc : this function is dedicated to reading frames and pushing them into the queue . it will run in a separate daemon thread .
overrides config params if config file is provided
overrides config params if a dict is provided
""" formats url strings"
checks host availability
returns the first available host
returns current configuration parameters
creates the url for querying the rest service
creates the gene client
creates the protein client
creates the protein client
creates the variation client
creates the xref client
creates the region client
creates the variant client
creates the genome sequence client
creates the clinical client
creates the tfbs client
creates the regulatory client
creates the regulatory client
creates the clinical client
absolute path to a file from current directory .
dummy gettext .
convert string to xml / html format
trim test name . trailing underscore and digits are removed
write html file for a function name
parse test file and add info to the nodes variable
"loops through the instances and adds exclusion , age and timeout"
returns a list of dictionaries containing gce instance data
"logs all expired instances , calls delete api when not dry_run"
return a datetime object for a string in iso 8601 format .
directory that contains the the settings for the project
"read the "" dsbfile "" file populates ` self.settings `"
read ` .dsb / instances.yaml ` populates ` self.cluster `
execute a salt ( or salt - ssh ) command
setup ` salt - ssh `
creates the ` salt - ssh ` required directory structure
generic csv export admin action .
test create a connection see if it exists and then delete it
create a standard table
create a table with folded cells
compare two multiline strings to find differences . helpful to find minor errors in the actual / expected outputs
test a simple table with header
test print a simple table no header
test a none table borders with header
test printing a plain table with borders and header
test a none table borders with header
test building a folded cell table plain with header
test a folded cell table simplewith header
test a folded cell table with header
get data files of delogx.
copy all files in src to dst .
create a new blog application .
create deployment files .
main function of the manager .
return context dict for a shell session so you can access app and db by default .
see ` help(jinja2.environment ) ` for options .
render given template string and return the result .
render given template string and return the result .
render given template file and return the result .
todo : test cases if given template file is missing but its path will be given by users on demand .
start : header definition
header : header_unit _ header |
header_unit _ : header_unit ' ; ' | header_unit
header_unit : syntax | package
syntax : syntax ' = ' literal
package : package identifier
definition : definition definition_unit _ |
definition_unit _ : definition_unit ' ; ' | definition_unit
definition_unit : service | message
message : seen_message ' { ' field_seq ' } '
seen_message : message identifier
field_seq : field ' ; ' field_seq |
field : field_req field_type identifier ' = ' intconstant
field_req : optional | repeated |
field_type : ref_type | definition_type
ref_type : identifier
definition_type : base_type | container_type
base_type : bool | string | bytes | double | float | int32 | int64 | uint32 | uint64 | sint32 | sint64 | fixed32 | fixed64 | sfixed32 | sfixed64
container_type : map_type
"map_type : map ' < ' base_type ' , ' base_type ' > ' | map ' < ' base_type ' , ' ref_type ' > '"
service : service identifier ' { ' func_seq ' } '
func_seq : func func_seq | func ' ; ' func_seq |
func : rpc identifier ' ( ' identifier ' ) ' returns ' ( ' identifier ' ) ' ' { ' ' } '
expects a ps command with a -o argument and parse the result returning only the value of interest .
get lists .
get a list by its token .
save a new list .
update an existing list .
update an existing list .
search for lists .
schedule a scan for the list .
save all sites for a list .
get a scan result by its i d.
normalize an url and remove get query .
get the first raw data element with the specified identifier .
get the first raw data element with the specified value for key .
"get a tuple ( pid , cmdline ) for all processes of user ."
compute a totp value as prescribed by oath specifications .
validate a totp value inside a window of [ drift - bacward_drift : drift+forward_drift ] of time steps . where drift is the drift obtained during the last call to accept_totp .
function receives a data class object and returns for each series a link to the first instance
convert a singleresult object to xml .
return the xml string for a singleresult object and possible bounds
save numeric results
save figures / images
read a .zip file .
return whether the value is near the target value .
try importing mpld3 . raises error if not installed . returns the mpld3 library .
get the response from the url .
type - enforced property . python cookbook 9.21 ( 3rd ed ) .
round a number to the given number of decimals . fixes small floating number errors .
boolean specifying if file is a proper dicom file .
check whether the passed object is numeric in any sense .
determine if an object is iterable .
go up directory levels from where the caller file is located .
analyse the cu wedge . first find all steps . calculate dynamic range
"concept : 1 . cut out rectangular roi 2 . for each cu step , measure mean and sd 3 . calculate snr and cnr 4 . calculate dynamicrange"
"qcmr_umcu checks : philips piqt reimplementen in python uniformity ( several ways ) geometrical deformation artifactlevel signal - to - noise ( several positions ) resolution ( mtf , ftw , slicewidth )"
read selected dicomfields and write to iqc database
drop the columns calendar_multiple_meetings and calendar_regional_meetings and rename meeting_region into meeting_location .
add the columns calendar_multiple_meetings and calendar_regional_meetings and rename meeting_location into meeting_region .
test the calendar init function .
test the calendar string representation function .
test the query of a calendar by its name .
test by_id query of a non - existant calendar .
test the calendar get_editor_groups function .
test the calendar get_admin_groups function .
test the calendar get_editor_groups function for a non existant calendar .
test the calendar get_admin_groups function for a non existant calendar .
test the calendar get_admin_groups function for a non existant calendar .
test the calendar get_all function .
test the calendar get_all function when the db is empty .
test the calendar.delete method .
the equivalent python code for a if - then - else sqf statement
test that we must construct with a storage client
test that two audit loggers share the same state
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
test that audit log results in a database insert
"evaluates and converts to the type in relation to its actual value , for example "" 180.2 "" to float 180.2"
evaluates the type in relation to its value
identify unique asset codes in the data block
retrieves the configuration from the category manager for a category name
""" set the default configuration for purge : return : configuration information that was set for purge process"
""" purge readings table based on the set configuration : return : total rows removed rows removed that were not sent to any historian"
""" starts the purge task"
returns information about the plugin .
initialise the plugin .
extracts data from the sensor and returns it in a json document as a python dict .
"reconfigures the plugin , it should be called when the configuration of the plugin is changed during the operation of the south device service . the new configuration category should be passed ."
"shutdowns the plugin doing required cleanup , to be called prior to the south device service being shut down ."
decorator that restrict access only for authorized users with correct permissions ( role_name )
request an introduction . forwarding to intro endpoint for backcompat
return a translated string which can be used in ui for displaying recipe type
return a translated string which can be used in ui for displaying misc ingredient use
return a qstandarditem for displaying misc name attribute . a reference to the model object is stored in model_data_role user role
return a qstandarditem for displaying misc amount attribute . a reference to the model object is stored in model_data_role user role
return a qstandarditem for displaying misc time attribute . a reference to the model object is stored in model_data_role user role
return a qstandarditem for displaying misc use attribute . a reference to the model object is stored in model_data_role user role
returns a displayable value for a time value
return a translated display value suitable for using in misc model instance
returns a displayable value for a amount value
return a translated display value suitable for using in misc amount instance
sets the database name to route to .
get the current database name or the default .
clear the database name ( restore default )
"strip all the whitespace from a and b , and then check a in b."
"this function should return some sort of tuple indicating if the message was successfully sent and if not , it should indicate if the error was fatal or tryagain"
getting a url for toggle enabled a contact
by posting to toggle - enabled you can toggle enabled or disabled a contact
when posting we the response contains the contact i d and the status
only the owner of the instances contact can toggle enabled
if a user that is not owner tries to post returns 404
it does not send emails when saving
the list of messages shown in the api is ordered by created date
push a new message to an instance with no autoconfirm message
not including email causes error 403 in a non auto confirm message
when it has an author_email it validates it
as described in # 773 emails can contain odd parts
"if i set the "" to "" header in the email and use it in the email_answer.recipient then i should not be getting her / his email address in the content"
an email answer can have attachments
when saving it also calls the save an attachment
process p- * properties
process u- * properties
process dt- * properties
process e- * properties
"given an ecs cluster , service name and desired instance count , change the instance count on aws ."
"creates an sns topic in moto , and yields the new topic arn ."
"creates an sqs queue in moto , subscribes it to an sns topic , and yields the new queue url ."
normalize a text using open - korean - text .
"tokenize a text into space - separated words . this is the most basic form of tokenization , where we do not wish to analyze morphology of each individual word ."
tokenize a bulk of text into list of sentences ( using mecab - ko ) .
tokenize a sentence into morpheme tokens ( using mecab - ko ) .
tokenize a bulk of text into list of sentences ( using mecab - ko ) .
tokenize a bulk of text into list of sentences ( using mecab - ko ) .
attempts to find the version number in the file names fname . raises runtimeerror if not found .
"return a function which finds the distance to a line specified by x1 , y1 and theta ."
"given the angles of two lines passing through a center , cluster a set of points by their distances to those two lines ."
what is the residual of points clustered by distance to lines through the center specified by angles of those two lines .
find the line angles which result in the smallest residuals between the peak points and the lines passing through center with angles theta1 and theta2
"from an image , gather the initial guesses to feed mcmc optimization ."
log prob that a generated peak comes from the data 's distribution .
run a sampler ensemble on the passed region of interest .
plot histograms of sample distributions .
row and col of max likelihood
"find the row , col location and its surrounding confidence interval ."
"this function takes care of syncing roms . after this function exits , steam will contain only non - ice shortcuts and the roms represented by ` roms ` ."
"checks the filesystem for images for a given rom . to do so , it makes use of a consoles ' images ' directory . if it finds an image in that directory with the same name as the roms name then it will return that ."
generates a command string that will launch ` rom ` with ` emulator ` ( using the format provided by the user ) . the return value of this function should be suitable to use as the ` exe ` field of a steam shortcut
returns the directory which stores the emulator . the return value of this function should be suitable to use as the ' startdir ' field of a steam shortcut
@param console - a console object @returns a list of rom objects representing all of the valid roms for a given console .
@param consoles - an iterable list of consoles @returns a list of all of the roms for all of the consoles in ` consoles `
args : index : index of the triplet or the matches - not of a single features
renders this field as an html widget .
"most widgets yield a single subwidget , but others like radioselect and checkboxselectmultiple produce one subwidget for each choice ."
returns an errorlist for this field . returns an empty errorlist if there are none .
"renders the field by rendering the passed widget , adding any html attributes passed as attrs . if no widget is specified , then the field 's default widget will be used ."
"returns a string of html for representing this as an < input type=""text "" > ."
returns a string of html for representing this as a < textarea > .
"returns a string of html for representing this as an < input type=""hidden "" > ."
"returns the data for this boundfield , or none if it was n't given ."
"returns the value for this boundfield , using the initial value if the form is not bound or the data otherwise ."
"wraps the given contents in a < label > , if the field has an id attribute . contents should be ' mark_safe'd to avoid html escaping . if contents are n't given , uses the field 's html - escaped label ."
returns a string of space - separated css classes for this field .
returns true if this boundfield 's widget is hidden .
"calculates and returns the id attribute for this boundfield , if the associated form has specified auto_id . returns an empty string otherwise ."
"wrapper around the field widget 's ` id_for_label ` method . useful , for example , for focusing on this field regardless of whether it has a single widget or a multiwidget ."
deserialize a stream or string of json data .
turns any callable into a lazy evaluated callable . you need to give result classes or types -- at least one is needed so that the automatic forcing of the lazy evaluation code is triggered . results are not memoized ; the function is evaluated on every access .
shortcut for the common case of a lazy callable that returns str .
"a decorator that allows a function to be called with one or more lazy arguments . if none of the args are lazy , the function is evaluated immediately , otherwise a _ _ proxy _ _ is returned that will evaluate the function when needed ."
a decorator for functions that accept lazy arguments and return text .
prevent older versions of pickle from trying to pickle the _ _ dict _ _ ( which in the case of a simplelazyobject may contain a lambda ) . the value will be ignored by _ _ reduce _ _ ( ) and the custom unpickler .
scan for devices and print results .
functional form of the spectral density
value of spectral_density_func divided by x at 0
full one - sided correlation function for debye spectral density
evaluate this pulse at the given time and frequency
"given an iterable of ndarrays of known length , all with the same shape and dtype , return a new ndarray containing all the provided arrays"
cast seed into a np.random . randomstate object
"return a shallow copy of the provided object , resetting the cache as used by imemoize ( if present )"
returns a sensible ` repr ` for an object by inspecting the arguments to its ` _ _ init _ _ ` method . assumes that each argument is available as a property of the same name .
functional interface to solvers from ` scipy.integrate.ode `
returns an n - dimensional slice along only the specified axis
fourier transform a signal defined in a rotating frame using fft
bound a signal by tick values along a given axis
rief print dump for binary object to trace file .
rief get notification from queue
rief raise exception only one time for one session and save current notification .
rief put notification to queue insert notification to queue . if queue is full raise connectionerror exception
rief put disconnect notification to queue
rief get notification from queue
rief put disconnect notification to queue
parse the oap notification data and return a oapnotif object .
rief convert raw temperature value to celsius .
rief convert raw adc values to mv.
rief search celsius temperature from a given value as a list .
"lock the given directory for use , unlike conda.lock . lock which locks the directory passed , meaning you have to come up with another name for the directory to lock ."
read filename to read the volumetric data in it .
"returns x , y , and z coordinate and charge density arrays . supported file formats : chg , chgcar"
"returns x , y , z , and local potential arrays"
"returns x , y , z and electron localization function arrays ."
returns center of electron density .
tries to return the dipole vector of the unit cell in atomic units . returns none when chg file is empty / not - present .
test neither columns nor extra_headers defined .
test only columns defined .
test only extra headers defined . should ignore it completely .
test custom columns and extra headers .
make sure that the file list gives the correct url .
test having multiple links works .
make sure that the search is checking text fields and finding the correct results .
test form generation .
test the file upload and post .
get package from specific section .
merge global settings to current context
"adds various preferences members to preferences.preferences , thus enabling easy access from code ."
make sure there is only a single preferences object per site . so remove sites from pre - existing preferences objects .
include site names .
test that the creation of a deal is successfull with relations .
test that the create of a deal is validated properly .
test that the update of a deal is validated properly .
"read from path assuming it 's a file with ' , ' separated values ."
"generates a url - safe token for the given user , action , time tuple ."
validates that the given token authorizes the user for the action .
try to execute a service call .
fetch the history list from the gmail api . this includes email and chat messages .
fetch all messageids from the gmail api . chat messages are filtered out .
fetch message information given message_id .
fetch all labels from the email account .
fetch label info given label_id
fetch labels & threadid for given message .
save currently set history_id to the emailaccount .
fetch attachment given message_id and attachment_id
"cleanup references , to prevent reference cycle ."
"read from path assuming it 's a file with ' , ' separated values ."
get primary key(s ) from post .
"default function from multipleobjectmixin.get_queryset , and slightly modified ."
should be overridden if there needs to be a success message after archiving objects .
"returns the succes_url if set , otherwise will raise improperlyconfigured ."
archives all objects found .
catch post to start archive process .
catch post to start un - archive process .
when project is changed : copy it 's department to the issue .
calls genome guided trinity on the bam file to generate assembled transcripts
"calls braker , may take a while"
it is used for the alignment of the primers to the reads : param seq : : param lele : : param dele2int : : return :
this function calculate the score and other results from the alignment
this function call the aligner software : param elem : : return :
filters out reads longer than length provided and it is used to call the alignemnt and parse the outputs
this module is used to mask the genome when a gff or bed file is provided
read and teturn the current temperature in celsius
"check for the most recent direct message that starts with code and was sent in the specified number of minutes . look for the command after the code , so for example , ac on . returns ( cmd , user ) if there was a command , where command is a string like "" on "" and user is a screen name . returns ( none , none ) if there was no command ."
helper method to return length for all seqs
distance matrix between two sets of descriptors
a helper for setting up log options
"ignore empty lines , valgrind output , android output ."
test upsilon package .
block tag that minifies the javascript it contains .
"get a stream uri from a playlist uri , ` ` uri ` ` ."
clusters ` ` data ` ` using the k - means algorithm where ` ` data ` ` can be either ` float32 ` or ` float64 ` . returns the centers of the clusters as an ` ndarray ` of the same dtype as ` ` data ` ` . also returns the cluster assignments .
project the given data to the corresponding cluster indices .
removes xml namespace in place .
splits an autosar url string into an array
"parses autosar version from the attributes in the root autosar tag returns a tuple with major , minor , patch , schemafile ( all integers except schemafile which is string )"
reads all messages in a topic from a bag file .
gets the topic names and types of messages in a bag file .
reads all data in a message
reads input data num_epochs times .
iterate over all registered plugins or plugin points and prepare to add them to database .
"mark all missing plugins , that exists in database , but are not registered ."
synchronize all registered plugins and plugin points to database .
encrypt database with new decrypter
"custom method to query for _ net_wm_name first , before falling back to python - xlib 's method , which ( currently ) only queries wm_name with type = string ."
test that pynetdicom client can talk to gonetdicom .
"this is the main function , we get a network and a desired size and try to make the samples ."
test object type domain under various name scenarios .
test rollback of an objecttype .
test compatible ( ) function .
test subtype graph with multiple root types .
test that basic subtype graphs are properly loaded .
test that diamond - shaped graph is properly loaded .
return the least common multiple of a and b.
returns true if role is a root role .
populate all object types and roles in the model .
populate all root roles played by an object type .
populate non - root roles with first n elements of root role 's pop .
populate all role sequences covered by an internal frequency constraint .
populate all fact types in the model by combining populations of fact type parts .
combine populations of elements in parts list to create a combined population of a given size .
split the population of an absorptionfacttype into populations of the original fact types .
write the populate of an object type to a file stream .
write the population of a fact type to a file stream .
write the entire population to csv files stored in a directory ( one file per object type or fact type ) .
writes entire population to stdout .
add tuple to the list . the ordering of elements in the tuple is assumed to match the order of self.names .
return a new relation containing first n elements of this one .
"combine self with a target relation according to the enumeration algorithm of smaragdakis , et al ."
: param text : string of text to be used for markov chain generation : return : instantiated provider
create a message : param mention : json object containing mention details from twitter ( or an empty dict { } ) : param max_message_length : maximum allowable length for created message : return : a random message created using a markov chain generator
yields the area calculated with the points provided as arguments .
"yields the span of the panel , which must be constant - p1p2 and p3p4 must be parallel - ."
"returns the ( x , y ) coordinates of the two points that define the position of the vortex horseshoe within the panel plus the control point , identified as pab in the documentation above ."
"returns the ( x , y ) coordinates of the control point ."
"returns the induced velocity by a horseshoe vortex and the induced velocity excluding the bounded segment at a control point , defined as argument of the method ."
simplified cross product of two 2d vectors .
simplified dot product of two 2d vectors .
normalized direction vector from point a to point b
distance from a point p to a straight line in a 2d euclidean space defined by a and b
"y ^ c + -+ d area of the polygon defined by 4 points , | / \ previously ordered in a clockwise | b + -----+ a ( or counterclockwise ) manner in a 2d + ----- > euclidean space . x"
parse a sourcemap from a file - like object
parse a sourcemap from a string
"given a javascript file , find the sourcemappingurl line"
parse a string of vlq - encoded data .
decode a source map object into a sourcemapindex .
returns the state 's printable name .
returns the state 's unique identifier .
returns the debug flag 's current setting .
sets the debug flag . a true value means debugging is on and false means off .
returns the stream to which debug output is written .
sets the debug output stream .
returns the current state .
is this state machine already inside a transition ? true if state is undefined .
returns the current transition 's name . used only for debugging purposes .
clears the current state .
returns the state which a transition left . may be none
sets the current state to the specified state .
returns true if the state stack is empty and false otherwise .
returns the state stack 's depth .
push the current state on top of the state stack and make the specified state the current state .
make the state on top of the state stack the current state .
remove all states from the state stack .
return regex and human readable expressions
send a federation query to a stellar federation service .
send a federation query to a stellar federation service .
retrieve the federation_server config from a domain 's stellar.toml .
retrieve the auth_server config from a domain 's stellar.toml .
retrieve the stellar.toml file from a given domain .
add an : class:`operation < stellar_base.operation . operation > ` to this transaction .
creates an xdr transaction object that represents this : class:`transaction ` .
packs and base64 encodes this : class:`transaction ` as an xdr string .
create a : class:`transaction ` object from a transaction xdr object .
helper function to make an app for this test module .
run a pytest.skip if either peewee or sqlalchemy are not installed .
ensure a bad backend produces the proper error .
ensure that if sqla and peewee are both installed we can specify .
"ensure that if both orms are installed and we do n't specify , we error out ."
ensure you can not swap backends on the fly .
ensure that each level can be logged .
ensure we can create an app with no frills .
ensure we 're passing kwargs in properly .
ensure it still works like flask .
fixture that provides a simple user model .
ensure that a model instance can be created sanely .
ensure that a model instance can be updated sanely .
ensure that a model can be fetched by id .
ensure that the i d portion of the data is removed when loaded .
ensure that the i d portion of the data is grabbed from the object .
returns a new suffix tree entity .
"returns a suffix tree entity , equipped with node and edge repos it ( at least at the moment ) needs ."
returns a set of ids for strings that contain the given substring .
returns an edge that matches the given substring .
gets or creates a log .
"returns none if test case class ends with ' testcase ' , which means the test case is n't included in the suite ."
sets up a connection to a datastore .
drops connection to a datastore .
sets up tables used to store events .
drops tables used to store events .
truncates tables used to store events .
simple event sourced attribute called ' foo ' .
"factory method , creates and returns a new aggregate1 root entity ."
"factory method , creates and returns a new aggregate1 root entity ."
initialize the parameters of the logistic regression
return the mean of the negative log - likelihood of the prediction of this model under a given target distribution .
return a float representing the number of errors in the minibatch over the total number of examples of the minibatch ; zero one loss over the size of the minibatch
: rng : sampling np for initialization
prints the last exception trace .
create the accepatble options for the test runner .
"get all test files from the passed test directory . if none is passed , use the default sdl test directory ."
loads a test .
creates a 8 bit grayscale color palette .
test det function
test det function with bad list
test det function with wrong dimensions
test det function with wrong size
test det function with non - container
test max function
test max function with bad list
test max function with non - container
test max function with wrong dimensions
test min function
test min function with bad list
test min function with wrong dimensions
test min function with non - container
test scale function
test scale function with wrong dimensions
test scale function with wrong size
test scale function with wrong type
test scale function with non - array
test floor function
test floor function with wrong dimensions
test floor function with wrong type
test floor function with non - array
test ceil function
test ceil function with wrong dimensions
test ceil function with wrong dimensions
test ceil function with non - array
test lusplit function
get version & version_info without importing markdown.__init _ _
build and return context to pass to template .
loads a given json file & returns it .
"given an existing set of endpoint data , this will deep - update it with any similarly structured data in the additions ."
actually load the region / endpoint information from the json files .
"given a service name ( like ` ` ec2 ` ` ) , returns a list of ` ` regioninfo ` ` objects for that service ."
connect to this region 's endpoint . returns an connection object pointing to the endpoint associated with this region . you may pass any of the arguments accepted by the connection class 's constructor as keyword arguments and they will be passed along to the connection object .
helper tests that assert basic sanity about the g4 tiff reading
test the ordinary file path load path
testing the string load path
testing the stringio loading code path
checking that we 're actually getting the data that we expect
checking that we 're actually getting the data that we expect
checking to see that the saved image is the same as what we wrote
test metadata writing through libtiff
tests string data in info directory
are we generating the same interpretation of the image as imagemagick is ?
"this test passes , but when running all tests causes a failure due to output on stderr from the error thrown by libtiff . we need to capture that but not now"
returns a string specifying the bundled version of pip .
bootstrap pip into the current python installation ( or the given root directory ) .
helper to support a clean default uninstall process on windows
patch l{forwarding . hostnameendpoint } to respond with a predefined answer for dns resolver requests .
fake that connection was established for first connecttcp request made on c{reactor } .
"when a hostname is sent as part of forwarding requests , it is resolved using hostnameendpoint 's resolver ."
convert inputs to arrays with at least one dimension .
view inputs as arrays with at least two dimensions .
view inputs as arrays with at least three dimensions .
stack arrays in sequence vertically ( row wise ) .
stack arrays in sequence horizontally ( column wise ) .
get the full name of the person
return the singleton searchengine instance for the process .
search backwards and return an re match object or none .
return tuple of ' line.col ' indexes from selection or insert mark .
"return ( line , col ) tuple of ints from ' line.col ' string ."
initialize variables that save search state .
set pattern after escaping if re .
return compiled cooked search pattern .
"return ( lineno , matchobj ) or none for forward / backward search ."
get all available regions for the amazon support service .
"check if the unicode string contains surrogate code points on a cpython platform with wide ( ucs-4 ) or narrow ( utf-16 ) unicode , i.e. characters that would be spelled as two separate code units on a narrow platform ."
"escape a byte string so that it can be written into c code . note that this returns a unicode string instead which , when encoded as iso-8859 - 1 , will result in the correct byte sequence being written ."
create py_unicode [ ] representation of a given unicode string .
fake - decode the byte string to unicode to support % formatting of unicode strings .
"subclasses should override this method to do a service call that will always succeed ( like fetch a list , even if it 's empty ) ."
"compare two sequences of log events , examining only the the keys which are present in both ."
test that c{beginloggingto ( ) } adds observers .
test that events are buffered until c{beginloggingto ( ) } is called .
"when invoked twice , l{logbeginner.beginloggingto } will emit a log message warning the user that they previously began logging , and add the new log observers ."
critical messages will be written as text to the error stream .
"once logging has begun with c{beginloggingto } , critical messages are no longer written to the output stream ."
l{logbeginner.beginloggingto } will re - direct the standard output and error streams by setting the c{stdio } and c{stderr } attributes on its sys module object .
l{logbeginner.beginloggingto } will leave the existing stdout / stderr in place if it has been told not to replace them .
"when l{logbeginner.beginloggingto } redirects stdout / stderr streams , the replacement streams will preserve the encoding of the replaced streams , to minimally disrupt any application relying on a specific encoding ."
l{logbeginner.beginloggingto } will redirect the warnings of its warnings module into the logging system .
test that the sasl error condition is correctly extracted .
test starting authentication with an initial response .
test starting authentication without an initial response .
test starting authentication where the initial response is empty .
test receiving a challenge message .
test receiving an empty challenge message .
test receiving a challenge message with illegal padding .
test receiving a challenge message with illegal characters .
test receiving a malformed challenge message .
set up the xml stream to have a sasl feature with the given mechanism .
test setting anonymous as the authentication mechanism .
test setting plain as the authentication mechanism .
test setting digest - md5 as the authentication mechanism .
test using an unacceptable sasl authentication mechanism .
test using an unacceptable sasl authentication mechanism with no jid .
ensure the deprecation of l{twisted.python.hashlib } is working .
l{hashlib.md5 } returns an object which can be used to compute an md5 hash as defined by u{rfc 1321 < http://www.ietf.org / rfc / rfc1321.txt > } .
l{hashlib.sha1 } returns an object which can be used to compute a sha1 hash as defined by u{rfc 3174 < http://tools.ietf.org / rfc / rfc3174.txt > } .
see : meth:` . columnoperators.__inv _ _ ` .
see : meth:` . columnoperators.__neg _ _ ` .
see : meth:` . columnoperators.match ` .
see : meth:` . columnoperators.distinct ` .
see : meth:` . columnoperators.between ` .
always returns a floating - point number .
"this instance is not callable , so we override the super method ."
"copied from zope 's dt_insv.py 's "" opt "" function ."
always returns a floating point number .
"returns list of ( $ r , $ a , $ b )"
get all available regions for the amazon simple workflow service .
export the hg repository at the url to the destination location
test that annotated clause constructs use the decorated class ' compiler .
change the working directory to the parent of the c{twisted } package so that l{twisted.python.dist.getextensions } finds twisted 's own extension definitions .
"if c{os.initgroups } is present ( python 2.7 and python 3.3 and newer ) , l{twisted.python._initgroups } is not returned as an extension to build from l{getextensions } ."
return true if this event key is registered to listen .
testing layermapping initialization .
test layermapping import of a simple point shapefile .
"testing the ` strict ` keyword , and import of a linestring shapefile ."
"testing the ` unique ` , and ` transform ` , geometry collection conversion , and foreignkey mappings ."
tests the ` fid_range ` keyword and the ` step ` keyword of .save ( ) .
tests layermapping on inherited models . see # 12093 .
tests layermapping on invalid geometries . see # 15378 .
tests that string content fits also in a textfield
test a layer containing utf-8 - encoded name
return true if the url belongs to any of the given domains
return true if the url belongs to the given spider
canonicalize the given url by applying the following procedures :
return urlparsed url from the given argument ( which could be an already parsed url )
return the crawleable url according to : http://code.google.com/web/ajaxcrawling/docs/getting-started.html
update statements via the orm flush process .
transform an opcode signature into rst nodes .
transform a pdb command signature into rst nodes .
test that the client and server protocol both have makeconnection invoked on them by loopbackasync .
test one of the permutations of client / server host / peer .
test that the server gets a transport with a properly functioning implementation of l{itransport.gethost } .
like c{test_serverhost } but for l{itransport.getpeer }
test that the client gets a transport with a properly functioning implementation of l{itransport.gethost } .
like c{test_clienthost } but for l{itransport.getpeer } .
test one of the permutations of write / writesequence client / server .
"test that on a connection where the client speaks first , the server receives the bytes sent by the client ."
"like c{test_clientgreeting } , but use c{writesequence } instead of c{write } to issue the greeting ."
"test that on a connection where the server speaks first , the client receives the bytes sent by the server ."
"like c{test_servergreeting } , but use c{writesequence } instead of c{write } to issue the greeting ."
test a push producer registered against a loopback transport .
test a pull producer registered against a loopback transport .
l{loopback.loopbackasync } does not call a protocol 's c{datareceived } method while that protocol 's transport 's c{write } method is higher up on the stack .
the callable passed as the value for the c{pumppolicy } parameter to l{loopbackasync } is called with a l{_loopbackqueue } of pending bytes and a protocol to which they should be delivered .
l{identitypumppolicy } is a pump policy which calls the target 's c{datareceived } method one for each string in the queue passed to it .
l{collapsingpumppolicy } is a pump policy which calls the target 's c{datareceived } only once with all of the strings in the queue passed to it joined together .
log the user out .
log the user in .
is the user logged in ?
the user that is logged in .
> > > obj = test_inside_lambda ( ) ( ) > > > next(obj ) 1 > > > next(obj ) 2 > > > try : next(obj ) ... except stopiteration : pass
try stuff known to be in the path
try under a well known directory not on the path
ensure cwd is on the path
ensure nocwd removes current dir from path
recursive attribute setting / getting on modules
recursive attribute setting / getting on drawings
test open and read of a simple relative file
test open and read of a relative file : url
test open and read of an http : url
test open and read of a simple relative file
test open and read of an rfc 2397 data uri with base64 encoding
test open and read of an rfc 2397 data uri without an encoding
check we get useful error messages
check mode='full ' futurewarning .
can be overridden to implement edge - caching
drop all the caches stored in this cache region
lazy access to a cacheitem
write some data to the serial device .
some data 's readable from serial device .
called when the serial port disconnects .
"> > > v1 , v2 , v3 = test_pxd_locals ( ) > > > isinstance(v1 , float ) true > > > isinstance(v2 , float ) true > > > v3 ( true , 0 )"
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
1 2 4
"i am a normal py file which must define a ' resource ' global , which should be an instance of ( a subclass of ) web.resource . resource ; it will be renderred ."
initialize me with a script name .
render me to a web client .
testing the size of the bucket .
testing the bucket 's drain rate .
l{htb . bucket.drip } returns c{true } if the bucket is empty after that drip .
ensure get on the add_view works .
ensure get on the add_view plus specifying a field value in the query string works .
ensure post on add_view works .
test that some admin urls work correctly .
"ensures that modeladmin.response_post_save_add ( ) controls the redirection after the ' save ' button has been pressed when adding a new object . refs 8001 , 18310 , 19505 ."
"ensures that modeladmin.response_post_save_change ( ) controls the redirection after the ' save ' button has been pressed when editing an existing object . refs 8001 , 18310 , 19505 ."
ensures that the modeladmin.response_add ( ) 's parameter ` post_url_continue ` controls the redirection after an object has been created .
"for backwards - compatibility , ensure that it 's possible to pass a requestcontext instance in the dictionary argument instead of the context_instance argument ."
is this child allowed in a drawing or group ? i.e. does it descend from shape or usernode ?
"override this . the renderers will pass the renderer , and the attribute name . algorithms can then backtrack up through all the stuff the renderer provides , including a correct stack of parent nodes ."
l{_errorformatter.formaterror } should use l{os.strerror } to format error messages if it is constructed without any better mechanism .
l{_errorformatter.formaterror } should use l{os.strerror } to format error messages if it is constructed with only an error tab which does not contain the error code it is called with .
l{_errorformatter.formaterror } should use c{errortab } if it is supplied and contains the requested error code .
l{_errorformatter.formaterror } should return the return value of c{formatmessage } if it is supplied .
"l{_errorformatter.formaterror } should return the message argument from the exception l{winerror } returns , if l{winerror } is supplied ."
l{_errorformatter.fromenvironment } should create an l{_errorformatter } instance with attributes populated from available modules .
"given an known - good errno , make sure that formatmessage gives results matching either c{socket.errortab } , c{ctypes . winerror } , or c{win32api . formatmessage } ."
"return the name of the version control backend if found at given location , e.g. vcs.get_backend_name('/path / to / vcs / checkout ' )"
prepare a location to receive a checkout / clone .
"return a string representing the requirement needed to redownload the files currently present in location , something like : { repository_url}@{revision}#egg={project_name}-{version_identifier } if find_tags is true , try to find a tag matching the revision"
"run a vcs subcommand this is simply a wrapper around call_subprocess that adds the vcs command name , and checks that the vcs is available"
> > > default_args ( ) true
execute the passed query against the passed model and check the output
compare the results of a raw query against expected results
check that the results of a raw query contain no annotations
check that the passed raw query results contain the expected annotations
basic test of raw query with a simple database query
raw queries are lazy : they are n't actually executed until they 're iterated over .
test of a simple raw query against a model containing a foreign key
test of a simple raw query against a model containing a field with db_column defined .
test of raw raw query 's tolerance for columns being returned in any order
test of raw query 's optional ability to translate unexpected result column names to specific model fields
test passing optional query parameters
test passing optional query parameters
test representation of raw query with parameters
test of a simple raw query against a model containing a m2 m field
test to insure that extra translations are ignored .
convert raw headers ( single multi - line string ) to the dictionary .
returns a raw http headers representation of headers
return ` authorization ` header for http basic access authentication ( rfc 2617 )
default literal block handler
default literal block handler
html document generator visit handler
latex document generator visit handler
latex document generator depart handler .
a copy of sphinx.directives . cmdoptiondesc.parse_signature ( )
run gdb and have cygdb import the debug information from the code defined in testparsetreetransforms 's setup method
normalize a description adding the platform byteorder .
check creation of 0 - dimensional objects
check creation of single - dimensional objects
check creation of multi - dimensional objects
check creation from tuples
check creation from list of tuples
check creation from list of list of tuples
check reading the top fields of a nested array
check reading the nested fields of a nested array ( 1st level )
check reading the nested fields of a nested array ( 2nd level )
check access nested descriptors of a nested array ( 1st level )
check access nested descriptors of a nested array ( 2nd level )
return an optimized visit dispatch function for the cls for use by the compiler .
"traverse the given expression structure , returning an iterator ."
"traverse the given expression structure , returning an iterator ."
visit the given expression structure using the given iterator of objects .
traverse and visit the given expression structure using the default iterator .
traverse and visit the given expression structure using the depth - first iterator .
"clone the given expression structure , allowing modifications by visitors ."
"clone the given expression structure , allowing element replacement by a given replacement function ."
"traverse the given expression structure , returning an iterator of all elements ."
traverse and visit the given expression structure .
iterate through this visitor and each ' chained ' visitor .
' chain ' an additional clausevisitor onto this clausevisitor .
"apply cloned traversal to the given list of elements , and return the new list ."
traverse and visit the given expression structure .
receive pre - copied elements during a cloning traversal .
traverse and visit the given expression structure .
load person objects on a range of names .
produce a new tag for testing .
l{tag.fillslots } returns self .
"l{tag.clone } copies all attributes and children of a tag , including its render attribute . if the shallow flag is c{false } , that 's where it stops ."
"l{tag.clone } copies all attributes and children of a tag , including its render attribute . in its normal operating mode ( where the deep flag is c{true } , as is the default ) , it will clone all sub - lists and sub - tags ."
"l{tag.clear } removes all children from a tag , but leaves its attributes in place ."
l{tag.__call _ _ } accepts python keywords with a suffixed underscore as the dom attribute of that literal suffix .
l{comment.__repr _ _ } returns a value which makes it easy to see what 's in the comment .
l{cdata.__repr _ _ } returns a value which makes it easy to see what 's in the comment .
l{charref.__repr _ _ } returns a value which makes it easy to see what character is referred to .
adapted version of twisted.web.client.getpage
"l{client._parse } should return c{str } for the scheme , host , and path elements of its return tuple , even when passed an url which has previously been passed to l{urlparse } as a c{unicode } string ."
l{client.getpage } returns a l{deferred } which is called back with the body of the response if the default method b{get } is used .
l{client.getpage } returns a l{deferred } which is called back with the empty string if the method is c{head } and there is a successful response code .
"when a non - zero timeout is passed to l{getpage } and the page is retrieved before the timeout period elapses , the l{deferred } is called back with the contents of the page ."
when a non - zero timeout is passed to l{getpage } and that many seconds elapse before the server responds to the request . the l{deferred } is errbacked with a l{error . timeouterror } .
# 7027 -- _ ( ) syntax should work with spaces
retrieve information about installed version of postgresql .
return the c compiler used for building the extension .
set final values for all build_pg options .
"check that function(value ) equals output . if output is none , check that function(value ) equals value ."
permissions and content types are not created for a swapped model
model names are case insensitive . check that model swapping honors this .
"encode the given data to be used in a multipart http post . data is a where keys are the field name , and values are either strings or tuples ( filename , content ) for file uploads ."
"# 24377 - if we 're adding a new object , a parent 's auto - generated pk from the model field default should be ignored as it 's regenerated on the save request ."
# 24377 - inlines with a model field default should ignore that default value to avoid triggering validation on empty forms .
returns a dict mapping code names to widgets
returns sorted list of supported bar code names
this creates and returns a drawing with a barcode .
"this creates and returns barcode as an image in memory . takes same arguments as createbarcodedrawing and also an optional format keyword which can be anything acceptable to drawing.asstring eg gif , pdf , tiff , py ......"
callable to generate a fake valueerror
callable to generate a fake jsondecodeerror
add the file / string fp to the destinations
remove the file / string fp from the destinations
write text to all the destinations
waveformatex attribute access
dscaps attribute access
dsbcaps attribute access
dsccaps attribute access
dscbcaps attribute access
dsbufferdesc attribute access
dsbufferdesc invalid lpwfxformat assignment
dscbufferdesc attribute access
dscbufferdesc invalid lpwfxformat assignment
directsoundenumerate ( ) sanity tests
directsoundcreate ( )
"mesdames et messieurs , la cour de devin dazzle"
directsoundcaptureenumerate ( ) sanity tests
directsoundcreate ( )
"check that the shortcut view ( used for the admin "" view on site "" functionality ) returns a complete url regardless of whether the sites framework is installed"
ensures that displaying content types in admin ( or anywhere ) does n't break on leftover content type records in the db for which no model is defined anymore .
"contenttype.name has been removed . test that a warning is emitted when creating a contenttype with a ` name ` , but the creation should not fail ."
check that ` runtimeerror ` with nice error message is raised if ` get_for_model ` fails because of database errors .
ensure a warning is raised upon class definition to suggest renaming the faulty method .
ensure ` old ` complains and not ` new ` when only ` new ` is defined .
ensure ` old ` complains when only ` old ` is defined .
ensure the correct warnings are raised when a class that did n't rename ` old ` subclass one that did .
ensure the correct warnings are raised when a class that renamed ` old ` subclass one that did n't .
ensure the correct warnings are raised when a subclass inherit from a class that renamed ` old ` and mixins that may or may not have renamed ` new ` .
ensure the correct warning is raised when wsgirequest . request is accessed .
ensure the correct warning is raised when memoize is used .
ensure the correct warning is raised when simpletestcase.urls is used .
regression test for # 10153 : foreign key _ _ gte lookups .
regression test for # 10153 : foreign key _ _ lte lookups .
regression test for # 14019 : sqlinsertcompiler.as_sql ( ) failure
regression for # 18432 : chained foreign keys with to_field produce incorrect query
ensures that you can filter by objects that have an ' evaluate ' attr
verify if the python version is returned correctly .
l{platform.isknown } returns a boolean indicating whether this is one of the l{runtime.knownplatforms } .
verify consistency of l{platform.isvista } : it can only be c{true } if l{platform.iswinnt } and l{platform.iswindows } are c{true } .
l{platform.ismacosx } can only return c{true } if l{platform.gettype } returns c{'posix ' } .
"l{platform.islinux } can only return c{true } if l{platform.gettype } returns c{'posix ' } and l{sys.platform } starts with c{""linux "" } ."
"l{platform.iswinnt } can return only c{false } or c{true } and can not return c{true } if l{platform.gettype } is not c{""win32 "" } ."
l{platform.iswinnt } is deprecated in favor of l{platform.iswindows } .
"l{platform.supportsthreads } returns c{true } if threads can be created in this runtime , c{false } otherwise ."
"if an operating system name is supplied to l{platform } 's initializer , l{platform.gettype } returns the platform type which corresponds to that name ."
"if a system platform name is supplied to l{platform } 's initializer , it is used to determine the result of l{platform.ismacosx } , which returns c{true } for c{""darwin "" } , c{false } otherwise ."
"if a system platform name is supplied to l{platform } 's initializer , it is used to determine the result of l{platform.islinux } , which returns c{true } for values beginning with c{""linux "" } , c{false } otherwise ."
test that ' literal binds ' mode works - no bound params .
l{jstrports.parse } accepts an endpoint description string and returns a tuple and dict of parsed endpoint arguments .
l{jstrports.client } returns a l{tcpclient } service .
return the section headers of the config file .
return the list of variable names .
make an ndarray from the given array with the given shape and strides .
broadcast any number of arrays against each other .
"compute the screen location at which a sample value would be drawn . ` ` size ` ` is the width or height of the chart , in points . ` ` val ` ` is the sample value . ` ` min ` ` and ` ` max ` ` are the minimum and maximum sample values that are to be displayed over the length of ` ` size ` ` ."
generate the list of places for drawing tick marks .
compute the min / max values to be displayed in the chart . parameters ` ` min ` ` and ` ` max ` ` are the minimum and maximum values of the sample data passed to the plots . parameter ` ` interval ` ` is the value of attribute area . t.x_grid_interval ( or y_grid_interval ) . it is none if these attributes are non - specified .
run one iteration of a simple decision engine
run one iteration of a simple worker engine
get a dictionary with setup keywords that ( can ) have side effects .
"make sure i say "" when . """
make sure i resumeproducing when my buffer empties .
test that gen_filenames ( ) also yields the built - in django locale files .
test that gen_filenames also yields from locale_paths locales .
test that gen_filenames also yields from the current directory ( project root ) .
test that gen_filenames also yields from locale dirs in installed apps .
"if i18n machinery is disabled , there is no need for watching the locale files ."
"when calling a second time gen_filenames with only_new = true , only files from newly loaded modules should be given ."
method called when a position is received .
method called when position error is received .
method called when time and date information arrives .
method called when a true heading is received .
method called when an altitude is received .
method called when the speed is received .
method called when the climb is received .
method called when positioning beacon information is received .
method called when a sentence is received .
"look for column objects with type info in them , and work up a lookup table ."
chr(x ) if 0 < x < 128 ; unicode(x ) if x > 127 .
"testfiles can be none , in which case the command line arguments are used as filenames . testfiles can be a string , in which case that file is parsed . testfiles can be a list . in all cases , the filenames will be globbed . if more than one file is parsed successfully , a dictionary of parseresults is returned . otherwise , a simple parseresults is returned ."
"determine whether an event should be logged , based on the result of c{predicates } ."
determine whether an event should be logged .
@param observer : an observer to which this observer will forward events when c{predictates } yield a positive result . @type observer : l{ilogobserver }
forward to next observer if predicate allows it .
@param defaultloglevel : the default minimum log level . @type defaultloglevel : l{loglevel }
determine an appropriate log level for the given namespace .
sets the log level for a logging namespace .
clears all log levels to the default .
"given a path ( mapper a , prop x ) , replace the prop with the wildcard , e.g. ( mapper a , ' relationship : . * ' ) or ( mapper a , ' column : . * ' ) , then return within the ( "" loader "" , path ) structure ."
"assert that a root element , when flattened , is equal to a string ."
"assert that a root element , when flattened , is equal to a string , and performs no asynchronus deferred anything ."
assert flattening a root element raises a particular exception .
use this decorator to disable test on specified backend .
create a logger for test l{loggingfile } instances to use .
l{loggingfile.softspace } is 0 .
some l{loggingfile } attributes are read - only .
some l{loggingfile } methods are unsupported .
default level is l{loglevel.info } if not set .
default encoding is c{sys.getdefaultencoding ( ) } if not set .
"reported mode is c{""w "" } ."
the c{newlines } attribute is c{none } .
the c{name } attribute is fixed .
l{loggingfile.close } closes the file .
l{loggingfile.flush } does nothing .
l{loggingfile.fileno } returns c{-1 } .
l{loggingfile.isatty } returns c{false } .
writing buffers correctly .
bytes are decoded to unicode .
unicode is unmodified .
log level is emitted properly .
"log format is c{u""{message } "" } ."
c{writelines } does not add newlines .
l{loggingfile } can replace l{sys.stdout } .
construct a l{loggingfile } with a built - in observer .
regression test for # 7512
for a affine 2d represented as 6vec return 6vec version of a**(-1 )
a postmultiplied by b
"used to compute when we need to change the graphics state . for example , if we have two adjacent red shapes we do n't need to set the pen color to red in between . returns the effect the given shape would have on the graphics state"
"take a new state dictionary of changes and push it onto the stack . after doing this , the combined state is accessible through getstate ( )"
"steps back one , and returns a state dictionary with the deltas to reverse out of wherever you are . depending on your back end , you may not need the return value , since you can get the complete state afterwards with getstate ( )"
returns the complete graphics state at this point
returns the current transformation matrix at this point
returns the complete graphics state value of key at this point
sets the complete graphics state value of key to value
"this is the top level function , which draws the drawing at the given location . the recursive part is handled by drawnode ."
this is the recursive method called for each node in the tree
return current state parameter for given key
"examine a node for any values which are derived , and replace them with their calculated values . generally things may look at the drawing or their parent ."
dispatch on the node 's ( super ) class : shared code
"this takes a set of states , and outputs the operators needed to set those properties"
test reportlab.lib.boxstuff.normalizepadding .
> > > test_sizeof ( ) true true true true true
"> > > test_declare(100 ) ( 100 , 100 ) > > > test_declare(100.5 ) ( 100 , 100 ) > > > test_declare(none ) # doctest : + ellipsis traceback ( most recent call last ): ... typeerror : ..."
> > > test_cast(1.5 ) 1
> > > test_address(39 ) 39
"> > > raised = [ ] > > > class nogil(object ): ... def _ _ enter__(self ): ... pass ... def _ _ exit__(self , exc_class , exc , tb ): ... raised.append(exc ) ... return exc_class is none"
"> > > test_struct(389 , 1.64493 ) ( 389 , 1.64493 )"
"> > > test_imports ( ) ( true , true )"
> > > test_declare_c_types(0 ) > > > test_declare_c_types(1 ) > > > test_declare_c_types(2 )
test that a declared return type is honoured when compiled .
"> > > result , return_type = call_cdef_inline(1 ) > > > ( not is_compiled and ' float ' ) or type(return_type).__name _ _ ' float ' > > > ( not is_compiled and ' double ' ) or return_type ' double ' > > > ( is_compiled and ' int ' ) or return_type ' int ' > > > result = = 2.0 or result true"
"> > > digits = ' 37692837651902834128342341 ' > > > '' .join(sorted(digits ) ) ' 01112222333334445667788899 ' > > > count_digits_in_carray(map(int , digits ) ) [ 1 , 3 , 4 , 5 , 3 , 1 , 2 , 2 , 3 , 2 ]"
pto stands for please turn over and is a means for specifying content to be inserted when stuff goes over a page . this makes one long multi - page paragraph .
test rotated image shape adding it to a pdf page .
test convert a greyscale bitmap file as image shape into a tmp . pdf file .
"# 16770 -- the template system does n't wrap exceptions , but annotates them ."
# 7876 -- error messages should include the unexpected block name .
# 18169 -- noreversematch should not be silence in block.super .
# 23060 -- test non - ascii model representation in debug output .
# 24338 -- allow extending django.template.backends.django . template objects .
get all available regions for the amazon cognito identity service .
"when the redirect target is '' , return a 410"
"configure the exporter by poping options from the ` ` options ` ` dict . if dont_fail is set , it wo n't raise an exception on unexpected options ( useful for using with keyword arguments in subclasses constructors )"
"return the fields to export as an iterable of tuples ( name , serialized_value )"
> > > c = closure_func(2 ) > > > c ( ) 2
> > > for i in generator_func ( ): print(i ) 1 2
test the echo flag 's independence to a specific engine .
executing the changepassword management command with a database option should operate on the specified db
createsuperuser command should operate on specified db
l{error . connectingcancellederror } has an c{address } attribute .
l{error . connectionclosed } is a superclass of l{error . connectionlost } .
l{error . connectionclosed } is a superclass of l{error . connectiondone } .
l{valueerror } is a superclass of l{error . invalidaddresserror } .
"when called with a tuple with the given errno , l{error.getconnecterror } returns an exception which is an instance of the expected class ."
"the given result of l{error.getconnecterror } has the given attributes ( c{oserror } and c{args } ) , and is an instance of the given class ."
l{error.getconnecterror } converts based on errno for c{socket.error } .
l{error.getconnecterror } converts to a l{error . unknownhosterror } given a c{socket.gaierror } instance .
l{error.getconnecterror } converts to a l{error . connecterror } given an argument that can not be unpacked .
a fake of l{resource.getrlimit } which returns a pre - determined result .
"fake os.getpid , always return the same thing"
"fake os.listdir , depending on what mode we 're in to simulate behaviour ."
this is a mock for l{open } . it keeps track of opened files so extra descriptors can be returned from the mock for l{os.listdir } when used on one of the list - of - filedescriptors directories .
make the l{resource } module unimportable for the remainder of the current test method .
make a l{fakeresourcemodule } instance importable at the l{resource } name .
restore the original resource module to l{sys.modules } .
"set up the tests , giving ourselves a detector object to play with and setting up its testable knobs to refer to our mocked versions ."
l{fddetector._getimplementation } returns the first method from its c{_implementations } list which returns results which reflect a newly opened file descriptor .
l{fddetector._getimplementation } returns the last method from its c{_implementations } list if none of the implementations manage to return results which reflect a newly opened file descriptor .
"check that the identity of _ listopenfds changes after running _ listopenfds the first time , but not after the second time it 's run ."
"l{_fddetector._devfdimplementation } raises l{oserror } if there is no i{/dev / fd } directory , otherwise it returns the basenames of its children interpreted as integers ."
"l{_fddetector._procfdimplementation } raises l{oserror } if there is no i{/proc/<pid>/fd } directory , otherwise it returns the basenames of its children interpreted as integers ."
"l{_fddetector._fallbackfdimplementation } uses the l{resource } module if it is available , returning a range of integers from 0 to the minimum of c{1024 } and the hard i{nofile } limit ."
"l{_fddetector._fallbackfdimplementation } , the implementation of last resort , succeeds with a fixed range of integers from 0 to 1024 when the l{resource } module is not importable ."
file descriptors returned by l{_listopenfds } are mostly open .
l{_listopenfds } lists expected file descriptors .
returns a string containing the xml version of the lifecycle configuration as defined by s3 .
"add a rule to this lifecycle configuration . this only adds the rule to the local copy . to install the new rule(s ) on the bucket , you need to pass this lifecycle config object to the configure_lifecycle method of the bucket object ."
decorator for registering view functions and adding templates to it .
build a url
"if the test label is empty , discovery should happen on the current working directory ."
"when given a dotted path to a module , unittest discovery searches not just the module , but also the directory containing the module ."
tests should n't be discovered twice when discovering on overlapping paths .
reverse should reorder tests while maintaining the grouping specified by ` ` discoverrunner.reorder_by ` ` .
convert two integers to a string for the date and time .
the raw data - file uses usaf - codes to identify weather - stations . if you download another data - set from ncdc then you will have to change this function to use the usaf - codes in your new data - file .
"this converts a raw data - file obtained from the ncdc database . this function may be useful as an inspiration if you want to download another raw data - file from ncdc , but you will have to modify this function to match the data you have downloaded ."
"resample the contents of a pandas data - frame by first removing empty rows and columns , then up - sampling and interpolating the data for 1 - minute intervals , and finally down - sampling to 60 - minute intervals ."
download and extract the weather - data if the data - files do n't already exist in the data_dir .
load and return the original data that has not been resampled .
load and return the resampled weather - data .
hidden is composed of z and c
add the black color in front of ' name ' color
plot a classification map using matplotlib .
display a classification map using matplotlib .
process the s06av95a_envi file and extract the < substance > and/or < sample > features according to the < baseline > value .
"normalizes m to be in range [ 0 , 1 ] ."
plot an abundance map using matplotlib
performs unconstrained least squares abundance estimation on the hsi cube m using the spectral library u.
nnls performs non - negative constrained least squares of each pixel in m using the endmember signatures of u.
performs fully constrained least squares of each pixel in m using the endmember signatures of u.
center a hyperspectral image to the mean and component wise scale to unit variance .
receive as input a hypercubes list and the corresponding masks list . the function reshape and concatenate both to create the x and y arrays .
return string containing the contents of the file at * relpath * relative to this file .
parse command line arguments : return namespace : parsed arguments
runs scripts which match name_patten in path : param str path : : param str name_pattern :
do the specified action
formats a query suitable to send to the arxiv api
produces an url for the zbl identifier
"to create an instance , pass a clarity results url for the top - level political jurisdiction ( a state , for example ) , and the corresponding level in lowercase ( "" state "" or "" county "" ) ."
"returns a list of subjurisdictions depending on the level of the main jurisdiction . states always have counties , and counties and cities may have precincts ."
"the parsed version of the original url is used by several methods , so we assign it to self.parsed_url on init . if url has "" /web01/ "" segment , that gets stripped out ."
returns the two - digit state abbreviation from the url .
"returns a url for the county detail page , which lists urls for each of the counties in a state . if original jurisdiction is not a state , returns none ."
parse subjurisdictions_url to find paths for counties .
returns base url used by _ subjurisdiction_url .
checks county page for redirect path segment and returns it . there are two types of pages : one with segment in meta tag and the other with segment in script tag .
"returns link to detailed report depending on format . formats are xls , txt and xml ."
returns the summary report url for a jurisdiction .
use special form during user creation
determines the httpresponse for the add_view stage . it mostly defers to its superclass implementation but is customized because the user model has a slightly different workflow .
"create new instance of edge(id , start_node , end_node , cost , reverse_cost , reversed )"
create a new edge which is reverse to self .
"test if it is the same edge with the other . while comparing costs , if their difference is under the precision , then they are considered as the same edge ."
returns an appropriate python object for an imported value .
returns an export representation of a python value .
returns a queryset of all objects for this model .
returns the httprequest object for this thread
configuration method . this is called during the start - up of ptpython .
initialize the logger .
write a message to the log at the specified level
log the message at info level .
log the message at error level .
"runs a program , and it 's paramters ( e.g. rcmd=""ls -lh /var / www "" ) returns output if successful , or none and logs error if not ."
"takes an s3 style acl and returns a list of header / value pairs that implement that acl in swift , or "" notimplemented "" if there is n't a way to do that yet ."
handle the x - amz - acl header . note that this header currently used for only normal - acl ( not implemented ) on s3acl . todo : add translation to swift acl like as x - container - read to s3acl
return an argparse option parser for this application .
get current object . this is useful if you want the real object behind the proxy at a time for performance reasons or because you want to pass the object into a different context .
find the position of an item . raise valueerror if not found . '
return number of occurrences of item '
"insert a new item . if equal keys are found , add to the left '"
remove first occurrence of item . raise valueerror if not found '
creates the cursor string from an offset .
rederives the offset from the cursor string .
"given an optional cursor and a default offset , returns the offset to use ; if the cursor contains a valid offset , that will be used , otherwise it will be the default ."
this event handler is a fix for the fact that the row selection in the wxgrid is deliberately broken . it 's also used to activate and deactivate relevant menubar items .
appends the slice grid commands to a menu . this can be used to build up the context menu or the drop - down one .
attempt to convert colourstring into tuple representation .
method required by columnsortermixin .
used by the columnsortermixin .
"update embedded rwi , i.e. update the image ."
performs the required transformation to match the image to the world coordinate system defined by medmeta
reflow the line s indented depth tabs .
generates a non - cryptographically secure int on the bell curve within the 1 - 6 range inclusive . ( ) - > int
generates a non - cryptographically secure int on the bell curve within the 2 - 12 range inclusive . ( ) - > int
"note : this is untested ! ! ! takes a dict of an instance , an attribute to modify , a key in that attribute , and an optional value . creates the key , value pair with a default if key does not exist ."
takes a file of one list item per line . returns a list of those items . removes whitespace and blank lines .
takes a file of one set of items per line . the first item must be an int > 0 . the rest of the line will be appended to the list as a string . returns that list .
returns a random item from the list .
modifies existing list with the modified value at index .
returns an int between 1 and 15 inclusive .
generates the introspection xml for an object path or partial object path that matches exported objects .
parses the supplied introspection xml string and returns a list of l{interface . dbusinerface } instances representing the xml interface definitions .
save state variables .
restore state variables .
reset internal state to initial values .
set up projection transformations .
tear down projection transformations .
switch back to perspective projection .
"center orthographic projection box on ( 0 , 0 , 0 ) ."
: type name : str : rtype : templatelisting
"@param name can be the full name e.g. node.ssh or a rule but then use e.g. node . * ( are regexes , so need to use . * at end ) @param state new ok error disabled"
"@param name can be the full name e.g. node.ssh or a rule but then use e.g. node . * ( are regexes , so need to use . * at end ) @param state new ok error disabled"
: type action_name : str : type actor : str : type key : str : type logs : list[log ] : type service_key : str : type service_name : str : type state : str : rtype : job
generate a dict that represent a service from a service object
generate a dict that represent a run
generate a dict that represent a service from a service object
tests auto bahavior
"@param name can be the full name e.g. myappserver or a prefix but then use e.g. myapp . * @param actor can be the full name e.g. node.ssh or role e.g. node . * ( but then need to use the . * extension , which will match roles ) @param parent is in form $ actorname!$instance @param producer is in form $ actorname!$instance"
"@param name can be the full name e.g. myappserver or a prefix but then use e.g. myapp . * @param actor can be the full name e.g. node.ssh or role e.g. node . * ( but then need to use the . * extension , which will match roles ) @param parent is in form $ actorname!$instance @param producer is in form $ actorname!$instance"
takes in a flat services dict and outputs a structured tree to be rendered by bootstrap - treeview .
: type name : str : type role : str : rtype : servicepointer
recursive fastmap clustering .
read comma - seperated rows that might be split over many lines . finds strings that can compile to nums . kills comments and white space .
leaps over any columns marked ' skip ' .
discrete independent variables
"have the changes been implemented ? """
map the usage of the ancestor field in gaemodel
this should probably be seperated from the class definitions
parse command - line arguments . note that the input and output directories are positional arguments
returns last exception as a string
"processes the input stream , assuming show - coords output , with five header lines , and whitespace separation ."
"render an svg file into paths , and then plot them with matplotlib ."
"render an svg file into linear segments , and then plot them with matplotlib ."
creates a new root document . all inputs have to be strings .
creates a new simulation .
creates new filename . required for some elements .
creates a new metfile .
creates a new clock .
creates a new summary file .
"creates a new area , or paddock ."
creates a new folder .
creates a new soil .
creates a new managment rule shortcut to name .
creates a new surface organic matter .
creates a new fertiliser .
creates a new irrigation .
creates a new crop .
creates a new outputfile .
creates a new tracker .
creates a new graph .
generates pretty apsim xml and saves file .
make a dictionary structure for the values in the registry
looks up which ( mosaic ) actions are associated to a certain z3c widget .
calculate the annuity .
create an energy system and optimize the dispatch at least costs .
grid for custom transform .
the function to predict .
returns a random string of up to 9 characters .
return axisinfo instance for x and unit
return the default unit for x or none
pretty printer for first n digits of a fraction
writes first n base - digits of a mpmath function to file
simple function to interact with user
a non - interactive runner
display a correct numeric colorbar for a shaded plot .
use a custom norm to control the displayed z - range of a shaded plot .
demonstrates displaying different variables through shade and color .
return the label for time x at position pos
create the root folder of a new project with the given name .
create required subfolders in the given folder .
translate the attribute string to dictionary
calculate one of the shortest cycles which includes the node v.
return the angle between the two points in the range between 0 and 2 * pi .
the amount one needs to rotate from angle a1 to angle a2 in a clockwise direction . i.e. increasing a1 until it reaches a2 .
sends a message and piggybacks a file descriptor through a unix domain socket .
receive a message and a file descriptor from a unix domain socket .
scales the input signal from current 4 - 20 ma to the human readable measurements . : param raw_in : current value . : param scaling : scaling constants . : return : signal value .
scales the input signal from human readable measurements to current 4 - 20 ma. : param scale_in : signal value . : param scaling : scaling constants . : return : current value .
copy treebuilders from the given module into this module .
register a treebuilder based on its advertised features .
might a tag with this name be an empty - element tag ?
wrap an html fragment to make it look like a document .
"replaces class=""foo bar "" with class=[""foo "" , "" bar "" ]"
check that tk is installed and available .
"generate proper events to click at the x , y position ( tries to act like an x server ) ."
create a regular polygon
create the coordinates of the regular polygon specified
: param num_rrs : the number of route reflectors in the cluster .
set up the route reflector clusters when entering context . : return : self .
tear down the route reflector hosts when exiting context . : return : none
pop a route reflector off the stack and clean it up .
return a redundancy group to use . this iterates through redundancy groups each invocation . : return : a list of rrs in the redundancy group .
return a list with tuples containing all gap positions and length . seq is a string .
infer splicing sites from a fasta file full of est sequences
a list ( input_list ) is saved in a file ( file_name )
returns a unique i d of the nodeset
register a command to the nodeset
get list of node host names may return empty list if node set is not allocated yet
create a nodeset possibly with asked properties
submit the nodeset request to nodepool return false if error happened
return status of node set
return the hosts that comprise this nodepool
run node set workers .
free a node set
cleans up all nodesets
"delete a job , given it 's i d"
check if job can run by looking at any user / job limits
update information about the workers started by this nodepool .
return the account string for this job
need to be explained .
generic function to get a specific parameter
generic function to get all parameters
generic function to set a specific parameter
get root name
get device uuid
get device status
get device model
get device manufacturer
get serial number of the device .
get asset tag of the device .
get sku number of the device .
get part number of the device .
resets provider instance to default state .
returns authentication credentials if any .
sets authentication credentials .
applies authentication routines on further request . mostly used to set right ` authorization ` header or cookies to pass the challenge .
updates provider routines from the http response data .
wraps request coroutine function to apply the authentication context .
resets provider instance to default state .
returns authentication credentials .
sets authentication credentials .
adds basicauth header to ` ` headers ` ` .
resets provider instance to default state .
"adds cookies to provided ` ` headers ` ` . if ` ` headers ` ` already contains any cookies , they would be merged with instance ones ."
updates cookies from the response .
resets provider instance to default state .
returns oauth credentials .
"sets oauth credentials . currently , all keyword arguments are required for successful auth ."
adds oauth1 signature to ` ` headers ` ` .
"returns three - element tuple of defined username , roles and secret ."
sets proxyauth credentials .
adds proxyauth credentials to ` ` headers ` ` .
raises : exc:`aiohttp.errors . httperrorexception ` exception in case of ` ` > = 400 ` ` response status code .
returns username .
helper method over : meth:`aiocouchdb.v1.document . document.update ` to change a user password .
helper method over : meth:`aiocouchdb.v1.document . document.update ` to change a user password .
checks each keyword from the keyword table to the fields of the comment . returns true if a keyword matches . otherwise returns false .
connects to akismet and returns true if akismet marks this comment as spam . otherwise returns false .
determine whether a given comment is allowed to be posted on a given object .
"determine whether a given comment on a given object should be allowed to show up immediately , or should be marked non - public and await approval ."
"метод создаёт папки , принимает параметры для работы c различными типами капчи . : param rucaptcha_key : ключ от сайта rucaptcha : param service_type : url с которым будет работать программа , возможен вариант "" 2captcha""(стандартный ) и "" rucaptcha "" : param recaptchavoice : передать true , если передаваемая капча является recaptcha : param solveaudio : передать true , если передаваемая капча является solvemedia : param sleep_time : время ожидания решения капчи"
"метод полчает параметры и аозвращает решение капчи . передаётся лишь один из параметров , либо audio_name либо audio_download_link . : param audio_name : передаётся имя файла который должен лежать в папке с названием "" mediacaptcha_audio "" , рядом со скриптом . : param audio_download_link : передаётся ссылка для скачивания аудио файла . не ссылка на капчу или ещё что - либо . а именно ссылка по которой можно скачать аудио файл . для последующей отправке rucaptcha . : return : возвращает решение капчи ."
inject into root .
from_string(s ) - convert string of chars into string of scancodes .
this methods return list of already allocated networks .
start method is called every time you want to boot up node
"if you add main_field__secondary_field , main_field should also be in the set ."
override of the default to_representation .
save whatever python object to a pickled file .
read a pickled file .
"try to get the date that a file was created , falling back to when it was last modified if that 's not possible ."
class has already been created ... register
our version ignores emptypage .
start a bunch of servers for blob testing .
deprecated . do n't bother with this .
add a randomly initialized set of weights / biases to the wb class . it is initialized with mean 0 and variance 0.1
recursively copy a directory tree .
decorator which will raise an apierror for api calls
mock api with canned responses
test specifying shape information when constructing a variable
this is a special case that results in shape inference failure after moving simple_bind logic from frontend to backend . added here for testing against the network similar to the following one .
phy_slot / phy_subslot / phy_port : xpi.xci
the parser rensponsible for resolving the command line arguments set by the user .
"handles all the methods to import ixp related information from peeringdb .json files . input : a ) reserved_tree : the subnettree containing the reserved subnets . b ) country2cc : a dictionary with { country}=country code . output : a ) sub2names : a dictionary with { ixp subnet}=[ixp long name , ixp short name ] . b ) ip2asn : a dictionary with { ixp ip}=[asn ] . c ) ixp_to_names : a dictionary with { ixp ip}=[ixp long name , ixp short name ] . d ) subnet2region : a dictionary with { ixp subnet}=[ixp country , ixp city ] ."
imports .json files from peeringdb and returns a list of dictionaries with all the retrieved ixp information . input : a ) filename : a .json file name . b ) mypath : the directory path of the database . c ) option : flag to download the file . d ) config : dictionary that contains the config file . ouput : a ) a list of dictionaries .
extracts a json table and returns a key - to - key dictionary to bind the ix.json with the ixpfx.json via the ixlan.csv file . input : a ) json_ixlan : a json table with ixlan and ix ids . ouput : a ) ixlan_dict : a dictionary with { ixlan key}=ix key .
"extracts the ixp id - to - ixp names from the ix.json file . input : a ) json_names : a json table with ix ids and the ixp long and short names . b ) country2cc : country to country code dictionary . output : a ) names_dict : a dictionary with { ix id}=[ixp long name , ixp short name ] . b ) region_dict : a dictionary with { ix id}=[ixp country , ixp city ] ."
"extracts the prefixes from ixpfxs : input : a ) json_pfx : a json table containing the ixp prefixes and ids to ixlan . b ) ixlan_dict : a dictionary with { ixlan id}=[ix i d ] to bind ixp prefixes and ixp names . c ) id_to_names : a dictionary with { ix id}=[ixp long name , ixp short name ] d ) reserved_tree : the subnettree containing the reserved subnets . e ) region_dict : a dictionary with { ix id}=[ixp country , ixp city ] . output : a ) pfxs_dict : a dictionary with { ixp subnet}=[ixp long name , ixp short name ] . b ) temp_subnet_tree : a subnet tree with ixp subnet - to - ix i d. c ) subnet2region : a dictionary with { ixp subnet}=[ixp country , ixp city ] ."
"extracts the ixp ips from peeringdb . input : a ) json_ip : a json table containing ixp ips , ixp short names and ixp ids . b ) temp_subnet_tree : the subnet tree containing the ixp subnets from peeringdb . c ) reserved_tree : the subnettree containing the reserved subnets . output : a ) ixp_to_asn : a dictionary with { ixp ip}=[asn ] ."
get an oauth signature to be used in signing a request
parse the json response body .
"finds all .scss files that are in a scss folder in all staticfiles search locations , and returns a list of html < link > tags that contain references to those .scss files ready for consumption by e.g. django - compressor ."
test if block is a margin note
convert markdown to margin notes
compare rpm component version ' a ' with ' b ' . ' name ' is implied equal as it is the key ( ) lookup
find the component lists from each worker build .
run the plugin .
run the plugin .
run the plugin .
": param tasker : dockertasker instance : param workflow : dockerbuildworkflow instance : param load_exported_image : bool , when running squash plugin with ` dont_load = true ` , you may load the exported tar with this switch"
run the plugin
run the plugin
create user interface of tray icon
exit program in a clean way .
returns the last n lines of a file .
reads the line of a log file that has the chosen stack_level
restoring the saved command from stack to the arguments object
"rebuilds command string , logs it for --resume future requests and parses it ."
fills all the context configuration variables from the command line and retrieves the needed remote information
parses the args array to create an args object storing the defaults and user - given values . it also sets the output directory and the log files .
fills the part of the context that needs to be retrieved from the remote server . creates a connection to the api and manages the requests that retrive the resource ids to be used . transforms arguments from the command - line - friendly format to the required structure .
constructor that extracts the command from the file
logging the resumed command in the sessions_log file
builds a generator from a csv file
returns a list of headers with the new extended field names for each objective label
receives a comma - separated list of fields given by name or column number and returns column number list
starts a new csv reader object
iterator method for next item
"returns the next row . if extended is true , the row is extended with a list of booleans depending on whether the label is in the objective field value or not . if reset is true , the file is reopened and pointer starts at the beginning of the file ."
returns the number of rows in the test file
returns whether the training set file has a headers row
returns the list of labels in the multi - label fields
returns the list of labels in a multi - label field
"returns headers . if objective_field is false , the objective field header is removed ."
"dict of 2 - item lists ' field_column ' : [ label , label_column ] describing the per label extension"
returns a dict to store the multi - label info that defines this source
closing file handler
adding arguments for the analyze subcommand
adding arguments for the anomaly subcommand
returns whether there 's some kind of time - series id
creates or retrieves time_series from the input data
retrain - related options
string of code that represents a value according to its type
builds the code to predict when the field is missing
part of the condition that checks for missings when missing_splits has been used
condition code for the split
"translate the model into a set of "" if "" javascript statements ."
extracts the properties of the created resources and generates code to rebuild them
creating or retrieving a project from input arguments
updating project attributes according to input arguments
evaluates a list of models or ensembles with the given dataset
cross - validates using a monte - carlo variant
evaluates models or ensembles against datasets
computes the standard deviation
traverses the tree to find measure lists and compute standard deviation
reads the contents of the evaluations files and averages its measures
adds a new set of evaluation measures to the cumulative average
add two n x n matrices
adds a new set of per class evaluation measures to the total average
creates a model per label for multi - label datasets
creates or retrieves models from the input data
retrieves fields info from model resource
predictor for imagen from model/5a143f443980b50a74003699
main processing of the parsed options for bigmler analyze
multi - label - related options
returns whether there 's some kind of sample option in the command
checks whether there 's any argument that needs the sample fields structure to be translated into field ids
creates or retrieves samples from the input data
retrieves fields info from sample resource
checks if obj is a persistent object ( external storage ) . : param obj : object to check : return : boolean
checks if the object has a getid method . : param obj : object to check : return : boolean
retrieve the persistent object identificator . : param psco : persistent object : return : i d
retrieve the actual object from a persistent object identificator . : param i d : persistent object identificator : return : the object that corresponds to the i d
store arguments passed to the decorator # self = itself . # args = not used . # kwargs = dictionary with the given constraints . : param args : arguments : param kwargs : keyword arguments
parse and set the constraints within the task core element . : param func : function to decorate : return : decorated function .
aplicacion que utiliza la funcionalidad de launch_pycompss_applicacion llamando a aplicaciones externas sin parametros ( de distinto fichero ! sin anidamiento ) _ _ main _ _ -- > launch(maqueta.main)|-------- > task(function_a )
aplicacion que utiliza la funcionalidad de launch_pycompss_applicacion llamando a aplicaciones con parametros ( de distinto fichero ! sin anidamiento ) _ _ main _ _ -- > launch(app ) |-------- > task(function_a )
aplicacion que utiliza la funcionalidad de launch_pycompss_applicacion llamando a aplicaciones con parametros y con anidamiento ( distintos ficheros ! )
this test : - instantiates a sco . - makes it persistent . - calls a task with that psco - > in parameter . - waits for the task result . - deletes the psco .
this test : - instantiates a sco . - makes it persistent . - calls a task with that psco - > in parameter . - the task receives the psco and gets its value . - instantiates another sco and makes it persistent within the task . - returns the new psco . - calls another task with the input from the first one . - gets the output psco and receives it as input . - waits for the first task result . - waits for the second task result .
this test checks what happens when a not persisted persistent object is passed an inout task parameter and made persistent within the task .
"this test checks what happens when a not persisted persistent object is passed as in task parameter , made persistent within the task , and returned ."
"init the storage client . basically , we set the redis client and connects it to the instance / cluster"
per - worker init function
same as finish . no additional actions are needed
"finish the storage : nothing to do , as python redis clients have no close method ."
"retrieves the object that has the given identifier from the redis database . that is , given an identifier , retrieves the contents from the backend that correspond to this key , deserializes it and returns the reconstructed object ."
retrieves a set of objects from their identifiers by pipelining the get commands
persists an object to the redis backend . does nothing if the object is already persisted .
"deletes a persisted object . if the object was not persisted , then nothing will be done ."
test function files
test function objects
test function return primitive
test function return object
test function future parameter
test function future object list
test function without params
test when the function has the same object as in and inout
"apply function of two arguments cumulatively to the items of data , from left to right , so as to reduce the iterable to a single value . : param iterable : data . : param comp : specifies a custom comparison function of two arguments . : param key : specifies a function of one argument that is used to extract a comparison key from each list element . : param reverse : if set to true , then the list elements are sorted as if each comparison were reversed . : return : a new sorted list from the items in iterable ."
test iterable object
test nested iterable object wait
test wait on string
worker main method ( invocated from _ _ main _ _ ) .
"check that we have a proper python version and a proper os ( i.e : not windows ) also , check that we have java_home defined"
write data to etcd to describe a dhcp - enabled subnet .
delete data from etcd for a subnet that is no longer wanted .
start the ovirtcli shell .
> > > sect_port('program : httpd-8080 ' ) 8080
get value of metric .
"iterate over metrics , return list of ` ( name , value ) ` tuples"
metrics as json object .
serve metrics via http / json on port .
get list of dictionary words .
bar chart of last letter frequency .
load module from name
sorted list ( by name ) of models in module
property type ( string )
dot represtantation of model
"very simple white space tokenizer , in real life we 'll be much more fancy ."
very simple spliting to sentences by [ . ! ? ] and paragraphs . in real life we 'll be much more fancy .
return frequency ( count ) for each token in the text
iterator return all python files under ' start '
all lines from all python files under start
check that val points to an existing directory
filter with iteration
filter with merge
query with df.query
"for a given executable command , substitute any known variables contained within names with the correct values"
"perform any required modifications on an executable command , then run it in a subprocess and return the results ."
execute the setup / teardown commands for a test case . optionally terminate test execution if the command fails .
driver function for the unit tests .
create the network namespace in which the tests will be run and set up the required network devices for it .
destroy the network namespace for testing ( and any associated network devices as well )
search the list for empty id fields and return true / false accordingly .
open the json file containing the test cases and return them as an ordered dictionary object .
create the argument parser .
set the command line arguments for tdc .
"process any arguments overriding the default settings , and ensure the settings are correct ."
generate a list of all ids in the test cases .
check for duplicate test case ids .
check if a given id already exists in the list of test cases .
"if a test case has a blank id field , generate a random hex id for it and then write the test cases back to disk ."
"if a test case file is specified , retrieve tests from that file . otherwise , glob for all json files in subdirectories and load from each one ."
"load the test case data and process remaining arguments to determine what the script should do for this run , and call the appropriate function ."
"start of execution ; set up argument parser and get the arguments , and start operations ."
the http status code of the response that precipitated the error or ` ` ' n / a ' ` ` if not applicable .
a string error message .
"dict of returned error info from es , where available ."
mark the connection as dead ( failed ) . remove it from the live pool and put it on a timeout .
mark connection as healthy after a resurrection . resets the fail counter for the connection .
attempt to resurrect a connection from the dead pool . it will try to locate one ( not all ) eligible ( it 's timeout is over ) connection to return to th live pool .
return a connection from the pool using the ` connectionselector ` instance .
rotate the corners of the decam ccds to a given sky location .
"apply the given basemap projection to the decam focal plane at a location given by ra , dec ."
find the most likely sequence of labels using the viterbi algorithm on prob_matrix
"given an object , returns an httpresponse object with a json serialized version of that object"
save the initial referer
"this returns the ancestors of this urlpath . these ancestors are hopefully cached from the article path lookup . accessing a foreign key included in add_selecte_related on one of these ancestors will not occur an additional sql query , as they were retrieved with a select_related ."
returns true if this article or any of its ancestors have been deleted
"nb ! this deletes this urlpath , its children , and all of the related articles . this is a purged delete and cannot be undone ."
strategy : do n't handle all kinds of weird cases . be strict . accepts paths both starting with and without ' / '
utility function : creates a new urlpath with an article and a new revision for the article
"creates a new urlpath , using meta data from ` ` request ` ` and copies in the permissions from ` ` perm_article ` ` ."
return an ordered list of all chilren
helper function to create filestream for upload .
tests that simple file upload uploads correctly uploading a file should preserve the original filename . uploading should not modify file in any way .
"tests that previous revisions are not deleted tests that only the most recent revision is deleted when "" replace "" is checked ."
call the search view
used when the entire index for model is updated .
insert abbrpreprocessor before referencepreprocessor .
fromenum : : a - > int
succ : : a - > a
pred : : a - > a
enumfromthen : : a - > a - > [ a ]
enumfrom : : a - > [ a ]
enumfromthento : : a - > a - > a - > [ a ]
enumfromto : : a - > a - > [ a ]
"evaluate the next element of the tail , and add it to the head ."
evaluate the entire list .
^ is the cons operator ( equivalent to : in haskell )
( + ) : : [ a ] - > [ a ] - > [ a ]
"plots precision vs. recall for multiple data series . each argument of the form ( [ < prfscores1 > , < prfscores2 > , ... ] , < fmt(s ) > , < label(s ) > ) provides precision / recall data points in prfscores instances , and optionally labels and format specifier strings for the matplotlib plot ( ) function ."
"returns whether this is a binary confusion matrix , in which case the first three entries ( aonly , bonly , both ) are all numeric values ."
heuristic characterization of the cohen 's kappa value according to landis & koch ( 1977 ) .
create a confusion matrix for binary - valued data given sets of item identifiers for the two annotators plus a set which may contain additional items .
create a confusion matrix for categorical data given dicts mapping item identifiers to labels for the respective annotators . a third set may contain additional items .
"create a confusion matrix for categorical data given parallel iterables , assumed to be the same length , over corresponding labels from the respective annotators for each item . a value of ' none ' is taken to mean that no label was provided by that annotator ."
memoization decorator for a function taking one or more arguments . source : http://code.activestate.com/recipes/578231-probably-the-fastest-memoization-decorator-in-the-/#c4
"network : a value from pycoinnet.helpers.networks host_port_q : a queue that is being fed potential places to connect should_download_block_f : a function that accepting(block_hash , block_index ) and returning a boolean indicating whether that block should be downloaded . only used during fast - forward . block_chain_store : usually a blockchainstore instance blockchain_change_callback : a callback that expects ( blockchain , list_of_ops ) that is invoked whenever the block chain is updated ; blockchain is a blockchain object and list_of_ops is a pair of tuples of the form ( op , block_hash , block_index ) where op is one of "" add "" or "" remove "" , block_hash is a binary block hash , and block_index is an integer index number ."
"connect to the remote drone instance . by default , it is already called when the object is created ."
disconnect from the remote drone instance .
reconnect to the remote drone instance .
get the list of all the ports on the remote host . they are stored in the : attr:`ports ` dictionnary .
"get ports from : attr:`ports ` by name . if the port is not found , ` ` none ` ` is returned ."
gives all the sessions on all the ixp we have
"returns a tuple of args , kwargs passed to the function . useful for recording arguments for future function calls ."
stores the various properties related to a routing url rule .
attempts to match a url to the given path .
returns a relative path for the given dictionary of items .
"returns a query string for the given dictionary of items . all keys and values in the provided items will be urlencoded . if necessary , any python objects will be pickled before being urlencoded ."
returns a relative path complete with query string for the given dictionary of items .
the regex for matching paths against this url rule .
the bound function
the url pattern
the name of this url rule .
the list of path keywords for this url rule .
returns the sort method specified . sort_method is case insensitive . will raise an attributeerror if the provided sort_method does not exist .
a decorator that sets the error_message attribute of the decorated function to the provided value .
"currently only one positional arg , create ."
a callable that retunrs the value passed
returns true if the provided value is a valid plugin i d
returns true if the provided path is an existing directory
"displays the provided prompt and gets input from the user . this behavior loops indefinitely until the provided validator returns true for the user input . if a default value is provided , it will be used only if the user hits enter and does not provide a value ."
"displays the provided prompt and returns the input from the user . if the user hits enter and there is a default value provided , the default is returned ."
"edits the given file in place , replacing any instances of { key } with the appropriate value from the provided items dict . if the given filename ends with "" .xml "" values will be quoted and escaped for xml ."
creates a new kodi plugin directory based on user input
required run function for the ' create ' cli command .
: param sequence : : param start : : param stop : : param step : : param kwargs : : return :
: type frame_seq : collections . iterable : param frame_seq : : param kwargs : : return :
: type frame_seq : collections . iterable : param frame_seq : : return :
: type frame_seq : collections . iterable : param frame_seq : : return :
: param av_format : : param _ kwargs : : return :
: param colour_size : : param kwargs : : return :
: param pixel_size_coef : : param kwargs : : return :
: param kwargs : : return :
: param frame_size : : param _ kwargs : : return :
: param image_size : : param _ kwargs : : return :
: type frame_seq : collections . iterable : param frame_seq : : param _ kwargs : : return :
: type image_seq : collections . iterable : param image_seq : : return :
: type image_seq : collections . iterable : param image_seq : : param _ kwargs : : return :
: type image_seq : collections . iterable : param image_seq : : param kwargs : : return :
: type image_seq : collections . iterable : param image_seq : : return :
: param vector : : return :
: type image_seq : collections . iterable : param image_seq : : param kwargs : : return :
returns advanced filter of mean polynomial approximation .
"generates the sequence of filters with different window sizes ,"
returns filter of mean polynomial approximation .
"generates the sequence of filters with different delays ,"
: param kwargs_items : : param kwargs :
: param kwargs : : return :
: param type obj_type : : return :
: param type obj_type : : param basevideounit obj : : return :
: return :
: return :
: return :
: return :
: return :
: return :
: return :
: return :
: param feature : : param norm_function : : param kwargs : : return :
: param size : : return :
: param size : : return :
: param feature_tuple : : param kwargs : : return :
: param feature_tuple : : param kwargs : : return :
: param op_func_args : : return :
: param result : : return :
: param feature_tuple : : return :
: param feature_tuple : : return :
: param args : : return :
: param any other : : return :
: param collections . iterable sequence : initial sequence of any element . : param int window_delay : offset from which window handling starts . : param int fill_d : : param int slice_d : : param kwargs : : return :
: param sequence : : param window_delay : : param fill_d : : param slice_d : : return :
: param sequence : : param window_delay : : param kwargs : : return :
: param vector : : param kwargs : : return :
: param vector : : param kwargs : : return :
: param window_seq : : param depth : : param kwargs : : return :
: param caller :
: param func_seq : : param args : : param kwargs : : return :
: param func_seq : : param args : : param kwargs : : return :
: param func : : param args : : param kwargs : : return :
: param func_seq : : param args : : param kwargs : : return :
: param futures : : return :
: param obj :
: return :
: return :
: param obj : : return :
: param item : : return :
: param obj : : return :
: param obj : : return :
: param obj : : return :
: param obj : : return :
: param obj : : return :
: param obj : : return :
: param obj : : return :
: return :
: param value : : return :
: param value : : return :
: return :
: param value : : return :
: param value : : return :
: param value : : return :
: param value : : return :
: param value : : return :
: param value : : return :
: param value : : return :
: param item_seq : : return :
: param item_seq : : return :
: param window_features : : param kwargs : : return :
apply filter sequential_filters consecutively .
recommended window size is 25 * 32 : param window_seq : : param return_velocity : : param kwargs : : return :
: param _ kwargs : : return :
: type image_seq : collections . iterable : param image_seq : : return :
: type image_seq : collections . iterable : param image_seq : : return :
: param feature : : param kwargs : : return :
: param kwargs :
: param _ : : return :
: param objects : : param kwargs : : return :
: param objects : : param window_delay : : param kwargs : : return :
: param objects : : param kwargs : : return :
not used handle features in ` feature_seq ` with sliding windows
return the sequence ( generator ) of sliding windows .
reduce sliding windows into values
reduce one sliding window into one value
: param objects : : param features : : param centre_samples : : param overlap_size : : param kwargs : : return :
: param objects : : param features : : param strict_windows : : param kwargs : : return :
: param window : : param window_size : : param _ : : return :
: param pp_servers :
: param func : : param args : : param kwargs : : return :
: param kwargs_items : : param kwargs :
: param feature : : param kwargs : : return :
: return :
: param point_seq : : param kwargs : : return :
: param point_seq : : param _ kwargs : : return :
: param point_seq : : param _ feature_seq : : param _ kwargs : : return :
: param event_seq : : param kwargs : : return :
: param event_seq : : param kwargs : : return :
: return :
: param feature : : param diff : : return :
: param diff : : return :
: param v0 : : param v1 : : return :
: param feature : : return :
firebird supports ' drop col ' instead of ' drop column col ' syntax
rename table not supported
changing null is not supported
cascading constraints is not supported
"given a unique identifier , return a dictionary key this should be overridden by child classes , to specify which parameters should determine an object 's uniqueness"
shell interface to : mod:`migrate.versioning.api ` .
little hack to support all --some_option = value parameters
given : column objects or names ; return col names and ( maybe ) a table
create the constraint in the database .
drop the constraint from the database .
mimic the database 's automatic constraint names
mimic the database 's automatic constraint names
mimic the database 's automatic constraint names
clear all class level listeners
return an event collection which can be modified .
return an event collection which can be modified .
execute this event .
"execute this event , but only if it has not been executed already for this collection ."
execute this event .
return an event collection which can be modified .
populate from the listeners in another : class:`_dispatch ` object .
tokenize sql .
"return an iterable of ( tokentype , value ) pairs generated from ` text ` . if ` unfiltered ` is set to ` true ` , the filtering mechanism is bypassed even if filters are defined ."
specify whether to record warnings and if an alternative module should be used other than sys.modules['warnings ' ] .
find user - specified instrumentation management for a class .
"replace global class / object management functions with extendedinstrumentationregistry implementations , which allow multiple types of class managers to be present , at the cost of performance ."
restore simplified lookups .
return a collection of factories in play or specified for a hierarchy .
install a default instancestate if none is present .
test that a scalar select as a column is returned as such and that type conversion works ok .
make a nice header string .
produce a sequence of formatted lines from info .
return a string summarizing the call stack .
"print a summary of the stack to stdout , or some place else ."
"given a 64 - bit i d , make a shorter 16 - bit one ."
write a log message as forcefully as possible .
"for debugging , we can use aspectlib to trace execution ."
configure the options and output file for debugging .
decide whether to output debug information in category ` option ` .
a context manager to prevent call stacks from being logged .
write a line of debug output .
"write a sequence of ( label , data ) pairs nicely ."
get the process - wide singleton debugoutputfile .
just like file.write
"the raw text - writer , so that we can use it ourselves ."
true if the given sorting conforms to the given partial ordering .
return a function with a given _ _ name _ _ .
"run the given function under the given contextmanager , simulating the behavior of ' with ' to support older python versions ."
converts the results of sql execution into a plain set of column tuples .
"provide bound metadata for a single test , dropping afterwards ."
"force the given table names to be dropped after test complete , isolating for foreign key cycles"
"generate a csrf token . the token is cached for a request , so multiple calls to this function will generate the same token ."
check if the given data is a valid csrf token . this compares the given signed token to the one stored in the session .
"find config value based on provided value , flask config , and default value ."
mark a view or blueprint to be excluded from csrf protection .
register a function that will generate the response for csrf errors .
construct engine the smart way
test asbool parsing
load model from dotted name
guess object type from string
unary rpc ( simple rpc ) y(x ) = x^2
"server - side streaming rpc ( response streaming rpc ) y(x)_j = { t | t in n+ , t < = x}_j"
client - side streaming rpc ( request streaming rpc ) y(x_i ) = sum x_i
"duplex streaming rpc ( bidirectional rpc ) y(x_i)_j = { x_i + x_(i-1 ) + x_(i-2 ) | i mod 3 = 2}_j ,"
find the specified protocol layer based on the class name
"set the packet payload . expects a string , array to packet of type packet_base"
override me with packet parsing code
override me to return packet headers
convert header and payload to str
init . @param xid the request that this reply responds to reply to an earlier request .
returns the execution time of a submission
process top - level entries .
process sub - entries .
initialize from string source .
get a value from the nested data structure .
creates a profile on the server .
"core solving routine : param dat : a good ticdat for the input_schema : return : a good ticdat for the solution_schema , or none"
"core solving routine : param dat : a good ticdat for the input_schema : return : a good ticdat for the solution_schema , or none"
do n't call this function explicitly . a opalyticsticfactory will automatically be associated with the opalytics attribute of the parent ticdatfactory . : param tic_dat_factory : : return :
"find the row counts for duplicated rows . : param inputset : an opalytics inputset consistent with this ticdatfactory : param raw_data : boolean . should data cleaning be skipped ? see create_tic_dat . : return : a dictionary whose keys are table names for the primary - ed key tables . each value of the return dictionary is itself a dictionary . the inner dictionary is keyed by the primary key values encountered in the table , and the value is the count of records in the table with this primary key . row counts smaller than 2 are pruned off , as they are n't duplicates ."
"create a ticdat object from an opalytics inputset : param inputset : an opalytics inputset consistent with this ticdatfactory : param raw_data : boolean . should data cleaning be skipped ? on the opalytics cloud platform cleaned data will be passed to instant apps . data cleaning involves removing data type failures , data row predicate failures , foreign key failures and deactivated records . : param freeze_it : boolean . should the returned object be frozen ? : return : a ticdat object populated by the tables as they are rendered by inputset"
add user to group synchronously : param engine : sqlalchemy engine . : param user_id : int . user i d to add . : param group_id : int . group i d to add user to .
"create a group with specified permissions on targets , plus all join tables . : param engine : sqlalchemy engine . database engine to connect through . : param name : group name . : param permission_pairs : tuple . list of permission names and targets to create . : return : int . group i d created ."
when a new package is added to an advisory work out what hosts it applies to .
when a package is added to a host find any advisories that apply to it and create problems .
when a package is removed from a host find any problems removing it might solve .
` is.gd < http://is.gd/ > ` _ error code :
` is.gd < http://is.gd/ > ` _ description for this error .
init the exception with code and description taken from ` is.gd < http://is.gd/ > ` _ .
init the exception with description taken from ` is.gd < http://is.gd/ > ` _ .
init the exception with description taken from ` is.gd < http://is.gd/ > ` _ .
init the exception with description taken from ` is.gd < http://is.gd/ > ` _ .
init the exception with description taken from ` is.gd < http://is.gd/ > ` _ .
lookup an url shortened with ` is.gd - v.gd url service < http://is.gd/developers.php > ` _ and return the real url
shorten an url using ` is.gd - v.gd url shortener service < http://is.gd/developers.php > ` _ .
init url shortener class
init url shortener class
init url shortener class
parse the output according to specified format .
"runs a single test , comparing output and rc to expected output and rc ."
"loads and parses the input file , runs all tests and reports results"
fetch block contents from disk given extents
"find the next block to be written in the input , and copy it to the output ."
"do a http request , with retry if we get disconnected ( e.g. due to a timeout ) . this is a workaround for https://bugs.python.org/issue3566 which is fixed in python 3.5 ."
adds a default value and a default type for a key .
adds serialization support for a new type .
decorator . attaches the global key - value store of this hierarchy to an object .
decorator . attaches a global key - value store to a django model .
quick and dirty hack to fix change_view and delete_view ; they use self.queryset(request).get ( ... ) to get the object they should work with . our modifications to the queryset when include_ancestors is enabled make get ( ) fail often with a multipleobjectsreturned exception .
returns the changelist class for use on the changelist page .
the ' change list ' admin view for this model .
"handle the changelist view , the django view for the model instances change list / actions page ."
returns a queryset of all model instances that can be edited by the admin site . this is used by changelist_view .
should raise an exception .
builds a dictionary of all the messages available in a set of files .
initializes a new factory .
builds a proto2 message class based on the passed in descriptor .
gets all the messages from a specified file .
pulls out all the symbols from a descriptor proto .
adds the filedescriptorproto and its types to this database .
finds the file descriptor proto by file name .
finds the file descriptor proto containing the specified symbol .
get a proto class from the messagefactory by name .
create a protobuf class whose fields are basic types .
executes a cli command in a subprocess and return the results .
returns the ipaddress based upon a name part of the full container name
returns the ipaddress based upon a name part of the full container name
draw a random sample .
construct the neural network of maximum entropy classifier .
load the maximum entropy classifier from saved model .
convert the shorttext into a sparse vector given the dictionary .
convert the gensim corpus into a sparse matrix . ( deprecated )
index the class outcome labels .
convert the training data into sparse matrices for training .
train the classifier .
save the trained model into files .
load a trained model from files .
calculate the scores for all the class labels for the given short sentence .
initialize the stacking class instance .
register the intermediate classifiers .
register output labels .
add a classifier .
delete a classifier .
represent the given short text as the input matrix of the stacking class .
convert the label into an array of bucket .
returns a generator that returns the input matrix and the output labels for training .
train the stacked generalization .
calculate the scores for each class labels .
train the stacked generalization .
calculate the scores for all the class labels for the given short sentence .
save the logistic stacked model into files .
load the model with the given prefix .
save a keras sequential model into files .
load a keras sequential model from files .
mdfile : 需要转换的markdown的完整路径 htmlfile : 需要生成html文件的完整路径 theme : themes中任选其中一个
mdfile : 需要转换的markdown的完整路径 htmlfile : 需要生成html文件的完整路径 theme : themes中任选其中一个
reads a list of parameters from file . returns whether it has succeeded in doing so .
saves a list of parameters to file . returns whether it has succeeded in doing so . overwrites anything on the given path .
"only if value has the type parameter it gets added to the list , so that the parameter list stays consistent ."
nothing needs to be done for ct scans . the values of the sliders are not dependent on the imagedata . : type imagedata : vtkimagedata
returns a widget with sliders / fields with which properties of this volume property can be adjusted . : rtype : qwidget
parameter ' value ' is unused . this is a callback for all the interactive widgets in the parameter widget .
camera modified event callback . copies the parameters of the renderer camera into the camera of the overlay so they stay synced at all times .
* show progress bar dialog * define folder for output ( projectfolder / data / result-<id>/. ) * write parameter file to output folder * call elastix to process the data * load the new data into the moving widget / project
set the renderwidget for direct control instead of signal / slot messages . : type renderwidget : renderwidget
: type filename : str
apply the settings from the provided rendersettings object .
return a rendersettings object with all the right properties set . : rtype : rendersettings
swithes the renderer to the given render type . previously used render types are saved so that switching back to a previously used render type will produce the same visualization as before .
: rtype : qwidget
: type sliceindex : int : type visibility : bool
: type visibility : bool
: type visibility : bool
should be called by all interface elements that adjust the volume property . this makes sure that the render widget takes notice and renders accordingly .
update the model . if the number of transformations is bigger than last time : clear the selection .
remove the last transformation in the list .
activate the transformation from the complete list .
slot that reads properties of the dataset and displays them in a few widgets .
check if dir exist if not we create the path
ca n't move different sized registers back and forth
returns the path to the root src directory .
returns the path to the src / chrome / test / data directory .
returns the preferred build directory that contains given paths .
returns the file version of the given file .
returns the product name of the given file .
returns ' . ' plus the unpadded base32 encoding of the md5 of the user 's sid .
expands variables in the given string .
finds a rule whose name is |component_name| .
finds a matching component name which a given |bucket| belongs to .
finds a matching component which a given mmap |region| belongs to .
finds a matching component which a given unhooked |region| belongs to .
loads a policy file of |filename| in a |format| .
parses a policy file content in a |format| .
parses policy file in json format .
categorizes a pageframe based on its sharing status .
"loads a set of policies via the "" default policy directory "" ."
"returns a tuple of a character indicating what type of rule this is , and a string holding the path the rule applies to ."
"returns a tuple ( allow , dependent dir , dependee dir ) for this rule , which is fully self - sufficient to answer the question whether the dependent is allowed to depend on the dependee , without knowing the external context ."
"returns true if the input string is an exact match or is a parent of the current rule . for example , the input "" foo "" would match "" foo / bar "" ."
"returns true if the input string would be covered by this rule . for example , the input "" foo / bar "" would match the rule "" foo "" ."
initializes the current rules with an empty rule list for all files .
"returns a list of tuples ( allow , dependent dir , dependee dir ) for the specified rules ( general / specific ) . currently only general rules are supported ."
adds a rule for the given rule string .
returns the rule that applies to |include_path| for a dependee file located at |dependee_path| .
minidom helper function that iterates all the element nodes . iteration order is pre - order depth - first .
raises an exception if the given attribute is deprecated .
write the given dom to filename .
"return true if the dom is a style resource , false otherwise ."
"if a style resource is in input_dir , raises an exception ."
convert layout resource to api 14 compatible layout resource .
convert style resource to api 14 compatible style resource .
convert api 17 layout resource to api 14 compatible layout resource .
convert api 17 style resources to api 14 compatible style resource .
convert layout resources to api 14 compatible resources in input_dir .
convert style resources to api 14 compatible resources in input_dir .
"verify that the resources in input_dir is compatible with v14 , i.e. , they do n't use attributes that cause crashes on certain devices . print an error if they have ."
"raises an exception if resources in input_dir have deprecated attributes , e.g. , paddingleft , paddingright"
parses command line options .
default parent_path should behave correctly
pathed(path ) should n't create duplicate objects of the same path
parents should be fetched correctly
parses the output of memdump .
"returns a copy of the given decoder action , with fields that name the instruction decoder to use removed . neutralizes the corresponding baseline action ."
"takes the given decoder table , and builds the corresponding internal maps , so that we can consistently name baseline classes . returns the ( sorted ) list of baseline classes to build ."
rebuilds the baseline decoders map if already defined . should be called whenever decoder actions are changed .
"takes the given decoder table , and builds the corresponding internal maps , so that we can consistently name baseline classees ."
generates baseline decoder c++ declarations in the given file .
generates baseline decoder c++ declarations in the given file .
generates the baseline decoder c++ definitions in the given file .
generates c++ class declarations for each of the given baseline decoders .
generates c++ class definitions for each of the given baseline decoders .
add entry into baseline_name_to_baselines_map for the given baseline class .
replaces the sets in baseline_name_to_baselines_map with corresponding sorted lists .
"installs a unique name for each baseline , based on the baseline decoders with the same ( dgen_decoder ) baseline name ."
returns the name to use for the baseline .
"returns the ( sorted ) list of baseline class to include in block n , assuming baseline classes are split using the list of separators ."
"adds the automatically generated baseline decoders ( in files "" * _ baselines.h "" and "" * _ baselines.cc "" into the listed tables of the decoder , and returns the generated ( new ) decoder ."
"generates a copy of the given table , where the ' baseline ' field is defined by the corresponding automatically generated baseline decoder ( described in the table ) ."
"generates a copy of the given row , where ( if applicable ) , the field ' baseline ' is defined by the corresponding ( baseline ) instruction decoder described by the action of the row ."
create a new testrunner .
do nothing .
get the values in the stats table after the page is loaded .
add results for this page to the results object .
l{_hassubstring } returns true if the specified substring is present in the text being searched .
l{_hassubstring } returns false if the specified substring is not present in the text being searched .
l{_hassubstring } returns false if the specified substring is present in the text being searched but the characters surrounding the substring are alphanumeric .
l{_hassubstring } uses a regular expression to determine if a substring exists in a text snippet . the substring is escaped to ensure that it does n't interfere with the regular expression .
@param host : @param port : @param identityname : @param password : @param servicename : @param perspectivename :
construct a new l{buildrequest } from a dictionary as returned by l{buildrequestsconnectorcomponent.getbuildrequest } .
return a reason for the merged build request .
find the only .diff file
passes the changes to tryjobsubversion .
for each change submit a job
makes the backend think we 're not logged in even though we are . should only be used in unit tests to simulate --dont - override - profile .
logs in to a test account .
add the tests listed in ' tests ' to the factory_cmd_obj .
removes values from existing construction variables in an environment .
applies a sconscript to the current environment .
builds a sconscript based on the current environment .
"replacement subst_list designed for flags / parameters , not command lines ."
calculates the relative path from source to target .
scons entry point for this tool .
initialises a new instance of a firefox profile
sets the preference that we want in the profile .
gets the profile directory that is currently being used
gets the port that webdriver is working on
sets the port that webdriver will be running on
"a zipped , base64 encoded string of profile directory for use with remote webdriver json wire protocol"
creates a temp folder to store user.js and the extension
writes the current user prefs dictionary to disk
"installs addon from a filepath , url or directory of addons in the profile . - path : url , path to .xpi , or directory of addons - unpack : whether to unpack unless specified otherwise in the install.rdf"
"returns a dictionary of details about the addon - addon_path : path to the addon directory returns : { ' i d ' : u'rainbow@colors.org ' , # i d of the addon ' version ' : u'1.4 ' , # version of the addon ' name ' : u'rainbow ' , # name of the addon ' unpack ' : false } # whether to unpack the addon"
return differences of model against database .
return differences of model against another model .
summarize differences .
"used in bool evaluation , return of 0 means no diffs ."
an extremely simple ( and limited ) server request_handler .
"process a new push_tcp connection , tcp_conn ."
start a response . must only be called once per response .
send part of the response body . may be called zero to many times .
"signal the end of the response , whether or not there was a body . must be called exactly once for each response ."
indicate that the server should pause ( true ) or unpause ( false ) the request .
pause / unpause sending the response body .
the server connection has closed .
process a request body chunk from the wire .
indicate that the request body is complete .
indicate a parsing problem with the request body .
handle a problem with the request by generating an appropriate response .
create a test case initialized to run |test_name| .
runs a single java test in a java testrunner .
calls a list of tests and stops at the first test failure .
splits source code text into segments in preparation for comment stripping .
strips comments out of javascript source code .
"gets the screenshot of the current window . returns false if there is any ioerror , else returns true . use full paths in your filename ."
extracts the ' version ' key from the contents of an app.yaml file . allow overriding the key to parse e.g. the cron file ( ' target ' ) .
"return whether the app.yaml version |lhs| > |rhs| . this is tricky because versions are typically not numbers but rather 2 - 0 - 9 , 2 - 0 - 12 , 2 - 1 - 0 , etc - and 2 - 1 - 0 > 2 - 0 - 10 > 2 - 0 - 9 ."
probably only useful for tests .
returns true if the |app_version| is up to date with respect to the one checked into the host file system .
finds the first revision that the version in app.yaml was greater than |app_version| .
return a path which is the url where a browser would presumably take you if you clicked on a link with an href as given .
parses the output of android 's am dumpheap -n .
factory method for instanciating the admlwriter . every writer needs a getwriter method because the templateformatter uses this method to instantiate a writer .
"adds an adml "" string "" element to the passed parent . the following adml snippet contains an example :"
"generates the adml elements for a policy . < stringtable > ... < string id=""$(policy_group_name)"">$(caption)</string > < string id=""$(policy_group_name)_explain"">$(description)</string > < /stringtable >"
"generates adml elements for a policy - group . for each policy - group two adml "" string "" elements are added to the string - table . one contains the caption of the policy - group and the other a description . a policy - group also requires an adml "" presentation "" element that must be added to the presentation - table . the "" presentation "" element is the container for the elements that define the visual presentation of the policy - goup 's policies . the following adml snippet shows an example :"
"adds adml "" string "" elements to the string - table that are referenced by the admx file but not related to any specific policy - group or policy ."
convert an integer represented as a base 128 string into an c{int } or c{long } .
set the limit on the prefix length for all banana connections established after this call .
encode a list s - expression .
decode a banana - encoded string .
set the prefix limit for decoding done by this protocol instance .
surrogate for connectionmade called after protocol negotiation .
"called when an expression ( list , string , or int ) is received ."
initializes the bucket .
"given a old and new int value , return a string representing the difference"
set output stream
write a line in the output buffer
display results encapsulated in the layout tree
display the layout
simple wrapper for pkg - config .
verifies a local file exists .
initializes the adbwrapper .
runs an adb command with a timeout and retries .
runs an adb command on the device associated with this object .
consider instances equal if they refer to the same device .
the string representation of an instance .
get the list of active attached devices .
gets the device serial number associated with this object .
pushes a file from the host to the device .
pulls a file from the device to the host .
runs a shell command on the device .
get the logcat output .
forward socket connections from the local socket to the remote socket .
list of pids of processes hosting a jdwp transport .
install an apk on the device .
remove the app |package| from the device .
write an archive of the device 's data to |path| .
restore device contents from the backup archive .
block until the device is online .
get device state .
gets the device path .
remounts the /system partition on the device read - write .
reboots the device .
"restarts the adbd daemon with root permissions , if possible ."
entry point for the background periodic tracer task .
"returns a tuple ( completion_rate , message ) ."
override to accept custom command - line arguments .
override to process command - line arguments .
main method to run this command as a standalone script .
main method to run this command as a standalone script .
"convert the given string to the native newline format , assuming it is already in normal unix newline format ( ) . use this to create the appropriate expectation in a failunlessequal"
"check if a path should be redirected , first according to host redirection rules , then from rules in redirects.json files ."
"lookup the redirects configuration file in the directory that contains the requested resource . if no redirection rule is matched , or no configuration file exists , returns none ."
"redirect paths from the old code.google.com to the new developer.chrome.com , retaining elements like the channel and https , if used ."
load files during a cron run .
test that i{get } and i{put } commands are responded to correctly by l{postfix . postfixtcpmapserver } when its factory is an instance of l{postifx . postfixtcpmapdictserverfactory } .
test that i{get } and i{put } commands are responded to correctly by l{postfix . postfixtcpmapserver } when its factory is an instance of l{postifx . postfixtcpmapdeferringdictserverfactory } .
forms an actions xml string and returns it after processing .
assign to a key attribute .
find an attribute by caseless name .
special setattr to prevent changing of key values .
populate instance with default attributes .
use this to set the ' dirty ' flag .
required method to auto register this checker
inspect the source file to found encoding problem or fixmes like notes
substitutes the variable parts into a plist template . the result of this function can be used as an expected result to test the output of plistwriter .
compares two strings that should be identical except for whitespace
"call a function , ignoring any exceptions"
gets the standardized hash value for a given archive .
initialize archiveinfo object .
loads a archive info file into this object .
saves this object as a serialized json file if the object is valid .
returns a dict representation of this object for json .
replaces currently set with new archiveinfotuple .
returns the current archiveinfotuple tuple .
"when l{posixreactorbase } is instantiated , it creates a waker and adds it to its internal readers set ."
any l{ireaddescriptors } in l{posixreactorbase._internalreaders } are left alone by l{posixreactorbase._removeall } .
l{posixreactorbase._removeall } returns a list of removed l{ireaddescriptor } and l{iwritedescriptor } objects .
l{twisted.internet.interfaces . ireactorarbitrary } is redundant with l{twisted.internet.interfaces . ireactorfdset } and is deprecated .
"l{posixreactorbase } implements the deprecated l{ireactorarbitrary } , and l{posixreactorbase.listenwith } is a part of that interface . to avoid unnecessary deprecation warnings when importing posixbase , the l{twisted.internet.interfaces._ireactorarbitrary } alias that does n't have the deprecation warning is imported , and instead l{posixreactorbase.listenwith } generates its own deprecation warning ."
"l{posixreactorbase } implements the deprecated l{ireactorarbitrary } , and l{posixreactorbase.connectwith } is a part of that interface . to avoid unnecessary deprecation warnings when importing posixbase , the l{twisted.internet.interfaces._ireactorarbitrary } alias that does n't have the deprecation warning is imported , and instead l{posixreactorbase.connectwith } generates its own deprecation warning ."
l{port.stoplistening } returns a l{deferred } which errbacks if l{port.connectionlost } raises an exception .
"ignore the reader . this is necessary because the waker will be added . however , we wo n't actually monitor it for any events ."
"there are no readers or writers , so there is nothing to remove . this will be called when the reactor stops , though , so it must be implemented ."
override the real clock with a deterministic one that can be easily controlled in a unit test .
"if there are no delayed calls , c{doiteration } is called with a timeout of c{none } ."
"if there is a delayed call , c{doiteration } is called with a timeout which is the difference between the current time and the time at which that call is to run ."
"if a delayed call is scheduled and then some time passes , the timeout passed to c{doiteration } is reduced by the amount of time which passed ."
"if there are several delayed calls , c{doiteration } is called with a timeout which is the difference between the current time and the time at which the earlier of the two calls is to run ."
"if a delayed call is reset , the timeout passed to c{doiteration } is based on the interval between the time when reset is called and the new delay of the call ."
"if a delayed call is re - delayed , the timeout passed to c{doiteration } is based on the remaining time before the call would have been made and the additional amount of time passed to the delay method ."
"if the only delayed call is canceled , c{none } is the timeout passed to c{doiteration } ."
l{connecteddatagramport } does not call the deprecated c{loseconnection } in l{connecteddatagramport.connectionfailed } .
l{connecteddatagramport } calls l{connecteddatagramport.stoplistening } instead of the deprecated c{loseconnection } in l{connecteddatagramport.connectionfailed } .
initializes a templatewriter object .
checks if the given deprecated policy is supported by the writer .
checks if the given future policy is supported by the writer .
"checks if the given policy is supported by the writer . in other words , the set of platforms supported by the writer has a common subset with the set of platforms that support the policy ."
checks if the given policy can be recommended .
checks if |policy| is supported on |platform| .
filters the list of policies in the passed group that are supported by the writer .
"initializes the writer . if the writetemplate method is overridden , then this method must be called as first step of each template generation process ."
writes the given template definition .
"preprocesses a list of policies according to a given writer 's needs . preprocessing steps include sorting policies and stripping unneeded information such as groups ( for writers that ignore them ) . subclasses are encouraged to override this method , overriding implementations may call one of the provided specialized implementations . the default behaviour is to use sortpoliciesgroupsfirst ( ) ."
appends the template text corresponding to a policy into the internal buffer .
appends the template text corresponding to a recommended policy into the internal buffer .
appends the template text corresponding to the beginning of a policy group into the internal buffer .
appends the template text corresponding to the end of a policy group into the internal buffer .
appends the template text corresponding to the beginning of a recommended policy group into the internal buffer .
appends the template text corresponding to the end of a recommended policy group into the internal buffer .
appends the text corresponding to the beginning of the whole template into the internal buffer .
appends the text corresponding to the end of the whole template into the internal buffer .
gets the content of the internal template buffer .
"sorts a list of policies alphabetically . the order is the following : first groups alphabetically by caption , then other policies alphabetically by name . the order of policies inside groups is unchanged ."
"sorts a list of policies according to |sorting_key| , defaulting to alphabetical sorting if no key is given . if |policy_list| contains policies with type=""group "" , it is flattened first , i.e. any groups ' contents are inserted into the list as first - class elements and the groups are then removed ."
extracts a sorting key from a policy . these keys can be used for list.sort ( ) methods to sort policies . see templatewriter . sortpolicies for usage .
start shaping traffic .
"install the wxpython support , given a wxapp instance"
execute pending wx events followed by wx idle events and reschedule .
serve a get request .
serve a head request .
parse the header and get the range values specified .
loads all files in directory_path into the in - memory resource map .
loads file_path into the in - memory resource map .
initializes this object with all the data necessary to output a policy template .
parses and converts the string items of the list of supported platforms into dictionaries .
processes localized message strings in a policy or a group . also breaks up the content of ' supported_on ' attribute into a list .
adds localized message strings to each item in a list of policies and groups . also breaks up the content of ' supported_on ' attributes into lists of dictionaries .
"generates the text of the template from the arguments given to the constructor , using a given templatewriter ."
return current cpu processing time of pid in seconds .
return current timestamp in seconds .
like the following with nicer default message : asserttrue(expected < = actual + tolerance & & expected > = actual - tolerance )
"makes a lextoken with the given parameters . ( note that lineno is 1 - based , but lexpos is 0 - based . )"
makes a lextoken for the given keyword .
"tests valid , single keywords ."
"tests valid , single ( non - keyword ) tokens ."
gets a list of tokens for the given input string .
gets the single token for the given input string . ( raises an exception if the input string does not result in exactly one token . )
"splits the branchfile argument and assuming branch is the first path component in branchfile , will return branch and file else none ."
"a decorator which can be optionally applied to the compilation function passed to compiledfilesystem . create , indicating that the function only needs access to the file which is given in the function 's callback . when this is the case some optimisations can be done ."
"a decorator which can be optionally applied to the compilation function passed to compiledfilesystem . create , indicating that the function processes the file 's data as unicode text ."
returns a future containing the recursive directory listing of |path| as a flat list of paths .
"calls |compilation_function| on the contents of the file at |path| . if |binary| is true then the file will be read as binary - but this will only apply for the first time the file is fetched ; if already cached , |binary| will be ignored ."
calls |compilation_function| on the listing of the files at |path| . assumes that the path given is to a directory .
sets the highest possible performance mode for the device .
sets the performance mode for the device to its default mode .
resets the original performance mode of the device .
return the trial reporter plugin with the given long option .
one of the reporter plugins is the subunit reporter plugin .
add coverage related build steps and dependency links .
scons entry point for this tool .
handlers swarm_client / swarm_trigger_step.py .
handles swarm_client / swarming.py starting r219798 .
handles swarm_client / swarming.py starting 7c543276f08 .
handles swarm_client / swarming.py starting b39e8cf08c .
executes the proper handler based on the code layout and --version support .
converts build properties and factory properties into expected flags .
note : this is solely to run the current master 's code and can totally differ from the underlying script flags .
serializes the trace result to a file - like object
return a styleprocessorconfiguration instance for testing .
check that count and error messages are initialized .
call the given error handler with a test error .
test the _ _ eq _ _ ( ) method for the return value of true .
test the _ _ eq _ _ ( ) method for the return value of false .
test the _ _ ne _ _ ( ) method .
test _ _ call _ _ ( ) with a non - reportable error .
test error report suppression in _ _ call _ _ ( ) method .
test the line_numbers parameter .
adds buildfactory inherited properties .
strip the dirnames and version suffixes from a list of nexe dependencies .
create an empty test .nexe file for use in create_nmf tests .
retrieves dom element counts .
"static method to create a filter based on constructor args change_filter , branch , and categories ; use default values @code{none } , @code{notabranch } , and @code{none } , respectively . these arguments are interpreted as documented for the l{buildbot.schedulers.basic . scheduler } class ."
return the number of current exclusive and counting owners .
return a boolean whether the lock is available for claiming
claim the lock ( lock must be available )
release the lock
"fire when the lock * might * be available . the caller will need to check with isavailable ( ) when the deferred fires . this loose form is used to avoid deadlocks . if we were interested in a stronger form , this would be named ' waituntilavailable ' , and the deferred would fire after the lock had been claimed ."
express how the lock should be accessed
"for buildbot 0.7.7 compability : when user does n't specify an access mode , this one is chosen ."
load the media metrics js code prior to running the action .
"this does n't really belong in this unittest file , but what the heck ."
configure the fake fetcher paths relative to the docs directory .
initialize this l{twisted.web.distrib . request } based on the copied state so that it closely resembles a l{twisted.web.server . request } .
write the given bytes to the response body .
get persistent state for this resourcesubscription .
i 've connected to a publisher ; i 'll now send all my requests .
i ca n't connect to a publisher ; i 'll now reply to all pending requests .
"render this request , from my server ."
look up the resource for the given request and render it .
return a list of two - tuples giving links to user resources and text to associate with those links .
render as html a listing of all known users with links to their personal resources .
add summary results to the results object .
add valgrind binaries dependency for webrtc .
add the main solution for webrtc standalone builds .
helper config for loading the webrtc - limited solution .
combines dictionary members in two objects into a third one using addition .
"decorates recipetestapi member functions to allow those functions to return just the placeholder data , instead of the normally required steptestdata ( ) object ."
note : injected dependencies are not available in _ _ init _ _ ( ) .
returns a new empty testdata with the name filled in .
returns a new testdata with the mock data filled in for a single step .
see _ step_data ( )
see _ step_data ( )
unzip the file
return a generator for the zipfile . this implementation will yield after every file .
"predict the number of chunks that will be extracted from the entire zipfile , given chunksize blocks ."
count the number of chunks that will result from the given l{zipinfo } .
count the number of entries in a zip archive . ( do n't use this function . )
"return a generator for the zipfile . this implementation will yield after every chunksize uncompressed bytes , or at the end of a file , whichever comes first ."
return file - like object for name .
create a l{_fileentry } from a l{chunkingzipfile } .
returns false because zip files should not be ttys
close self ( file - like object )
read a line .
"implement next as file does ( like readline , except raises stopiteration at eof )"
returns a list of all the lines
returns an iterator ( so self )
returns an iterator ( so self )
this is called once with each line of the test log .
utility method for tests : figure out which tcp port we just opened .
"return a new , realistic failure ."
test that a standard log message does n't go anywhere near the result .
test that an observed error gets added to the result
check that flushing the observer with no args removes all errors .
check that flushing the observer remove all failures of the given type .
check that c{_ignoreerrors } actually causes errors to be ignored .
check that c{_clearignores } ensures that previously ignored errors get captured .
test that a logged error gets reported as a test error .
"test that when two errors get logged , they both get reported as test errors ."
test that errors logged in callbacks get reported as test errors .
check that an error logged in one test does n't fail the next test .
check http response status is expected .
returns the number of consecutive characters from |chars| that occur at the end of |string| .
"finds the next token in |tokens| that occurs in |string| from |start| . returns a tuple ( index , token key ) ."
process command - line arguments .
try to parse an int ( port number ) from a string .
"given a list of lists of tokens , pretty prints them in columns ."
"given a list of lists of tokens , prints them as comma - separated values ."
display a list of masters and their associated hosts and ports .
check for port conflicts and misconfigurations on masters .
lists triplets of available ports for easy discoverability .
extracts the data we want from a collection of possibly - masters .
upload a file to google storage .
"grep given file , which is in hosts(5 ) standard format , for an address entry with a given name ."
sets up the test environment before each test method .
cleans up the test environment after each test method .
tests deps parsing .
calculatetrunctedmean raises an error when passed an empty list .
tests the calculatemean function with a single number .
tests the calculatemean function with a short list .
tests calculatemean by comparing against an alternate implementation .
tests the confidence calculation .
tests the confidence calculation when it 's expected to be 0 .
tests the confidence calculation when it 's expected to be 100 .
tests the common cases for calculating relative change .
tests what happens when relative change from zero is calculated .
tests that relative change given is always positive .
initializes the measurement after the browser is started .
takes a sample and adds a result if enough time has passed .
records information and add it to the results .
adds summary results ( single number for one test run ) .
"given a |pexe| the |arch| for translation and additional pnacl - translate |flags| , check that the commandline for llc really contains the |expected_flags| . this ensures that the pnacl - translate script does not drop certain flags accidentally ."
user - friendly name of this profiler .
true iff this profiler is currently supported by the platform .
override to customize the browser 's options before it is created .
called before the browser is stopped .
returns a dict with pid : output_file .
collect the profile from the profiler .
adds a ' usage_more ' property to a cmd function .
adds an ' epilog ' property to a cmd function .
prints list of commands or help for a specific command .
returns the colorama module if available .
module is the name of the main python module where to look for commands .
returns a dict of command and their handling function .
retrieves the function to handle a command .
generates the short list of supported commands .
modifies an optionparser object with the function 's documentation .
creates a oneline summary from the command 's docstring .
dispatches execution to the right command .
"parse options and call run - webkit - tests , using python from the tree ."
make a win32 event object for a socket .
add a new win32 event to the event loop .
remove an event .
add a socket filedescriptor for notification of data available to read .
add a socket filedescriptor for notification of data available to write .
remove a selectable for notification of data available to read .
remove a selectable for notification of data available to write .
"remove all selectables , and return a list of them ."
spawn a process .
return the canonical name of the cipher whose number is provided .
return the canonical name of the mac whose number is provided .
factory method for creating plistwriter objects . see the constructor of templatewriter for description of arguments .
adds a plist key - value pair to a parent xml element .
"adds a plist key - value pair to a parent xml element , where the value element contains a string . the name of the value element will be < string > ."
adds the following xml snippet to an xml element : < key > pfm_targets</key > < array > < string > user - managed</string > < /array >
check that pnacl_flag does n't get passed to clang .
test that we do not pass the made - up --pnacl- * flags along to clang .
"return the gsutil executable path . if we ca n't find it , download it ."
gets the file at file_path if it has a hash file that does n't match .
calculates and returns the hash of the file at file_path .
"given a list of files , call isolateserver.py with them . then verify they are all on the server ."
tries to download the files from the server .
instantiates subclass of factorycommands appropriate for skia .
does a ' make clean '
adds a compile step to the build .
adds a step that uploads a file to a google storage bucket .
adds a step that commits all files within a directory to a special svn repository .
runs something we built .
"when set to true , the first run of the test is discarded . this is useful for cases where it 's desirable to have some test resource cached so the first run of the test can warm things up ."
"when set to true , the browser 's disk and memory cache will be cleared before each run ."
"when set to true , all tabs are closed before running the test for the first time ."
maximum number of times test will be attempted .
maximum number of failures allowed for the page set .
maximum number of errors allowed for the page set .
should the browser be restarted for the page ?
should the browser be stopped after the page is run ?
override to add test - specific options to the browseroptions object
set options specific to the test and the given page .
override to manipulate the browser environment before it launches .
override to customize the browser right after it has launched .
override to customize if the test can be ran for the given page .
override to do operations before the page set(s ) are navigated .
override to do operations after all page set(s ) are completed .
override to do operations before each page is iterated over .
override to do operations after each page is iterated over .
override to do operations after the http server is started .
"override to do operations before the page is navigated , notably telemetry will already have performed the following operations on the browser before calling this function : * ensure only one tab is open . * call waitfordocumentreadystatetocomplete on the tab ."
override to do operations right after the page is navigated and after all waiting for completion has occurred .
override to do operations before running the actions on the page .
override to do operations after running the actions on the page .
"called after the test run method was run , even if it failed ."
override to make this test generate its own expectations instead of any that may have been defined in the page set .
"override to select a different tab for the page . for instance , to create a new tab for every page , return browser.tabs . new ( ) ."
override to examine the page set before the test run . useful for example to validate that the pageset can be used with the test .
override to check the actual test assertions .
navigates the tab to the page url attribute .
"|compiled_fs_chain| is a list of tuples ( compiled_fs , file_system ) ."
checks the tsan suppressions files for bad suppressions .
launches the browser for the given profile name . it is assumed the profile already exists .
kill the browser .
blocks until the extension is connectable in the firefox .
return the command to start firefox .
returns the fully qualified path by searching path of the given name
"same as the parent class method , but this also adds some source - specific patches :"
assert that the sourcedata ( from the patched functions - see make_command ) is correct . use this as a deferred callback .
"return the fully qualified name of a module , class , method or function . classes and functions need to be module level ones to be correctly qualified ."
return the warning method currently used to record deprecation warnings .
set the warning method to use to record deprecation warnings .
return a string indicating that the python name was deprecated in the given version .
return a string indicating that the callable was deprecated in the given version .
return a decorator that marks callables as deprecated .
append the given text to the docstring of c{thingwithdoc } .
mark a module - level attribute as being deprecated .
declare a module - level attribute as being deprecated .
get a string containing the type of the module proxy and a representation of the wrapped module object .
set an attribute on the wrapped module object .
get an attribute on the wrapped module object .
initialise a deprecated name wrapper .
get the underlying attribute value and issue a deprecation warning .
recursively compares two objects ( original and deserialized ) .
i{getpwuid } accepts a uid and returns the user record associated with it .
i{getpwuid } raises l{keyerror } when passed a uid which does not exist in the user database .
i{getpwnam } accepts a username and returns the user record associated with it .
i{getpwnam } raises l{keyerror } when passed a username which does not exist in the user database .
"the user record returned by i{getpwuid } , i{getpwnam } , and i{getpwall } has a length ."
"the user record returned by i{getpwuid } , i{getpwnam } , and i{getpwall } is indexable , with successive indexes starting from 0 corresponding to the values of the c{pw_name } , c{pw_passwd } , c{pw_uid } , c{pw_gid } , c{pw_gecos } , c{pw_dir } , and c{pw_shell } attributes , respectively ."
create a l{userdatabase } with no user data in it .
add a new user to c{self.database } and return its information .
"l{userdatabase.adduser } accepts seven arguments , one for each field of a l{pwd.struct_passwd } , and makes the new record available via l{userdatabase.getpwuid } , l{userdatabase.getpwnam } , and l{userdatabase.getpwall } ."
"read and return the next record from c{self._users } , filtering out any records with previously seen uid values ( as these can not be found with c{getpwuid } and only cause trouble ) ."
"tries to parse a dictionary into a corresponding date , datespan , time , or timespan instance ."
"check that you can update a message ( optimistically or not ) , and that the update is queued in the actionlog ."
provider dict should be exportable as json
sync a new draft back to the remote backend .
sync an updated draft back to the remote backend .
"delete a draft from the remote backend . ` args ` should contain an ` nylas_uid ` or a ` message_id_header ` key . this is used to find the draft on "" the backend ."
create an email on the remote backend . generic providers expect us to create a copy of the message in the sent folder .
"delete an email on the remote backend , in the sent folder ."
test that all subclasses of hasrevisions are mapped by the transaction_objects ( ) function .
gmail addresses with and without periods are the same .
make the tables .
returns a session that implements two - phase - commit . parameters ---------- engine_map : dict mapping of table cls instance : database engine
returns a session bound to the given engine .
provide a transactional scope around a series of operations .
"may be overriden by subclasses . this should be the list of relationship attribute names that should trigger an update revision when changed . ( we want to version changes to some , but not all , relationship attributes . )"
"may be overridden by subclasses . this is the list of attribute names that should trigger an update revision for a /related/ object - for example , when a message 's ` is_read ` or ` categories ` is changed , we want an update revision created for the message 's thread as well . such manual propagation is required because changes to related objects are not reflected in the related attribute 's history , only additions and deletions are . for example , thread.messages.history will not reflect a change made to one of the thread 's messages ."
"may be overridden by subclasses . we do n't want to version certain specific objects - for example , block instances that are just raw message parts and not real attachments . use this property to suppress revisions of such objects . ( the need for this is really an artifact of current deficiencies in our models . we should be able to get rid of it eventually . )"
"return true if the object has changes on any of its column properties or any relationship attributes named in self.versioned_relationships , or has been manually marked as dirty ( the special ' dirty ' instance attribute is set to true ) ."
squared exponential covariance function
exponential covariance function
matern covariance function with nu=3/2
matern space covariance function with nu=5/2
wendland space covariance function
sparse wendland space covariance function
squared exponential for temporal and spatial covariance .
exponetial for temporal covariance . squared exponential for spatial covariance .
1 - d c2 wendland function for temporal covariance . squared exponential for spatial covariance .
1 - d c4 wendland function for temporal covariance . squared exponential for spatial covariance .
1 - d c2 wendland function for temporal covariance . squared exponential for spatial covariance .
1 - d c4 wendland function for temporal covariance . squared exponential for spatial covariance .
first - order gauss - markov for temporal covariance . squared exponential for spatial covariance .
brownian motion for temporal covariance . squared exponential for spatial covariance .
integrated brownian motion for temporal covariance . squared exponential for spatial covariance .
matern ( nu=3/2 ) function for temporal covariance . squared exponential for spatial covariance .
matern ( nu=5/2 ) function for temporal covariance . squared exponential for spatial covariance .
"supposed to be a generic test that will check that metadata is created , updated and deleted in the search layer ."
returns an object that can be used as a generator . this should be used when streaming large files directly to the client .
"ensures artifact exists . this just wraps ` self._get_key ` which uses ` bucket.get_key ` from boto . boto does a head request to validate an artifact exists and returns none if it does not , a ` key ` object if it does . our ` _ get_key ` function raises an ` artifactnotfounderror ` if get_key returns ` none ` ."
uploads an artifact . if directory does not exist in path it will be created .
just gets the content of the artifact instead of streaming it to a file pointer . this should n't be used unless artifact is small enough to easily fit into memory
creates or updates artifact from a string .
gets md5hash of file .
gets the contents of a directory .
makes sure that the bucket we are trying to access is accessible . this covers three things .
"for use in "" with "" syntax"
"for use in "" with "" syntax"
builds elasticsearch query .
builds query based on search criteria encapsulated by the search object .
this function is used to generate metadata that will be put back to the metadata endpoint but removes things that will be initialized which also happen to be immutable .
args : config(dict ): the configuration file decoded logger(logging . logger )
returns : shelf.bulk_update.runner . runner
"function draws "" circle plot "" and exports axis handles"
calculates the intercontacttimes of each edge in a network
this function check if given midi event is meaningful
this function converts given notenum to ss13 note according to previous runs expressed using _ accidentals _ and _ octaves _
this functions returns float representation of duration ready to be added to the note after /
asks user to select midi and returns this file opened in binary mode for reading
"transforms aforementioned file into a score , truncates it and returns it"
filters out irrevelant events and returns new score
filters out empty tracks and returns new score
recreates score with only note numbers and start time of each note and returns new score
merges all tracks together and returns new score
sorts events by start time and returns new score
transform start_time into delta_time and returns new score
rounds delta times to the nearest multiple of time quanta as byond ca n't process duration less than that and returns new score
returns the most frequent duration throughout the whole melody
"reforms score into a chord - duration list : [ [ chord_notes ] , duration_of_chord ] and returns it"
returns unformated sheet music from score
splits unformatted sheet music into formated lines of line_len_lim and such and returns a list of such lines
"recreates sheet music from exploded sheet music , truncates it and returns it"
activate the script
"given a neo object , return a dictionary of attributes and annotations ."
get all ` neo ` objects of a given type from a container .
get all ` neo . spiketrain ` objects from a container .
get all ` neo . event ` objects from a container .
get all ` neo . epoch ` objects from a container .
helper function checks content of record view entry with supplied view_id
helper function creates entity data with supplied entity_id
helper function checks content of form - updated record type entry with supplied entity_id
uri for record field description data ; also view using default entity view
uri for record field description editing view
entity values used when creating a record field entity
get the base uri from the supplied uri by removing any parameters and/or fragments .
returns a key - value pair for a supplied query parameter string .
extract parameter dictionary from the supplied uri
create a merged dictionary from the supplied dictionaries and keyword parameters .
construct a uri parameter string from the supplied dictionary values ( or values which are convertible to a dictionary using ` dict ( ) ` ) .
construct a uri from the supplied base uri ( with any parameters and/or fragment removed ) and uri parameters created using the supplied dictionary values .
run annalist server tests .
message sent callback
' nginx : optimized_by_middleware ' returns x - accel response .
' nginx : optimized_by_decorator ' returns x - accel response .
return : class:`django.core.files.base . contentfile ` object .
return wrapper on ` ` six . stringio ` ` object .
return wrapper on ` ` stringiteratorio ` ` object .
apply : class:`~django_downloadview.lighttpd.middlewares . xsendfilemiddleware ` to ` ` view_func ` ` .
make ` ` test_case ` ` assert that ` ` response ` ` is a xsendfileresponse .
return url of hello-world.txt file on github .
initializes root and content - type
creates a virtual fibre mapping between given vios object and lpar args : ip : ip address of hmc managedsystem_uuid : uuid of virtualioserver x_api_session : session to be used vios_object : vios object in which mapping is created lpar_id : uuid of logical partition to which mapping is created
"makes an httprequest to get the details of the corresponding object and store the response content into a python object . args : service : uom or web ip : ip address of the hmc root : root element in rest uri content_type : type of object to be extracted ( logicalpartition , logicalpartitionprofile , managedsystem , virtualioserver and other objects ) session_id : to access the session uuid : root unique i d returns : list of corresponding objects"
assign the root and content_type for request
args : ip : ip address of hmc cluster_id : the uuid of the cluster in which the lu to be clonned x_api_session : the session used for cloning lu source_udid : source lus unique device id dest_udid : destination lus unique device id
this function is used for the performance and capacity monitoring of the hmc
changes the adapter mode from shared to dedicated and dedicated to shared args : ip : ip address of hmc managedsystem_uuid : uuid of the managedsystem adapter_object : object of sriov adapter to change the mode x_api_session : session to be used
controls the cluster menu args : choice : option to perform corresponding function ip : ip address of hmc x_api_session : session to be used
initializes root and content_type args : partition_type : type of object logical partition or virtualioserver
performs poweron operation for the provided logicalpartition object args : ip : ip address of hmc logicalpartition_object : object of the logical partition to be activated session_id : session to be used
performs the httppost request with modified volume group
adds a physical volume to the selected volume group args : ip : ip address of hmc vios_uuid : uuid of virtualioserver x_api_session : session to be used volumegroup_object : volume group object to be modified
creates a virtualdisk in volumegroup args : ip : ip address of hmc vios_uuid : uuid of virtualioserver x_api_session : session to be used volumegroup_object : volume group object to be modified
"read data from file , and return indexed inputs . if this is for test , do not add new words to the vocabulary ( treat them as unk ) . pad_info is applicable when we want to pad data to a pre - specified length ( for example when testing , we want to make the sequences the same length as those from train ) ."
takes integer indices and converts them into one hot representations .
"takes a list of tuples containing indexed sentences , indexed event structures and labels , and returns numpy arrays ."
pad and/or truncate an indexed string to the max length . both padding and truncation happen from the left .
returns the information required to pad or truncate new datasets to make new inputs look like those processed so far . this is useful to make test data the same size as train data .
"reads in a gzipped pretrained embedding file , and returns a numpy array with vectors for words in word index ."
returns the number of unique words seen in indexed data .
returns time stamp for the event as a datetime object
returns event type
returns true if this is a queue event
returns true if this is a start event
returns true if this is a end event
returns true if this is a delete event
return true if the event information has the specified key
return value in the event information for the specified key
returns string representation of the event
update the job info based on this event
parse a job event info string into a dictionary
format values in info dictionary
log in to girder and return a reference to the client .
make sure we have a test collection with a folder with test data .
make sure the specified cli is installed .
get the memory use as reported by the system .
run the cli on an image and make sure we get an annotation out of it .
make sure we have a test collection with a folder with test data .
wait for a job to complete .
performs generalized laplacian of gaussian blob detection .
convert to hsi the rgb pixels in i m. adapted from https://en.wikipedia.org/wiki/hsl_and_hsv#hue_and_chroma .
"compute the stain matrix for color deconvolution with the pca - based "" macenko "" method ."
take a 2xn matrix of vectors and return a length - n array of an angle - like quantity .
calculate the index in arr of the element nearest the pth percentile .
calculates features for nuclei classification
removes small objects from label image .
check vector v for validity
generate valid test vectors
generate possibly invalid vector
return true with p(p )
generate invalid test vectors
convolve an array with a kernel using fft . implemntation based on the convolve_fft function from astropy .
return the number of rows in the model .
return role specific data for the item referred by the index .
set the role data for the item at index to value .
return the active flags for the given index
insert items at a given position in the model .
remove items from the model .
insert items at the end of model .
return the data stored in the model at the given index .
entry point for generating required kernel configuration items from portage installed packages .
print message to stdout if _ _ verbose is true .
roll dice and return a string of the results as well as the total .
"[ random.randint(1 , faces ) for _ in range(dice ) ] simulate a roll using normal distributions . do it as many times as neccessary to avoid float inaccuracy , unless that means rolling more times than limit ."
use a normal distribution to roll some dice . method hits float inaccuracies rather easily . in order to avoid float inaccuracy you 'll need to make sure that : 1 . dice has fewer than 16 digits 2 . faces has fewer than 8 digits 3 . dice and faces have fewer than 16 digits combined
proxy should be the domain name ezproxy is installed on . see the subclasses that come with with this code for some examples .
login to an ezproxy proxy using its default login address and its default credentials of a library barcode number + last name
rewrite all requests going through this session to go through the library proxy .
hook send ( ) purely for tracing
"notice : uw flips the order of user / pass : name is the username and barcode is the pass . by default , ezproxy has them the other way ."
dynamically mix in classes before a given obj 's type .
todo : document
ask a y / n question ; defaults to * no * on errors
"exhaust a generator to a list , and additionally return its return value which normally you need to catch in an exception handler . returns : ( list(g ) , return_value )"
"moving window generator example : given a sequence g = [ 1,2,3,4 , ... ] and windowsize n=2 , return the sequence [ ( 1,2 ) , ( 2,3 ) , ( 3,4 ) , ... ]"
remove trailing newline
flatten a nested list by one level
"parse an integer , possibly an american - style comma - separated integer ."
"check that the string w is a wos number you find these in the ' ut ' field in exported .isi files . it is also called the "" accession number """
"parse an isi format "" date "" ( pd field ) . this sometimes does n't exist , sometimes includes a month , and sometimes includes a day , and sometimes includes a year ."
read records from an open isi - format file
"utf-8 - sig is the most widely compatible text codec . it handles both ascii files ( because of utf-8 backwards compatibility ) and most unicode files , with or without a bom . if you happen to have a different encoding , you can provide it . see the codecs module for options . todo : use the chardet module ?"
"encode dict of form fields and dict of files as multipart / form - data . return tuple of ( body_string , headers_dict ) . each value in files is a dict with required keys ' filename ' and ' content ' , and optional ' mimetype ' ( if not specified , tries to guess mime type or uses ' application / octet - stream ' ) ."
overload of the qwizard iscomplete method .
overload of the qwizardpage nextid method .
sets up the user interface .
connects the signals with the related slots .
overload of the bwizard reloaddata method .
slot called when the user click on an entry of the toolchain list .
slot called when the user adds manually a toolchain .
slot called when the user removes manually a toolchain .
slot called when the user clicks on the ' search ' button . it opens the toolchain search dialog .
slot called when the user clicks on the validate button . it starts the toolchain validation procedure for all the toolchains .
fills the toolchain list with the toolchains stored in the qsettings .
removes all the toolchain from the list .
"searches for toolchains in the stored directories , and stores them in the qsettings ."
sets the item at index as a valid item and associates the given info to it .
sets the item at index as an invalid item .
toolchain validation procedure .
returns true if the given toolchain is one of the default toolchains .
disable the remove button .
enable the remove button .
start the udpplugin
shutdown the plugin
schedule the timer for the next sending
submit a monitor point or alarm with the give id to the java plugin .
the periodic task that send monitor points to the java plugin through the udp socket
send the passed monitor points to the java plugin through the udp socket
test if the license file exists in the created module
test if the plugin send nothing before being started
test that the plugin send a monitor point to the udp after being started
test that the plugin effectively sent what has been submitted
constructor @param srcfolder : the folder with sources to generate their documentation @param dstfolder : destination folder for the api docs @param outfile : the file where the output generated by calling java / scala / py - doc must be sent
"check if the source and dest folders are valid and if it is not the case , throws an exception @param src : the folder with java sources to check @param dst : destination folder to check"
@param folder : the folder ( src or test ) to check if contains java sources @param fileextension : the extension of the files that the folder is supposed to contain @return : true if the passed folder contains java sources
scan the source folder and return a list of source folders containg java files . java source can be contained into src or test ( the latter is used only if the includetestfolder parameter is true ) the search is recursive because a folder can contains several modules
get handler for help page
construct page for help
construct page for changelog
construct page for changelog
get handler for help page
construct page for help
handles requests for new bands
"create a new instance of the retrievestatistics choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the days input for this choreo . ( ( optional , integer ) the number of days ( greater than 0 ) for which block data will be retrieved . )"
"set the value of the enddate input for this choreo . ( ( optional , string ) specify the end of the date range for which blocks are to be retireved . the specified date must be in yyyy - mm - dd format . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format of the response from sendgrid , in either json , or xml . default is set to json . )"
"set the value of the startdate input for this choreo . ( ( optional , string ) the start of the date range for which blocks are to be retireved . the specified date must be in yyyy - mm - dd format , and must be earlier than the enddate variable value . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from sendgrid . the format corresponds to the responseformat input . default is json . )"
"create a new instance of the createinvite choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the inviteduseremail input for this choreo . ( ( conditional , string ) the email address of the user to invite ; user can be a fitbit member already . required unless providing the inviteduserid . )"
"set the value of the inviteduserid input for this choreo . ( ( conditional , string ) the fitbit user i d of the user to send an invite to . required unless providing the inviteduseremail . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from fitbit . )"
"create a new instance of the getwatergoal choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"create a new instance of the getlastcall choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountsid input for this choreo . ( ( required , string ) the accountsid provided when you signed up for a twilio account . )"
"set the value of the authtoken input for this choreo . ( ( required , string ) the authorization token provided when you signed up for a twilio account . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from twilio . )"
"create a new instance of the deletephonenumber choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountsid input for this choreo . ( ( required , string ) the accountsid provided when you signed up for a twilio account . )"
"set the value of the authtoken input for this choreo . ( ( required , string ) the authorization token provided when you signed up for a twilio account . )"
"set the value of the incomingphonenumbersid input for this choreo . ( ( required , string ) the i d of the incoming phone number to retrieve . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the subaccountsid input for this choreo . ( ( optional , string ) the sid of the subaccount associated with the phone number . if not specified , the main accountsid used to authenticate is used in the request . )"
"create a new instance of the obtaincontactinformation choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by constant contact . )"
"set the value of the contactid input for this choreo . ( ( required , integer ) the id for the contact you want to retrieve information for . )"
"set the value of the password input for this choreo . ( ( required , password ) your constant contact password . )"
"set the value of the username input for this choreo . ( ( required , string ) your constant contact username . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from constant contact . )"
"create a new instance of the listrecentphotos choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by flickr ( aka the oauth consumer key ) . )"
"set the value of the extras input for this choreo . ( ( optional , string ) a comma - separated list returning additional photo information such as : license , description , date_upload , date_taken . additional options are listed on this method 's api doc page . )"
"set the value of the page input for this choreo . ( ( optional , integer ) specify the page of photos that is to be returned . if unspecified , the first page is returned . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) specify how many photos to display per page . default is set to : 100 . the mamimum allowed value is : 500 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml and json . defaults to json . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from flickr . )"
"create a new instance of the logbodyweight choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the date input for this choreo . ( ( required , date ) the date that corresponds with the new log entry ( in the format yyyy - mm - dd ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the time input for this choreo . ( ( optional , string ) time of the measurement ; hours and minutes in the format hh : mm : ss ; set to last second of the day if not provided . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"set the value of the weight input for this choreo . ( ( required , decimal ) a new value ( in pounds ) to log for weight . in the format of x.xx . )"
"create a new instance of the getlatestunreademail choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the label input for this choreo . ( ( optional , string ) the name of a gmail label to retrieve messages from ( e.g. , important , starred , sent , junk - e - mail , all ) . )"
"set the value of the password input for this choreo . ( ( optional , password ) a google app - specific password that you 've generated after enabling 2 - step verification ( note : authenticating with oauth credentials is the preferred authentication method ) . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format for the response . valid values are json and xml . this will be ignored when providng an xpath query because results are returned as a string or json depending on the mode specified . )"
"set the value of the username input for this choreo . ( ( optional , string ) your full google email address e.g. , martha.temboo@gmail.com ( note : authenticating with oauth credentials is the preferred authentication method ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from google . this will contain the data from the gmail feed , or if the xpath input is provided , it will contain the result of the xpath query . )"
"retrieve the value for the "" authoremail "" output from this choreo execution . ( ( string ) the author 's email address . )"
"retrieve the value for the "" authorname "" output from this choreo execution . ( ( string ) the author 's name . )"
"retrieve the value for the "" messagebody "" output from this choreo execution . ( ( string ) the email body . note that this corresponds to the "" summary "" element in the feed . )"
"retrieve the value for the "" newaccesstoken "" output from this choreo execution . ( ( string ) contains a new accesstoken when the refreshtoken is provided . )"
"retrieve the value for the "" subject "" output from this choreo execution . ( ( string ) the subject line of the email . note that this corresponds to the "" title "" element in the feed . )"
"create a new instance of the updatesigningcertificate choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the certificateid input for this choreo . ( ( required , string ) the id of the signing certificate you want to update . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the status input for this choreo . ( ( required , string ) the status you want to assign to the certificate . active means the certificate can be used for api calls to aws , while inactive means the certificate can not be used . )"
"set the value of the username input for this choreo . ( ( optional , string ) name of the user the signing certificate belongs to . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from amazon . )"
"create a new instance of the getlistingspercentiles choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the bedrooms input for this choreo . ( ( optional , integer ) limits the results by number of bedrooms to search for . defaults to 1 . )"
"set the value of the daterange input for this choreo . ( ( required , string ) sets the quarter , month , week or day for the results ( i.e. 2008 - q1 , 2008 - w52 , 2007 - 07 , 2010 - 10 - 01 , etc ) . )"
"set the value of the geoextentlevel input for this choreo . ( ( required , string ) the geographical unit for the results ( i.e. borough , neighborhood , or zip ) . )"
"set the value of the geoextentvalue input for this choreo . ( ( required , string ) limits the search to a specific area . for example , if geoextentlevel is borough , the value for geoextentvalue could be brooklyn . )"
"set the value of the geosummarylevel input for this choreo . ( ( required , string ) the geographic unit for grouping the results ( borough , neighborhood , or zip ) . )"
"set the value of the percentile input for this choreo . ( ( required , integer ) specify a percentile for the listing prices you want to retrieve ( i.e 50 ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from the ny times api . )"
"create a new instance of the logsleep choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the date input for this choreo . ( ( required , date ) the date that corresponds with the log entry you want to create ( in the format yyyy - mm - dd ) . )"
"set the value of the duration input for this choreo . ( ( required , string ) the sleep duration in milliseconds . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the starttime input for this choreo . ( ( required , string ) the sleep start time ; hours and minutes in the format hh : mm . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"create a new instance of the deletewordlist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from wordnik . )"
"set the value of the password input for this choreo . ( ( required , string ) the password of the wordnik account . )"
"set the value of the username input for this choreo . ( ( required , string ) the username of the wordnik account . )"
"set the value of the wordlist input for this choreo . ( ( required , string ) the perma - link of the wordlist to delete . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from wordnik . )"
"create a new instance of the listposts choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid oauth 2.0 access token . )"
"set the value of the category input for this choreo . ( ( optional , integer ) specify a category id for which posts wil be retrieved . )"
"set the value of the cursor input for this choreo . ( ( optional , string ) default is set to null . )"
"set the value of the forum input for this choreo . ( ( optional , string ) forum short name ( i.e. , the subdomain of the disqus site url ) to display all posts contained in that forum . if null , posts from all forums moderated by the authenticating user will be retrieved . )"
"set the value of the include input for this choreo . ( ( optional , string ) a post status parameter to filter results by . valid parameters include : unapproved , approved , spam , deleted , flagged , highlighted . default is set to : approved . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of records to return . defaults to 25 . )"
"set the value of the order input for this choreo . ( ( optional , string ) the sort order of the results . valid values are : asc or desc . default is set to : asc . )"
"set the value of the publickey input for this choreo . ( ( required , string ) the public key provided by disqus ( aka the api key ) . )"
"set the value of the query input for this choreo . ( ( optional , string ) a search string to retrieve posts mathching the query . default is set to null . )"
"set the value of the related input for this choreo . ( ( optional , string ) specify a related thread or forum that are to be included in the response . valid entries include : thread , or forum . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) , jsonp , or rss . )"
"set the value of the sinceid input for this choreo . ( ( optional , integer ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the since input for this choreo . ( ( optional , string ) a unix timestamp ( or iso datetime standard ) to obtain results from . ( e.g. 2014 - 02 - 02t01:01:00z ) default is set to null . )"
"set the value of the threadid input for this choreo . ( ( optional , string ) the thread id to narrow post search results . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from disqus . )"
"create a new instance of the retrieveaggregates choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the aggregate input for this choreo . ( ( required , integer ) retrieve all time totals . must be set to 1 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format of the response from sendgrid , in either json , or xml . default is set to json . )"
"create a new instance of the createuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the email input for this choreo . ( ( required , string ) the email address you use to login to your zendesk account . )"
"set the value of the password input for this choreo . ( ( required , password ) your zendesk password . )"
"set the value of the server input for this choreo . ( ( required , string ) your zendesk domain and subdomain ( e.g. , temboocare.zendesk.com ) . )"
"set the value of the userdata input for this choreo . ( ( required , json ) a json - formatted string containing the user properties you wish to set . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) )"
"create a new instance of the updateitem choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the itemid input for this choreo . ( ( required , string ) the i d of an item on a list that you wish to update . )"
"set the value of the listid input for this choreo . ( ( required , string ) the id of a user - created list to update )"
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the photoid input for this choreo . ( ( optional , string ) if present and non - empty , adds a photo to this item . if present and empty , will remove the photo on this item . if the photo was a private checkin photo , it will be promoted to a public venue photo . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the text input for this choreo . ( ( optional , string ) if present , this creates a public tip on the venue and replaces any existing tip on the item . can not be used in conjuction with tipid or photoid . )"
"set the value of the tipid input for this choreo . ( ( optional , string ) the i d of a tip to add to the list . can not be used in conjunction with the text and url inputs . note that one of the following must be specified : venueid , tipid , itemlistid , or itemid . )"
"set the value of the url input for this choreo . ( ( optional , string ) if adding a new tip using the text input , this can associate a url with the tip . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from foursquare . corresponds to the responseformat input . defaults to json . )"
"create a new instance of the getweeklychartlist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
set the value of the apikey input for this choreo . ( ( string ) your last.fm api key . )
set the value of the user input for this choreo . ( ( string ) the last.fm username to fetch the charts of . )
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from last.fm . )"
"create a new instance of the search choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( conditional , string ) the access token retrieved from the final oauth step . )"
"set the value of the center input for this choreo . ( ( conditional , string ) the coordinates for a place ( such as 37.76,122.427 ) . used only when specifying an object type of "" place "" . )"
"set the value of the distance input for this choreo . ( ( optional , integer ) the distance search parameter used only when specifying an object type of "" place "" . defaults to 1000 . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) used to page through results . limits the number of records returned in the response . )"
"set the value of the objecttype input for this choreo . ( ( required , string ) the type of object to search for such as : user , page , event , group , or place . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) used to page through results . returns results starting from the specified number . )"
"set the value of the query input for this choreo . ( ( conditional , string ) the facebook query term to send in the request . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the since input for this choreo . ( ( optional , date ) used for time - based pagination . values can be a unix timestamp or any date accepted by strtotime . )"
"set the value of the until input for this choreo . ( ( optional , date ) used for time - based pagination . values can be a unix timestamp or any date accepted by strtotime . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from facebook . corresponds to the responseformat input . defaults to json . )"
"retrieve the value for the "" hasnext "" output from this choreo execution . ( ( boolean ) a boolean flag indicating that a next page exists . )"
"retrieve the value for the "" hasprevious "" output from this choreo execution . ( ( boolean ) a boolean flag indicating that a previous page exists . )"
"create a new instance of the listattachmentsforbug choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the attachmentswithdata input for this choreo . ( ( optional , integer ) enter 1 to obtain full bug attachments data . if null , only attachments fields will be returned with no associated data . )"
"set the value of the bugid input for this choreo . ( ( required , integer ) the id for the bug to list attachments for . )"
"set the value of the password input for this choreo . ( ( optional , password ) your bugzilla password . )"
"set the value of the server input for this choreo . ( ( optional , string ) the base url for the bugzilla server to access . defaults to https://api-dev.bugzilla.mozilla.org/latest . to access the test server , set to https://api-dev.bugzilla.mozilla.org/test/latest . )"
"set the value of the username input for this choreo . ( ( optional , string ) your bugzilla username . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from bugzilla . )"
"create a new instance of the gethistoricalupdates choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by linkedin ( aka the client id ) . )"
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process ( aka the oauth user secret ) . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process ( aka the oauth user token ) . )"
"set the value of the companyid input for this choreo . ( ( required , integer ) a linkedin assigned id associated with the company . )"
"set the value of the endtimestamp input for this choreo . ( ( optional , date ) the starting timestamp of when the stats search should begin ( milliseconds since epoch ) . the current time will be used if a timestamp is not provided . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml ( the default ) and json . )"
"set the value of the secretkey input for this choreo . ( ( required , string ) the secret key provided by linkedin ( aka the client secret ) . )"
"set the value of the starttimestamp input for this choreo . ( ( required , date ) the starting timestamp of when the stats search should begin ( milliseconds since epoch ) . the current time will be used if a timestamp is not provided . )"
"set the value of the timegranularity input for this choreo . ( ( required , string ) granularity of statistics . valid values are : day , month . )"
"set the value of the updatekey input for this choreo . ( ( optional , string ) optionally provide an update key value to return statistics for a specific company update . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from linkedin . )"
"create a new instance of the musicandthearts choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( optional , string ) the apikey provided by donorschoose.org . defaults to the test apikey ' donorschoose ' . )"
"set the value of the index input for this choreo . ( ( optional , integer ) the number of the first row to return in the result . for example , if index=10 , the results could show rows 10 - 59 . )"
"set the value of the max input for this choreo . ( ( optional , integer ) the max number of projects to return . can return up to 50 rows at a time . defaults to 10 when left empty . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to xml . )"
"set the value of the showcounts input for this choreo . ( ( optional , boolean ) set to 1 to return facet counts in the response )"
"set the value of the showsynopsis input for this choreo . ( ( optional , boolean ) set to 1 to show the synopsis for each project listing )"
"set the value of the subject input for this choreo . ( ( optional , string ) enter a sub - category of music & the arts . when left empty , all art & music projects are returned . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from donorschoose.org )"
"create a new instance of the getdrivingdirections choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the alternatives input for this choreo . ( ( optional , string ) if set to true , additional routes will be returned . )"
"set the value of the avoid input for this choreo . ( ( optional , string ) specify whether the calculated directions should avoid the following features : tolls , or highways . )"
"set the value of the destination input for this choreo . ( ( required , string ) enter the address or latitude / longitude coordinates from which directions will be generated ( i.e. ""104 franklin st , new york , ny "" or "" 40.7160,-74.0037 "" ) . )"
"set the value of the origin input for this choreo . ( ( required , string ) enter the address or latitude / longitude coordinates from which directions will be computed ( i.e. ""104 franklin st , new york , ny "" or "" 40.7160,-74.0037 "" ) . )"
"set the value of the region input for this choreo . ( ( optional , string ) enter the region code for the directions , specified as a cctld two - character value . )"
"set the value of the sensor input for this choreo . ( ( optional , boolean ) indicates whether or not the directions request is from a device with a location sensor . value must be either 1 or 0 . defaults to 0 ( false ) . )"
"set the value of the units input for this choreo . ( ( optional , string ) specify the units to be used when displaying results . options include , metric , or imperial . )"
"set the value of the waypoints input for this choreo . ( ( optional , string ) specify route waypoints , either by address , or latitude / longitude coordinates . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from google . )"
"create a new instance of the toprecipientorganizations choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by sunlight data services . )"
"set the value of the entityid input for this choreo . ( ( required , string ) the id for the entity that you want to return information for . this id can be retrieved by running the searchbyname choreo . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of resutls to return . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from influence explorer . )"
"create a new instance of the listall choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by onelogin . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from onelogin . )"
"create a new instance of the createquotepost choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the quote input for this choreo . ( ( required , string ) the full text of the quote . )"
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by tumblr ( aka the oauth consumer key ) . )"
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the basehostname input for this choreo . ( ( required , string ) the standard or custom blog hostname ( i.e. temboo.tumblr.com ) . )"
"set the value of the date input for this choreo . ( ( optional , date ) the gmt date and time of the post . can be an epoch timestamp in milliseconds or formatted like : dec 8th , 2011 4:03pm . defaults to now ( ) . )"
"set the value of the markdown input for this choreo . ( ( optional , boolean ) indicates whether the post uses markdown syntax . defaults to false . set to 1 to indicate true . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the secretkey input for this choreo . ( ( required , string ) the secret key provided by tumblr ( aka the oauth consumer secret ) . )"
"set the value of the slug input for this choreo . ( ( optional , string ) adds a short text summary to the end of the post url . )"
"set the value of the source input for this choreo . ( ( optional , string ) the cited source of the quote . html is allowed . )"
"set the value of the state input for this choreo . ( ( optional , string ) the state of the post . specify one of the following : published , draft , queue . defaults to published . )"
"set the value of the tags input for this choreo . ( ( optional , string ) comma - separated tags for this post . )"
"set the value of the tweet input for this choreo . ( ( optional , string ) manages the autotweet ( if enabled ) for this post . set to "" off "" for no tweet . enter text to override the default tweet . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from tumblr . default is json , can be set to xml by entering ' xml ' in responseformat . )"
"create a new instance of the deleteentry choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the entryid input for this choreo . ( ( required , string ) this can be the individual i d of the sleep entry , or you can pass the full uri for the entry as returned from the retrieveentries choreo ( i.e. /sleep/-12985593 - 1351022400000 ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( boolean ) contains the string "" true "" when an entry is deleted successfully . )"
"create a new instance of the objectdelete choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by cloudmine after registering your app . )"
"set the value of the all input for this choreo . ( ( conditional , boolean ) indicates that all keys should be deleted if the keys input is left empty . set to "" true "" to delete all keys . )"
"set the value of the applicationidentifier input for this choreo . ( ( required , string ) the application identifier provided by cloudmine after registering your app . )"
"set the value of the keys input for this choreo . ( ( conditional , string ) a comma separated list of keys to delete . required unless specifying "" true "" for the all parameter . )"
"set the value of the sessiontoken input for this choreo . ( ( conditional , string ) the session token for an existing user ( returned by the accountlogin choreo ) . this is only required if your app is performing this operation on behalf of another user . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from cloudmine . )"
"create a new instance of the listsnapshots choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the filter input for this choreo . ( ( optional , string ) a filter expression for narrowing results in the form : { field_name } { comparison_string } { literal_string } ( e.g. name eq testsnapshot ) . comparison strings can be eq ( equals ) or ne ( not equals ) . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of results to return . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" found in the response which is used to page through results . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the getratelimitstatus choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret provided by twitter or retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token provided by twitter or retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the api key ( or consumer key ) provided by twitter . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the api secret ( or consumer secret ) provided by twitter . )"
"set the value of the resources input for this choreo . ( ( optional , string ) a comma - separated list of resources you want to know the current rate limit disposition for ( e.g. , statuses , friends , trends ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from twitter . )"
"retrieve the value for the "" limit "" output from this choreo execution . ( ( integer ) the rate limit ceiling for this particular request . )"
"retrieve the value for the "" remaining "" output from this choreo execution . ( ( integer ) the number of requests left for the 15 minute window . )"
"retrieve the value for the "" reset "" output from this choreo execution . ( ( date ) the remaining window before the rate limit resets in utc epoch seconds . )"
"create a new instance of the initializeoauth choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by tumblr ( aka the oauth consumer key ) . )"
"set the value of the accountname input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the appkeyname input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the appkeyvalue input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the forwardingurl input for this choreo . ( ( optional , string ) the url that temboo will redirect your users to after they grant access to your application . this should include the "" https:// "" or "" http:// "" prefix and be a fully qualified url . )"
"set the value of the secretkey input for this choreo . ( ( required , string ) the secret key provided by tumblr ( aka the oauth consumer secret ) . )"
"retrieve the value for the "" authorizationurl "" output from this choreo execution . ( ( string ) the authorization url that the application 's user needs to go to in order to grant access to your application . )"
"retrieve the value for the "" callbackid "" output from this choreo execution . ( ( string ) an id used to retrieve the callback data that temboo stores once your application 's user authorizes . )"
"retrieve the value for the "" oauthtokensecret "" output from this choreo execution . ( ( string ) the temporary oauth token secret that can be exchanged for permanent tokens using the finalizeoauth choreo . )"
"create a new instance of the passwordcriteria choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the maxlength input for this choreo . ( ( optional , integer ) the max length you want to allow for the password . defaults to 14 . )"
"set the value of the minlength input for this choreo . ( ( optional , integer ) the minimum length you want to allow for the password . defaults to 6 . )"
"set the value of the password input for this choreo . ( ( required , string ) the password to validate . )"
"retrieve the value for the "" match "" output from this choreo execution . ( ( string ) contains a string indicating the result of the match -- "" valid "" or "" invalid "" . )"
"create a new instance of the comparecommits choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( conditional , string ) the access token retrieved during the oauth process . required when accessing a protected resource . )"
"set the value of the base input for this choreo . ( ( required , string ) the base commit ( i.e. "" master "" ) . )"
"set the value of the head input for this choreo . ( ( required , string ) the head commit . )"
"set the value of the repo input for this choreo . ( ( required , string ) the name of the repository . )"
"set the value of the user input for this choreo . ( ( required , string ) the github username . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from github . )"
"retrieve the value for the "" limit "" output from this choreo execution . ( ( integer ) the available rate limit for your account . this is returned in the github response header . )"
"retrieve the value for the "" remaining "" output from this choreo execution . ( ( integer ) the remaining number of api requests available to you . this is returned in the github response header . )"
"create a new instance of the menu choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the clientid input for this choreo . ( ( conditional , string ) your foursquare client id , obtained after registering at foursquare . required unless using the oauthtoken input . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) your foursquare client secret , obtained after registering at foursquare . required unless using the oauthtoken input . )"
"set the value of the oauthtoken input for this choreo . ( ( conditional , string ) the foursquare api oauth token string . required unless specifying the clientid and clientsecret . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the venueid input for this choreo . ( ( required , string ) the id of the venue to retrieve menu information for . )"
"create a new instance of the delete choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth2 process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fileid input for this choreo . ( ( required , string ) the id of the file . )"
"set the value of the permissionid input for this choreo . ( ( required , string ) the id for the permission . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the createaccountalias choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the accountalias input for this choreo . ( ( required , string ) name of the account alias to create . must contain only digits , lowercase letters , and hyphens ( - ) , but can not begin or end with a hyphen . ex . : alias - account - name . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"create a new instance of the touch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth2 process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) selector specifying a subset of fields to include in the response . )"
"set the value of the fileid input for this choreo . ( ( required , string ) the id of the file to update . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the query choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by npr . )"
"set the value of the datetype input for this choreo . ( ( optional , string ) controls the meaning of startdate and enddate . values can be story or correction . )"
"set the value of the date input for this choreo . ( ( optional , string ) the exact date for which stories will be returned . format : yyyy - mm - dd the special value current is also allowed . can not be used with startdate or enddate . )"
"set the value of the enddate input for this choreo . ( ( optional , string ) the end date for which stories will be returned . format : yyyy - mm - dd can be used with startdate to search a range . can not be used with date . the meaning of this parameter can be modified with datetype . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - delimited list of fields to be returned in the output for the results . list of fields can be made up of selectable fields or compilation fields . defaults to all available fields . )"
"set the value of the idboolean input for this choreo . ( ( optional , string ) describes how ids are searched . allowed values : and , or , union . )"
"set the value of the id input for this choreo . ( ( optional , string ) comma - delimited list of id numbers corresponding to topics , music genres , programs , blogs , bios , music artists , and series . )"
"set the value of the numresults input for this choreo . ( ( optional , integer ) the number of stories to be returned up to 20 maximum . )"
"set the value of the orgid input for this choreo . ( ( optional , string ) comma - delimited list of id numbers of local stations . )"
"set the value of the requiredassets input for this choreo . ( ( optional , string ) comma - delimited list that limits the resulting set to contain only stories with a particular type of asset . allowed values : audio , image , text , and correction . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are xml ( the default ) , and json . )"
"set the value of the searchterm input for this choreo . ( ( optional , string ) term to search in npr 's search engine . can be used with searchtype to specify which fields should be searched . )"
"set the value of the searchtype input for this choreo . ( ( optional , string ) used with searchterm to specify which fields should be searched . default searches all fields . allowed values : main and full . )"
"set the value of the sort input for this choreo . ( ( optional , string ) determines the order in which the stories will be returned . default is date descending . other allowed values : date ascending , editor assigned , and featured . )"
"set the value of the startdate input for this choreo . ( ( optional , string ) the start date for which stories will be returned . format : yyyy - mm - dd can be used with enddate to search a range . can not be used with date . the meaning of this parameter can be modified with datetype . )"
"set the value of the startnum input for this choreo . ( ( optional , integer ) determines where in the result set to start returning stories . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from npr . )"
"create a new instance of the accountlogout choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by cloudmine after registering your app . )"
"set the value of the applicationidentifier input for this choreo . ( ( required , string ) the application identifier provided by cloudmine after registering your app . )"
"set the value of the sessiontoken input for this choreo . ( ( required , string ) the session token obtained from the accountlogin choreo . )"
"create a new instance of the getneighbours choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
set the value of the apikey input for this choreo . ( ( string ) your last.fm api key . )
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to fetch per page . defaults to 50 . )"
set the value of the user input for this choreo . ( ( string ) the last.fm username to fetch the neighbours of . )
"create a new instance of the removerolefrominstanceprofile choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the instanceprofilename input for this choreo . ( ( required , string ) name of the instance profile to update . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the rolename input for this choreo . ( ( required , string ) name of the role to remove . )"
"create a new instance of the getrelatedwords choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key from wordnik . )"
"set the value of the cannonical input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the limitpertype input for this choreo . ( ( optional , integer ) limits the amount of results returned for each relationship type included in the output . defaults to 10 . )"
"set the value of the relationshiptype input for this choreo . ( ( optional , string ) limits the total results per type of relationship . acceptable values inlcude adjective , noun , etc . see docs for complete list . )"
"set the value of the responsetype input for this choreo . ( ( optional , string ) response can be either json or xml . defaults to json . )"
"set the value of the usecanonical input for this choreo . ( ( optional , boolean ) if true will try to return the correct word root ( ' cats ' - > ' cat ' ) . if false returns exactly what was requested . defaults to false . )"
"set the value of the word input for this choreo . ( ( required , string ) the word you want to look up on wordnik . )"
"create a new instance of the readlikes choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( optional , string ) the i d of an action to retrieve . if an i d is not provided , a list of all like actions will be returned . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) used to page through results . limits the number of records returned in the response . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) used to page through results . returns results starting from the specified number . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the retrieverecords choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from runkeeper . )"
"create a new instance of the finalizeoauth choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the callbackid input for this choreo . ( ( required , string ) the callback token returned by the initializeoauth choreo . used to retrieve the authorization code after the user authorizes . )"
"set the value of the clientid input for this choreo . ( ( required , string ) the client id provided by salesforce . )"
"set the value of the clientsecret input for this choreo . ( ( required , string ) the client secret provided by salesforce . )"
"set the value of the suppresserrors input for this choreo . ( ( optional , boolean ) when set to true , errors received during the oauth redirect process will be suppressed and returned in the errormessage output . )"
"set the value of the timeout input for this choreo . ( ( optional , integer ) the amount of time ( in seconds ) to poll your temboo callback url to see if your app 's user has allowed or denied the request for access . defaults to 20 . max is 60 . )"
"retrieve the value for the "" accesstoken "" output from this choreo execution . ( ( string ) the access token for the user that has granted access to your application . )"
"retrieve the value for the "" errormessage "" output from this choreo execution . ( ( string ) contains an error message if an error occurs during the oauth redirect process and if suppresserrors is set to true . )"
"retrieve the value for the "" refreshtoken "" output from this choreo execution . ( ( string ) a token that may be used to obtain a new access token when the short - lived access token expires . )"
"create a new instance of the getsnapshot choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the snapshot input for this choreo . ( ( required , string ) the name of the snapshot to retrieve . )"
"create a new instance of the getpronunciations choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key from wordnik . )"
"set the value of the cannonical input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the dictionary input for this choreo . ( ( optional , string ) source dictionary to return pronunciation from . acceptable values : ahd , century , cmu , macmillan , wiktionary , webster , wordnet . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) maximum number of results to return . defaults to 50 . )"
"set the value of the responsetype input for this choreo . ( ( optional , string ) response can be either json or xml . defaults to json . )"
"set the value of the typeformat input for this choreo . ( ( optional , string ) text pronunciation type . acceptable values : ahd , arpabet , gcide - diacritical , ipa . )"
"set the value of the usecanonical input for this choreo . ( ( optional , boolean ) if true will try to return the correct word root ( ' cats ' - > ' cat ' ) . if false returns exactly what was requested . defaults to false . )"
"set the value of the word input for this choreo . ( ( required , string ) the word you want to look up on wordnik . )"
"create a new instance of the listaddresses choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the filter input for this choreo . ( ( optional , string ) a filter expression for narrowing results in the form : { field_name } { comparison_string } { literal_string } ( e.g. name eq your - address - name ) . comparison strings can be eq ( equals ) or ne ( not equals ) . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of results to return . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" found in the response which is used to page through results . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the region input for this choreo . ( ( required , string ) the name of the region associated with this request . )"
"create a new instance of the addcollaboration choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth2 process . )"
"set the value of the asuser input for this choreo . ( ( optional , string ) the id of the user . only used for enterprise administrators to make api calls for their managed users . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma - separated list of fields to include in the response . )"
"set the value of the folderid input for this choreo . ( ( required , string ) the i d of the folder that you want to create a collaboration for . )"
"set the value of the login input for this choreo . ( ( conditional , string ) the email address of someone who this collaboration applies to . required unless providing the userid . note , this does not need to be a box user . )"
"set the value of the role input for this choreo . ( ( optional , string ) the access level of the collaboration . valid values are "" viewer "" or "" editor "" . defaults to "" viewer "" . )"
"set the value of the userid input for this choreo . ( ( conditional , string ) the i d of a box user who this collaboration applies to . required unless providing the emailaddress . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from box . )"
"create a new instance of the incidentspertime choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by pagerduty . )"
"set the value of the rollup input for this choreo . ( ( optional , string ) used to rollup totals by time period . valid values are : daily , weekly , or monthly . )"
"set the value of the since input for this choreo . ( ( required , date ) the start of the date range to search ( e.g. , 2013 - 03 - 06t15:28 - 05 ) . note that including the time is optional . )"
"set the value of the subdomain input for this choreo . ( ( required , string ) the subdomain of your pagerduty site address . )"
"set the value of the until input for this choreo . ( ( required , date ) the end of the date range to search ( e.g. , 2013 - 03 - 06t15:28 - 05 ) . note that including the time is optional . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from pagerduty . )"
"create a new instance of the destroylist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret provided by twitter or retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token provided by twitter or retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the api key ( or consumer key ) provided by twitter . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the api secret ( or consumer secret ) provided by twitter . )"
"set the value of the listid input for this choreo . ( ( conditional , string ) the numerical id of the list . required unless slug is provided . )"
"set the value of the ownerid input for this choreo . ( ( optional , string ) the user id of the user who owns the list being requested by a slug . )"
"set the value of the ownerscreenname input for this choreo . ( ( optional , string ) the screen name of the user who owns the list being requested by a slug . )"
"set the value of the slug input for this choreo . ( ( optional , string ) when identifying a list by a slug , either ownerscreenname or ownerid must be provided . )"
"create a new instance of the closestmatchsearch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the format input for this choreo . ( ( optional , string ) the format of the place search results . one of xml , kml , json , georss or txt . defaults to "" xml "" . )"
"set the value of the gazetteer input for this choreo . ( ( optional , string ) the place - name source to take locations from . the options are geonames , os , naturalearth or unlock which combines all the previous . defaults to "" unlock "" . )"
"set the value of the maxrows input for this choreo . ( ( optional , integer ) the maximum number of results to return . defaults to 20 . can not exceed 1000 . )"
"set the value of the name input for this choreo . ( ( required , string ) one or more names of places to search for ( separated by commas ) . )"
"set the value of the startrow input for this choreo . ( ( optional , integer ) the row to start results display from . defaults to 1 . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from unlock . defaults to xml based on the format input parameter . )"
"create a new instance of the listorganizationsbyuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the email input for this choreo . ( ( required , string ) the email address you use to login to your zendesk account . )"
"set the value of the id input for this choreo . ( ( required , string ) id of the user . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page number of the results to be returned . used together with the number parameter to paginate a large set of results . )"
"set the value of the password input for this choreo . ( ( required , password ) your zendesk password . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) the number of results to return per page . maximum is 100 and default is 100 . )"
"set the value of the server input for this choreo . ( ( required , string ) your zendesk domain and subdomain ( e.g. , temboocare.zendesk.com ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from zendesk . )"
"retrieve the value for the "" nextpage "" output from this choreo execution . ( ( integer ) the index for the next page of results . )"
"retrieve the value for the "" previouspage "" output from this choreo execution . ( ( integer ) the index for the previous page of results . )"
"create a new instance of the createfollow choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the createdtime input for this choreo . ( ( optional , date ) the time that the action was created ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the endtime input for this choreo . ( ( optional , date ) the time that the user ended the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the expiresin input for this choreo . ( ( optional , integer ) the amount of time ( in milliseconds ) from the publish_time that the action will expire . )"
"set the value of the explicitlyshared input for this choreo . ( ( optional , boolean ) indicates that the user is explicitly sharing this action . requires the explicitly_shared capability to be enabled . )"
"set the value of the explicityshared input for this choreo . ( ( optional , boolean ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message attached to this action . setting this parameter requires enabling of message capabilities . )"
"set the value of the nofeedstory input for this choreo . ( ( optional , boolean ) whether or not this action should be posted to the users feed . )"
"set the value of the place input for this choreo . ( ( optional , string ) the facebook page id of the location associated with this action . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the profile input for this choreo . ( ( required , string ) the url or id for an open graph object representing the profile to follow . )"
"set the value of the reference input for this choreo . ( ( optional , string ) a string identifier up to 50 characters used for tracking and insights . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the starttime input for this choreo . ( ( optional , date ) the time that the user started the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the tags input for this choreo . ( ( optional , string ) a comma separated list of other profile ids that also performed this action . )"
"retrieve the value for the "" activityurl "" output from this choreo execution . ( ( string ) the url for the newly created action . )"
"create a new instance of the downloadbase64encodedfile choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( conditional , string ) the api key provided by filesanywhere . required unless supplying a valid token input . )"
"set the value of the orgid input for this choreo . ( ( conditional , integer ) defaults to 0 for a filesanywhere web account . use 50 for a filesanywhere webadvanced account . )"
"set the value of the password input for this choreo . ( ( conditional , password ) your filesanywhere password . required unless supplying a valid token input . )"
"set the value of the path input for this choreo . ( ( required , string ) the path to the file you want to download ( i.e. \johnsmith\myfolder\myfile.txt ) . )"
"set the value of the token input for this choreo . ( ( conditional , string ) if provided , the choreo will use the token to authenticate . if the token is expired or not provided , the choreo will relogin and retrieve a new token when apikey , username , and password are supplied . )"
"set the value of the username input for this choreo . ( ( conditional , string ) your filesanywhere username . required unless supplying a valid token input . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( string ) the response from filesanywhere . the response contains the base64 encoded content of the file you are downloading . )"
"retrieve the value for the "" token "" output from this choreo execution . ( ( conditional , string ) if provided , the choreo will use the token to authenticate . if the token is expired or not provided , the choreo will relogin and retrieve a new token when apikey , username , and password are supplied . )"
"create a new instance of the recordactivity choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the activity input for this choreo . ( ( required , json ) a json string containing the key / value pairs for the activity to create . see documentation for formatting examples . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( boolean ) contains the string "" true "" when an activity is created successfully . )"
"retrieve the value for the "" uri "" output from this choreo execution . ( ( string ) the activity uri that was created . )"
"create a new instance of the unlikemedia choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth 2.0 process . )"
"set the value of the mediaid input for this choreo . ( ( required , string ) the id of the media to unlike . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from instagram . )"
"create a new instance of the getspamreports choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the date input for this choreo . ( ( optional , string ) the timestamp of the block records . enter 1 to return a date in a mysql timestamp format - yyyy - mm - dd hh : mm : ss )"
"set the value of the days input for this choreo . ( ( optional , integer ) the number of days ( greater than 0 ) for which block data will be retrieved . )"
"set the value of the email input for this choreo . ( ( optional , string ) a specific email address to search for . )"
"set the value of the enddate input for this choreo . ( ( optional , string ) the end of the date range for which blocks are to be retireved . the specified date must be in yyyy - mm - dd format . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) a number to limit the number of results returned . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the beginning point in the list to retrieve bounces from . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format of the response from sendgrid , in either json , or xml . default is set to json . )"
"set the value of the startdate input for this choreo . ( ( optional , string ) the start of the date range for which blocks are to be retireved . the specified date must be in yyyy - mm - dd format , and must be earlier than the enddate variable value . )"
"create a new instance of the leadershippacs choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times )"
"set the value of the campaigncycle input for this choreo . ( ( required , integer ) enter the campaign cycle year in yyyy format . this must be an even year . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) enter json or xml . default is json . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from the ny times api corresponds to the setting ( json , or xml ) entered in the responseformat variable . default is set to json . )"
"create a new instance of the addphonenumber choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apiversion input for this choreo . ( ( optional , string ) calls to this phone number will start a new twiml session with this api version . either 2010 - 04 - 01 or 2008 - 08 - 01 . )"
"set the value of the accountsid input for this choreo . ( ( required , string ) the accountsid provided when you signed up for a twilio account . )"
"set the value of the areacode input for this choreo . ( ( conditional , integer ) the desired area code for your new incoming phone number . required unless specifying the complete phonenumber . )"
"set the value of the authtoken input for this choreo . ( ( required , string ) the authorization token provided when you signed up for a twilio account . )"
"set the value of the friendlyname input for this choreo . ( ( optional , string ) a human readable description of the new incoming phone number resource , with maximum length 64 characters . )"
"set the value of the phonenumber input for this choreo . ( ( conditional , string ) the phone number you want to purchase . required unless provided the areacode . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the smsapplicationsid input for this choreo . ( ( optional , string ) the 34 character sid of the application twilio should use to handle smss sent to this number . )"
"set the value of the smsfallbackmethod input for this choreo . ( ( optional , string ) the http method that should be used to request the smsfallbackurl . either get or post . )"
"set the value of the smsfallbackurl input for this choreo . ( ( optional , string ) a url that twilio will request if an error occurs requesting or executing the twiml defined by smsurl . )"
"set the value of the smsmethod input for this choreo . ( ( optional , string ) the http method that should be used to request the smsurl . either get or post . )"
"set the value of the smsurl input for this choreo . ( ( optional , string ) the url that twilio should request when somebody sends an sms to the new phone number . )"
"set the value of the statuscallbackmethod input for this choreo . ( ( optional , string ) the http method twilio will use to make requests to the statuscallback url . either get or post . )"
"set the value of the statuscallback input for this choreo . ( ( optional , string ) the url that twilio will request to pass status parameters ( such as call ended ) to your application . )"
"set the value of the subaccountsid input for this choreo . ( ( optional , string ) the sid of the subaccount associated with the phone number . if not specified , the main accountsid used to authenticate is used in the request . )"
"set the value of the voiceapplicationsid input for this choreo . ( ( optional , string ) the 34 character sid of the application twilio should use to handle phone calls to this number . )"
"set the value of the voicecalleridlookup input for this choreo . ( ( optional , string ) do a lookup of a caller 's name from the cnam database and post it to your app . either true or false . )"
"set the value of the voicefallbackmethod input for this choreo . ( ( optional , string ) the http method that should be used to request the voicefallbackurl . either get or post . )"
"set the value of the voicefallbackurl input for this choreo . ( ( optional , string ) a url that twilio will request if an error occurs requesting or executing the twiml defined by voiceurl . )"
"set the value of the voicemethod input for this choreo . ( ( optional , string ) the http method that should be used to request the voiceurl . either get or post . )"
"set the value of the voiceurl input for this choreo . ( ( optional , string ) the url that twilio should request when somebody dials the phone number . )"
"create a new instance of the spacialnamesearch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the format input for this choreo . ( ( optional , string ) the format of the place search results . one of xml , kml , json , georss or txt . defaults to "" xml "" . )"
"set the value of the gazetteer input for this choreo . ( ( optional , string ) the place - name source to take locations from . the options are geonames , os , naturalearth or unlock which combines all the previous . defaults to "" unlock "" . )"
"set the value of the maxlatitude input for this choreo . ( ( required , decimal ) the maximum latitude point of a bounding box . )"
"set the value of the maxlongitude input for this choreo . ( ( required , decimal ) the maximum longitude point of a bounding box . )"
"set the value of the maxrows input for this choreo . ( ( optional , integer ) the maximum number of results to return . defaults to 20 . can not exceed 1000 . )"
"set the value of the minlatitude input for this choreo . ( ( required , decimal ) the minimum latitude point of a bounding box . )"
"set the value of the minlongitude input for this choreo . ( ( required , decimal ) the minimum longitude point of a bounding box . )"
"set the value of the name input for this choreo . ( ( required , string ) one or more names of places to search for ( separated by commas ) . )"
"set the value of the operator input for this choreo . ( ( optional , any ) valid values are : "" within "" and "" intersect "" . the results will therefore be entirely within , or overlapping with ( intersecting ) , the bounding box . defaults to "" within "" . )"
"set the value of the startrow input for this choreo . ( ( optional , integer ) the row to start results display from . defaults to 1 . )"
"create a new instance of the getrelationship choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth 2.0 process . )"
"set the value of the userid input for this choreo . ( ( required , string ) the id of the target user . )"
"create a new instance of the getlist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( required , string ) a valid basecamp account name . this is the first part of the account 's url . )"
"set the value of the listid input for this choreo . ( ( required , integer ) the id for the to - do list to return . )"
"set the value of the password input for this choreo . ( ( required , password ) the basecamp account password . use the value ' x ' when specifying an api key for the username input . )"
"set the value of the username input for this choreo . ( ( required , string ) a basecamp account username or api key . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response returned from basecamp . )"
"create a new instance of the putobjectacl choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the accesscontrollist input for this choreo . ( ( optional , xml ) custom access control list xml for advanced configuration . see description for an example , plus amazon documentation . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket that contains the object that you want to create or update a policy for . )"
"set the value of the cannedacl input for this choreo . ( ( conditional , string ) most common acl usage , required unless creating a custom policy . values : private , public - read , public - read - write , authenticated - read , bucket - owner - read , or bucket - owner - full - control . )"
"set the value of the filename input for this choreo . ( ( required , string ) the name of the file or object that you want to put access controls on in s3 . ex . : file.txt or folder / file.txt . )"
"set the value of the owneremailaddress input for this choreo . ( ( optional , string ) the email address of the owner who is granting permission . required if creating your own custom acl policy . )"
"set the value of the ownerid input for this choreo . ( ( optional , string ) the canonical user i d of the owner who is granting permission . required if creating your own custom acl policy . )"
"retrieve the value for the "" response "" output from this choreo execution . ( stores the response from amazon . note that for a successful acl creation , no content is returned and this output variable is empty . )"
"create a new instance of the retrievelistrow choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the link input for this choreo . ( ( optional , string ) the entry 's resource url found in the link element of the entry . can be retrieved by running the retrievelistfeed choreo . when this is provided , spreadsheetkey , worksheetid , and rowid are not needed . )"
"set the value of the password input for this choreo . ( ( optional , password ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml ( the default ) and json . )"
"set the value of the rowid input for this choreo . ( ( conditional , string ) the unique id of the row you want to retrieve . required unless providing the link input . )"
"set the value of the spreadsheetkey input for this choreo . ( ( conditional , string ) the unique key of the spreadsheet associated with the row you want to retrieve . required unless providing the link input . )"
"set the value of the username input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the worksheetid input for this choreo . ( ( conditional , string ) the unique id of the worksheet associated with the row you want to retrieve . required unless providing the link input . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from google . )"
"create a new instance of the writefeedmetadata choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the feeddata input for this choreo . ( ( optional , any ) custom data body for the new feed in json or xml format ( set by feedtype ) . see documentation for how to write your own feed . if custom feeddata is used , all other optional inputs are ignored . )"
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by xively . )"
"set the value of the description input for this choreo . ( ( optional , string ) a description of the feed . leave empty to keep existing description . type "" blank "" to clear existing description . )"
"set the value of the email input for this choreo . ( ( optional , string ) contact email . leave empty to keep existing email . type "" blank "" to clear existing email . )"
"set the value of the feedid input for this choreo . ( ( required , integer ) the id for the feed that you would like to update . )"
"set the value of the feedtype input for this choreo . ( ( optional , string ) the type of feed that is being provided for custom feeddata . valid values are "" json "" ( the default ) and "" xml "" . )"
"set the value of the icon input for this choreo . ( ( optional , string ) the url of an icon which is relevant to this feed . leave empty to keep existing icon . type "" blank "" to clear existing icon . )"
"set the value of the private input for this choreo . ( ( optional , boolean ) specifies whether or not the feed is private to the creator of the feed . if ' true ' the feed is private , if ' false ' the feed is public . leave empty to keep existing settings . )"
"set the value of the tags input for this choreo . ( ( optional , string ) comma - separated list of searchable tags ( the characters ' , "" , and commas are not allowed ) . tags input overwrites previous tags , enter "" blank "" to clear all tags . ex : "" power , energy "" . )"
"set the value of the title input for this choreo . ( ( optional , string ) a descriptive name for the feed . leave empty to keep existing title . type "" blank "" to clear existing title . )"
"set the value of the website input for this choreo . ( ( optional , string ) the url of a website which is relevant to this feed . leave empty to keep existing website . type "" blank "" to clear existing website . ex . : http://www.homepage.com . )"
"retrieve the value for the "" responsestatuscode "" output from this choreo execution . ( ( integer ) the response status code returned from xively . for a successful feed update , the code should be 200 . )"
"create a new instance of the insert choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the requestbody input for this choreo . ( ( required , json ) a json representation of fields in a permissions resource . the json string must contain keys for role , type , and value . see documentation for formatting examples . )"
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth2 process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) selector specifying a subset of fields to include in the response . )"
"set the value of the fileid input for this choreo . ( ( required , string ) the id of the file . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the sendnotificationemails input for this choreo . ( ( optional , boolean ) whether to send notification emails . ( default : true ) . )"
"create a new instance of the entityoverview choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by sunlight data services . )"
"set the value of the cycle input for this choreo . ( ( optional , date ) specify a yyyy - formatted election cycle . example : 2012 , or 2008|2012 to limit results between 2008 and 2012 . )"
"set the value of the entityid input for this choreo . ( ( required , string ) the id for the entity that you want to return information for . this id can be retrieved by running the searchbyname choreo . )"
"create a new instance of the updatecollaboration choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth2 process . )"
"set the value of the asuser input for this choreo . ( ( optional , string ) the id of the user . only used for enterprise administrators to make api calls for their managed users . )"
"set the value of the collaborationid input for this choreo . ( ( required , string ) the i d of the collaboration to edit . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma - separated list of fields to include in the response . )"
"set the value of the role input for this choreo . ( ( conditional , string ) the access level of the collaboration . valid values are "" viewer "" or "" editor "" . defaults to "" viewer "" . this value can only be updated by the owner of the folder . )"
"set the value of the status input for this choreo . ( ( conditional , string ) whether this collaboration has been accepted . valid values are : "" accepted "" or "" rejected "" . this value can only be updated by the user who has been invited to the collaboration . )"
"create a new instance of the getrelationshipreferences choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from littlesis.org . )"
"set the value of the categoryid input for this choreo . ( ( optional , string ) comma delimited list of category ids . )"
"set the value of the current input for this choreo . ( ( optional , integer ) set to 1 to limit the relationships returned to only past relationships . set to 0 to limit relationships returned to only current relationships . defaults to all . )"
"set the value of the id input for this choreo . ( ( required , decimal ) the id of the record for which you want relationship references . )"
"set the value of the number input for this choreo . ( ( optional , integer ) specifies what number of results to show . used in conjunction with page parameter , a number of 20 and a page of 6 will show results 100 - 120 . )"
"set the value of the order input for this choreo . ( ( optional , integer ) specifies what order the given entity must have in the relationship . )"
"set the value of the page input for this choreo . ( ( optional , integer ) specifies what page of results to show . used in conjunction with number parameter . a number of 20 and a page of 6 will show results 100 - 120 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) format of the response returned by littlesis.org . acceptable inputs : xml or json . defaults to xml )"
"set the value of the sortby input for this choreo . ( ( optional , string ) defaults to sorting by entity , which returns a list of relationships grouped by related entity . specify another sort order for the results . acceptable inputs : category or relationship . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from littlesis.org . )"
"create a new instance of the retrievefollowedblogsforuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by tumblr ( aka the oauth consumer key ) . )"
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to return : 1 - 20 . defaults to 20 . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the result to start at . defaults to 0 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the secretkey input for this choreo . ( ( required , string ) the secret key provided by tumblr ( aka the oauth consumer secret ) . )"
"create a new instance of the localbreakdown choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by sunlight data services . )"
"set the value of the entityid input for this choreo . ( ( required , string ) the id for the entity that you want to return information for . this id can be retrieved by running the searchbyname choreo . )"
"create a new instance of the deletelisten choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( required , string ) the i d of an action to delete . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( boolean ) the response from facebook . returns "" true "" on success . )"
"create a new instance of the getdisk choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the disk input for this choreo . ( ( required , string ) the name of the persistent disk resource to retrieve . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the zone input for this choreo . ( ( required , string ) the name of the zone associated with this request . )"
"create a new instance of the drivingdistancematrix choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the alternatives input for this choreo . ( ( optional , string ) if set to true , additional routes will be returned . )"
"set the value of the avoid input for this choreo . ( ( optional , string ) specify whether the calculated directions should avoid the following features : tolls , or highways . )"
"set the value of the destinations input for this choreo . ( ( required , string ) enter the address or latitude / longitude coordinates to which directions will be generated . multiple destinations can be separated by pipes ( | ) . for example : boston , ma|new haven|40.7160,-74.0037 . )"
"set the value of the language input for this choreo . ( ( optional , string ) set the language in which to return restults . a list of supported languages is available here : https://spreadsheets.google.com/pub?key=p9pdwsai2hdmslkxsom05kq&gid=1 )"
"set the value of the origins input for this choreo . ( ( required , string ) enter the address(es ) or geo - coordinates from which distance and time will be computed . multiple destinations can be separated by pipes ( | ) . for example : boston , ma|new haven|40.7160,-74.0037 . )"
"set the value of the region input for this choreo . ( ( optional , string ) enter the region code for the directions , specified as a cctld two - character value . )"
"set the value of the sensor input for this choreo . ( ( optional , boolean ) indicates whether or not the directions request is from a device with a location sensor . value must be either 1 or 0 . defaults to 0 ( false ) . )"
"set the value of the units input for this choreo . ( ( optional , string ) specify the units to be used when displaying results . options include , metric , or imperial . )"
"retrieve the value for the "" distance "" output from this choreo execution . ( ( integer ) the distance of this route , expressed in meters . )"
"retrieve the value for the "" duration "" output from this choreo execution . ( ( integer ) the duration of this route , expressed in seconds . )"
"create a new instance of the getrecentnewsitems choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to return . defaults to 20 . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) a numeric value indicating the starting point of the result set . this can be used in combination with the limit input to page through results . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the section input for this choreo . ( ( optional , string ) limits the set of items by one or more sections . separate sections by semicolons . defaults to "" all "" to get all sections . see choreo documentation for more options for this input . )"
"set the value of the source input for this choreo . ( ( optional , string ) limits the set of items by originating source . set to "" nyt "" for new york times items only and "" iht "" for international herald tribune items . set to "" all "" for both ( the default ) . )"
"set the value of the timeperiod input for this choreo . ( ( optional , integer ) limits the set of items by time published . valid range is number of hours , 1–720 ( in hours ) . defaults to 24 . )"
"create a new instance of the updatecontactprofileemailaddress choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the newemailaddress input for this choreo . ( ( required , string ) a valid email address , not exceeding 100 characters . this address will be used for all future communication with sendgrid . a confirmation email will be sent to validate the change of address . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format of the response from sendgrid , in either json , or xml . default is set to json . )"
"create a new instance of the runcommand choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the databasename input for this choreo . ( ( required , string ) the name of the database to connect to . )"
"set the value of the password input for this choreo . ( ( required , password ) the password for the database user . )"
"set the value of the port input for this choreo . ( ( optional , integer ) the database port . defaults to 5432 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the preferred format for the database results . accepted formats are json ( the default ) and xml . this input only applies when providing a select statement for the sql input . )"
"set the value of the sql input for this choreo . ( ( required , multiline ) a sql statement to execute . )"
"set the value of the server input for this choreo . ( ( required , string ) the name or ip address of the database server . )"
"set the value of the username input for this choreo . ( ( required , string ) the database username . )"
"set the value of the version input for this choreo . ( ( optional , decimal ) the version of the postgres database . allowed values are 8 and 9 ( the default ) . )"
"retrieve the value for the "" resultdata "" output from this choreo execution . ( the data returned from the database . this output will only contain a value when a select statement is provided . results are returned as json or xml depending on the responseformat . )"
"retrieve the value for the "" success "" output from this choreo execution . ( ( boolean ) indicates the result of the database command . the value will be "" true "" when the sql statement executes successfully . )"
"create a new instance of the listforums choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the cursor input for this choreo . ( ( optional , string ) default is set to null . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of records to return . defaults to 25 . )"
"set the value of the order input for this choreo . ( ( optional , string ) the sort order for the results . valid vaues are : asc or desc . default is set to : asc . )"
"set the value of the publickey input for this choreo . ( ( required , string ) the public key provided by disqus ( aka the api key ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) , jsonp , or rss . )"
"set the value of the sinceid input for this choreo . ( ( optional , string ) a unix timestamp to obtain results from . default is set to null . )"
"set the value of the userid input for this choreo . ( ( conditional , string ) the disqus user id , for which active forum information will be retrieved . if userid is set , then username must be null . )"
"set the value of the username input for this choreo . ( ( conditional , string ) a disqus username . if username is being set , then userid must be null . )"
"create a new instance of the logwater choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the amount input for this choreo . ( ( required , decimal ) the amount of water consumed . corresponds to the unit input . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the date input for this choreo . ( ( required , date ) the date that corresponds with the new log entry ( in the format yyyy - mm - dd ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the unit input for this choreo . ( ( required , string ) unit of measurement for the water entry . valid values : ' ml ' , ' fl oz ' , or ' cup ' . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"create a new instance of the retrievepropertyvalue choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the applicationid input for this choreo . ( ( required , string ) the application id provided by parse . )"
"set the value of the classname input for this choreo . ( ( required , string ) the class name for the object being retrieved . )"
"set the value of the objectid input for this choreo . ( ( required , string ) the id of the object to retrieve . )"
"set the value of the propertyname input for this choreo . ( ( required , string ) the name of the property to return . )"
"set the value of the restapikey input for this choreo . ( ( required , string ) the rest api key provided by parse . )"
"retrieve the value for the "" value "" output from this choreo execution . ( ( string ) the value of the specified property . )"
"create a new instance of the deletewaterlog choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"set the value of the waterlogid input for this choreo . ( ( required , integer ) the i d of the water log you want to delete . the i d is returned in the logwater response . )"
"create a new instance of the like choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the set input for this choreo . ( ( optional , boolean ) set to 1 ( the default ) to like this checkin . set to 0 to undo a previous like . )"
"set the value of the venueid input for this choreo . ( ( required , string ) the id of the venue to like or unlike . )"
"create a new instance of the deletefavoritefood choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the foodid input for this choreo . ( ( required , integer ) the i d of the food to delete from you favorites list . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"create a new instance of the searchanonymous choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the email input for this choreo . ( ( required , string ) the email address you use to login to your zendesk account . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page number of the results to be returned . used together with the perpage parameter to paginate a large set of results . )"
"set the value of the password input for this choreo . ( ( required , password ) your zendesk password . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) the number of results to return per page . maximum is 100 and default is 100 . )"
"set the value of the query input for this choreo . ( ( required , string ) the search text to be matched . )"
"set the value of the server input for this choreo . ( ( required , string ) your zendesk domain and subdomain ( e.g. , temboocare.zendesk.com ) . )"
"set the value of the sortby input for this choreo . ( ( optional , string ) acceptable values : updated_at , created_at , priority , status , ticket_type . )"
"set the value of the sortorder input for this choreo . ( ( optional , string ) indicate either : relevance , asc ( for ascending ) , desc ( for descending ) . defaults to relevance . )"
"create a new instance of the deletebucket choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket that will be deleted . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from amazon . note that no content is returned for successful deletions . )"
"create a new instance of the listfirewalls choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the filter input for this choreo . ( ( optional , string ) a filter expression for narrowing results in the form : { field_name } { comparison_string } { literal_string } ( e.g. name eq default - ssh ) . comparison strings can be eq ( equals ) or ne ( not equals ) . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of results to return . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" found in the response which is used to page through results . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the getactivitydailygoals choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"retrieve the value for the "" caloriesout "" output from this choreo execution . ( ( integer ) the number representing the daily calorie burn goal . )"
"retrieve the value for the "" distance "" output from this choreo execution . ( ( decimal ) the distance specified as the daily goal . )"
"retrieve the value for the "" steps "" output from this choreo execution . ( ( integer ) the number of steps specified for a daily goal . )"
"create a new instance of the authorizesecuritygroupingress choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the groupid input for this choreo . ( ( conditional , string ) the id of the security group to modify . can be used instead of groupname . )"
"set the value of the groupname input for this choreo . ( ( conditional , string ) the name of the security group to modify . can be used instead of groupid . )"
"set the value of the ippermissionscidrip input for this choreo . ( ( optional , string ) the cidr range . can not be used when specifying a source security group . )"
"set the value of the ippermissionsfromport input for this choreo . ( ( optional , integer ) the start of port range for the tcp and udp protocols , or an icmp type number . for the icmp type number , you can use -1 to specify all icmp types . )"
"set the value of the ippermissionsgroupid input for this choreo . ( ( optional , string ) the id of the source security group . can not be used when specifying a cidr ip address . )"
"set the value of the ippermissionsgroupname input for this choreo . ( ( optional , string ) the name of the source security group . can not be used when specifying a cidr ip address . )"
"set the value of the ippermissionsipprotocol input for this choreo . ( ( required , string ) the ip protocol name or number . valid values for ec2 - classic : tcp , udp , icmp ( or 6 , 17 , 1 ) . valid values for ec2 - vpc : tcp , udp , icmp , any valid protocol number ( 0 - 254 ) , or -1 ( to specify all ) . )"
"set the value of the ippermissionstoport input for this choreo . ( ( optional , integer ) the end of port range for the tcp and udp protocols , or an icmp code number . for the icmp code number , you can use -1 to specify all icmp codes for the given icmp type . )"
"set the value of the ippermissionsuserid input for this choreo . ( ( optional , string ) the aws account id that owns the source security group . can not be used when specifying a cidr ip address . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the ec2 endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"create a new instance of the listcommitcomments choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( conditional , string ) the access token retrieved during the oauth process . required when accessing a protected resource . )"
"set the value of the page input for this choreo . ( ( optional , integer ) indicates the page index that you want to retrieve . this is used to page through many results . defaults to 1 . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) the number of results to return per page . )"
"set the value of the repo input for this choreo . ( ( required , string ) the name of the repository . )"
"set the value of the sha input for this choreo . ( ( required , string ) the sha of the commit . )"
"set the value of the user input for this choreo . ( ( required , string ) the github username . )"
"retrieve the value for the "" firstpage "" output from this choreo execution . ( ( integer ) the index for the first page of results . )"
"retrieve the value for the "" lastpage "" output from this choreo execution . ( ( integer ) the index for the last page of results . )"
"create a new instance of the searchbykeyword choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( optional , string ) the api key provided by ny times . )"
"set the value of the criticspick input for this choreo . ( ( optional , string ) set this parameter to y to limt the results to nyt critics ' picks . to get only those movies that have not been highlighted by times critics , specify n. )"
"set the value of the dvd input for this choreo . ( ( optional , string ) set this parameter to y to limit the results to movies that have been released on dvd . to get only those movies that have not been released on dvd , specify n. )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to return . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) a numeric value indicating the starting point of the result set . this can be used in combination with the limit input to page through results . )"
"set the value of the openingdate input for this choreo . ( ( optional , date ) limits by date or range of dates . the opening - date is the date the movie 's opening date in the new york region . format yyyy - mm - dd . separate ranges with semicolons . )"
"set the value of the order input for this choreo . ( ( optional , string ) sets the sort order of the results . accepted values are : by - title , by - publication - date , by - opening - date , by - dvd - release - date . )"
"set the value of the publicationdate input for this choreo . ( ( optional , date ) limits by date or range of dates . the publication - date is the date the review was first publish.ed in the times . format yyyy - mm - dd . separate ranges with semicolons . )"
"set the value of the query input for this choreo . ( ( conditional , string ) a string of search keywords . matches movie titles and indexed terms . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the reviewer input for this choreo . ( ( optional , string ) limits results to reviews by a specific critic . reviewer names should be hyphenated or concatenated with dots ( i.e manohla.dargis ) . )"
"set the value of the thousandbest input for this choreo . ( ( optional , string ) set this parameter to y to limit the results to movies on the times list of the best 1,000 movies ever made . to get only those movies that are not on the list , specify n. )"
"create a new instance of the insertfirewall choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the firewallresource input for this choreo . ( ( optional , json ) a json string containing the firewall resource properties to set . this can be used as an alternative to individual inputs representing firewall properties . )"
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the allowedipprotocol input for this choreo . ( ( conditional , json ) the ip protocol that is allowed for this rule . this is an array and can have the following properties : ipprotocol ( valid values are : tcp , udp , or icmp ) and ports [ ] . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the description input for this choreo . ( ( optional , string ) a description of the firewall . )"
"set the value of the name input for this choreo . ( ( conditional , string ) the name of the firewall resource being created . )"
"set the value of the network input for this choreo . ( ( conditional , string ) the fully - qualified url of the network to which this firewall is applied . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the sourceranges input for this choreo . ( ( conditional , json ) an array of address blocks that this rule applies to . this is required if the sourcetags input is not provided . )"
"set the value of the sourcetags input for this choreo . ( ( conditional , json ) an array of instance tags which this rule applies to . this is required unless the sourceranges input is provided . )"
"create a new instance of the receivemessage choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awsaccountid input for this choreo . ( ( required , integer ) the i d for the aws account associated with the queue you 're retrieving a message from ( remove all dashes in the account number ) . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the attributename input for this choreo . ( ( optional , string ) the attribute you wish to return . values are : all ( default ) , senderid , senttimestamp , approximatereceivecount , or approximatefirstreceivetimestamp . )"
"set the value of the maxnumberofmessages input for this choreo . ( ( optional , integer ) the maximum number of messages to return . defaults to 1 . )"
"set the value of the messageattributename input for this choreo . ( ( optional , string ) the name of a message attribute to return . you can return all of the attributes by specifying "" all "" . )"
"set the value of the queuename input for this choreo . ( ( required , string ) the name of the queue you want to retrieve a message from . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the sqs endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"set the value of the visibilitytimeout input for this choreo . ( ( optional , integer ) the duration ( in seconds ) that the received messages are hidden from future retrieve requests after a receivemessage request ( max is 43200 ) . )"
"set the value of the waittimeseconds input for this choreo . ( ( optional , integer ) the duration ( in seconds ) for which the call will wait for a message to arrive in the queue before returning . if a message is available , the call will return sooner than waittimeseconds . )"
"retrieve the value for the "" body "" output from this choreo execution . ( ( string ) the body of the latest message . )"
"retrieve the value for the "" messageid "" output from this choreo execution . ( ( string ) a unique identifier for the latest message . )"
"retrieve the value for the "" receipthandle "" output from this choreo execution . ( ( string ) an identifier associated with the act of receiving the message . a new receipt handle is returned every time you receive a message . provide the last received receipt handle to delete the message . )"
"create a new instance of the finalizeoauth choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the appkeyname input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the appkeyvalue input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the clientid input for this choreo . ( ( required , string ) the client id provided by dwolla after registering your application . )"
"set the value of the clientsecret input for this choreo . ( ( required , string ) the client secret provided by dwolla after registering your application . )"
"retrieve the value for the "" expiresin "" output from this choreo execution . ( ( integer ) the lifetime of the access token , in seconds . )"
"retrieve the value for the "" refreshexpiresin "" output from this choreo execution . ( ( integer ) the lifetime of the refresh token , in seconds . )"
"retrieve the value for the "" refreshtoken "" output from this choreo execution . ( ( string ) a refresh token that can be used to generate a new access token when the current token expires . )"
"create a new instance of the getpopularmedia choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( conditional , string ) the access token retrieved during the oauth 2.0 process . required unless you provide the clientid . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by instagram after registering your application . required unless you provide an accesstoken . )"
"set the value of the count input for this choreo . ( ( optional , integer ) the number of results to return . )"
"create a new instance of the leaderboard choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the neighbors input for this choreo . ( ( optional , integer ) the number of friends ' scores to return that are adjacent to your score , in ranked order . )"
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the subscribe choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the application input for this choreo . ( ( optional , integer ) specifies the device type for which the notification is to be activated . set to 1 for bodyscale . )"
"set the value of the callbackurl input for this choreo . ( ( required , string ) the url the api notification will be pushed to . )"
"set the value of the comment input for this choreo . ( ( optional , string ) a comment string used for a description to display to the user when presenting them with your notification setup . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by withings . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by withings . )"
"set the value of the userid input for this choreo . ( ( required , string ) the id of the user to setup a subscription for . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from withings . )"
"create a new instance of the gettopicexercises choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the topicid input for this choreo . ( ( required , string ) the id of the topic . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from khan academy . )"
"create a new instance of the gettranslationsarray choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token . this can be retrieved by running the gettoken choreo . required unless providing the clientid and clientsecret . )"
"set the value of the category input for this choreo . ( ( optional , string ) a string containing the category ( domain ) of the translation . defaults to "" general "" . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id obtained when signing up for microsoft translator on azure marketplace . this is required unless providing an accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret obtained when signing up for microsoft translator on azure marketplace . this is required unless providing an accesstoken . )"
"set the value of the contenttype input for this choreo . ( ( optional , string ) the format of the text being translated . the only supported , and the default , option is "" text / plain "" . )"
"set the value of the from input for this choreo . ( ( required , string ) a string representing the iso 639 - 1 language code of the translation text ( e.g. , en ) . )"
"set the value of the maxtranslations input for this choreo . ( ( required , integer ) an integer representing the maximum number of translations to return . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the state input for this choreo . ( ( optional , string ) user state to help correlate request and response . the same contents will be returned in the response . )"
"set the value of the texts input for this choreo . ( ( required , json ) an array containing the texts for translation . all strings must be of the same language . the total of all texts must not exceed 10000 characters . the max number of array items is 2000 . )"
"set the value of the to input for this choreo . ( ( required , string ) a string representing the iso 639 - 1 language code to translate the text into ( e.g. , es ) . )"
"set the value of the uri input for this choreo . ( ( optional , string ) filter results by this uri . default : all )"
"set the value of the user input for this choreo . ( ( optional , string ) filter results by this user . default : all )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from microsoft . )"
"retrieve the value for the "" expiresin "" output from this choreo execution . ( ( integer ) contains the number of seconds for which the access token is valid when clientid and clientsecret are provided . )"
"retrieve the value for the "" newaccesstoken "" output from this choreo execution . ( ( string ) contains a new accesstoken when the clientid and clientsecret are provided . )"
"create a new instance of the compareartists choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
set the value of the apikey input for this choreo . ( ( string ) your last.fm api key . )
set the value of the artist1 input for this choreo . ( ( string ) the first artist to compare . )
set the value of the artist2 input for this choreo . ( ( string ) the second artist to compare . )
"set the value of the limit input for this choreo . ( ( optional , integer ) how many shared artists to display . defaults to 5 . )"
"create a new instance of the musicgenres choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the musicgenre input for this choreo . ( ( optional , string ) the specific music genre title to return . multiple genre titles can be specified separated by commas ( i.e. blues , classical ) . genre ids are returned when this input is used . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are xml ( the default ) , and json . )"
"set the value of the storycountall input for this choreo . ( ( optional , integer ) returns only items with at least this number of associated stories . )"
"set the value of the storycountmonth input for this choreo . ( ( optional , integer ) returns only items with at least this number of associated stories published in the last month . )"
"set the value of the storycounttoday input for this choreo . ( ( optional , integer ) returns only items with at least this number of associated stories published today . )"
"retrieve the value for the "" i d "" output from this choreo execution . ( ( integer ) the id of the music genre . this is only returned when the musicgenre input is specified . when multiple genres are specified , this will be a list of ids separated by commas . )"
"create a new instance of the getcomponents choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the setid input for this choreo . ( ( required , string ) the unique id assigned by dailymed to each drug . you can find the setid of a drug by first running the searchbyname or searchbyndc choreos . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from dailymed . )"
"create a new instance of the likespage choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final oauth step . )"
"set the value of the pageid input for this choreo . ( ( required , string ) the id of the page to check against the acting user 's likes . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the id of the user whose likes you want to check the pageid against . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"retrieve the value for the "" likes "" output from this choreo execution . ( ( boolean ) returns as true or false depending on whether or not the pageid specified is liked by the acting user . )"
"create a new instance of the getbucketacl choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket associated with the acl you want to retrieve . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"create a new instance of the gettemperature choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the address input for this choreo . ( ( required , string ) the address to be searched . )"
"set the value of the units input for this choreo . ( ( optional , string ) the unit of temperature in the response . acceptable inputs : f for fahrenheit or c for celsius . defaults to f. when c is specified , all units measurements returned are changed to metric . )"
"retrieve the value for the "" temperature "" output from this choreo execution . ( ( integer ) the current temperature ( defaults to fahrenheit ) . )"
"create a new instance of the retrievecoupon choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by stripe )"
"set the value of the couponid input for this choreo . ( ( required , string ) the unique identifier of the coupon you want to retrieve )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from stripe )"
"create a new instance of the updatelisten choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( required , string ) the i d of the action to update . )"
"set the value of the album input for this choreo . ( ( optional , string ) the url or id for an open graph object representing representing an album . )"
"set the value of the endtime input for this choreo . ( ( optional , date ) the time that the user ended the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the expiresin input for this choreo . ( ( optional , integer ) the amount of time ( in milliseconds ) from the publish_time that the action will expire . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message attached to this fitness action . setting this parameter requires enabling of message capabilities . )"
"set the value of the musician input for this choreo . ( ( optional , string ) the url or id for an open graph object representing representing a musician . )"
"set the value of the paused input for this choreo . ( ( optional , boolean ) whether the audio is paused or not )"
"set the value of the place input for this choreo . ( ( optional , string ) the url or id for an open graph object representing the location associated with this action . )"
"set the value of the playlist input for this choreo . ( ( optional , string ) the url or id for an open graph object representing representing a playlist . )"
"set the value of the radiostation input for this choreo . ( ( optional , string ) the url or id for an open graph object representing representing a radio station . )"
"set the value of the song input for this choreo . ( ( optional , string ) the url or id for an open graph object representing representing a song . )"
"set the value of the tags input for this choreo . ( ( optional , string ) a comma separated list of other profile ids that also performed this action . )"
"set the value of the viauser input for this choreo . ( ( optional , integer ) the id of anyone whom the user discovered this audio from )"
"create a new instance of the getbestsellerhistory choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the agegroup input for this choreo . ( ( optional , string ) the target age group for the best seller . )"
"set the value of the author input for this choreo . ( ( optional , string ) the author of the best seller . )"
"set the value of the contributor input for this choreo . ( ( optional , string ) the author of the best seller , as well as other contributors such as the illustrator . )"
"set the value of the isbn input for this choreo . ( ( optional , string ) international standard book number , 10 or 13 digits . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the first 20 results are shown by default . to page through the results , set offset to the appropriate value . )"
"set the value of the price input for this choreo . ( ( optional , decimal ) the publisher 's list price of the best seller , including decimal point . )"
"set the value of the publisher input for this choreo . ( ( optional , string ) the standardized name of the publisher . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should bein . valid values are : json ( the default ) , and xml . )"
"set the value of the sortby input for this choreo . ( ( optional , string ) the column name to sort by . valid values are : age - group , author , contributor , isbn , price , publisher , and title . )"
"set the value of the sortorder input for this choreo . ( ( optional , string ) the sort order . valid values are : asc and desc . )"
"set the value of the title input for this choreo . ( ( conditional , string ) the title of the best seller to retrieve data for . )"
"create a new instance of the propertydata choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided my mixpanel . you can find your mixpanel api key in the project settings dialog in the mixpanel app . )"
"set the value of the apisecret input for this choreo . ( ( required , string ) the api secret provided by mixpanel . you can find your mixpanel api secret in the project settings dialog in the mixpanel app . )"
"set the value of the eventname input for this choreo . ( ( required , string ) the name of the event that you wish to get data for . )"
"set the value of the expire input for this choreo . ( ( optional , integer ) the amount of minutes past now ( ) before the request will expire . defaults to 1 . )"
"set the value of the interval input for this choreo . ( ( required , integer ) the time interval to return . this relates to the value provided for unit . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the maximum number of values to return . defaults to 255 . )"
"set the value of the propertyname input for this choreo . ( ( required , string ) the name of the property you would like to get data for . )"
"set the value of the propertyvalues input for this choreo . ( ( optional , json ) a json array containing property values that you wish to retrieve . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and csv . )"
"set the value of the type input for this choreo . ( ( required , string ) the analysis type you would like to get data for . valid values are : general , unique , or average )"
"set the value of the unit input for this choreo . ( ( required , string ) the granularity of the data to return . valid values are : minute , hour , day , week , or month . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from mixpanel . )"
"create a new instance of the listallinvoiceitems choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by stripe )"
"set the value of the count input for this choreo . ( ( optional , integer ) the limit of invoice items to be returned . can range from 1 to 100 . defaults to 10 . )"
"set the value of the customerid input for this choreo . ( ( optional , string ) the unique identifier of the customer whose invoice items to return . if not specified , all invoice items will be returned . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) stripe will return a list of invoice items starting at the specified offset . defaults to 0 . )"
"create a new instance of the uploadphoto choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the albumid input for this choreo . ( ( optional , string ) the i d of the album to upload the photo to . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message to attach to the photo . )"
"set the value of the photo input for this choreo . ( ( conditional , string ) the base64 encoded image to upload . this is required unless using the url input to publish the photo . )"
"set the value of the place input for this choreo . ( ( optional , string ) the id of a location where the photo was taken . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the source input for this choreo . ( ( optional , string ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the url input for this choreo . ( ( conditional , string ) a url to a hosted photo that should be uploaded . this is required unless providing a base64 encoded image for the photo input . )"
"create a new instance of the getteacherstats choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) your school finder api key . )"
"set the value of the districtid input for this choreo . ( ( conditional , string ) the education.com district i d. )"
"set the value of the districtlea input for this choreo . ( ( conditional , string ) the lea i d of the district . )"
"set the value of the nces input for this choreo . ( ( conditional , string ) the national center for education statistics ( nces ) i d of the school . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) format of the response returned by education.com . defaluts to xml . json is also possible . )"
"set the value of the schoolid input for this choreo . ( ( conditional , string ) the education.com i d of the school you want to find . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from education.com . )"
"create a new instance of the federallobbying choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by sunlight data services . )"
"set the value of the amount input for this choreo . ( ( optional , string ) enter the amount of dollars spent on lobbying . valid formats include : 500 ( exactly $ 500 ) ; > |500 ( greater than , or equal to 500 ) ; < |500 ( less than or equal to 500 ) . )"
"set the value of the clientparentorganization input for this choreo . ( ( optional , string ) specify a full - text search of a client 's parent organizationfor . )"
"set the value of the clientsearch input for this choreo . ( ( optional , string ) enter the name of the client for whom this lobbyist is working . this parameter executes a full - text search . )"
"set the value of the filingtype input for this choreo . ( ( optional , string ) specify the type of filing as identified by crp . example : n , for non - self filer parent . for more info , go here : http://data.influenceexplorer.com/api/lobbying/ )"
"set the value of the lobbyistsearch input for this choreo . ( ( optional , string ) specify a full - text search of a lobbyist 's name . )"
"set the value of the registrantsearch input for this choreo . ( ( optional , string ) specify a full - text search of an organization or a person , who is fling the lobbyist registration . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) indicates the desired format for the response . accepted values are : json ( the default ) , csv , and xls . note when specifying xls , restults are returned as base64 encoded data . )"
"set the value of the transactionid input for this choreo . ( ( optional , string ) enter the report id given by the senate office of public records . )"
"set the value of the transactiontype input for this choreo . ( ( optional , string ) enter the type of filing as reported by the senate office of public records . see here for additional info : http://assets.transparencydata.org.s3.amazonaws.com/docs/transaction_types-20100402.csv )"
"set the value of the yearfiled input for this choreo . ( ( optional , string ) specify the year in which a registration was filed . use the following format : yyyy . example : 2011 . logical or is also possible by using the | ( pipe ) symbol . example : 2008|2012 . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from influence explorer . corresponds to the responseformat input . defaults to json . )"
"create a new instance of the getretweets choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret provided by twitter or retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token provided by twitter or retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the api key ( or consumer key ) provided by twitter . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the api secret ( or consumer secret ) provided by twitter . )"
"set the value of the count input for this choreo . ( ( optional , integer ) specifies the number of records to , up to a maximum of 100 . )"
"set the value of the id input for this choreo . ( ( required , string ) the numerical id of the tweet to retrieve retweets for . )"
"set the value of the trimuser input for this choreo . ( ( optional , boolean ) when set to true , each tweet returned in a timeline will include a user object including only the status authors numerical id . )"
"create a new instance of the deleteuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the email input for this choreo . ( ( required , string ) the email address you use to login to your zendesk account . )"
"set the value of the id input for this choreo . ( ( required , integer ) the id of the user to delete . )"
"set the value of the password input for this choreo . ( ( required , password ) your zendesk password . )"
"set the value of the server input for this choreo . ( ( required , string ) your zendesk domain and subdomain ( e.g. , temboocare.zendesk.com ) . )"
"retrieve the value for the "" responsestatuscode "" output from this choreo execution . ( ( integer ) the response status code returned from zendesk . )"
"create a new instance of the deletegrouppolicy choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the groupname input for this choreo . ( ( required , string ) name of the group the policy is associated with . )"
"set the value of the policyname input for this choreo . ( ( required , string ) name of the policy document . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"create a new instance of the createcheckin choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accuracyofcoordinates input for this choreo . ( ( optional , integer ) accuracy of the user 's latitude and longitude , in meters . )"
"set the value of the altitudeaccuracy input for this choreo . ( ( optional , integer ) vertical accuracy of the user 's location , in meters . )"
"set the value of the altitude input for this choreo . ( ( optional , integer ) altitude of the user 's location , in meters . )"
"set the value of the broadcast input for this choreo . ( ( optional , string ) who to broadcast this check - in to . can be a comma - delimited list : private , public , facebook , twitter , or followers . defaults to ' public ' . )"
"set the value of the eventid input for this choreo . ( ( optional , string ) the event the user is checking in to . a venueid for a venue with this eventid must also be specified in the request . )"
"set the value of the latitude input for this choreo . ( ( optional , decimal ) the latitude point of the user 's location . )"
"set the value of the longitude input for this choreo . ( ( optional , decimal ) the longitude point of the user 's location . )"
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the shout input for this choreo . ( ( optional , string ) a message about your check - in . the maximum length of this field is 140 characters . )"
"set the value of the venueid input for this choreo . ( ( required , string ) the venue where the user is checking in . no venueid is needed if shouting or just providing a venue name . )"
"set the value of the venue input for this choreo . ( ( optional , string ) if you are not shouting , but you do n't have a venue id or prefer a ' venueless ' checkin , pass the venue name as a string using this parameter . )"
"create a new instance of the committee choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the committeeid input for this choreo . ( ( optional , integer ) the i d of the committee resource . when using this input , all other filter parameters are ignored , and a single record is returned . )"
"set the value of the committee input for this choreo . ( ( optional , string ) indicates if the object is a committee or a subcommittee . to filter for committees , you can pass "" null "" . for subcommittees , pass the id of the parent . filter operators allowed . sortable . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return in the response . use double - underscores to span relationships ( e.g. person__firstname ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) results are paged 100 per call by default . set the limit input to a high value to get all of the results at once . )"
"set the value of the obsolete input for this choreo . ( ( optional , string ) whether or not the committee still exists . set to "" true "" to return committees that are obsolete . filter operators allowed . sortable . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) offset the results by the number given , useful for paging through results . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the sort input for this choreo . ( ( optional , string ) you can order the results using fieldname ( ascending ) or -fieldname ( descending ) where "" fieldname "" is one of the variables that is listed as ' sortable ' in the description . ex : ' -lastname ' )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from govtrack . )"
"create a new instance of the addlist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the collaborative input for this choreo . ( ( optional , boolean ) a flag indicating that this list can be edited by friends . set to 1 for true . defaults to 0 ( false ) . )"
"set the value of the description input for this choreo . ( ( optional , string ) the description of the list . )"
"set the value of the name input for this choreo . ( ( required , string ) the name of the list . )"
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the photoid input for this choreo . ( ( optional , string ) the i d of a photo that should be set as the list photo . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the getitem choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the detaillevel input for this choreo . ( ( optional , string ) the response detail level . valid values are : itemreturnattributes , itemreturndescription , and returnall . )"
"set the value of the includeitemspecifics input for this choreo . ( ( optional , boolean ) if set to true , the response returns the itemspecifics node ( if the listing has custom item specifics ) . )"
"set the value of the includetaxtable input for this choreo . ( ( optional , boolean ) if set to true , an associated tax table is returned in the response . )"
"set the value of the includewatchcount input for this choreo . ( ( optional , boolean ) indicates if the caller wants to include watch count for that item in the response when set to true . only the seller is allowed to use this argument . )"
"set the value of the itemid input for this choreo . ( ( required , string ) the itemid that uniquely identifies the item listing to retrieve . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the sandboxmode input for this choreo . ( ( conditional , boolean ) indicates that the request should be made to the sandbox endpoint instead of the production endpoint . set to 1 to enable sandbox mode . )"
"set the value of the siteid input for this choreo . ( ( optional , string ) the ebay site id that you want to access . defaults to 0 indicating the us site . )"
"set the value of the transactionid input for this choreo . ( ( optional , string ) a unique identifier for a transaction ( i.e. an order line item ) . an order line item is created when the buyer commits to purchasing an item . )"
"set the value of the usertoken input for this choreo . ( ( required , string ) a valid ebay auth token . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from ebay . )"
"retrieve the value for the "" currentprice "" output from this choreo execution . ( ( decimal ) the current price for the item . )"
"retrieve the value for the "" daysleft "" output from this choreo execution . ( ( integer ) the number of days until the auction ends . )"
"retrieve the value for the "" hoursleft "" output from this choreo execution . ( ( integer ) the number of hours until the auction ends . )"
"retrieve the value for the "" minutesleft "" output from this choreo execution . ( ( integer ) the number of minutes until the auction ends . )"
"retrieve the value for the "" secondsleft "" output from this choreo execution . ( ( integer ) the number of seconds until the auction ends . )"
"create a new instance of the weatherbyzipcode choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the enddate input for this choreo . ( ( optional , date ) enter today 's date , or some future date in utc format . format : 2004 - 04 - 27t12:00 . defaults to now if not provided . )"
"set the value of the ndfdparametername input for this choreo . ( ( optional , string ) enter an additional weather parameter in the following format : phail = phail . use only if product is set to : glance . )"
"set the value of the product input for this choreo . ( ( required , string ) enter one of two parameters : time - series ( to return all data between the begin and end time parameters ) ; glance for a subset of 5 often used parameters )"
"set the value of the startdate input for this choreo . ( ( optional , date ) enter the start time for retrieval of ndwd information in utc format . if null , the earliest date in the database is returned . format : 2004 - 04 - 27t12:00 . )"
"set the value of the unit input for this choreo . ( ( optional , string ) enter the unit format the data will be displayed in . default is : e , for standard english ( u.s. standard ) . or : m , for metric ( si units ) . )"
"set the value of the zipcodelist input for this choreo . ( ( required , integer ) enter the zipcode for which ndfd weather information will be retrieved . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) response from ndfd servers . )"
"create a new instance of the writedatastreammetadata choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by xively . )"
"set the value of the currentvalue input for this choreo . ( ( optional , string ) the current value of the datastream . leave empty to keep existing currentvalue . type "" blank "" to clear existing value . )"
"set the value of the customdatastreamdata input for this choreo . ( ( optional , json ) custom datastream formatted as a json array . see documentation for how to construct your own datastream feed . if custom datastreamdata is used , all other optional inputs are ignored . )"
"set the value of the datastreamid input for this choreo . ( ( required , string ) the id of the datastream you would like to add metadata to . required unless you are using customdatastreamdata . )"
"set the value of the feedid input for this choreo . ( ( required , integer ) the id for the feed that you would like to update . )"
"set the value of the maxvalue input for this choreo . ( ( optional , string ) the maximum value since the last reset . leave empty to keep existing maxvalue . type "" blank "" to clear existing value . )"
"set the value of the minvalue input for this choreo . ( ( optional , string ) the minimum value since the last reset . leave empty to keep existing minvalue . type "" blank "" to clear existing value . )"
"set the value of the tags input for this choreo . ( ( optional , string ) comma - separated list of searchable tags ( the characters ' , "" , and commas are not allowed ) . tags input overwrites previous tags , enter "" blank "" to clear all tags . ex : "" power , energy "" . )"
"set the value of the unitsymbol input for this choreo . ( ( optional , string ) the symbol of the unit . leave empty to keep existing unitsymbol . type "" blank "" to clear existing value . ex : "" c "" . )"
"set the value of the unittype input for this choreo . ( ( optional , string ) the type of unit . leave empty to keep existing unittype . type "" blank "" to clear existing value . ex : "" basicsi "" . )"
"set the value of the units input for this choreo . ( ( optional , string ) the units of the datastream . leave empty to keep existing units . type "" blank "" to clear existing units . ex : "" celsius "" . )"
"retrieve the value for the "" responsestatuscode "" output from this choreo execution . ( ( integer ) the response status code returned from xively . for a successful datastream update , the code should be 200 . )"
"create a new instance of the renameitem choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( conditional , string ) the api key provided by filesanywhere . required unless supplying a valid token input . )"
"set the value of the newname input for this choreo . ( ( required , string ) enter the new name for the item . )"
"set the value of the orgid input for this choreo . ( ( conditional , integer ) defaults to 0 for a filesanywhere web account . use 50 for a filesanywhere webadvanced account . )"
"set the value of the password input for this choreo . ( ( conditional , password ) your filesanywhere password . required unless supplying a valid token input . )"
"set the value of the path input for this choreo . ( ( required , string ) the path to the file you want to rename ( i.e. \johnsmith\myfolder\myfile.txt ) . )"
"set the value of the token input for this choreo . ( ( conditional , string ) if provided , the choreo will use the token to authenticate . if the token is expired or not provided , the choreo will relogin and retrieve a new token when apikey , username , and password are supplied . )"
"set the value of the type input for this choreo . ( ( required , string ) specify the type of file being renamed by entering : folder , or , file . )"
"set the value of the username input for this choreo . ( ( conditional , string ) your filesanywhere username . required unless supplying a valid token input . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from filesanywhere . )"
"create a new instance of the updatebike choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( required , string ) the i d of the action to update . )"
"set the value of the course input for this choreo . ( ( optional , string ) the url or id for an open graph object representing the course . )"
"set the value of the endtime input for this choreo . ( ( optional , date ) the time that the user ended the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the expiresin input for this choreo . ( ( optional , integer ) the amount of time ( in milliseconds ) from the publish_time that the action will expire . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message attached to this fitness action . setting this parameter requires enabling of message capabilities . )"
"set the value of the place input for this choreo . ( ( optional , string ) the url or id for an open graph object representing the location associated with this action . )"
"set the value of the tags input for this choreo . ( ( optional , string ) a comma separated list of other profile ids that also performed this action . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( boolean ) the response from facebook . )"
"create a new instance of the searchnumbers choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) your api key provided to you by nexmo . )"
"set the value of the apisecret input for this choreo . ( ( required , string ) your api secret provided to you by nexmo . )"
"set the value of the country input for this choreo . ( ( required , string ) 2 - digit country code . ( e.g. ca ) )"
"set the value of the index input for this choreo . ( ( optional , integer ) page index )"
"set the value of the pattern input for this choreo . ( ( optional , string ) pattern to match . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" json "" ( the default ) and "" xml "" . )"
"set the value of the size input for this choreo . ( ( optional , integer ) page size . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from nexmo . corresponds to the responseformat input . defaults to json . )"
"create a new instance of the storetoken choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the expires input for this choreo . ( ( optional , integer ) the lifetime of the token ( in seconds ) . defaults to 0 indicating no expiration . )"
"set the value of the name input for this choreo . ( ( required , string ) the token name . when a token does not exist , it will be inserted . when a token does exist , an update is performed . )"
"set the value of the value input for this choreo . ( ( required , string ) the token value to store . the maximum number of characters for a token is 4096 . )"
"retrieve the value for the "" updated "" output from this choreo execution . ( ( boolean ) returns true if token is stored successfully . )"
"create a new instance of the retrieveactivity choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the activityid input for this choreo . ( ( required , string ) this can be the individual i d of the activity , or you can pass the full uri for the activity as returned from retrieveactivities response ( i.e. /strengthtrainingactivities/125927913 ) . )"
"create a new instance of the listbyactivity choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the activityid input for this choreo . ( ( required , string ) the id of the activity to get the list of people for . activiyids can be retrieved by running the google . plus . activities . search choreo . )"
"set the value of the callback input for this choreo . ( ( optional , string ) specifies a javascript function that will be passed the response data for using the api with jsonp . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the collection input for this choreo . ( ( required , string ) valid values are : "" plusoners "" ( lists all people who have +1'd this activity ) and "" resharers "" ( lists all people who have reshared this activity ) . )"
"set the value of the fields input for this choreo . ( ( optional , string ) used to specify fields to include in a partial response . this can be used to reduce the amount of data returned . see documentation for syntax rules . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of people to include in the response . used for paging through results . valid values are : 1 to 20 . default is 10 . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" returned in the choreo output . used to page through large result sets . )"
"set the value of the prettyprint input for this choreo . ( ( optional , boolean ) a flag used to pretty print the json response to make it more readable . defaults to "" true "" . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the userip input for this choreo . ( ( optional , string ) identifies the ip address of the end user for whom the api call is being made . used to enforce per - user quotas . )"
"create a new instance of the deletekeypair choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the keyname input for this choreo . ( ( required , string ) a unique name for the key pair . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the ec2 endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"create a new instance of the listmergevaradd choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by mailchimp . )"
"set the value of the choices input for this choreo . ( ( optional , string ) a list of up to 10 choices for radio and dropdown type fields ) separated by commas ) . )"
"set the value of the dateformat input for this choreo . ( ( optional , string ) valid for birthday and date fields . for birthday , must be "" mm / dd "" ( default ) or "" dd / mm "" . for date type , must be "" mm / dd / yyyy "" ( default ) or "" dd / mm / yyyy "" . )"
"set the value of the defaultcountry input for this choreo . ( ( optional , string ) the iso 3166 2 digit character code for the default country . defaults to "" us "" . )"
"set the value of the defaultvalue input for this choreo . ( ( optional , string ) the default value for the new field . )"
"set the value of the fieldtype input for this choreo . ( ( optional , string ) must be either left unset or one of ' text ' , ' number ' , ' radio ' , ' dropdown ' , ' date ' , ' address ' , ' phone ' , ' url ' , or ' imageurl . defaults to text . )"
"set the value of the listid input for this choreo . ( ( required , string ) the id of the list on which to add the new merge var . )"
"set the value of the name input for this choreo . ( ( required , string ) provide a long merge var name for user display ( i.e. first name ) )"
"set the value of the phoneformat input for this choreo . ( ( optional , string ) defaults to "" us "" - any other value will cause them to be unformatted ( international ) . )"
"set the value of the public input for this choreo . ( ( optional , boolean ) indicates whether the field is displayed in public . specify ' 1 ' ( true ) or ' 0 ' ( false ) . defaults to 1 . )"
"set the value of the req input for this choreo . ( ( optional , boolean ) indicates that the field will be required . specify ' 1 ' ( true ) or ' 0 ' ( false ) . defaults to 0 . )"
"set the value of the show input for this choreo . ( ( optional , boolean ) indicates whether the field is displayed in the app 's list member view . specify ' 1 ' ( true ) or ' 0 ' ( false ) . defaults to 1 . )"
"set the value of the tag input for this choreo . ( ( required , string ) provide a short merge var tag name . must be 10 utf-8 chars , including ' a - z ' , ' 0 - 9 ' , or ' _ ' only ( i.e. desc123456 ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( boolean ) the response from mailchimp . returns the string "" true "" for success and an error description for failures . )"
"create a new instance of the initializeoauth choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the customcallbackid input for this choreo . ( ( optional , string ) a unique identifier that you can pass to eliminate the need to wait for a temboo generated callbackid . callback identifiers may only contain numbers , letters , periods , and hyphens . )"
"set the value of the publickey input for this choreo . ( ( conditional , string ) the public key provided by disqus ( aka the api key ) . )"
"set the value of the scope input for this choreo . ( ( optional , string ) available permissions to request on behalf of the user are read , write and admin , multiple values separated by a comma ( ex : "" read , write "" ) . default ( blank ) is same as "" read , write "" . )"
"retrieve the value for the "" authorizationurl "" output from this choreo execution . ( ( string ) the authorization url that the user needs to go to in order to grant access to your application . )"
"create a new instance of the getaccount choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountsid input for this choreo . ( ( required , string ) the accountsid provided when you signed up for a twilio account . )"
"set the value of the authtoken input for this choreo . ( ( required , string ) the authorization token provided when you signed up for a twilio account . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the subaccountsid input for this choreo . ( ( optional , string ) the sid of the subaccount to retrieve . if not specified , the main accountsid used to authenticate is used in request . )"
"create a new instance of the retrieveentry choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the entryid input for this choreo . ( ( required , string ) this can be the individual i d of the sleep entry , or you can pass the full uri for the entry as returned from the retrieveentries response ( i.e. /sleep/-12985593 - 1347998400000 ) . )"
"create a new instance of the like choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the objectid input for this choreo . ( ( required , string ) the i d of a graph api object to like . )"
"create a new instance of the getcollaboratorstatus choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( conditional , string ) the access token retrieved during the oauth process . required when accessing a protected resource . )"
"set the value of the collaborator input for this choreo . ( ( required , string ) the username of the collaborator to check . )"
"set the value of the repo input for this choreo . ( ( required , string ) the name of the repo that has the collaborators to retrieve . )"
"set the value of the user input for this choreo . ( ( required , string ) the github username . )"
"create a new instance of the getlenderloans choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the appid input for this choreo . ( ( optional , string ) your unique application id , usually in reverse dns notation . )"
"set the value of the lendername input for this choreo . ( ( required , string ) the lender name for which to return details . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page position of results to return . defaults to 1 . )"
"set the value of the responsetype input for this choreo . ( ( optional , string ) output returned can be xml or json . defaults to json . )"
"set the value of the sortby input for this choreo . ( ( optional , string ) the order by which to sort results . acceptable values : oldest , newest . defaults to newest . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from kiva . )"
"create a new instance of the urldecode choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the text input for this choreo . ( ( required , string ) the text that should be url decoded . )"
"retrieve the value for the "" urldecodedtext "" output from this choreo execution . ( ( string ) the url decoded text . )"
"create a new instance of the createinstanceprofile choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the instanceprofilename input for this choreo . ( ( required , string ) name of the instance profile to create . )"
"set the value of the path input for this choreo . ( ( optional , string ) the path for the user name . if it is not included , it defaults to a slash ( / ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"create a new instance of the getcensusidbycoordinates choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the geographytype input for this choreo . ( ( required , string ) specify one of the following geography type values : "" state "" , "" county "" , "" tract "" , "" block "" , "" congdistrict "" , "" statehouse "" , "" statesenate "" , "" censusplace "" , or "" msa "" ( metropolitan statistical area ) . )"
"set the value of the latitude input for this choreo . ( ( required , decimal ) specify a latitude to search for , such as "" 41.486857 "" . )"
"set the value of the longitude input for this choreo . ( ( required , decimal ) specify a longitude to search for , such as "" -71.294392 "" . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml ( the default ) and json . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response returned from the api . )"
"retrieve the value for the "" censusid "" output from this choreo execution . ( ( integer ) the id retrieved from the api call . )"
"create a new instance of the updateentry choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the entry input for this choreo . ( ( required , json ) a json string containing the key / value pairs for the fields to be updated in the sleep entry . see documentation for formatting examples . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the entryid input for this choreo . ( ( required , string ) this can be the individual i d of the sleep entry , or you can pass the full uri for the entry as returned from the retrieveentries response ( i.e. /sleep/-12985593 - 1347998400000 ) . )"
"create a new instance of the readquotes choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( optional , string ) the i d of an action to retrieve . if an i d is not provided , a list of all quote actions will be returned . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) used to page through results . limits the number of records returned in the response . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) used to page through results . returns results starting from the specified number . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the getfood choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the foodid input for this choreo . ( ( required , integer ) the id of the food to retrieve . )"
"create a new instance of the getrecentstations choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) your last.fm api key . )"
"set the value of the apisecret input for this choreo . ( ( required , string ) your last.fm api secret . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to fetch per page . defaults to 10 . maximum is 25 . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page number to fetch . defaults to first page . )"
"set the value of the sessionkey input for this choreo . ( ( required , string ) the session key retrieved in the last step of the authorization process . )"
"set the value of the user input for this choreo . ( ( required , string ) the last.fm username to fetch the recent stations of . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from last.fm . )"
"create a new instance of the enditem choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the endingreason input for this choreo . ( ( required , string ) the reason the listing is ending early . valid values are : lostorbroken , notavailable , incorrect , otherlistingerror , customcode , selltohighbidder , or sold . )"
"set the value of the itemid input for this choreo . ( ( required , string ) the id of the item to end . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the sandboxmode input for this choreo . ( ( conditional , boolean ) indicates that the request should be made to the sandbox endpoint instead of the production endpoint . set to 1 to enable sandbox mode . )"
"set the value of the sellerinventoryid input for this choreo . ( ( optional , string ) unique identifier that the seller specified when they listed the half.com item . this paramater only applies to half.com . )"
"set the value of the siteid input for this choreo . ( ( optional , string ) the ebay site id that you want to access . defaults to 0 indicating the us site . )"
"set the value of the usertoken input for this choreo . ( ( required , string ) a valid ebay auth token . )"
"create a new instance of the getreportbyid choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awsmarketplaceid input for this choreo . ( ( required , string ) the marketplace id provided by amazon web services . )"
"set the value of the awsmerchantid input for this choreo . ( ( required , string ) the merchant id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the endpoint input for this choreo . ( ( conditional , string ) the base url for the mws endpoint . defaults to mws.amazonservices.co.uk . )"
"set the value of the mwsauthtoken input for this choreo . ( ( optional , string ) the amazon mws authorization token for the given seller and developer . )"
"set the value of the reportid input for this choreo . ( ( required , integer ) the i d of the report to retrieve . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from amazon which contains the contents of the report requested . this is typically a flat file or xml information . )"
"retrieve the value for the "" contentmd5header "" output from this choreo execution . ( ( string ) )"
"create a new instance of the retrievepostswithtag choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by tumblr ( aka the oauth consumer key ) . )"
"set the value of the before input for this choreo . ( ( optional , string ) the timestamp of when you 'd like to see posts before ( e.g. 1363716547 ) . )"
"set the value of the filter input for this choreo . ( ( optional , string ) specifies the post format to return . valid values are : text ( plain text , no html ) or raw ( as entered by the user ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of posts to return : 1- 20 . defaults to 20 . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the post number to start at . defaults to 0 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the tag input for this choreo . ( ( required , string ) the tag on the posts you 'd like to retrieve . )"
"create a new instance of the getuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from wordnik . )"
"set the value of the password input for this choreo . ( ( required , string ) password of the wordnik account . )"
"set the value of the responsetype input for this choreo . ( ( optional , string ) response can be either json or xml . defaults to json . )"
"set the value of the username input for this choreo . ( ( required , string ) username of the wordnik account . )"
"create a new instance of the candidatedetails choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the campaigncycle input for this choreo . ( ( required , integer ) enter the campaign cycle year in yyyy format . this must be an even year . )"
"set the value of the fecid input for this choreo . ( ( required , string ) enter the fec id for the candidate . id can be obtained by first running the candidatesearch choreo . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) enter json or xml . default is json . )"
"create a new instance of the createaction choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actiontype input for this choreo . ( ( required , string ) the type of action that a user is performing in your app ( e.g. runs , walks , bikes ) . )"
"set the value of the appnamespace input for this choreo . ( ( required , string ) the namespace that you chose for you app . this can be found in the settings section of your app page . )"
"set the value of the createdtime input for this choreo . ( ( optional , date ) the time that the action was created ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the endtime input for this choreo . ( ( optional , date ) the time that the user ended the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the expiresin input for this choreo . ( ( optional , integer ) the amount of time ( in milliseconds ) from the publish_time that the action will expire . )"
"set the value of the explicitlyshared input for this choreo . ( ( optional , boolean ) indicates that the user is explicitly sharing this action . requires the explicitly_shared capability to be enabled . )"
"set the value of the explicityshared input for this choreo . ( ( optional , boolean ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message attached to this action . setting this parameter requires enabling of message capabilities . )"
"set the value of the nofeedstory input for this choreo . ( ( optional , boolean ) whether or not this action should be posted to the users feed . )"
"set the value of the place input for this choreo . ( ( optional , string ) the url or id for an open graph object representing the location associated with this action . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the propertyname input for this choreo . ( ( required , string ) the name of a property that you 've defined for this open graph story . this will be an object type ( e.g. album , song , book ) . multiple property names can be separated by commas . )"
"set the value of the propertyvalue input for this choreo . ( ( required , string ) the url or id for an open graph object representing the object specified as the propertyname . multiple property values can be separated by commas . )"
"set the value of the reference input for this choreo . ( ( optional , string ) a string identifier up to 50 characters used for tracking and insights . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the starttime input for this choreo . ( ( optional , date ) the time that the user started the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the tags input for this choreo . ( ( optional , string ) a comma separated list of other profile ids that also performed this action . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from facebook . )"
"create a new instance of the deletedevice choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by xively . )"
"set the value of the productid input for this choreo . ( ( required , string ) the product id for the device you would like to delete . )"
"set the value of the serialnumber input for this choreo . ( ( required , string ) the serial number for the device you would like to delete . )"
"retrieve the value for the "" responsestatuscode "" output from this choreo execution . ( ( integer ) the response status code returned from xively . for a successful deletion , the status code should be 200 . )"
"create a new instance of the listphotosforlocation choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by flickr ( aka the oauth consumer key ) . )"
"set the value of the apisecret input for this choreo . ( ( required , string ) the api secret provided by flickr ( aka the oauth consumer secret ) . )"
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the accuracy input for this choreo . ( ( optional , integer ) recorded accuracy level of the location information . current range is 1 - 16 . defaults to 16 if not specified . )"
"set the value of the extras input for this choreo . ( ( optional , string ) a comma - delimited list of extra information to retrieve for each returned record . see choreo documentation for accepted values . )"
"set the value of the latitude input for this choreo . ( ( required , decimal ) the latitude whose valid range is -90 to 90 . anything more than 6 decimal places will be truncated . )"
"set the value of the longitude input for this choreo . ( ( required , decimal ) the longitude whose valid range is -180 to 180 . anything more than 6 decimal places will be truncated . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page of results to return . used for paging through many results . defaults to 1 . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) number of photos to return per page . if this argument is omitted , it defaults to 100 . the maximum allowed value is 500 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml and json . defaults to json . )"
"create a new instance of the stargist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the id input for this choreo . ( ( required , string ) the i d for the gist you want to star . )"
"create a new instance of the regeneratekey choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key you would like to regenerate . on successful regeneration , this api key will no longer be valid . )"
"set the value of the masterapikey input for this choreo . ( ( optional , string ) specify a masterapikey with sufficient permissions if the apikey you would like to regenerate does not have the permissions to do so . )"
"retrieve the value for the "" apikeylocation "" output from this choreo execution . ( ( string ) the url of the newly regenerated apikey . )"
"retrieve the value for the "" newapikey "" output from this choreo execution . ( ( string ) the regenerated apikey obtained from the apikeylocation returned by this choreo . )"
"create a new instance of the getlowestofferlistingsforasin choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the asin input for this choreo . ( ( required , string ) a comma - separated list of up to 20 asin values used to identify products in the given marketplace . )"
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awsmarketplaceid input for this choreo . ( ( required , string ) the marketplace id provided by amazon web services . )"
"set the value of the awsmerchantid input for this choreo . ( ( required , string ) the merchant id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the endpoint input for this choreo . ( ( conditional , string ) the base url for the mws endpoint . defaults to mws.amazonservices.co.uk . )"
"set the value of the itemcondition input for this choreo . ( ( optional , string ) filters the offer listings to be considered based on item condition . valid values : new , used , collectible , refurbished , club . )"
"set the value of the mwsauthtoken input for this choreo . ( ( optional , string ) the amazon mws authorization token for the given seller and developer . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"retrieve the value for the "" response "" output from this choreo execution . ( stores the response from amazon . )"
"create a new instance of the deleteaction choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( required , string ) the i d of an action to delete . )"
"create a new instance of the createdbsecuritygroup choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the dbsecuritygroupdescription input for this choreo . ( ( required , string ) a description for the security group you 're creating . )"
"set the value of the dbsecuritygroupname input for this choreo . ( ( required , string ) a unique name for the security group you want to create . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the rds endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from amazon . )"
"create a new instance of the readwalks choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( optional , string ) the i d of an action to retrieve . if an i d is not provided , a list of all walk actions will be returned . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) used to page through results . limits the number of records returned in the response . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) used to page through results . returns results starting from the specified number . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the committeesearch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the campaigncycle input for this choreo . ( ( required , integer ) enter the campaign cycle year in yyyy format . this must be an even year . )"
"set the value of the name input for this choreo . ( ( required , string ) specify the name of the committee to be retireved . partial names are also acceptable . examples : viacom . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) enter json or xml . default is json . )"
"create a new instance of the unfriend choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( required , string ) the id of a user to unfriend . )"
dispatch the request to every httpplugin
"create a new instance of the getsuggestedusers choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret provided by twitter or retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token provided by twitter or retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the api key ( or consumer key ) provided by twitter . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the api secret ( or consumer secret ) provided by twitter . )"
"set the value of the language input for this choreo . ( ( optional , string ) restricts the suggested categories to the requested language . the language must be specified by the appropriate two letter iso 639 - 1 code ( e.g. , en ) . )"
"set the value of the members input for this choreo . ( ( optional , boolean ) when set to true , makes a request to users / suggestions/:slug / members and retrieves the most recent statuses for users that are not protected . )"
"set the value of the slug input for this choreo . ( ( required , string ) the short name of the category ( e.g. , news , technology , government ) . these are returned in the response of the getsuggestedcategories choreo . )"
"create a new instance of the findsubstring choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the casesensitive input for this choreo . ( ( optional , boolean ) when set to true , the search will be case - sensitive . defaults to false indicating a case - insensitive search . )"
"set the value of the startnumber input for this choreo . ( ( optional , string ) the character position at which to begin the search . defaults to 1 . )"
"set the value of the substring input for this choreo . ( ( required , string ) the sub - string to search within the specified text ( searching from left to right ) . )"
"set the value of the text input for this choreo . ( ( required , string ) the text to search for a sub - string . )"
"retrieve the value for the "" count "" output from this choreo execution . ( ( integer ) the count of sub - strings found . )"
"retrieve the value for the "" positions "" output from this choreo execution . ( ( json ) the positions of the sub - strings that were found in the search . )"
"create a new instance of the verifycredentials choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret provided by twitter or retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token provided by twitter or retrieved during the oauth process . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the api key ( or consumer key ) provided by twitter . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the api secret ( or consumer secret ) provided by twitter . )"
"set the value of the includeuserentities input for this choreo . ( ( optional , boolean ) the user "" entities "" node containing extra metadata will not be included when set to false . )"
"set the value of the skipstatus input for this choreo . ( ( optional , boolean ) when set to true , statuses will not be included in the returned user objects . )"
"create a new instance of the gettransactiondetails choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apiloginid input for this choreo . ( ( required , string ) the api login i d provided by authorize.net when signing up for a developer account . )"
"set the value of the endpoint input for this choreo . ( ( optional , string ) set to api.authorize.net when running in production . defaults to apitest.authorize.net for sandbox testing . )"
"set the value of the transactionid input for this choreo . ( ( required , integer ) the i d of the transaction that you want to retrieve information for . )"
"set the value of the transactionkey input for this choreo . ( ( required , string ) the transactionkey provided by authorize.net when signing up for a developer account . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from authorize.net . )"
"create a new instance of the segmentationforvisitorstodayviasearch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of records you want to retrieve . defaults to 30 . )"
"set the value of the output input for this choreo . ( ( optional , string ) what format you want the returned data to be in . accepted values : xml , php , json , csv . defaults to ' xml ' . )"
"set the value of the siteid input for this choreo . ( ( required , integer ) your request must include the site 's id that you want to access data from . available from your site preferences page . )"
"set the value of the sitekey input for this choreo . ( ( required , string ) the unique key assigned to you when you first register with clicky . available from your site preferences page . )"
"set the value of the type input for this choreo . ( ( optional , string ) the type of data you want to retrieve . defaults to "" segmentation "" . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from clicky formatted as specified in the output parameter . default is xml . )"
"create a new instance of the getentry choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( required , string ) a valid basecamp account name . this is the first part of the account 's url . )"
"set the value of the entryid input for this choreo . ( ( required , integer ) the id for the calendar entry to retrieve . )"
"set the value of the password input for this choreo . ( ( required , password ) the basecamp account password . use the value ' x ' when specifying an api key for the username input . )"
"set the value of the projectid input for this choreo . ( ( required , integer ) the id for the project from which to retrieve the calendar entry . )"
"set the value of the username input for this choreo . ( ( required , string ) a basecamp account username or api key . )"
"create a new instance of the createbike choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the course input for this choreo . ( ( required , string ) the url or id for an open graph object representing the course . )"
"set the value of the createdtime input for this choreo . ( ( optional , date ) the time that the action was created ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the endtime input for this choreo . ( ( optional , date ) the time that the user ended the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the expiresin input for this choreo . ( ( optional , integer ) the amount of time ( in milliseconds ) from the publish_time that the action will expire . )"
"set the value of the explicitlyshared input for this choreo . ( ( optional , boolean ) indicates that the user is explicitly sharing this action . requires the explicitly_shared capability to be enabled . )"
"set the value of the explicityshared input for this choreo . ( ( optional , boolean ) deprecated ( retained for backward compatibility only ) . )"
"set the value of the message input for this choreo . ( ( optional , string ) a message attached to this action . setting this parameter requires enabling of message capabilities . )"
"set the value of the nofeedstory input for this choreo . ( ( optional , boolean ) whether or not this action should be posted to the users feed . )"
"set the value of the place input for this choreo . ( ( optional , string ) the url or id for an open graph object representing the location associated with this action . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the user 's profile . defaults to "" me "" indicating the authenticated user . )"
"set the value of the reference input for this choreo . ( ( optional , string ) a string identifier up to 50 characters used for tracking and insights . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the starttime input for this choreo . ( ( optional , date ) the time that the user started the action ( e.g. 2013 - 06 - 24t18:53:35 + 0000 ) . )"
"set the value of the tags input for this choreo . ( ( optional , string ) a comma separated list of other profile ids that also performed this action . )"
"create a new instance of the advancedsearch choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the operator input for this choreo . ( ( optional , string ) default output is "" = "" when searchtype = sector_id or product_id , and "" containing "" when searchtype = partner , product , or sector . other possible values are : "" < "" , "" > "" , "" ! = "" , and "" beginning "" . )"
"set the value of the responseformat input for this choreo . ( ( conditional , string ) response can be returned in json or xml . defaults to xml . )"
"set the value of the rowend input for this choreo . ( ( optional , integer ) number 1 or greater indicates the ending row number of the results displayed . default is 4999 when rowstart is 0 . up to 5000 entries are returned in the output . )"
"set the value of the rowstart input for this choreo . ( ( optional , integer ) indicates the starting row number of the results displayed . default is 0 . )"
"set the value of the searchtype input for this choreo . ( ( conditional , string ) indicate either "" sector "" , "" sector_id "" , "" partner "" , "" product "" , or "" product_id . "" used together with searchvalue and the optional operator input to formulate a specific search of the dfe database . )"
"set the value of the searchvalue input for this choreo . ( ( conditional , integer ) indicate the product , code , or sector to search for . used together with searchtype and the optional operator input to create a customized search . )"
"retrieve the value for the "" count "" output from this choreo execution . ( the total number of records returned for any given search . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from envirofacts . )"
"create a new instance of the committeeindependentexpenditures choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by ny times . )"
"set the value of the campaigncycle input for this choreo . ( ( required , integer ) enter the campaign cycle year in yyyy format . this must be an even year . )"
"set the value of the fecid input for this choreo . ( ( required , string ) enter the fec id for the committee . id can be obtained by first running the committeesearch choreo . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the first 20 results are shown by default . to page through the results , set offset to the appropriate value ( e.g. , offset=40 displays results 41–60 ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) enter json or xml . default is json . )"
"create a new instance of the listgrouppolicies choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the groupname input for this choreo . ( ( required , string ) the name of the group to list policies for . )"
"set the value of the marker input for this choreo . ( ( optional , string ) used for pagination to indicate the starting point of the results to return . )"
"set the value of the maxitems input for this choreo . ( ( optional , integer ) used for pagination to limit the number of results returned . defaults to 100 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"create a new instance of the getpricingbyprefix choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) your api key provided to you by nexmo . )"
"set the value of the apisecret input for this choreo . ( ( required , string ) your api secret provided to you by nexmo . )"
"set the value of the prefix input for this choreo . ( ( required , integer ) international dialing code . ( e.g. 44 ) )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" json "" ( the default ) and "" xml "" . )"
"create a new instance of the updateuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the userobject input for this choreo . ( ( required , json ) a json object representing the user 's information that should be updated . see documentation for formatting examples . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth2 process . )"
"set the value of the asuser input for this choreo . ( ( optional , string ) the id of the user . only used for enterprise administrators to make api calls for their managed users . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma - separated list of fields to include in the response . )"
"set the value of the userid input for this choreo . ( ( required , string ) the i d of the user whose information should be updated . )"
"create a new instance of the searchvenues choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accuracyofcoordinates input for this choreo . ( ( optional , integer ) accuracy of latitude and longitude , in meters . currently , this parameter does not affect search results . )"
"set the value of the altitudeaccuracy input for this choreo . ( ( optional , integer ) accuracy of the user 's altitude , in meters . currently , this parameter does not affect search results . )"
"set the value of the altitude input for this choreo . ( ( optional , integer ) altitude of the user 's location , in meters . currently , this parameter does not affect search results . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) your foursquare client id , obtained after registering at foursquare . required unless using the oauthtoken input . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) your foursquare client secret , obtained after registering at foursquare . required unless using the oauthtoken input . )"
"set the value of the intent input for this choreo . ( ( optional , string ) indicates your intent when performing the search . enter : checkin ( default ) , match ( requires query and latitude / longitude to be provided ) . )"
"set the value of the latitude input for this choreo . ( ( required , decimal ) the latitude point of the user 's location . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) number of results to retun , up to 50 . )"
"set the value of the longitude input for this choreo . ( ( required , decimal ) the longitude point of the user 's location . )"
"set the value of the oauthtoken input for this choreo . ( ( conditional , string ) the foursquare api oauth token string . required unless specifying the clientid and clientsecret . )"
"set the value of the query input for this choreo . ( ( optional , string ) your search string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the deletemultipleobjects choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the the name of the bucket that contains the objects that you want to delete . )"
"set the value of the filenames input for this choreo . ( ( required , string ) a list of file names to delete ( separated by commas ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from amazon . note that no content is returned for a successful delete operation . )"
"create a new instance of the findbykeyword choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by flickr ( aka the oauth consumer key ) . )"
"set the value of the query input for this choreo . ( ( required , string ) the query string to use for place id lookups . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : xml and json . defaults to json . )"
"create a new instance of the userdetail choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the id of the user to get details for . pass "" self "" to get details of the acting user . defaults to "" self "" . )"
"create a new instance of the getratesummary choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the outputformat input for this choreo . ( ( optional , string ) enter the desired query output format . enter : xml , or json . default output is set to : xml . )"
"set the value of the state input for this choreo . ( ( optional , string ) enter a u.s. state abbreviation for which to retrieve mortgage rates . if null , the national average rate is returned . )"
"set the value of the zwsid input for this choreo . ( ( required , string ) enter a zillow web service identifier ( zws id ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from zillow . )"
"create a new instance of the getfoldermetadata choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by amazon . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by amazon . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma - separated list of additional fields to include in the response . )"
"set the value of the handlerequestthrottling input for this choreo . ( ( optional , boolean ) whether or not to perform a retry sequence if a throttling error occurs . set to true to enable this feature . the request will be retried up - to five times when enabled . )"
"set the value of the id input for this choreo . ( ( required , string ) the id of the folder to return metadata for . )"
"set the value of the metadataurl input for this choreo . ( ( optional , string ) the appropriate metadataurl for your account . when not provided , the choreo will lookup the url using the account . getendpoint choreo . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from amazon . )"
"create a new instance of the getpasswordinfo choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by salesforce . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by salesforce . required unless providing a valid accesstoken . )"
"set the value of the id input for this choreo . ( ( required , string ) the id of the user you 're getting info for . )"
"set the value of the instancename input for this choreo . ( ( required , string ) the server url prefix that indicates which instance your salesforce account is on ( e.g. na1 , na2 , na3 , etc ) . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from salesforce . )"
"create a new instance of the removeuserfromgroup choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the groupname input for this choreo . ( ( required , string ) name of the group to update . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the username input for this choreo . ( ( required , string ) name of the user to remove . )"
"create a new instance of the deleterecipientlist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the list input for this choreo . ( ( required , string ) the name of a recipient list to be deleted from this account . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format of the response from sendgrid , in either json , or xml . default is set to json . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( string ) the response from sendgrid . the format corresponds to the responseformat input . default is json . )"
"create a new instance of the getpeopleacrossprojects choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( required , string ) the basecamp account name for you or your company . this is the first part of your account url . )"
"set the value of the password input for this choreo . ( ( required , password ) your basecamp password . you can use the value ' x ' when specifying an api key for the username input . )"
"set the value of the username input for this choreo . ( ( required , string ) your basecamp username or api key . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from basecamp . )"
"create a new instance of the deletebucketwebsite choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket associated with the website configuration you want to delete . )"
"retrieve the value for the "" response "" output from this choreo execution . ( stores the response from amazon . note that for a successful delete operation , no content is returned and this output variable is empty . )"
"create a new instance of the putbucketversioning choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket to create a notification for . )"
"set the value of the status input for this choreo . ( ( required , string ) indicates whether or not the bucket has versioning enabled . valid values are : enabled or suspended ( case - sensitive ) . )"
"retrieve the value for the "" response "" output from this choreo execution . ( stores the response from amazon . note that for a successful execution , no content is returned and this output variable should be empty . )"
"create a new instance of the followuser choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) a valid oauth 2.0 access token . )"
"set the value of the callback input for this choreo . ( ( optional , string ) the name of a callback function to wrap the response in . used when setting responseformat to "" jsonp "" . )"
"set the value of the publickey input for this choreo . ( ( required , string ) the public key provided by disqus ( aka the api key ) . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and jsonp . )"
"set the value of the userid input for this choreo . ( ( conditional , string ) the user id that is to be followed . if userid is set , then username must be null . )"
"set the value of the username input for this choreo . ( ( conditional , string ) the disqus username that is to be followed . if username is being set , then userid must be null . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from disqus . )"
"create a new instance of the listrolepolicies choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the marker input for this choreo . ( ( optional , string ) used for pagination to indicate the starting point of the results to return . )"
"set the value of the maxitems input for this choreo . ( ( optional , integer ) used for pagination to limit the number of results returned . defaults to 100 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the rolename input for this choreo . ( ( required , string ) name of the role that you would like to retrieve policies for . )"
"create a new instance of the removechild choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the childid input for this choreo . ( ( required , string ) the id of the folder that is being removed from a parent folder . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by amazon . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by amazon . required unless providing a valid accesstoken . )"
"set the value of the handlerequestthrottling input for this choreo . ( ( optional , boolean ) whether or not to perform a retry sequence if a throttling error occurs . set to true to enable this feature . the request will be retried up - to five times when enabled . )"
"set the value of the metadataurl input for this choreo . ( ( optional , string ) the appropriate metadataurl for your account . when not provided , the choreo will lookup the url using the account . getendpoint choreo . )"
"set the value of the parentid input for this choreo . ( ( required , string ) the id of the parent folder that contains the child folder that 's being removed . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the disassociateaddress choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the associationid input for this choreo . ( ( conditional , string ) [ ec2 - vpc ] the association id corresponding to the elastic ip address . )"
"set the value of the publicip input for this choreo . ( ( conditional , string ) [ ec2 - classic ] the elastic ip address . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the ec2 endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"create a new instance of the gettoptracks choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) your last.fm api key . )"
"set the value of the artist input for this choreo . ( ( conditional , string ) the artist name . required unless providing mbid . )"
"set the value of the autocorrect input for this choreo . ( ( optional , boolean ) transform misspelled artist names into correct artist names . the corrected artist name will be returned in the response . defaults to 0 . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of results to fetch per page . defaults to 50 . )"
"set the value of the mbid input for this choreo . ( ( conditional , string ) the musicbrainz i d for the artist . required unless providing artist . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page number to fetch . defaults to 1 . )"
"create a new instance of the createentry choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( required , string ) a valid basecamp account name . this is the first part of the account 's url . )"
"set the value of the enddate input for this choreo . ( ( required , date ) the date the entry ends , in yyyy - mm - dd format . this is the same as startdate for one - day entries . )"
"set the value of the password input for this choreo . ( ( required , password ) the basecamp account password . use the value ' x ' when specifying an api key for the username input . )"
"set the value of the projectid input for this choreo . ( ( required , integer ) the id for the project in which to create the new entry . )"
"set the value of the responsibleparty input for this choreo . ( ( optional , any ) the user id or company id ( preceded by a “ c ” , as in "" c1234 "" ) to assign the entry to . applies only to "" milestone "" entry types . )"
"set the value of the startdate input for this choreo . ( ( required , date ) the date the entry starts , in yyyy - mm - dd format . )"
"set the value of the title input for this choreo . ( ( required , string ) the title for the calendar entry to create . )"
"set the value of the type input for this choreo . ( ( required , string ) the type of calendar entry to create , either "" milestone "" or "" calendarevent "" ( the default ) . )"
"set the value of the username input for this choreo . ( ( required , string ) a basecamp account username or api key . )"
"create a new instance of the deletealarm choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the alarmid input for this choreo . ( ( required , string ) the id of the alarm to delete . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"set the value of the deviceid input for this choreo . ( ( required , string ) the i d of the device you would like to manage the alarm on . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that you want the response to be in : xml or json . defaults to json . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the user 's encoded i d. defaults to "" - "" ( dash ) which will return data for the user associated with the token credentials provided . )"
"create a new instance of the deletefile choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth2 process . )"
"set the value of the asuser input for this choreo . ( ( optional , string ) the id of the user . only used for enterprise administrators to make api calls for their managed users . )"
"set the value of the fileid input for this choreo . ( ( required , string ) the i d of the file that you want to delete . )"
"create a new instance of the getuserinformation choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by tumblr ( aka the oauth consumer key ) . )"
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the secretkey input for this choreo . ( ( required , string ) the secret key provided by tumblr ( aka the oauth consumer secret ) . )"
"create a new instance of the listnetworks choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) comma - seperated list of fields you want to include in the response . )"
"set the value of the filter input for this choreo . ( ( optional , string ) a filter expression for narrowing results in the form : { field_name } { comparison_string } { literal_string } ( e.g. name eq default ) . comparison strings can be eq ( equals ) or ne ( not equals ) . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of results to return . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" found in the response which is used to page through results . )"
"set the value of the project input for this choreo . ( ( required , string ) the id of a google compute project . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"create a new instance of the putbucketwebsiteredirectall choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the bucketname input for this choreo . ( ( required , string ) the name of the bucket that you wish to configure . )"
"set the value of the hostname input for this choreo . ( ( required , string ) name of the host where requests will be redirected . ex . : example.com )"
"set the value of the protocol input for this choreo . ( ( optional , string ) protocol to use ( http , https ) when redirecting requests . the default is http . )"
"retrieve the value for the "" response "" output from this choreo execution . ( stores the response from amazon . note that for a successful website configuration request , no content is returned and this output variable will be empty . )"
"create a new instance of the searchbycallletters choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by npr . )"
"set the value of the band input for this choreo . ( ( optional , string ) enter am or fm . )"
"set the value of the callletters input for this choreo . ( ( required , string ) enter the unique identifier associated with a station . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are xml ( the default ) , and json . )"
"create a new instance of the describeregions choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the filtername input for this choreo . ( ( optional , string ) the name of a supported filter to narrow results with . )"
"set the value of the filtervalue input for this choreo . ( ( optional , string ) a value for the specified filter . )"
"set the value of the regionname input for this choreo . ( ( optional , string ) one or more region names . this can be a comma - separated list of up to 10 region names . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the userregion input for this choreo . ( ( optional , string ) the aws region that corresponds to the ec2 endpoint you wish to access . the default region is "" us - east-1 "" . see description below for valid values . )"
"create a new instance of the retrieveentries choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the pagesize input for this choreo . ( ( optional , integer ) the number entries to return per page . defaults to 25 . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page of entries to return . this parameter is used in combination with the pagesize input to page through results . defaults to 0 ( the first page ) . )"
"retrieve the value for the "" next "" output from this choreo execution . ( ( integer ) the next page of entries that is available . this value can be passed into the page input while paging through entries . )"
"retrieve the value for the "" previous "" output from this choreo execution . ( ( integer ) the previous page of entries that is available . this value can be passed into the page input while paging through entries . )"
"create a new instance of the retrievecommentthread choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved after the final step in the oauth process . )"
"set the value of the uri input for this choreo . ( ( required , string ) the uri of the activity thread to retrieve comments for ( e.g. , /fitnessactivities/327844402 ) . )"
"create a new instance of the listincidents choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key provided by pagerduty . )"
"set the value of the assignedtouser input for this choreo . ( ( optional , string ) returns only incidents assigned to the specified user . )"
"set the value of the daterange input for this choreo . ( ( optional , string ) when set to "" all "" , this allows you to retrieve all incidents since the account was created . )"
"set the value of the fields input for this choreo . ( ( optional , string ) allows you to select specific incident properties to be returned in the response . )"
"set the value of the incidentkey input for this choreo . ( ( optional , string ) returns only incidents with the specified key . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of incidents returned . default ( and max limit ) is 100 . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) the offset of the first incident record returned . default is 0 . )"
"set the value of the service input for this choreo . ( ( optional , string ) returns only incidents associated with the specified service . )"
"set the value of the since input for this choreo . ( ( optional , date ) the start of the date range to search ( e.g. , 2013 - 03 - 06t15:28 - 05 ) . note that including the time is optional . )"
"set the value of the sortby input for this choreo . ( ( optional , string ) used to specify both the field you wish to sort the results on ( incident_number , created_on , or resolved_on ) , as well as the direction ( asc / desc ) of the results ( e.g. , created_on : desc ) . )"
"set the value of the status input for this choreo . ( ( optional , string ) returns only the incidents with this specified status . valid values are : triggered , acknowledged , and resolved . )"
"set the value of the subdomain input for this choreo . ( ( required , string ) the subdomain of your pagerduty site address . )"
"set the value of the timezone input for this choreo . ( ( optional , string ) the time zone in which dates in the result will be rendered . defaults to account time zone . )"
"set the value of the until input for this choreo . ( ( optional , date ) the end of the date range to search ( e.g. , 2013 - 03 - 06t15:28 - 05 ) . note that including the time is optional . )"
"create a new instance of the videotags choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) used to page through results . limits the number of records returned in the response . )"
"set the value of the offset input for this choreo . ( ( optional , integer ) used to page through results . returns results starting from the specified number . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the profile to retrieve video tags for . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the since input for this choreo . ( ( optional , date ) used for time - based pagination . values can be a unix timestamp or any date accepted by strtotime . )"
"set the value of the until input for this choreo . ( ( optional , date ) used for time - based pagination . values can be a unix timestamp or any date accepted by strtotime . )"
"create a new instance of the getactivity choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the activityid input for this choreo . ( ( required , integer ) the id of the activity to retrieve . )"
"set the value of the consumerkey input for this choreo . ( ( required , string ) the consumer key provided by fitbit . )"
"set the value of the consumersecret input for this choreo . ( ( required , string ) the consumer secret provided by fitbit . )"
"create a new instance of the updateplaylist choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required for oauth authentication unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required for oauth authentication unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required for oauth authentication unless providing a valid accesstoken . )"
"set the value of the description input for this choreo . ( ( optional , string ) the playlist 's description . )"
"set the value of the fields input for this choreo . ( ( optional , string ) allows you to specify a subset of fields to include in the response using an xpath - like syntax ( i.e. items / snippet / title ) . )"
"set the value of the part input for this choreo . ( ( optional , string ) a comma - separated list of fields that are being set and that will be returned in the response ( i.e. snippet , status ) . )"
"set the value of the playlistid input for this choreo . ( ( required , string ) the i d of the playlist to update . )"
"set the value of the privacystatus input for this choreo . ( ( optional , string ) the playlist 's privacy status . valid values are : private or public . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required for oauth authentication unless providing a valid accesstoken . )"
"set the value of the title input for this choreo . ( ( required , string ) the title of the playlist . )"
"create a new instance of the ecobycoordinates choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apicredentials input for this choreo . ( ( optional , string ) a json dictionary containing credentials for genability . see choreo documentation for formatting examples . )"
"set the value of the latitude input for this choreo . ( ( required , decimal ) the latitude coordinate for the user 's current location . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) the number of facility records to search for in the envirofacts database . )"
"set the value of the longitude input for this choreo . ( ( required , decimal ) the longitude coordinate for the user 's current location . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from the eco choreo . )"
"create a new instance of the listuserpolicies choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the awsaccesskeyid input for this choreo . ( ( required , string ) the access key id provided by amazon web services . )"
"set the value of the awssecretkeyid input for this choreo . ( ( required , string ) the secret key id provided by amazon web services . )"
"set the value of the marker input for this choreo . ( ( optional , string ) used for pagination to indicate the starting point of the results to return . )"
"set the value of the maxitems input for this choreo . ( ( optional , integer ) used for pagination to limit the number of results returned . defaults to 100 . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are "" xml "" ( the default ) and "" json "" . )"
"set the value of the username input for this choreo . ( ( required , string ) the name of the user to list policies for . )"
"create a new instance of the deletereading choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the actionid input for this choreo . ( ( required , string ) the i d of an action to delete . )"
"create a new instance of the listmyplaylists choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth process . this is required for oauth authentication unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required for oauth authentication unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required for oauth authentication unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) allows you to specify a subset of fields to include in the response using an xpath - like syntax ( i.e. items / snippet / title ) . )"
"set the value of the maxresults input for this choreo . ( ( optional , integer ) the maximum number of results to return . )"
"set the value of the pagetoken input for this choreo . ( ( optional , string ) the "" nextpagetoken "" found in the response which is used to page through results . )"
"set the value of the part input for this choreo . ( ( optional , string ) specifies a comma - separated list of playlist resource properties that the api response will include . part names that you can pass are : i d , snippet , and status . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required for oauth authentication unless providing a valid accesstoken . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( json ) the response from youtube . )"
"create a new instance of the listlabels choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( optional , string ) a valid access token retrieved during the oauth2 process . this is required unless you provide the clientid , clientsecret , and refreshtoken to generate a new access token . )"
"set the value of the clientid input for this choreo . ( ( conditional , string ) the client id provided by google . required unless providing a valid accesstoken . )"
"set the value of the clientsecret input for this choreo . ( ( conditional , string ) the client secret provided by google . required unless providing a valid accesstoken . )"
"set the value of the fields input for this choreo . ( ( optional , string ) used to specify fields to include in a partial response . this can be used to reduce the amount of data returned . see choreo notes for syntax rules . )"
"set the value of the refreshtoken input for this choreo . ( ( conditional , string ) an oauth refresh token used to generate a new access token when the original token is expired . required unless providing a valid accesstoken . )"
"set the value of the userid input for this choreo . ( ( optional , string ) the id of the acting user . defaults to "" me "" indicating the user associated with the access token or refresh token provided . )"
"create a new instance of the putdelta choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstokensecret input for this choreo . ( ( required , string ) the access token secret retrieved during the oauth process . )"
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved during the oauth process . )"
"set the value of the appkey input for this choreo . ( ( required , string ) the app key provided by dropbox ( aka the oauth consumer key ) . )"
"set the value of the appsecret input for this choreo . ( ( required , string ) the app secret provided by dropbox ( aka the oauth consumer secret ) . )"
"set the value of the changes input for this choreo . ( ( required , json ) a json - encoded list of changes . see choreo notes for formatting details . )"
"set the value of the handle input for this choreo . ( ( required , string ) the handle of an existing datastore . )"
"set the value of the nonce input for this choreo . ( ( optional , string ) an optional dbase64 string ( up to 100 characters ) used to uniquely identify this delta . if set to "" default "" a nonce will be auto - generated . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"set the value of the revision input for this choreo . ( ( required , string ) the revision from which to start . )"
"retrieve the value for the "" response "" output from this choreo execution . ( the response from dropbox . corresponds to the responseformat input . defaults to json . )"
"create a new instance of the listall choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"create a new instance of the listfollowers choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the listid input for this choreo . ( ( required , string ) the i d of a user - created list . )"
"set the value of the oauthtoken input for this choreo . ( ( required , string ) the foursquare api oauth token string . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that response should be in . can be set to xml or json . defaults to json . )"
"create a new instance of the createpeople choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accountname input for this choreo . ( ( required , string ) a valid highrise account name . this is the first part of the account 's url . )"
"set the value of the background input for this choreo . ( ( optional , string ) corresponds to the background field in highrise )"
"set the value of the companyname input for this choreo . ( ( optional , string ) corresponds to the company name field in highrise . )"
"set the value of the emailaddress input for this choreo . ( ( optional , string ) corresponds to the email address field in highrise . )"
"set the value of the firstname input for this choreo . ( ( required , string ) corresponds to the first name field in highrise . )"
"set the value of the homephone input for this choreo . ( ( optional , string ) corresponds to the home phone field in highrise . )"
"set the value of the lastname input for this choreo . ( ( optional , string ) corresponds to the last name field in highrise . )"
"set the value of the password input for this choreo . ( ( required , password ) the highrise account password . use the value ' x ' when specifying an api key for the username input . )"
"set the value of the title input for this choreo . ( ( optional , string ) corresponds to the title field in highrise . )"
"set the value of the username input for this choreo . ( ( required , string ) a highrise account username or api key . )"
"set the value of the workphone input for this choreo . ( ( optional , string ) corresponds to the work phone field in highrise . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from highrise . )"
"create a new instance of the searchbyreviewer choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( optional , string ) the api key provided by ny times . )"
"set the value of the criticspick input for this choreo . ( ( optional , string ) set this parameter to y to limt the results to nyt critics ' picks . to get only those movies that have not been highlighted by times critics , specify n. )"
"set the value of the offset input for this choreo . ( ( optional , integer ) a numeric value indicating the starting point of the result set . used to page through results . )"
"set the value of the order input for this choreo . ( ( optional , string ) sets the sort order of the results . accepted values are : by - title , by - publication - date , by - opening - date , by - dvd - release - date . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . valid values are : json ( the default ) and xml . )"
"set the value of the reviewername input for this choreo . ( ( required , string ) the name of the times reviewer . reviewer names should be separated by hyphens or dots ( i.e. manohla - dargis or manohla.dargis ) . )"
"create a new instance of the prioritymailservicerequest choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the destinationzip input for this choreo . ( ( required , integer ) first 3 digits of a 5 - digit zip code )"
"set the value of the endpoint input for this choreo . ( ( optional , string ) if you are accessing the production server , set to ' production ' . defaults to ' testing ' which indicates that you are using the sandbox . )"
"set the value of the originzip input for this choreo . ( ( required , integer ) first 3 digits of a 5 - digit zip code )"
"set the value of the password input for this choreo . ( ( required , password ) the password assigned by usps )"
"set the value of the userid input for this choreo . ( ( required , string ) alphanumeric id assigned by usps . required value . )"
"retrieve the value for the "" response "" output from this choreo execution . ( ( xml ) the response from usps web service )"
"create a new instance of the listticketsbyorganization choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the email input for this choreo . ( ( required , string ) the email address you use to login to your zendesk account . )"
"set the value of the organizationid input for this choreo . ( ( required , integer ) the id number of the organization . )"
"set the value of the page input for this choreo . ( ( optional , integer ) the page number of the results to be returned . used together with the perpage parameter to paginate a large set of results . )"
"set the value of the password input for this choreo . ( ( required , password ) your zendesk password . )"
"set the value of the perpage input for this choreo . ( ( optional , integer ) the number of results to return per page . maximum is 100 and default is 100 . )"
"set the value of the server input for this choreo . ( ( required , string ) your zendesk domain and subdomain ( e.g. , temboocare.zendesk.com ) . )"
"create a new instance of the listavailableapps choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the apikey input for this choreo . ( ( required , string ) the api key obtained from sendgrid . )"
"set the value of the apiuser input for this choreo . ( ( required , string ) the username registered with sendgrid . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the username registered with sendgrid . )"
"create a new instance of the taggablefriends choreo . a temboosession object , containing a valid set of temboo credentials , must be supplied ."
"set the value of the accesstoken input for this choreo . ( ( required , string ) the access token retrieved from the final step of the oauth process . )"
"set the value of the after input for this choreo . ( ( optional , string ) a cursor that points to the end of the page of data that has been returned . you can pass this cursor to retrievet he next page of results . )"
"set the value of the before input for this choreo . ( ( optional , string ) a cursor that points to the start of the page of data that has been returned . you can pass this cursor to retrieve the previous page of results . )"
"set the value of the fields input for this choreo . ( ( optional , string ) a comma separated list of fields to return ( i.e. id , name ) . )"
"set the value of the limit input for this choreo . ( ( optional , integer ) limits the number of records returned in the response . )"
"set the value of the profileid input for this choreo . ( ( optional , string ) the i d of the profile to retrieve tagged places for . defaults to "" me "" indicating the authenticated user . )"
"set the value of the responseformat input for this choreo . ( ( optional , string ) the format that the response should be in . can be set to xml or json . defaults to json . )"
"given a 4d mini - batch tensor of shape ( b x c x h x w ) , makes a grid of images"
"applies additional settings before clone takes place """
returns a list of tuples . the first element in each tuple is the coded value for the option that will appear in the url query . the second element is the human - readable name for the option that will appear in the right sidebar .
returns the filtered queryset based on the value provided in the query string and retrievable via ` self.value ( ) ` .
return font with gsub compiled from given source .
return input generator for gsub compiled from given source .
check whether ` command ` exists
"parameters ---------- options : iterable , optional env : dict , optional"
"parameters ---------- options : iterable , optional env : dict , optional"
routine to compute the rhf energy for a closed shell molecule
routine to build the ao basis fock matrix
routine to orthogonalize the ao fock matrix to orthonormal basis
routine to unorthogonalize the orthonormal fock matrix to ao basis
routine to orthogonalize the ao density matrix to orthonormal basis
routine to unorthogonalize the orthonormal density matrix to ao basis
routine to compute the scf energy
routine to compute the scf electronic dipole moment
returns hermitian adjoint of a matrix
"returns commutator [ a , b ]"
"rebuilds / updates the fock matrix if you add external fields , etc ."
return the index of an n - dimensional position embedded in a 1 - dimensional array .
determine whether an array of n - dim positions is sorted .
give the layers of swaps which sort an array of positions .
give a layer of swaps as part of a sorting network for an array of positions .
return symbolic representation of a fermi - hubbard hamiltonian .
is the app running ?
"run commands , raise exception if failed"
run the doxygen make commands
build mxnet .so lib
build r pdf
build scala doc and then move the outdir
convert a markdown table to rst format
find tables in a markdown and then convert them into the rst format
a iterator that returns if a line is within a code block
split lines into code and non - code blocks
return a markdown code block
evaluate python source codes
"correct grad = ( y - p)/(p - p^2 ) but if y is just 1 or 0 , then this simplifies to grad = 1/(p-1+y ) which is more numerically stable"
grad = ( y - p)/(p - p^2 )
"check input imdbs , make sure they have same classes"
"get total number of images , init indices"
"given index , find out sub - db and sub - index"
"given image index , find out full path"
"given image index , return preprocessed ground - truth"
load library by searching possible path .
check the return value of c api call .
create ctypes array from a python array .
convert ctypes pointer to buffer type .
convert a ctypes pointer to a numpy array .
build argument docs in python style .
notify mxnet about a shutdown .
append the definition position to each function contained in module .
a utility function that converts the argument to a list if it is not already .
"check whether the given op_name starts with any words in ` _ op_name_prefix_list ` . if found , return the prefix ; else , return an empty string ."
"registers op functions created by ` make_op_func ` under ` root_namespace.module_name.[submodule_name ] ` , where ` submodule_name ` is one of ` _ op_submodule_name_list ` ."
add new metrics as new columns to selected pandas dataframe .
"assuming a is shorter than b , copy the end of b onto a"
"generates callback arguments for model.fit ( ) for a set of callback objects . callback objects like pandaslogger ( ) , livelearningcurve ( ) get passed in . this assembles all their callback arguments ."
"the dataframe with training data . this has metrics for training minibatches , logged every "" frequent "" batches . ( frequent is a constructor param )"
the dataframe with evaluation data . this has validation scores calculated at the end of each epoch .
the dataframe with epoch data . this has timing information .
return a dict of dataframes
calcaulate the elapsed time from training starting .
append new metrics to selected dataframes .
callback funtion for training .
callback function for evaluation
update parameters for selected dataframe after a completed batch parameters ---------- dataframe : pandas . dataframe selected dataframe needs to be modified .
callback function after each epoch . now it records each epoch time and append it to epoch dataframe .
"returns * * kwargs parameters for model.fit ( ) to enable all callbacks . e.g. model.fit(x = train , eval_data = test , * * pdlogger.callback_args ( ) )"
render a bokeh object and return a handle to it .
update the bokeh object with new data .
check whether it is time to update plot . returns ------- boolean value of whethe to update now
render the plot with bokeh.io and push to notebook .
update the plot chart data and render the updates .
callback function after a completed batch .
callback function after an evaluation .
"returns * * kwargs parameters for model.fit ( ) to enable all callbacks . e.g. model.fit(x = train , eval_data = test , * * pdlogger.callback_args ( ) )"
calculate elasped time from starting
update selected dataframe after a completed batch parameters ---------- df_name : str selected dataframe name needs to be modified .
adds block on top of the stack .
"convert shape string to list , internal use only ."
convert symbol for detail information .
creates a visualization ( graphviz digraph object ) of the given computation graph . graphviz must be installed for this function to work .
return function that computes both gradient of arguments and loss value .
return function that computes gradient of arguments .
ctypes implementation of imperative invoke wrapper
ctypes implementation of imperative invoke wrapper
"given image index , find out full path"
"given image index , return preprocessed ground - truth"
initialize all entries given annotation json file
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
"on save , update timestamps"
read the full alingment
read the gene - partitioned alignment
for getting the overlap between test seqs
check for alignment overlap
get a random gene from the set of genes in seq
returns the list of quizquestions in this quiz .
returns the quiz question with the given i d
create a new quiz question for this quiz
updates an existing quiz question for this quiz
< b>204 no content < b > response code is returned if the deletion was successful .
gets the outcome results for users and outcomes in the specified context .
gets the outcome rollups for the users and outcomes in the specified context .
fetch all preferences for the given communication channel
fetch all preferences for the given communication channel
fetch the preference for the given notification for the given communicaiton channel
fetch the preference for the given notification for the given communicaiton channel
change the preference for a single notification for a single communication channel
change the preference for a single notification for a single communication channel
change the preferences for multiple notifications for a single communication channel at once
change the preferences for multiple notifications for a single communication channel at once
test that global session variable is set when new session is created .
test that global session variable is set when new session is created .
test that global session variable is set when new session is created .
test that global session variable is set when new session is created .
"list accounts that the current user can view or manage . typically , students and even teachers will get an empty list in response , only account admins can view the accounts that they are in ."
list accounts that are sub - accounts of the given account .
create and return a new module
update and return an existing module
assert that request_context is passed to client ' get ' call
assert that an absolute url made of base_api_url from context and method path is passed to client ' get ' call
assert that validate_attr_is_acceptable called for include
assert that client ' get ' called with default values for payload data
assert that client ' get ' called with user defined arg values for payload data
assert that client ' get ' called with kwargs as additional parameters
assert that method returned the result of client ' get ' call
assert that request_context.per_page is called when no user value passed in
assert that request_context.per_page is called when no user value passed in
assert that client ' post ' called with default values for payload data
assert that client ' post ' called with user 's arg values for payload data
assert that client ' post ' called with kwargs as additional parameters
assert that method returned the result of client ' post ' call
assert that request_context.per_page is called when no user value passed in
assert that request_context.per_page is called when no user value passed in
assert that client ' put ' called with user 's arg values for payload data
assert that client ' put ' called with kwargs as additional parameters
assert that method returned the result of client ' delete ' call
assert that request_context.per_page is called when no user value passed in
assert that request_context.per_page is called when no user value passed in
assert that client ' delete ' called with kwargs as additional parameters
assert that method returned the result of client ' delete ' call
test expected default status for instance of canvasapierror
test expected default msg attribute for instance of canvasapierror
test expected default error_json attribute for instance of canvasapierror
test default canvasapierror instance represented as a str
test default canvasapierror instance represented as unicode
test string representation of canvasapierror with custom attributes
python implementation of probabilistic matrix factorization ( pmf ) .
"return the same object reloaded from the database , or optinally load an arbitrary object by pk if this id is provided ."
"fail if response content has any lines containing the ' errorlist ' keyword , which indicates the form submission failed with errors ."
"if the item is publishable , get the visible version"
only render the plugin if the item can be shown to the user
: return :
filter the content types selectable for the content listing .
"return ` ` compress_enabled ` ` , ` ` site_name ` ` , and any settings listed in ` ` icekit_context_processor_settings ` ` as context ."
"produces a description of how to display a paginated list 's page numbers . rather than just spitting out a list of every page available , the page numbers returned will be trimmed to display only the immediate numbers around the start , end , and the current page ."
helper function to get an appropriate response page if it exists .
custom page not found ( 404 ) handler .
custom 500 error handler .
prefetch instagram data and clean it .
get the instagram data for the url .
get the image thumbnail url if it exists .
get the default embed if it exists .
helper function for @view and @query decorators .
helper for event_property decorator
return all endpoints ( returned in a format identical to schema view )
generic code to handle views and requests
adds a view to advertise defined event properties
returns all available views and queries as a json object .
"handles generic view . category is where this should be place ( per student , per problem , etc . ) name is specific"
"handles generic view . category is where this should be place ( per student , per problem , etc . ) name is specific"
"receives either an event or a list of events , as sent by djeventstream ( either from a python logging httphandler or snshandler ."
read an http/1.1 response from ` ` stream ` ` .
read http headers from ` ` stream ` ` .
build an authorization header for http basic auth .
carga la instancia de un componente
devuelve la instancia de un componente
carga un componente lateral
devuelve la instancia de un componente lateral
"instala la barra de menú ( qmenubar ) , acciones , shortcuts , toolbars y conexiones de cada qaction ."
"carga el componente principal ( editor container ) , componentes laterales y la salida del compilador ."
limpia el título de la ventana
cambia el título de la ventana ( filename - { edis } )
se abre la url para reportar un bug
cambia la visibilidad de la barra de herramientas
cambia la visibilidad del dock lateral
oculta todo excepto la barra de menú y el editor
cambia a modo fullscreen
cambia la visibilidad de la salida del compilador
carga archivos al editor desde la última sesión y actualiza el menú de archivos recientes .
muestra el díalogo acerca de qt
"éste médoto es llamado automáticamente por qt cuando se cierra la aplicación , guarda algunas configuraciones como posición y tamaño de la ventana , archivos , etc ."
corre el comando cpp
computes geodesic distances to all vertices in the mesh idx can be either an integer ( single vertex index ) or a list of vertex indices or an array of bools of length n ( with n the number of vertices in the mesh )
return the basename plus an appropriate extension for the type .
"write str(obj ) to a file . if fmt is given , format the string first ."
read a file written with _ simple_write .
write a dict as json .
read a json into a dict .
write result to disk .
read result from disk .
` decu exec ` should accept one single argument .
` decu exec ` on two equal scripts should generate two equal log files .
"convert a bit array to a prettily formated hex string . if the array length is not a multiple of 8 , it is padded with 0 - bits from the left . for example , [ 1,0,0,1,1,0,1,0,0,1,0 ] becomes 04 : d2 . args : bit_array : the bit array to convert returns : the formatted hex string ."
"convert a bytestring to a prettily formated hex string : for example , ' ò ' becomes 04 : d2 . args : byte_string : the bytes to convert . returns : the formatted hex string ."
"convert an integer to a prettily formated hex string : for example , 1234 ( 0x4d2 ) becomes 04 : d2 and -1234 becomes ' -:04 : d2 ' args : int_value : the value to convert . returns : the formatted hex string ."
"split the long string into line chunks according to the wrap limit and existing newlines . args : long_string : a long , possibly multiline string wrap : maximum number of characters per line . 0 or negative wrap means no limit . returns : a list of lines of at most |wrap| characters each ."
"append lines to the buffer . if the first line can be appended to the last line of the buf without exceeding wrap characters , the two lines are merged . args : lines : an iterable of lines to append wrap : maximum number of characters per line . 0 or negative wrap means no limit . buf : an iterable of lines to append to"
determine the openshift version variables as dictated by the origin shell utilities and overwrite the specfile to reflect them . a line with the following syntax is expected in the specfile :
determine the openshift version variables as dictated by the origin shell utilities . the git tree state is spoofed .
update the specfile to reflect the latest commit . a line with the following syntax is expected in the specfile :
write a protocol buffer to the state file .
read a protocol buffer from the state file .
removing the lineprocessor import from stashpy.__init__.py breaks custom processors .
make exploit data
base64 decode > > > print base64_encode('ehnz ' ) ' xss ' : param data : base64 data : return : data : rtype : str
base64 encode > > > print base64_encode('xss ' ) ' ehnz '
url encode > > > print url_encode('1 2 & ' ) ' 1%202%26 '
url encode > > > print url_decode('1%202%26 ' ) ' 1 2 & ' : rtype str : param data : : return : url decode str
url encode > > > print html_decode('&lt ' ) ' < ' : rtype str : param data : html encode data : return : url decode str
simulates adding a global secondary index at a later time .
"simulates adding a global secondary index at a later time . however , with the test attribute selected , no change is actually made ."
tests that no index changes are performed
updates index throughput values by comparing the current values to those from the actual database .
tests that throughput provisioning specified directly at update time are applied to the index .
test handling a missing table
tests that the wait loop effectively waits for the status to change .
argument handler .
initiate the passed files and options .
open a scheme file to validate the to - be - read file .
open xml file and return the root .
catch xml nodes and attributes .
print data to csv .
we compare triangle midpoints .
: param x : n x m : param y : n x m : return : 1 x m
normalizes x in - place and returns the normalizing constant s : param x : numpy float : param axis : axis to normalize over
"asserts that the numpy array x has the required shape . required dimensions of none are ignored . e.g. x.shape=(3,5,6 ) is equivalent to required_shape=(3,none,6 ) : param x : numpy array : param required_shape : tuple of required shape dimensions"
normalizes x_log in - place and returns the normalizing constant s_log . the returned x will not be in log space anymore . s is returned in log space . : param x : numpy float : param axis : axis to normalize over
"if there are decorator arguments , the function to be decorated is not passed to the constructor !"
"if there are decorator arguments , _ _ call _ _ ( ) is only called once , as part of the decoration process ! you can only give it a single argument , which is the function object ."
calculate the sum of the squared residuals of the midas equations . parameters are arranged a_h = a[0 ] b_h = a[1 ] theta is a[2 : n ] y lag params are a[n :]
displays home page : param request : : return render :
displays about page : param request : : return render :
displays contact page : param request : : return render :
logs in current user : param request : : return render :
logs out current user : param request : : return render :
fetches all property lists from : property_list/ : param request : : return render :
fetches plists for specific user from : user/<user_id>/property_list/ : param request : : param user_id : : return render :
fetches one plist from : property_list/<plist_id>/ : param request : : param plist_id : : return render :
fetches one plist and converts it to plist format ( xml based ) from : property_list/<plist_id>/download/ : param request : : param plist_id : : return :
adds one property list from : property_list / add/ : param request : : return :
index view - unauthenticated users go to registration page
index view - authenticated basic and staff users
"index view - authenticated , staff or instance manager user"
login view - authenticate a basic and staff users
login view - authenticate an instance manager user
"admin view - anonymous , basic and instance manager users go to login page"
index view - staff users see the admin page
add named arguments .
"verify redeployment arguments with user , and then start redeployment loop ."
"get the number of pending , ongoing , failed , and/or successful instance redeployments ."
return the parsed batch frequency as a user - friendly string .
tag marking those instances whose redeployment is in progress .
"tag marking those instances whose redeployment succeeded , and are awaiting activation ."
tag marking those instances whose redeployment failed .
creates or returns a tag named self.options['tag ' ] + ' - ' + suffix
return a queryset containing the instances that need to be redeployed .
return a queryset containing the failed tagged instances .
"determine how many instances will be redeployed , and other basic stats ."
"returns true if redeployment is complete , false if it is still in progress ."
log the current status of the redeployment .
run the mysql commands specified by the command parameters .
"run the redeployment in batches , logging the status for each loop ."
get - authenticated - instance manager user is allowed access
"create an instance , and add an active appserver ."
verify the api returns valid instance data with an active appserver .
the number of database queries required to fetch /api / v1 / instance/ should be o(1 )
get - instance list - is ' newest_appserver ' in fact the newest one ?
get - detailed attributes
get - detailed attributes
get - detailed attributes
"combine sub_domain and base_domain fields into a single internal_lms_domain field . also generate and store internal_lms_preview_domain and internal_studio_domain fields , which are generated by prepending ' preview- ' and ' studio- ' to the lms domain . these were the hardcoded values for preview / studio domain prefixes at the time this migration was created , but they will be configurable in the future ."
run a tarsnap command .
"tries to backup folder using tarsnap , handling cache mismatch running ` --fsck ` ."
"function that runs tarsnap using ` keyfile ` and ` cachedir ` , to create archive named ` archive_name ` that contains contents of ` directory `"
test that an instance gets correctly provisioned when the email addresses are confirmed .
set up properties used to verify captured logs
verify that the command correctly requires the --tag parameter
"verify that the user can cancel the redeployment by answering "" no """
"verify that the user can continue with the redeployment by answering "" yes """
verify that the user is not promped when --force is provided
verify status is logged as expected with default arguments
create instances to test redeployments .
test the instance redeployment when everything goes well
test the instance redeployment when instances fail .
"clean fields , including the ' object_id ' field"
"whenever an object is deleted , check if there are corresponding log entries to delete ."
"send the request to the provided url , attaching custom headers , and returns the deserialized object from the returned json ."
"converts a ` fork_name ` ( eg . ` ' open - craft / edx - platform ' ` ) to a ` fork_tuple ` ( eg . ` [ ' open - craft ' , ' edx - platform ' ] ` )"
get the ` commit_id ` currently attached to a git reference
extract a settings string from a pr description body
"return true if the pr body specified that the sandbox should use ephemeral databases , false if it specifies persistent databases , or none otherwise"
return dict containing all available information about pr identified by ` pr_target_fork_name ` and ` pr_number ` .
returns a pr object based on the reponse
retrieve the current active prs for a given user
retrieve the current active prs for a given set of users
retrieve a team by organization & team name
retrieve the usernames of a given team 's members
create datetime object from ` date ` .
user - friendly unique description of a pr object .
this pr 's title truncated to 4 words
extra settings contained in the pr body
"return the setting given by "" name "" from extra_settings ."
construct the url for the pull request
does this pr request ephemeral databases ?
"connect to the given url and returns its contents as a string . does several attempts in case the first one failed . by default it verifies ssl certificates , but it can be disabled to be able to access external pages ."
check that the given url is accessible and that it returns a success status code .
determine if the server at ip_addr is accepting connections on the given port or not .
merge of two yaml strings with overlapping variables
merge of a yaml string with none
run the ansible - playbook command
run the render_sandbox_creation_command function
check if create_temp_dir behaves correctly when no exception is raised from inside it .
check if create_temp_dir behaves correctly when an exception is raised from inside it .
check if string_to_file_path creates a file with proper contents .
create a new appserver for an existing instance .
mark an appserver as active or inactive .
shut down instances whose prs got merged ( more than ) one week ago .
terminate obsolete app servers for all instances .
clean up obsolete vms .
any load balancers that are dirty need to be reconfigured .
add the internal discovery domain field to each instance .
add the internal ecommerce domain field to each instance .
return extra attributes needed for database creation
create database server
"create the default database server configured in the django settings , if any ."
protocol to use for accessing this database server .
default port for this database server .
full url for this database server .
"return true if settings of this database server match settings passed to this method , else false ."
set default port before saving .
return extra attributes needed for database creation
get setting using prefix
get setting name for field
create dictionary with replica settings
"create the default database replica set configured in the django settings , if any ."
"select a replica set for a new instance . the current implementation selects one of the replica sets with servers that accept new clients at random . if no database server accepts new clients , doesnotexist is raised ."
serialize appserver object summary .
set the settings and call necessary functions
"convert parameters given as (: math:`\rho_0 , m_i ` ) to the parameterization used by this class ."
convert parameters given in this parameterization back to the linear state
convert the parameters to linear scale and return full cole - cole parameters sets ( in contrast to the reduced decomposition parameter set )
forward response of this model
"parameters ---------- pars_dec : numpy.ndarray array containing ( log10(rho0 ) , log10(m_i )"
return a dict with a description of the data base dimensions . in this case we have frequencies and re / im data
return size of flattened base dimensions
"return a dict with a description of the model base dimensions . in this case we have one dimension : the dd parameters ( rho0 , mi ) where m_i denotes all chargeability values corresponding to the relaxation times ."
create a new spark configuration .
set a configuration property .
set master url to connect to .
set application name .
set path where spark is installed on worker nodes .
set an environment variable to be passed to executors .
"set multiple parameters , passed as a list of key - value pairs ."
"get the configured value for some key , or return a default otherwise ."
get all values as a list of key - value pairs .
does this configuration contain a given key ?
"returns a printable version of the configuration , as a list of key = value pairs , one per line ."
reformat parameters into dict of format expected by the api .
return json dict from json formatted param .
resets / prepares to / for simulation with specified parameters .
prepares for simulation with specified parameters .
"start the prepared / configured simulation . note if run multiple times the previous state is used as the "" initial "" configuration of the simulation ( markov process ) ."
returns ------- ts_num_bonds : ndarray time - series of number of active bonds . if simulation has not been initialized yet then none .
returns ------- ts_num_cluster : ndarray time - series of number of clusters / components . if simulation has not been initialized yet then none .
returns ------- ts_size_giant : ndarray time - series of the size of largest component . if simulation has not been initialized yet then none .
returns ------- ts_sec_cs_moment : ndarray time - series of the second moment of the cluster size distribution . if simulation has not been initialized yet then none .
returns ------- ts_four_cs_moment : ndarray time - series of the fourth moment of the cluster size distribution . if simulation has not been initialized yet then none .
: type driver : contestodriver
: type args : tuple of str
: type path_to_file : str
check test is failure / error for py2x unittest . testcase implementation : return : bool
check test is failure / error for py3x unittest . testcase implementation : return : bool
: rtype : driver
: raise : connectionerror
: raise : connectionerror
: raise : elementnotfound
: type sizzle_selector : str : rtype : contestowebelement : raise : elementnotfound
: type sizzle_selector : str : rtype : list of contestowebelement : raise : elementnotfound
: raise : javascriptinjectionerror
: rtype : bool
: rtype : str
decorate a function to receive a single argument and expand to multiple arguments . this is specially useful for mapping functions that can only send a single argmument . e.g. : ` multiprocessing.pool.map ` .
"convert a number of seconds to time in the "" hh : mm : ss.xxx "" format where "" xxx "" is the number of milliseconds or zero if not given ."
find the seek position with second and millissecond values based on video framerate and amount of frames to seek .
find the amount of frames after a specified time .
calculate the video chunks sizes in order to split a file in a certain amount of small files depending on its length and maximum number of transcoding boxes available .
"copy this config , replacing the regions with those in the ` regions ` parameter ."
creates a record hash value for easy comparisons
"creates a record hash ,"
save only uuids
dumps an export table to a csv output file
writes a csv file for a web dump instead of a file save
"takes the row_dict , fills in blank cells , and writes to the csv file"
gets the maximum row numbre for the table
gets a list of the table field names
prepares a directory to receive export files
makes the project geojson
"processes the solr_json discovery geo tiles , aggregating to a certain depth"
sets the aggregatin depth for aggregating geospatial tiles
"parses a solr value if it has ' _ _ _ ' delimiters , to get the uri part string . if it 's already a uri part , it makes a url"
"parses a solr_value string into slug , solr - data - type , uri , and label parts"
"returns the value associated with a key , if the key exists else , none"
creates a navigation link to the project import
sets the project label
sets the label for the source table
creates navivation for source import steps
makes json for the profile item
checks to see if the input profile exists
"gets fields used in this import profile , it 's not super efficient but it does n't have to be because it is querying very small data"
returns a list of items made with the current profile
reverses / inverts a sorting term
redirects requests from the subjects index to the subjects - search view
"redirects from the original php version of open context when "" .php "" was in urls"
returns a json representation
processes the attributes xml file
loads or classifies attributes in a tree
classifies attributes in a tree
classifies open context types used with each attribute
"saves predicates and type items to the open context database , and / or reconciles these items with previously saved items from the same project"
gets a key for language to express in a json - ld object
gets a key for language to express in a json - ld object
"updates localization json with new text , or removes a language key of the text is blank"
"makes an value object for json_ld , which is either just a string or is a dict object ( container ) for localized_json"
gets the default value string from a value object found in json - ld
gets a dictionary object for all the non - default localized / translated languges as a key = > value dict .
gets and concatenates all the localization values in a value string or a value dict object found in json - ld
"creates a template for diplaying a concept or vocabulary entity , either in html or in json"
makes json strings for embedding in html
makes the json object for the current concept or vocabulary entity
gets the parents of a given entity
gets the children of a given entity
gets the children for a given uri
gets comments for the entity ( or vocabulary )
gets top level entities that are not part of parent classes or properties
makes a list of entities that are not children of other items in the hierarchy
gets entities in the vocabulary
makes a local path from a uri by removing the cannonical part of the uri
creates a hash - id to insure unique combinations of project_uuids and contexts
creates the hash - id on saving to insure a unique subject
"checks a label , if not valid suggests an alternative based on the prefix . if unique_in_project is true then validate uniqueness within the project , if false then the label will be checked for uniqueness within a context"
"suggests a valid label , unique for the whole project or for a context"
checks to see if a label already exists within the scope of a project or related context
prepends zeros if too short
"gets the manifest item , if present"
get the search context json - ld
creates a hash - id to insure unique combinations of project_uuids and content
creates the hash - id on saving to insure a unique string for a project
gets context information about an entity based on an identifier
"checks to see if a key exists , if so , does the value match the find string"
"gets a project context from a project identifier , which can be a uuid or a slug or a uri"
makes a valid ok cache key
gets a cached reddis object
saves a cached reddis object
creates a hash - id to insure unique combinations of uuids and location types
creates the hash - id on saving to insure a unique assertion
"returns a list of the centroid lon / lat coordinates yes , in that geojson coordinate order"
converts a geojson geojson_geometry_string or a coordinate string into a centroid
"gets author information associated for an item . if project_uuid is not false , look for project author information"
gets author information for a project
checks to see if an object_uri is an authorship object
checks to see if category and project lists for an item are relevant to catal
get json for a unit
gets json data from tdar in response to a keyword search
updates a containment relationship so the child item gets a new parent item
deletes a linking assertion between two items
gets json daa from the orcid uri
makes an orcid api uri based on an orcid uri
makes a zendo metadata object for a deposition of media files from an open context project
"zenodo wants an abbreviated license , not a full uri this is annoying , but it is what it wants"
makes a list of subjects that conform to the zenodo model
makes a list of keywords based on categories from the dir_dict
makes a list of related identifiers that conform to the zenodo model .
makes a list of creators that conform to the zenodo model
adds person names to a json - ld object dict
makes an iso 8601 year from a float year
makes a float year from an iso year
adds a bce / ce suffix to a float year
prepends zeros for a site with a total digit length
"iterates to check this works , the nonsense year 0 bce ? ce ? is the only exception"
"converts a list of ' who ' ( authors , contributors , creators ) into a string for ezid"
make a dictionary object of the metadata
nodataerrorを処理するデコレータです 。 このデコレータをつけておくと、内部でnodataerrorが発生したときに[nodata_return]が返るようになります 。
runs single command on host using ssh
"perform unix touch with extra based on : http://stackoverflow.com/questions/12654772/create-empty-file-using-python args : path : file path to touch times : a 2 - tuple of the form ( atime , mtime ) where each member is an int or float expressing seconds . defaults to current time . dirs : is set , create folders if not exists"
returns the path to a temp file with the given contents .
stringify time in iso 8601 format .
gets the current user from the request and prepares and connects a signal receiver with the user already attached to it .
disconnects the signal receiver to prevent it from staying active .
disconnects the signal receiver to prevent it from staying active in case of an exception .
"signal receiver with an extra , required ' user ' kwarg . this method becomes a real ( valid ) signal receiver when it is curried with the actor ."
"generate a neural network . ( todo : difference between "" fully "" and non - fully )"
return the dimension of the embedding space .
return the position of the origin of the embedding space .
return the underlying simplicial complex .
compute the distance between two points . this implementation returns the normal euclidean distance metric .
define an explicit position for a simplex .
return the position of a simplex in the complex when mapped through this embedding . locations are only available for 0 - simplices .
compute the position of the given 0 - simplex under this embedding . the position returned should have the same dimensions as the embedding space . this method should be overridden by sub - classes : the default returns the origin for all 0 - simplices .
return a dict of positions for a given set of 0 - simplices in the complex . the default is to return the positions of all 0 - simplices .
"clear the cache of simplex positions , forcing them all to be re - computed and/or re - specified . use this if the underlying complex is changed ."
"the length of the embedding is the number of 0 - simplices in the underlying simplicial complex , i.e. , the number of simplices we can return positions for ."
dict - like interface to define an explicit position for a simplex . equivalent to : meth:`positionsimplex ` .
dict - like interface to return the position of a simplex in the complex when mapped through this embedding . equivalent to : meth:`positionof ` .
test if the embedding will embed the given simplex . checks against the underlying simplicial complex .
"construct the : term:`vietoris - rips complex ` at scale eps corresponding to the given embedding . the resulting complex has the same 0 - simplices as the embedding , with a simplex constructed beyween every collection of simplices that are mutually a distance eps or less apart ."
make sure that a string is a byte string
make sure that a string is a text string
intelligently create a filter
returns a filter which matches message names against exact strings
return a filter which matches message names based on a list of globs
parse feature files and return list of feature model objects . handles :
collect feature file names by processing list of paths ( from command line ) . a path can be a :
helper function to create an undefined - step snippet for a step .
print snippets for the undefined steps that were discovered .
select scenario line for any given line .
discovers selected scenarios based on the provided file locations . in addition : * discover all scenarios * auto - correct bad line - numbers
determines which scenarios in the feature are selected and marks the remaining scenarios as skipped . scenarios with the following tags are excluded from skipped - marking :
parse contents of a features list file as text .
"read textual file , ala ' @features.txt ' ."
"registers a custom type that will be available to "" parse "" for type conversion during step matching ."
change the parameter matcher used in parsing step text .
"deprecated , use : func:`use_step_matcher ( ) ` instead ."
provide a textual description of the step function / matcher object .
"match me against the "" step "" name supplied ."
"better than excluding everything that is not needed , collect only what is needed ."
returns true if text is kodi - style hex value
returns true if * text is a number
save xml node * root as file with path * filename
decorator which re - tries the function in case of exception
decorator to put a function into a separate thread
decorator to check for self.is_busy only one of the decorated functions may run simultaniously
get cmd call for different platforms to execute sublime text
generate absolute file paths for the given directory
create zip with path * archive from folder with path * folderpath
return rgba hex values for st tooltip
gets contrast color for * col ( used to ensure readability )
"check file * filepath for bom , return true / false"
return first valid path of * paths list
"run texturepacker on * media_path , also needs * settings for texturepacker path"
"check if all brackets in * label match , return true / false"
return selected text or surrounding text for first selection
return surrounding text for for first selection
prints properly formatted output for json objects
prints properly formatted output for json objects
"return pofile object , go - to - failure in case of exception"
return xml root node from file * filename
creates a new pofile and returns it ( does nt save yet )
convert language xmls inside * path to .po files
get available addons from the kodi addon repository
returns the fallback xml folder as a string
find and load skin xml folder if existing
returns the add - on language folder path
returns the add - on language folder path
returns default language folder ( first one from settings file )
returns the add - on media folder path
"factory , return proper instance based on addon.xml"
get addon po files and update po files list
get list with pofile objects
update list of all include and window xmls
adds a label to the first pofile from settings ( or creates new one if non - existing )
add * rel_path to label with * label i d as a file comment
return translated path for textures
get value from include list
"update include , color and font infos ( not needed yet for python )"
yields absolute paths of all window files
bump addon.xml version and create changelog entry
returns empty list because kodi python add - ons do not support constants yet
"triggers of test of type "" check_type "" , then formats and logs them"
"send json command * data to kodi in separate thread , also needs * settings for remote ip etc ."
"send json command * data to kodi , also needs * settings for remote ip etc ."
create color list by parsing core color file
return userdata folder based on platform and portable setting
get path to userdata addon dir
get path to core addon dir
get path to core color xml
get path to userdata addon dir
get list of folders from userdata addon dir
init instance with * settings
get core po files
get list with pofile objects
fit training data .
fit training data without reinitializing the weights
shuffle training data
initialize weights to zeros
apply adaline learning rule to update the weights
calculate net input
compute linear activation
return class label after unit step
get a single character on windows .
make a project accessible to the flavor
make a project accessible to the flavor
make a project accessible to the flavor
get extra specs for a flavor
create extra specs for a flavor
update extra specs for a flavor
delete one key = value from extra specs
register a flavor
update a container
update metadata of a volume
delete metadata of a volume
create a volume
update properties of an image
download an image into a local file
register an image
get an image
register a volume type
get quota set for a project
update quota set for a project
delete quota set for a project
get default quota set for a project
update a lb member for a pool
create a lb member for a pool
register a service
get metadata of a volume snapshot
update metadata of a volume snapshot
delete metadata of a volume snapshot
create a snapshot of a volume
merge one or more tags
deletes a tag
create a new tag
retrieves a file 's content .
retrieves a file 's content .
adds a new file
launches a simple search against the database
deletes the corresponding entry from the database
deletes multiple entries from the database
updates multiple entries from the database
list all corresponding entries in the database . * * do not use on large datasets ! * *
get details on a specific element
create a new element
modify an element
list files attached to an element
get a file 's contents
tries a variety of robust fitting methods in what is considered descending order of how good the fits are with this type of data set ( found empirically ) .
"convert the passed libvirt node device name to a nodedevice instance , with proper error reporting . if the name is name is not found , we will attempt to parse the name as would be passed to devaddresstonodedev"
use device information to attempt to print a human readable device name .
helper function to read a files contents and return them
compare passed string output to contents of filename
"extra super caching to speed up the test suite . we basically cache the first guest / pool / vol poll attempt for each uri , and save it across multiple reopenings of that connection . we are n't caching libvirt objects , just parsed xml objects . this works fine since generally every test uses a fresh virconnect , or undoes the persistent changes it makes ."
open plain testdriver.xml and cache the instance . tests that use this are expected to clean up after themselves so driver state does n't become polluted .
": param _ from_object_init : only used for the refresh ( ) call from _ init_libvirt_state . tells us to not refresh the xml , since we just updated it ."
insert files into the root directory of the initial ram disk
divides an image into chunks to feed into ocr net
uses ocr to transform an image into a string
rejoin substrings according to position of subimages
"loads the ocr dataset . a is matrix of images ( nimg , height , width , channel ) . y is matrix of characters ( nimg , max_char ) fp : path to ocr data folder return : data matrix , target matrix , target strings"
"get number of ( rows , columns ) of subimages"
destroy iam resources .
check general assemblage .
check lambda policy .
check s3 policy .
check s3 policy with multiple buckets listed .
check simpledb policy with multiple domains listed .
automatically enable service for deployment types .
render iam policy template .
assemble iam policy for _ app _ .
render the json template with arguments .
create or update the elb after rendering json data from configs . asserts that the elb task was successful .
attaches listerner policies to an elb
attaches backend server policies to an elb
adds stickiness policy to created elb
"configure load balancer attributes such as idle timeout , connection draining , etc"
generate a filename to be used by packer .
tests that ` configs.apply_region_configs ` applies region specific overrides correctly
validates that the only regions list format continues to work .
convert a gene panel with hgnc symbols to a new one with hgnc ids .
template decorator .
fetch insitiute and case objects .
preprocess institute objects .
export the omim gene panel to a .bed like format .
export gene panels to .bed like format .
export gene panels to .bed like format with coordinates .
export all genes to .bed like format
export all transcripts to .bed like format
export causatives for a collaborator in .vcf format
export a list of genes base on hpo terms
export objects from the mongo database .
fetch a resource and return the resulting lines in a list send file_name to get more clean log messages
fetch the necessary mim files using a api key
fetch the latest version of the hpo terms in .obo format
fetch the latest version of the map from phenotypes to genes
fetch the latest version of the map from genes to hpo terms
fetch the latest version of the map from phenotype to terms
load the hpo terms and hpo diseases into database
load the hpo terms into the database
load the omim phenotypes into the database
return a list with the rank results header
get the format from a vcf header line description
return a list with the vep header
query the hgnc aliases
view objects from the database .
upload variants to a case
convert images to matrices assign label to every image according to person using test data to make the machine learn this data args : path : path to images directory
generate a unique hash from a label and master password .
create a password from a label and master password .
two letters are equal iif their symbols are equals
two letters are not equal if their symbols are not equals
symbols that are represented by the letter
this method returns the automata that is represented by the specified dot .
this method returns the dot code that represents the provided automata .
"return one line of a gophermap , built from one feed entry bject ."
return a gophermap string for a feed object produced by feedparser .
return a gophermap string for the feed at feed_url .
"make a simple string from feed title , to use as a directory name ."
"build a gophermap file in the specified directory , which presents an index for all the feeds in feed_objects ."
"build a single gophermap string , combining the entries from all provided feed objects ."
t027 test line_parse method in mnw2 package class
t027 test load of mnw2 package
t027 test make mnw2 package
t027 test export of mnw2 package to netcdf files
t027 test mnw2 package checks in flopy
"duration(self , duration )"
"extract(self , key , dict )"
make a subprocess according to the given command - line string
ensure that the process returned a zero exit code indicating success
the staging area is a place where we can temporarily store and manipulate vhds . the use of the staging area is different for upload and download :
remove staging area directory
"rename files to conform to new image format , if needed ."
sanity check to ensure that only appropriate vhds are marked as hidden .
"this check ensures that the timestamps listed in the vhd footer are n't in the future . this can occur during a migration if the clocks on the the two dom0 's are out - of - sync . this would corrupt the sr if it were imported , so generate an exception to bail ."
this check ensures that the parent pointers on the vhds are valid before we move the vdi chain to the sr . this is * very * important because a bad parent pointer will corrupt the sr causing a cascade of failures .
this check ensures that the vhds in the staging area are sequenced properly from 0 to n-1 with no gaps .
move vhds from staging area into the sr .
hard - link vhds into staging area .
create a tarball from a given path .
extract a tarball to a given path .
wrapper around xenapiplugin.dispatch which handles pickle serialization .
true if val is matched by the path component grammar in rfc3986 .
check if the user_data is encoded properly
validate values of args against validators in validator .
check that the capabilities provided by the compute service satisfy the extra specs associated with the instance type
return a list of hosts that can create instance_type .
coerces a console instance into proper dictionary format
coerces a console instance into proper dictionary format with correctly mapped attributes
returns a list of consoles for this instance
creates a new console
shows in - depth information on a specific console
you ca n't update a console
deletes a console
execute and return stdout
execute without returning stdout
"connect to a host on a given ( ssl ) port . if ca_file is pointing somewhere , use it to check server certificate ."
update information about a host from its compute_node info .
incrementally update host state from an instance
return whether or not this host passes filters .
since the caller may specify which filters to use we need to have an authoritative list of what is permissible . this function checks the filter names against a predefined set of acceptable filters .
filter hosts and return only ones passing all filters
update the per - service capabilities based on this notification .
"returns a dict of all the hosts the hostmanager knows about . also , each of the consumable resources in hoststate are pre - populated and adjusted based on data in the db ."
returns the list of volume types
return a single volume type item
makes sure valueerror from bug 926412 is gone
makes sure deleted exe 's are killed correctly
generate a wsgi response based on the exception passed to ctor .
connect the volume . returns xml for libvirt .
disconnect the volume
attach the volume to instance_name
detach the volume from instance_name
convert volume and snapshot i d columns from int to varchar .
convert volume and snapshot i d columns back to int .
creation of this object should basically cover all time consuming collection . methods after that should not cause time delays due to network operations or lengthy cpu operations .
"yields ( path , value ) tuples for metadata elements ."
sanitizes the msg_data field before logging .
prepares exception data to be sent over rpc .
close the connection .
create a consumer on this connection .
create a worker on this connection .
spawn a thread to handle incoming messages .
return a version of this context with admin flag set .
ensure the ca filesystem exists .
get crl file for project .
revoke a cert by file name .
revoke all user certs .
revoke all project certs .
revoke certs for user in project .
helper to generate user cert subject .
helper to generate user cert subject .
generate and sign a cert for user in project .
compute an md5 hash .
return all versions .
return multiple choices .
parse dictionary created by routes library .
retrieve all the instances associated with your account .
runs an image on ec2 .
create a volume object .
calculate an i / o based load by counting i / o heavy operations
update stats after an instance is changed .
save the useful bits of instance state for tracking purposes
returns a query with sorting / pagination criteria added .
check if the terminal to be opened is ipython .
run an interpreter either with an undo script or with a generic method .
replace raw_input_original property in terminalinteractiveshell .
replace raw_input_original as a property .
start an undoable instance of ipython .
parse command line arguments
get and return the ssl status of a domain .
return a phabricator client instance
return a list of phabricator 's projectphid
open a task on phabricator and return it
acknowledge the icinga alert
run the icinga event handler for ssl checks
this constructor adds a content - type : and a mime - version : header .
create a text/ * type mime document .
used so that it can work with the multiprocess plugin . monkeypatched because nose seems a bit unsupported at this time ( ideally the plugin would have this support by default ) .
"@param cond : fail , error , ok"
"encodes the object input and returns a tuple ( output object , length consumed ) ."
"decodes the object input and returns a tuple ( output object , length consumed ) ."
create a new completer for the command line .
return the next possible completion for ' text ' .
compute matches when text is a simple name .
compute matches when text contains a dot .
resolves a dotted attribute name to an object . raises an attributeerror if any attribute in the chain starts with a ' _ ' .
handles the http post request .
dispatches the xml - rpc method .
selectively log an accepted request .
registers an instance to respond to xml - rpc requests .
registers a function to respond to xml - rpc requests .
the main page for the project .
go away google
common location for mturk submission .
problem reporting handler .
one of these arguments must be provided : file_name -- path to file containing a robot robot -- instance of a robot code -- source code containing a robot name argument can be used to set robot 's name
need to be very careful here not to call any built - in functions on ' action ' unless it is known to be completely safe . a malicious bot may return an object with overwritten built - in functions that run arbitrary code .
"returns sanitized action , output and error flag from robot"
"returns a tuple of two dictionaries containing actions , and ( error flag and output ) for each bot , respectively"
an aggregate of all bots and their actions this turn .
load motherese dataset ( train and test ) .
detect the vcs type the project uses and initialize the correct handler to use internally .
agent metrics /node fixture
fixture for summary information for node
agent metrics /container fixture
creates a metronome client with the supplied configuration .
: param toml_config : configuration dictionary : type toml_config : config . toml : returns : metronome base url : rtype : str
the function checks if cluster has metronome capability .
returns info about metronome instance
returns a representation of the requested job .
get a list of known jobs .
add a new job .
"send an http request to update an application , group , or pod ."
update an application or group .
update a job .
completely removes the requested application .
gets the schedules for a given job
gets the schedules for a given job
gets the schedules for a given job
gets the schedules for a given job
completely removes the requested application .
add a new job .
gets the schedules for a given job
add a new job .
add a new job .
"substitutes a metronome "" id path "" into a url path format string , ensuring the result is well - formed ."
returns the query parameters that signify the provided force value .
attempts to parse the body of the given response as json .
gets the default service manager url
returns whether service manager is enabled .
starts a service that has been added to the cluster via cosmos ' package / add endpoint .
search everywhere for an executable name or path from the candidate list .
walk through home and yield git repositories .
reorder the roots by closeness to the name
find a repo that contains this path .
check if the root contains the path .
remove quotes from paths
"format tpl if it 's a string , or call it if it 's a function"
load configuration file and populate the cache if available
handle a url
replace the char with the word .
convert the text into the shortcut format which we can serialize .
extract the mac keys and the windows keys .
get the global log setup by the _ _ main _ _ script
setup the global log . add more specific settings as you please .
install node js from source .
get the version of node.js currently installed .
install a node.js package .
install node.js package dependencies .
get the installed version of a node.js package .
update a node.js package .
uninstall a node.js package .
create an openvz container .
destroy the container .
set container parameters .
start the container .
stop the container .
restart the container .
get the status of the container .
check if the container is running .
check if the container exists .
run a command inside the container .
download an openvz template .
get the list of currently used ctids .
get an available ctid .
update portage package definitions .
check if a portage package is installed .
install one or more portage packages .
remove one or more portage packages .
check if an apache module is enabled .
enable an apache module .
disable an apache module .
check if an apache site is enabled .
enable an apache site .
disable an apache site .
read .out file from winglink
read sites _ file output from winglink
get x ( e - w ) and y ( n - s ) position of station and put in middle of cell for a 3d model .
set up the palo alto vpn user sensor .
initialize the sensor .
return the name of the sensor .
"icon to use in the frontend , if any ."
return the state of the device .
could the device be accessed during the last update call .
get the latest data and updates the state .
initialize the palo alto api .
return data .
return proper uril scheme based on config setting .
prepare the url .
http request to the palo alto device .
get operational and configuration urls .
parses global protect users xml .
parses environment / temperature values .
parses system information .
parses active users xml .
parses data and populates sensors .
extracts good runs from random games . code from sentdex : return training_data :
"get all pitching stats for a set time range . this can be the past week , the month of august , anything . just supply the start and end date in yyyy - mm - dd format ."
"get all pitching stats for a set season . if no argument is supplied , gives stats for current season to date ."
"get data from war_daily_pitch table . returns war , its components , and a few other useful stats . to get all fields from this table , supply argument return_all = true ."
retrieve a table of player information given a list of player ids
strip the 's ' off of plural words to dumbly singularize them .
ping the server and check if it 's alive .
connect to the server using an ssh session and execute a command .
common code for adding / removing users .
add a user to a server .
remove user from a server .
wrapper to get a permittee keyword from threadlocals and make sure it is usable .
does the object c{permittee } have the permission named by c{perm_name } over target object or class c{target_obj_or_class } .
"does the object c{permittee } have the permission named by c{perm_name } over target object or class c{target_obj_or_class } . if not , then raise a permissiondenied exception ."
shortcut to create a new permission . see l{expedientpermissionmanager.create_permission } .
"give receiver the permission c{permission } over the object or class c{obj_or_class } . if c{giver } is specified , then the function checks that the giver is allowed to give the permission to the receiver . if c{can_delegate } is c{true } , the receiver is given the ability to further give the permission to others ."
take permission away from an owner .
convenience wrapper around l{permissionmiddleware } .
check that a slice expires correctly .
return the absolute name of the module to be imported .
import a module .
returns a string of 2 randome letters
read the htpasswd file into memory .
write the htpasswd file to disk
"replace the entry for the given user , or add it if new ."
remove the entry for the given user .
forces the update of the status of the vms . retrieves the server from the passed arguments and invokes the corresponding method on its vt am .
convert a slice name to a slice urn .
see framework_base for doc .
parse the rspec and return a tuple of lists of switches and links
attrs is a dict with the following keys : dl_src / dst / type vlan_id nw_src / dst / proto tp_src / dst
show buttons to download and upload rspecs .
"wrapper around c{django.conf.urls.defaults.url } to add the c{name } parameter to c{kwargs } as "" url_name "" , and to automatically assign the c{view } . c{use_name_for_dispatch } controls whether or not to add c{name } to c{kwargs }"
to allow the mocking of printing .
wait a specified delta number of seconds .
wait for the difference between now and last .
test and return the wait function .
publishes a line from stdin to the message queue . this function returns the timestamp of the last valid message processed .
reads and publishes messages .
application entry point .
gets a new boto3 session
adds all existing security groups used in the region .
adds security groups used by ec2 instances .
adds security groups used by launch configurations instances .
adds security groups used by network interfaces ( enis ) .
adds security groups used by classic elastic loadbalancers ( elbs ) .
adds security groups used by application loadbalancers ( albs ) .
adds security groups used by rds .
adds security groups used by redshift .
register callbacks required for the test
no work to do here
generator for running the reset test
decorate a function as a tool that may be hooked
add a hook to a compile function
add a hook to the compiler
add a hook to the linker
add a hook to the assemble
add a hook to the elf to binary tool
add a hook to a command line function
add a hook to the compiler command line
add a hook to the linker command line
add a hook to the assembler command line
add a hook to the elf to bin tool command line
get the command line after running all hooks
get the compiler command line after running all hooks
get the linker command line after running all hooks
get the assmebler command line after running all hooks
get the binary command line after running all hooks
returns true if the executable ( arm - none - eabi - gcc ) location specified by the user exists or the executable can be found on the path . returns false otherwise .
create a new options parser with the default compiler options added
lists available build profiles
extract a toolchain profile from parsed options
return tuple of directory and filename and extenstion .
return tuple of filename and extenstion .
function builds the greatschools api urls ( one for each level of school ) : return : sets self.error if issues arise during api calls
"uses elementtree builtin to parse the xml . it then generates a dictionary of key / value pairs found in the xml , including school name , distance from property address , and greatschools.org rating . the elementary , middle , and high schools closest to the given property address are populated as attributes of the greatschools object . : param : url used for greatschools api call for xml retrieval : return : none"
delete all generated files below the current directory .
"returns the includes used with protoc , in order of preference . it is important to keep the ' global ' searches at the bottom , to ensure the correct version is used if there are duplicates ."
run a command in a subprocess .
helper to run protoc with appropriate parameters .
build a service with the grpc - plugin for the --go_out and --grpc - gateway_out compilers .
parse input args and returns an args dict .
print help on argument parse error .
fh : file handle ; results : dict for results ;
validate and arrange directory related arguments .
tests the build_dataset function
builds a dictionary from given words
creates an identity matrix with size of dictionary
turns a sentence into a vector of word ids
turns an array of some users into an array with ones on those users indicies
takes a list of all subreddits and creates a dictionary of unique subreddits
turns a subreddit into an index
extract value from tensorboard summary protobuf
a function that reads the data and corresponding label from a csv file
unlocks given usernames and ip addresses
unlocks all usernames and ip addresses found in ` ` queryset ` `
returns if this login attempt is within the failed_auth_lockout_period . this should be checked for the last failed login attempt .
returns a random password and sets this as temporary password for provided user .
displays the login form and handles the login action .
saturate a channel in a specific image patch
""" saturates a channel of the image ( sets the value to 255 for all the pixels )"
"quantizes the rgb values into a specified number of bins . if normalize is true , it normalizes the rgb values before the quantization"
"begin sorting when it finds a pixel which is not ( r , g , b ) in the column or row , and will stop sorting when it finds a ( r , g , b ) pixel"
rescales the rgb values back to 0 - 255 in the image ( useful especially after applying audio filters )
pixelates the image : param x : input image : param block_height : height of the pixel : param block_width : width of the pixel : param operator : which function to use when computing the color value of the pixels : op_mean : average rgb in the block ( default ) op_max : max rgb value op_median : median rgb value op_min : min rgb value
convolve image x with 2d matrix h. returns a new modified matrix
searches the google places api ( max limit = 20 )
searches google for a specific place
setup the class
deal with the cal function
stories - state level scrambling : param text : a bunch of stories : return : a bunch of state - scrambled stories
"turn a story to a state - shuffled story : param story_text : any story , represented by a string of text : return : a state - shuffled story"
scramble a list according to scramble_type : param list : : param scramble_type : : return :
testing parse_odds_file and get_data_filename
create a spectra . color object in the cielab color space .
create a spectra . color object in the cie lch color space .
create a spectra . color object in the xyz color space .
create a spectra . color object in the srgb color space .
create a spectra . color object in the cmyk color space .
create a spectra . color object in the cmy color space .
create a spectra . color object in the hsl color space .
create a spectra . color object in the hsv color space .
create an rgb spectra . color object from a web - color or hexcode .
"create a color scale , based on a list of spectra . color objects ."
create a range of ` count ` colors between two or more base colors .
: param str space : name of the color space .
create srgb color from a web - color name or hexcode .
convert color to a different color space .
get this color 's corresponding rgb hex .
blend this color with another color in the same color space .
brighten this color by ` amount ` luminance .
darken this color by ` amount ` luminance .
saturate this color by ` amount ` chroma .
desaturate this color by ` amount ` chroma .
": param list colors : list of two or more spectra . colors , or web - color / hexcode strings . : param domain : list of two or more numbers . : type domain : list or none"
return the color corresponding to the given ` number ` .
create a new scale with the given domain .
list this scale 's domain .
create a new scale in the given color space .
create a list of colors evenly spaced along this scale 's domain .
create a fake config file
test the install function
generate api documentation using epydoc .
run unit tests .
analyze log file
load this subcommand
"return true if s ( str ) is a valid url , false otherwise ."
get sdmx message from rest service or local file
"retrieve sdmx messages . if needed , override in subclasses to support other data providers ."
"a one - dimensional embedding , where a single latent skill is enough to explain the data . the key observation here is that the model recovered positive skill gains for l1 , and "" correctly "" arranged students and assessments in the latent space . initially , carter fails both assessments , so his skill level is behind the requirements of both assessments . lee passes a1 but fails a2 , so his skill level is beyond the requirement for a1 , but behind the requirement for a2 . in an effort to improve their results , lee and carter complete lesson l1 and retake both assessments . now carter passes a1 , but still fails a2 , so his new skill level is ahead of the requirements for a1 but behind the requirements for a2 . lee passes both assessments , so his new skill level exceeds the requirements for a1 and a2 . this clear difference in results before completing lesson l1 and after completing the lesson implies that l1 had a positive effect on lee and carter 's skill levels , hence the non - zero skill gain vector recovered for l1 ."
"a two - dimensional embedding , where an intransitivity in assessment results requires more than one latent skill to explain . the key observation here is that the assessments are embedded on two different axes , meaning they require two completely independent skills . this makes sense , since student results on a1 are uncorrelated with results on a2 . fogell fails both assessments , so his skill levels are behind the requirements for a1 and a2 . mclovin passes both assessments , so his skill levels are beyond the requirements for a1 and a2 . evan and seth are each able to pass one assessment but not the other . since the assessments have independent requirements , this implies that evan and seth have independent skill sets ( i.e. evan has enough of skill 2 to pass a2 but not enough of skill 1 to pass a1 , and seth has enough of skill 1 to pass a1 but not enough of skill 2 to pass a2 ) ."
"we replicate the setting in test_independent_assessments , then add two new students slater and michaels , and two new lesson modules l1 and l2 . slater is initially identical to evan , while michaels is initially identical to seth . slater reads lesson l1 , then passes assessments a1 and a2 . michaels reads lesson l2 , then passes assessments a1 and a2 . the key observation here is that the skill gain vectors recovered for the two lesson modules are orthogonal , meaning they help students satisfy completely independent skill requirements . this makes sense , since initially slater was lacking in skill 1 while michaels was lacking in skill 2 , but after completing their lessons they passed their assessments , showing that they gained from their respective lessons what they were lacking initially ."
"we replicate the setting in test_independent_assessments , then add a new assessment module a3 and a new lesson module l1 . all students initially fail assessment a3 , then read lesson l1 , after which mclovin passes a3 while everyone else still fails a3 . the key observation here is that mclovin is the only student who initially satisfies the prerequisites for l1 , so he is the only student who realizes significant gains ."
"a one - dimensional embedding , where a single latent skill is enough to explain the data . the key observation here is that the model recovered positive skill gains for l1 , and "" correctly "" arranged students and assessments in the latent space . initially , carter fails both assessments , so his skill level is behind the requirements of both assessments . lee passes a1 but fails a2 , so his skill level is beyond the requirement for a1 , but behind the requirement for a2 . in an effort to improve their results , lee and carter complete lesson l1 and retake both assessments . now carter passes a1 , but still fails a2 , so his new skill level is ahead of the requirements for a1 but behind the requirements for a2 . lee passes both assessments , so his new skill level exceeds the requirements for a1 and a2 . this clear difference in results before completing lesson l1 and after completing the lesson implies that l1 had a positive effect on lee and carter 's skill levels , hence the non - zero skill gain vector recovered for l1 ."
a two - dimensional grid of assessments and a single student somewhere in the middle of it
"a two - dimensional embedding , where an intransitivity in assessment results requires more than one latent skill to explain . the key observation here is that the assessments are embedded on two different axes , meaning they require two completely independent skills . this makes sense , since student results on a1 are uncorrelated with results on a2 . fogell fails both assessments , so his skill levels are behind the requirements for a1 and a2 . mclovin passes both assessments , so his skill levels are beyond the requirements for a1 and a2 . evan and seth are each able to pass one assessment but not the other ."
"we replicate the setting in get_independent_assessments_history , then add two new students slater and michaels , and two new lesson modules l1 and l2 . slater is initially identical to evan , while michaels is initially identical to seth . slater reads lesson l1 , then passes assessments a1 and a2 . michaels reads lesson l2 , then passes assessments a1 and a2 ."
"we replicate the setting in get_independent_assessments_history , then add a new assessment module a3 and a new lesson module l1 . all students initially fail assessment a3 , then read lesson l1 , after which mclovin passes a3 while everyone else still fails a3 ."
sample a synthetic skill embedding and interaction history
get a dictionary mapping of all k : v pairs with key matching glob style expression ` pat ` .
minor diversion with built - in dict here ; clear can take a glob style expression and remove keys based on that expression .
sends an email notification when we detect that the game is down .
"this is a cron job that pings a url in the game , designed to test whether the game is up & healthy ."
add data to this qr code .
compile the data into a qr code array .
find the minimum size required to fit in the data .
make a pil image from the qr code data .
"returns a generator out of the file object , which - removes ` \ ` then ` ` then a shared prefix with the previous line then optional whitespace ; - keeps a line number ( starting from 0 ) of the first line being concatenated ."
creates a class that inherits from ` unittest . testcase ` with the decorated function as a method . create tests like this :
"return a suitable executor , based on the given flag"
collect a result .
execute the given function
make sure all results have been collected
@type config_obj : l{fedexconfig } @param config_obj : a valid fedexconfig object .
create the data structure and get it ready for the wsdl request .
fires off the fedex request .
adds an address to self . addressestovalidate .
saves an object to a file
the currently focused inode
get a new hivenavigator class focused at path .
seek to a new subkey . inodes and paths are supported .
returns true if the given pathation ( key ) exists .
returns the name of the current key .
gives a path representation of the focus in the hive .
lists all subkeys of the current focused key or path .
gets the value in a key - value pair in path . default can be used .
lists all values of this key or path .
provides a dictionary of the key - value pairs in this registry key .
returns true if the value name exists in key path .
returns the type of the value in path
"recurses through path and returns ( focus , keys , value_dict ) similar to os.walk"
create a description based on the object type
return the current version number of mapproxy webconf .
sets the module to its default state ( no used ranges ) .
upgrades a project 's used ranges module to the latest version .
"writes an empty file , ready to be filled by the user ."
reads a user - written list of ranges that should n't be touched .
"clears the used ranges list , since used ranges should be user - specified ."
makes a note of all the ranges which should n't be modified when writing .
"returns the amount of time in ms , in which the task has been running for"
"executes the tasks target function , and if a delay is specified it will proceed appropiately"
"checks for activation , then calls execute function above"
destroys the current task instance
allocates next task identification number
returns true if the task exists in the queue else false
removes a specific task from which ever queue its currently in
activates the task and places it in the waiting queue to be executed by the main loop
deactivates a task from whichever queue its currently running in
creates and appends the task to the queue to be executed
adds a new task to the task manager without a delay
adds a new task to the task manager with a delay
a decorator method for setting up a task managed function
removes and destroys the task fron the queue
recycles the task through the queue
"main task manager loop , executes tasks one by one"
"runs the task manager main loop method , by default on a seperate thread"
destroys the task manager instance
udp encap test
interface index assigned by vpp .
"mac - address of the remote interface "" connected "" to this interface"
mac - address of the vpp interface .
local ipv4 address on vpp interface ( string ) .
"local ipv4 address - raw , suitable as api parameter ."
"ipv4 address of remote peer "" connected "" to this interface ."
"ipv4 address of remote peer - raw , suitable as api parameter ."
local ipv6 address on vpp interface ( string ) .
"local ipv6 address - raw , suitable as api parameter ."
"ipv6 address of remote peer "" connected "" to this interface ."
"ipv6 address of remote peer - raw , suitable as api parameter"
local ipv6 linnk - local address on vpp interface ( string ) .
"local ipv6 link - local address - raw , suitable as api parameter ."
"link - local ipv6 address of remote peer "" connected "" to this interface ."
"link - local ipv6 address of remote peer - raw , suitable as api parameter"
name of the interface .
raw result of sw_interface_dump for this interface .
test case creating this interface .
remote hosts list
: param list value : list of remote hosts .
: param mac : mac address to find host by . : return : host object assigned to interface .
: param ip : ipv4 address to find host by . : return : host object assigned to interface .
: param ip : ipv6 address to find host by . : return : host object assigned to interface .
generate and add remote hosts for the interface .
configure ipv4 address on the vpp interface .
remove ipv4 address on the vpp interface .
for every remote host assign neighbor 's mac to ipv4 addresses .
configure ipv6 address on the vpp interface .
remove ipv6 address on the vpp interface .
for every remote host assign neighbor 's mac to ipv6 addresses .
unconfigure ipv6 and ipv4 address on the vpp interface .
set the interface in a ipv4 table .
set the interface in a ipv6 table .
configure ipv6 ra suppress on the vpp interface .
configure ipv6 ra suppress on the vpp interface .
configure ipv6 ra suppress on the vpp interface .
put interface admin - up .
put interface admin - down .
ipv6 enable interface
put interface admin - down .
register a sub - interface with this interface .
enable mpls on the vpp interface .
enable mpls on the vpp interface .
set the interface to unnumbered via ip_sw_if_index
unset the interface to unnumbered via ip_sw_if_index
set the interface to enable / disable proxy arp
map - e
create vpp pppoe4 interface
test xform.version can store more than 12 chars
"only restores xml submissions , media files are assumed to still be in storage and will be retrieved by the filename stored within the submission"
"if there is a ' .json ' style format suffix , filter the renderers so that we only negotiation against those that accept that format . if there is no renderer available , we use mediafilerenderer ."
renders * obj * into serialized xml .
replace app name in db.pending_create_signals to avoid crashing out at the end of the migration .
only give an object a new uuid if it does not have one .
'' iterate over a django queryset .
"check the status of records in the mysql db versus mongodb , and , if necessary , invoke the command to re - sync the two databases , sending an email report to the admins of before and after , so that manual syncing ( if necessary ) can be done ."
when setting the html for this google document we do two things :
make relative paths for images absolute .
here is an example of what a section header looks like in the html of a google document :
"for some weird reason google documents does n't like nesting lists , so their table of contents requires a bunch of special formatting . instead of trying to hack off what they provide us , we create a tree of sections based on each sections level . this tree will be used to construct the html for the table of contents ."
"return an html representation of the table of contents for this document . this is done recursively adding on a list item for each element in the tree , and an unordered list if this node has children . i might want to double check that this html is the correct way to nest lists ."
render the navigation html as a twitter bootstrap section .
return a cleaned up html representation of this google document .
add parsed json to json instance column .
remove json content .
returns a function that can be used with the filter method
"generate a qrcode , settings options and output ."
dump user information to console .
managing user accounts .
dump information about the logged - in or given user(s ) .
format a github exception nicely .
"return an authorized github api connection , based on the given configuration ."
context manager that provides an api object and nicely reports common runtime errors .
"load configuration , especially authentication ."
return bool indicating whether credentials were provided .
try to get login auth from either base url or netrc .
try to find login auth in ` ` ~/.netrc ` ` .
command fixture .
returns the state of the control .
sets the state of the control .
forwards the attribute access to the ` ` .data ` ` attribute if attribute lookup fails on this instance ( except for the ` ` data ` ` and ` ` convergence_report ` ` attributes ) .
returns a convergence report ( as a string ) for the result . this report shows whether the convergence options used for calculating this result were satisfied or not .
return variables and remove them from config .
return variables from config .
put a new variable into config .
parse flatten config with slashes . parameters ---------- config : dict or config
"transform nested dict into flatten dict . parameters ---------- config : dict , config or none if none self.config will be parsed else config . returns ------- new_config : dict"
return config items .
return config keys .
return config values .
update config with values from other .
create base vgg layers
a sequence of 3x3 and 1x1 convolutions followed by pooling
return a variable value
assign a variable value
initialize a variable value
lock the directory itself or a variable
unlock the directory itself or a variable
make a shallow copy of the directory
"return a sequence of ( name , params ) for all variables"
checks if a variable already exists
create a variable
create many variables at once
initialize all variables before a pipeline is run
return a variable value
set a variable value
remove the variable with a given name
evaluate a named expression recursively
return a value of a named expression
set a value to a named expression
assign a value to a named expression
append a value to a named expression
extend a named expression with a new value ( see list.extend https://docs.python.org/3/tutorial/datastructures.html#more-on-lists )
update a named expression with a new value ( see dict.update https://docs.python.org/3/library/stdtypes.html#dict.update or set.update https://docs.python.org/3/library/stdtypes.html#frozenset.update )
return a wrapped named expression
assign a value
return a value of a batch component
assign a value to a batch component
return a value of a pipeline config
assign a value to a pipeline config
return a value from a callable
assign a value by calling a callable
return a value of a pipeline variable
assign a value to a pipeline variable
return a value of a random variable
assign a value
return a wrapped named expression
return components data as a tuple
implement your custom date parser here .
float(uncertain(int(x ) ) ) should not raise .
"insert some mock data in self.subtables , check it parses correctly ."
we want more than 2 pixels across the beam major and minor axes .
"it has been identified that having too many pixels across the restoring beam can lead to bad images , however further testing is required to determine the exact number ."
if the beam is highly elliptical it can cause source association problems within trap. again further testing is required to determine exactly where the cut needs to be .
"this has been raised as an interesting test , as if the full field of view ( fov ) has not been imaged we may want to image the full dataset . the imaged fov information can be estimated using the number of pixels and the size of the pixels ."
"if the beam is not correctly fitted by awimager , one or more parameters will be recorded as infinite ."
are the beam shape properties ok ?
args : images ( tuple ): list of image urls returns : list : of imagemetadataforsort
args : hdulist ( astropy.io.fits . hdulist ): fits header to extract timestamp from
read an amount of bytes from the socket
read raw aarfaac protocol window
reconstruct a fits object from serialised fits header and data .
"handles the connection , waits until a windows is returned and puts it in the queue ."
"tries to connect to a specific host and port , if succesfull will call connection_handler ( ) with the connection ."
will monitor image_queue for images and group them by timestamp . when an image with an successive timestamp is received the group is put on the grouped queue .
connects to all hosts on port in ports . returns a generator yielding sets of images with the same timestamp .
default node has no outlets .
creates a ` node ` with operation ` op ` and operation ` options `
evaluates the operation with name ` opname ` within ` context `
looks up the object ` objname ` in ` store ` from ` engine ` .
returns the contained object .
` create ` node has one outlet for an object that will be used to fill the created object 's content .
creates a node graph with connections .
generates unique name for a node
add a ` node ` into the stream . does not allow to add named node if node with given name already exists . generate node name if not provided . node name is generated as ` ` node ` ` + sequence number . uniqueness is tested .
returns name of ` node ` .
"sets a name for ` node ` . raises an exception if the ` node ` is not part of the stream , if ` name ` is empty or there is already node with the same name ."
coalesce node reference : ` reference ` should be either a node name or a node . returns the node object .
remove a ` node ` from the stream . also all connections will be removed .
connects source node and target node . nodes can be provided as objects or names .
"remove connection between source and target nodes , if exists ."
returns topologically sorted nodes .
return nodes that ` node ` passes data into .
return a dictionary where keys are outlet names and values are nodes .
get bubbles default logger
create a default logger
sets ` value ` for ` key ` even if value is null .
returns path to a local file from ` url ` . returns ` none ` if the ` url ` does not represent a local file .
reads json from ` url ` . the ` url ` can also be a local file path .
creates a data resource for reading . arguments :
converts representation to ` operand ` definition
return list of common representations of ` objects `
for every operand get list of it 's representations . returns list of lists .
creates an operation prototype . the operation will have the same name as the function . optionaly a number of operands can be specified . if no arguments are given then one operand is assumed .
creates an operation signature . sitnature is a list of object representations for operation arguments .
signatures can be compared to lists or tuples of strings
returns ` true ` if the signature matches signature of ` operands ` . ` operands ` is a list of strings .
returns ` true ` if at least one operand is ` any ` ( ` ` * ` ` )
"returns a ` signature ` object that serves as a prototype for similar signatures . all representations in the prototype signature are set to ` any ` , number of arguments is preserved ."
"creates an operation with name ` name ` and ` operands ` . if ` operands ` is ` none ` , then one operand is assumed with name ` obj ` ."
return list of registered signatures .
returns a function for ` signature `
returns ordered list of signatures for ` operands ` . the generic signatures ( those containing at least one ` ` * ` ` /`any ` type are placed at the end of the list .
"return the represented thread local object . if object does not exist , try to create it using factory ."
codage : un entier ( décimal ) .
codage : amount . montants en centimes . ( p7 )
codage : paymethod . ( p6 )
"champ : bestcontracttariff . ( p37 , p10 , p39 , p59 )"
champ : specialeventseriousness . ( p32 )
champ : eventcode . ( p19 )
champ : eventserviceprovider . pas de table . ( p27 )
champ : eventresult . empirique . ( p24 pour sncf )
parse une partie de l'atr et affiche quelques paramètres intéressants .
retourne la chaine de la representation binaire de tab
generate grid structures in a specific area .
"takes a binary function ( taking success and error , respectively ) and builds a future from it ."
"creates a future from a static value , immediately returning it ."
"creates a future from a static value , immediately rejecting it ."
encases an ordinary function in a future . if the function runs as expected the return value will be returned to the success callback . if an exception occurs it will be returned to the error callback .
apply a transformation function fun to the future value .
chains a future to this one . this will intercept any calls to fork insofar as both futures are chained before any call to the callbacks . any error in both futures will result in a call to the error callback .
registers resolvers for this future .
sets log level as |verbose_count| .
makes a new tab .
closes the tab with the given debugger_url .
activates the tab with the given debugger_url .
"returns self[index ] if it exists , or ret if index is out of bounds ."
"initalize an instance of platformbackend from a device optionally . call sites need to use supportsdevice before intialization to check whether this platform backend supports the device . if device is none , this constructor returns the host platform backend which telemetry is running on ."
returns whether this platform backend is the platform backend to be used for the host device which telemetry is running on .
returns whether this platform backend supports intialization from the device .
start gathering a trace with frame timestamps close to physical display .
stop gathering a trace with frame timestamps close to physical display .
read a cpu model - specific register ( msr ) .
indicates whether the platform supports installing test ca .
install a test ca on the platform .
remove a previously installed test ca from the platform .
"indicates whether cooperativelyshutdown , below , is supported . it is not necessary to implement it on all platforms ."
cooperatively shut down the given process from subprocess . popen .
tests whether the given path exists on the target platform . args : path : path in request . timeout : timeout . retries : num of retries . return : whether the path exists on the target platform .
waits for device under test to cool down to temperature given . args : temp : temperature target in degrees c.
it 's possible to wait for different events .
with no selector the first media element is loaded .
only the element matching the selector is loaded .
both elements are loaded with selector='all ' .
the load action times out if the event does not fire .
"if the platform or tab supports screenshot , attempt to take a screenshot of the current browser ."
"if the platform or tab supports screenshot , attempt to take a screenshot of the current browser . if present it uploads this local path to cloud storage and returns the url of the cloud storage path ."
upload the given screenshot image to cloud storage and return the cloud storage url if successful .
a value representing a skipped page .
sets a monotonic clock for the mac platform .
sets a monotonic clock for linux platforms .
"determines if system can query the performance counter . the performance counter is a high resolution timer on windows systems . some chipsets have unreliable performance counters , so this checks that one of those chipsets is not present ."
sets a monotonic clock for windows platforms .
sets a monotonic clock for the current platform .
configures device content setings from a list .
sets lock screen settings on the device .
earth mover 's distance . http://en.wikipedia.org/wiki/earth_mover's_distance
uploading log files produce by this browser instance to cloud storage .
true if this browser backend supports extensions .
"return a path to the appropriate executable for < binary_name > , downloading from cloud storage if needed , or none if it can not be found ."
"return a local path to the given binary name , or none if an executable can not be found . will not download the executable ."
fetch all binary dependenencies for the given |platform| .
this method is styled on unittest . testcase.setupclass .
this does not apply to android app stories .
tear down anything created in the _ _ init _ _ method that is not needed .
container for the information needed to download a dependency from cloud storage .
gets the path to a downloaded version of the dependency .
create the specified file and add some content to it . use the ` open ( ) ` built in function .
delete the specified file .
return true if the specified file exists .
return the list of paths matching the specified glob expression .
delete the specified file hierarchy .
"override this to define custom interactions with the page . e.g : def runpageinteractions(self , action_runner ): action_runner . scrollpage ( ) action_runner . tapelement(text='next ' )"
converts a page object to a dict suitable for json output .
returns true iff this url points to a file .
"returns the path of the file , stripping the scheme and query string ."
"returns the file path , including the params , query , and fragment ."
clamp a value between some low and high value .
"sorts the samples , and map them linearly to the range [ 0,1 ] ."
"computes the discrepancy of a set of 1d samples from the interval [ 0,1 ] ."
a discrepancy based metric for measuring timestamp jank .
a discrepancy based metric for measuring duration jank .
calculates arithmetic mean .
calculates the standard deviation .
calculate the integral according to the trapezoidal rule
returns the float value of a number or the sum of a list .
"returns the quotient , or zero if the denominator is zero ."
gets the median of a list of values .
calculates the value below which a given percentage of values fall .
compute a rounded geometric mean from an array of values .
wraps the provided context manager and runs it if condition is true .
parses command line arguments .
runs the adb command .
runs the adb shell command .
runs command as root .
inputs a keyevent .
inputs text .
deletes file .
makes a certificate file that follows the format of files in cacerts .
installs a certificate putting it in /system / etc / security / cacerts .
installs certificate on the device using adb commands .
set up the raspio analog platform .
initialize the analog sensor .
return the state of the sensor .
get the name of the sensor .
"return the class of this device , from component device_classes ."
"return the unit of measurement of this entity , if any ."
get the latest value from the pin .
setup the enerpi platform sensors getting the platform config from discovery_info .
set up the enerpi cameras : local_file cameras mirroring svg tiles .
set up the vacuum switch from discovery info .
test if input text can be base64 decoded .
test if input text can be base64url decoded .
"return base64 text without any formatting , just the base64 ."
convert base64 text to base64url text .
convert base64url text to base64 text .
test if the text is base64 padded .
percent - encode base64url padding .
percent - decode base64url padding .
remove padding from input base64 text .
assure the input text ends with padding .
fold text into lines of text with max line length .
fold text into lines of text with max line length .
raise tokennotfound if the token is expired .
delete all tokens for a given domain .
delete all tokens for a given user or user - project combination .
delete all tokens for a list of user_ids .
forward calls to the ` token_provider_api ` persistence manager .
get a token by i d.
create a token by i d and data .
deletes a token by i d.
deletes tokens by user .
returns a list of current token_id 's for a user
returns a list of all revoked tokens
archive or delete tokens that have expired .
there should be a space after the # of block comments .
this object is created automatically by pep8 .
called automatically by pep8 .
add an error caused by a node to the list of errors for pep8 .
keeps lists of logging and i18n imports
return the fully qualified name or a name or attribute .
look for ' log = logging.getlogger '
look for the ' log.debug ' calls .
redirect to the roles extension .
clients requesting xml should get what they ask for .
clients requesting json should definitely not get xml back .
"if client does not specify an accept header , default to json ."
xml requests should be replaced by json requests .
json - only requests should be unaffected by the xml middleware .
construct a path and pass it to v3controller.base_url method .
create a new trust .
create a new trust .
checks if a role has been assigned to a trust .
get a role that has been assigned to a trust .
construct a path and pass it to v3controller.base_url method .
add urls for entities related with identity provider .
add ' links ' entry to the response dictionary .
add new entries to the ' links ' subdictionary in the response .
authenticate from dedicated url endpoint .
exchange a scoped token for a saml assertion .
list all domains available to an authenticated user 's groups .
list all projects available to an authenticated user 's groups .
ensure there are no ids that are bigger than 64 chars .
logs exceptions and aborts .
check if page defined by url is in cache
"return page if in cache , start parsing if not in cache"
read page from current url
place pages in cache
get page defined by current url from cache
check if tag has defined attribute
return url attribute from the list of provided attributes
return attribute value from the list of provided attributes
clean data block by removing special characters
start book genre page parsing
prepare site url from defined page number and genre url
check if page with defined url is in cache
cache current books
initializer . define bounding boxes for button label ( if any ) and icon ( if any )
create button layout
prepare labels rectangles
return button image bounding box
return button label bounding box
create rectangle by merging two joint rectangles
add background rectangle
set text and draw component
set text without drawing component
prepare label component representing this output text . used for web .
set new localized text
fetch text from provided object
replace string with unicode codes by characters
return text x coordinate taking into account shift and alignment values
return text y coordinate taking into account shift and alignment values
set visibility flag
add select event listener
notify select event listeners
handle event .
this view is the root index of the application . it is responsible for routing the requestor to the right place .
ejects the dvd drive not really worth its own class
main function for ripping does everything returns nothing
main function for skipping compression does everything returns nothing
main function for compressing does everything returns nothing
main function for filebotting and flagging forced subs does everything returns nothing
passes the necessary parameters to handbrake to start an encoding assigns a nice value to allow give normal system tasks priority
decorates / wraps functions that make authenticated http requests to muspy .
find the set of album artists belonging to the list of items and return it sorted .
make a put request to muspy with an artist id and store that id if successful .
make a delete request to muspy with an artist id .
store an item 's album artist if the artist has not been encountered yet .
unfollow album artists who no longer have albums present in the library .
return a flask view decorator to set sqlalchemy isolation level
return a list of allowed auth tokens from the application config
"when freezing from a windows venv , overwrite the values of the standard ` $ { tcl_library } ` , ` $ { tk_library } ` , and ` $ { tix_library } ` environment variables ."
"if the current tcl installation is a teapot - distributed version of activetcl * and * the current platform is os x , log a non - fatal warning that the resulting executable will ( probably ) fail to run on non - host systems ."
"get an os x - specific 2 - tuple of the absolute paths of the top - level external data directories for both tcl and tk , respectively ."
"get a platform - agnostic 2 - tuple of the absolute paths of the top - level external data directories for both tcl and tk , respectively ."
"get a platform - specific 2 - tuple of the absolute paths of the top - level external data directories for both tcl and tk , respectively ."
get a list of toc - style 3 - tuples describing all external tcl / tk data files .
freeze all external tcl / tk data files if this is a supported platform * or * log a non - fatal error otherwise .
"mobilenet model from the ` "" mobilenets : efficient convolutional neural networks for mobile vision applications "" < https://arxiv.org/abs/1704.04861 > ` _ paper ."
"mobilenetv2 model from the ` "" inverted residuals and linear bottlenecks : mobile networks for classification , detection and segmentation "" < https://arxiv.org/abs/1801.04381 > ` _ paper ."
"mobilenet model from the ` "" mobilenets : efficient convolutional neural networks for mobile vision applications "" < https://arxiv.org/abs/1704.04861 > ` _ paper , with width multiplier 1.0 ."
"mobilenetv2 model from the ` "" inverted residuals and linear bottlenecks : mobile networks for classification , detection and segmentation "" < https://arxiv.org/abs/1801.04381 > ` _ paper ."
"mobilenet model from the ` "" mobilenets : efficient convolutional neural networks for mobile vision applications "" < https://arxiv.org/abs/1704.04861 > ` _ paper , with width multiplier 0.75 ."
"mobilenetv2 model from the ` "" inverted residuals and linear bottlenecks : mobile networks for classification , detection and segmentation "" < https://arxiv.org/abs/1801.04381 > ` _ paper ."
"mobilenet model from the ` "" mobilenets : efficient convolutional neural networks for mobile vision applications "" < https://arxiv.org/abs/1704.04861 > ` _ paper , with width multiplier 0.5 ."
"mobilenetv2 model from the ` "" inverted residuals and linear bottlenecks : mobile networks for classification , detection and segmentation "" < https://arxiv.org/abs/1801.04381 > ` _ paper ."
"mobilenet model from the ` "" mobilenets : efficient convolutional neural networks for mobile vision applications "" < https://arxiv.org/abs/1704.04861 > ` _ paper , with width multiplier 0.25 ."
"mobilenetv2 model from the ` "" inverted residuals and linear bottlenecks : mobile networks for classification , detection and segmentation "" < https://arxiv.org/abs/1801.04381 > ` _ paper ."
set up the configure of profiler ( only accepts keyword arguments ) .
set up the configure of profiler .
set up the profiler state to ' run ' or ' stop ' .
dump profile and stop profiler . use this to save profile in advance in case your program can not exit normally .
dump profile and stop profiler . use this to save profile in advance in case your program can not exit normally .
return a printable string of aggregate profile stats .
pause profiling .
resume paused profiling .
create new task object owned by this domain
create new frame object owned by this domain
create new counter object owned by this domain
create new marker object owned by this domain
start timing scope for this object
stop timing scope for this object
set counter value .
increment counter value .
decrement counter value .
set up the profiler state to record operator .
set up a default url .
get the python license header for a license
source creation should succeed .
source creation without connection string should failed .
source creation with other connector should failed .
import data and returns error msg or empty string
"get a related model from its name , for better ui ."
parameters ---------- img_list : list of strings idx : numpy array tname : string
attempt to identify the language which src is written in .
return the most refined version of results as possible .
remove strings from line .
remove comments from line .
return line without comments and strings .
return all non - comment and non - string content in src .
compare two signatures using only the keys in known .
compute a ' signature ' using ` lang_data ` .
load an existing signature .
this is a doc string located within a the function hello_world .
this is a doc string located within the _ _ init _ _ method of the hello class .
this is a doc string located within the hi method the hello class .
"set up the user interface , signals & slots"
toggle play / pause status
open a media file in a mediaplayer
set the volume
set the position
updates the user interface
get profile of this user .
get detailed profile of this user .
get this user 's activities .
get questions that this user asked .
get answers that this user answered .
get atricles that this user post .
get collections owned by this user .
get followers .
get followees .
get columns owned by this user and its contributions .
get columns that this user followed .
get topics that this user followed and its controbutions .
get questions that this user followed .
get collections that this user followed .
用于获取聊天对象的 puid ( 持续有效，并且稳定唯一的用户id)，和保存映射关系
通过 value 查找 key
删除 value 及对应的 key
解码从 web 微信获得到的中文乱码
检查 response body : err_code 不为 0 时抛出 : class:`responseerror ` 异常
装饰器：检查从 itchat 返回的字典对象，并将其转化为指定类的实例 若返回值不为0，会抛出 responseerror 异常
判断文本内容中是否包含了所有的关键词 ( 不区分大小写 )
判断一个 chat 对象的名称是否包含了所有的关键词 ( 不区分大小写 )
将单个对象或列表中的每个项传入给定的函数，并返回单个结果或列表结果，类似于 map 函数
确保将用户转化为带有 username 键的用户字典
确保将用户转化为 user_name 字串
增强 requests . session 对象的网络连接性能
针对 web 微信增强机器人的网络请求
用于 message 和 sentmessage 对象的 _ _ repr _ _ 和 _ _ unicode _ _
获得 message 对象中的消息内容，并清理 @ 机器人的部分
消息的延迟秒数 ( 发送时间和响应时间的差值 )
消息所在的聊天会话 ( 始终为消息的接受者 )
撤回本条消息 ( 应为 2 分钟内发出的消息 )
| 需要通过注册获得 key 和 secret | 免费申请 : http://cloud.xiaoi.com/
choses the right impedance of subsystem_from . applies boundary conditions correction as well .
choses the right impedance of subsystem_from . applies boundary conditions correction as well .
shape of the junction .
components that are part of this junction .
subsystems that are used in this junction .
all available subsystems in this junction . : returns : generator
add component to junction .
remove component from junction .
disable this junction . optionally disable junctions ' couplings .
enable this junction . optionally enable junctions ' couplings .
"add a coupling to the junction , specifying manually which ` model ` to use for the coupling ."
add coupling to junction .
remove coupling from junction .
remove all couplings from junction .
add all possible couplings to the junction .
update couplings .
total impedance at the coupling .
calculate product of items in iterable .
"s - > ( s0,s1 ) , ( s1,s2 ) , ( s2 , s3 ) , ..."
plot ` y ` as function of ` x ` where ` y ` has quantity ` quantity ` and ` x ` is frequency : math:`f ` .
graph with subsystems as nodes and couplings as edges .
subsystems in path .
couplings in path .
energy ratio : math:`\frac{e_n}{_{1 } } ` .
attenuation along path .
energy in subsystem due to excitation .
draw a graph of types specified in ` objects ` .
determine all paths between specified subsystems .
determine whether there is a connection between two subsystems .
choses the right impedance of subsystem_from . applies boundary conditions correction as well .
choses the right impedance of subsystem_from . applies boundary conditions correction as well .
transmission coefficient .
coupling loss factor for transmission from a 2d cavity to a cavity .
test the methods of windows
test module - level functions
"binhex(infilename , outfilename ): create binhex - encoded copy of a file"
"hexbin(infilename , outfilename ) - decode binhexed file"
read at least wtd bytes ( or until eof )
os - specific conversion from a relative url of the ' file ' scheme to a file system path ; not recommended for general use .
os - specific conversion from a file system path to a relative url of the ' file ' scheme ; not recommended for general use .
write a shebang line .
"copy an application archive , modifying the shebang line ."
create an application archive from source .
run the zipapp command line interface .
test the normal data case on both master_fd and stdin .
test the empty read eof case on both master_fd and stdin .
set the input delimiter .
predicate for inclusion in the readable for select ( )
predicate for inclusion in the writable for select ( )
automatically close this channel once the outgoing queue is empty
return the total time spent on the process .
returns the infile = ... line of code for the reader process .
a common way to cleanup and fail with useful debug output .
generic buffered read method test harness to validate eintr behavior .
readline ( ) must handle signals and not lose data .
readlines ( ) must handle signals and not lose data .
readall ( ) must handle signals and not lose data .
returns the infile = ... line of code to make a bufferedreader .
bufferedreader.read ( ) must handle signals and not lose data .
returns the infile = ... line of code to make a textiowrapper .
readline ( ) must handle signals and not lose data .
readlines ( ) must handle signals and not lose data .
read ( ) must handle signals and not lose data .
create and fix makefile for 64bit
fix some stuff in all makefiles
import a module from importlib both w/ and w/o _ frozen_importlib .
class decorator that nullifies tests requiring a case - insensitive file system .
uncache a module from sys.modules .
context manager to manage the various importers and stored state in the sys module .
decorator to protect sys.dont_write_bytecode from mutation and to skip tests that require it to be set to false .
ensure that the _ _ pycache _ _ directory for pep 3147 pyc file exists .
temporarily create each named module with an attribute ( named ' attr ' ) that contains the name passed into the context manager that caused the creation of the module .
a mock sys.path_hooks entry .
return the name ( id ) of the current chunk .
return the size of the current chunk .
"seek to specified position into the chunk . default position is 0 ( start of chunk ) . if the file is not seekable , this will result in an error ."
"read at most size bytes from the chunk . if size is omitted or negative , read until the end of the chunk ."
"skip the rest of the chunk . if you are not interested in the contents of the chunk , this method should be called so that the file points to the start of the next chunk ."
indicate that a formerly enqueued task is complete .
blocks until all items in the queue have been gotten and processed .
return the approximate size of the queue ( not reliable ! ) .
"return true if the queue is empty , false otherwise ( not reliable ! ) ."
"return true if the queue is full , false otherwise ( not reliable ! ) ."
put an item into the queue .
remove and return an item from the queue .
put an item into the queue without blocking .
remove and return an item from the queue without blocking .
@contextmanager decorator .
return a recreated instance of self .
preserve the context stack by transferring it to a new instance
helper to correctly register callbacks to _ _ exit _ _ methods
registers a callback with the standard _ _ exit _ _ method signature
registers an arbitrary callback and arguments .
enters the supplied context manager
immediately unwind the context stack
"given a web browser instance method name along with arguments and keywords for same ( which defaults to the single argument url ) , creates a browser instance from the class pointed to by self.browser , calls the indicated instance method with the indicated arguments , and compares the resulting options and arguments passed to popen by the browser instance against the ' options ' and ' args ' lists . options are compared in a position independent fashion , and the arguments are compared in sequence order to whatever is left over after removing the options ."
decorator to make a repr function return fillvalue for a recursive call
perform testcase - specific configuration on a function before testing .
initializes a new threadpoolexecutor instance .
open or create database at path given by * file * .
guess which db package to use to open a db file .
construct a texttestrunner .
run the given test case or test suite .
"select a template from a string , which can include multiple template paths separated by commas ."
make a request to the gdc api .
convert decimal notation to quaternary notation we will use division and modulus recursively
generate quaternary hamming codes data = quaternary number list parity = number of parity bits to implement
calculate the percent gc content of a nucleotide string return result rounded to two decimal places
smash a base4 number to base2
decode nucleotide hamming barcode sequence and perform error correction
reverse the order of self
take the compliment of read.seq
take the reverse compliment of read.seq
trim all read class elements from the 3 ' end to the start of the adapter sequence alignment
trim all read class elements from the 5 ' start to the end of the adapter sequence alignment
trim all read class elements to the 1 - based ' trim ' values
"return read class : ( name , sequence , strand , qualities ) ."
generate a salted password
prompt user for a password twice for safety
wraps input for tests
prompt user for input
prompt the user to choose one of a list of options
display a blocking prompt until the user confirms
check for valid bucket name
create a server config file
migrate packages from one storage backend to another
dump the access control data to a universal format
load the access control data from a dump file or stdin
create the database schema if needed
drop the database schema
convert plain dictionaries to mutabledict .
perform a search .
parses the pipe content
an aggregator that asynchronously returns a specified number of items from a stream .
an operator that returns a specified number of items from a stream .
asynchronously parses the pipe content
parses the pipe content
a source that asynchronously fetches the content of a given web site as a string .
a source that fetches the content of a given web site as a string .
"напишете функция , която приема като аргумент дума ` word ` и списък от забранени символи . функцията трябва да връща като резултат ` true ` , ако думата не съдържа нито един от забранените символи ."
"напишете функция , която приема като аргумент дума ` word ` и списък от символи . функцията трябва да връща като резултат ` true ` , ако думата съдържа само символи от списъка ."
"напишете функция , която приема като аргумент дума ` word ` и списък от символи . функцията трябва да връща като резултат ` true ` , ако думата съдържа всеки от символите от списъка поне веднъж ."
"books = [ "" learn you a haskell "" , "" the healthy programmer "" , "" code complete "" , "" the pragmatic programmer "" , "" pro git "" , "" introduction to algorithms "" , "" concrete mathematics "" ]"
"convert serialized string data to valid python data , depending on current handler protocol"
"convert python data to serialized form , according to current handler protocol ."
"parse self.request to extract payload . parse it to retrieve rpc call information , and execute the corresponding rpc method . at any time , raise an exception when detecting error . : return : the result of rpc method execution"
return a httpresponse instance containing the result payload for the given data
return a httpresponse instance containing the result payload for the given exception
call the concrete python function corresponding to given rpc method ` name ` and return the result .
"look into each module listed in settings . modernrpc_methods_modules , import each module and register functions annotated with @rpc_method decorator in the registry"
"hook for specifying fieldsets for the add form , modified to only display fields inside fieldsets that the user has permission to view or change ."
returns a form class ( used by add_view and change_view ) modified to only include fields and inlines that the user has permissions to view .
returns boolean indicating whether the user has necessary permissions to view the passed inline .
returns boolean indicating whether the user has necessary permissions to view the passed field .
extract the i d key and validate the request structure .
deserialize ` ` value ` ` .
get config value from the given section and option .
parse the given config file and return configuration settings as a dictionary for further use .
create a parser for the command - line options . @return : an argparse . argumentparser instance
configure the logging framework .
sets _ webclient if it is defined in the given config .
submits a single run using the web interface of the verifiercloud . @return : the run 's result
executes a single cpachecker run in the verifiercloud via the web front end . all informations are given by the command line arguments . @return : the return value of cpachecker
a docstring .
process spawn docstring is preserved .
process spawn typeerror is raised if timeout is not number .
process spawn decorated classmethods .
process spawn decorated instance methods .
process spawn results are produced .
process spawn results are forwarded to the callback .
process spawn errors are raised by future.result .
process spawn errors are forwarded to callback .
process spawn pickling errors are raised by future.result .
process spawn raises timeouterror if so .
process spawn timeouterror is forwarded to callback .
process spawn processexpired is raised if process dies .
process spawn processexpired is forwarded to callback .
process spawn raises cancellederror if future was cancelled .
process spawn concurrent ignored sigterm signal are handled on unix .
"runs the decorated function within a concurrent thread , taking care of the result and error management ."
runs the actual function in separate thread and returns its result .
"view containers with a specific , exact key / pair"
"view containers with a specific , exact key / pair"
view all labels with a shared key
obtain the collection from a request
determine if a default opengl context has been set yet .
store information for the currently active context .
determine if an opengl extension is available .
get a list of available opengl extensions .
get the current opengl version .
determine if a version of opengl is supported .
determine the renderer string of the opengl context .
determine the vendor string of the opengl context .
move the marker a particular distance
check if the snake overlaps itself
draw a line for the given path
"begin processing events , scheduled functions and window updates ."
exit the application event loop .
move to the indicated cell .
initialize the sprite
get a cocos.rect . rect for this sprite .
returns a local - coordinates axis aligned bounding box
test whether this ( untransformed ) sprite contains the pixel coordinates given .
"when the sprite is not into a batch it will be draw with this method . if in a batch , this method is not called , and the draw is done by the batch ."
updates vertex list
store information for the currently active context .
determine if a version of glu is supported .
get the current glu version .
determine if a glu extension is available .
get a list of available glu extensions .
process tablet event and return true if some event was processed . return true if no tablet event found .
create a rich text label .
"pass in a filename as "" file "" or a pyglet source as "" source "" ."
get matching configs using standard pixelformatdescriptor technique .
get configs using the wgl_arb_pixel_format extension . this method assumes a ( dummy ) gl context is already created .
"the ' outpen ' argument is another pen object . it will receive the transformed coordinates . the ' transformation ' argument can either be a six - tuple , or a fonttools.misc.transform . transform object ."
"update the sprite with simple kinematics for the passage of "" dt "" seconds ."
see whether there 's a sprite at the pixel location
"see if the press occurs over a sprite and if it does , invoke the on_mouse_press handler on the sprite ."
a sprite is an image at some position with some rotation .
"return boolean whether the point defined by x , y is inside the rect area ."
"return boolean whether the "" other "" rect ( an object with .x , .y , .width and .height attributes ) overlaps this rect in any way ."
merge the given config into self.config .
"return the most - specific value for key along path , or default ."
create and return a request and response object .
release the current serving ( request and response ) .
"mount a new app from a root object , script_name , and config ."
mount a wsgi callable at the given script_name .
"the script_name of the app at the given path , or none ."
package installation entry point .
return an ss:`assessment ` of the linear regression * beta_hat * for the model specified by * y * and * x * ( see : func:`linregress ` ) composed of several metrics .
compute the linear regression given the model
"compute the exhaustive multiple linear regression for the combination of all parameters of the model * df * with respect to * y_column * ( see : func:`linregress ` ) . return the tuple of lists with 1 ) the best parameter first , 2 ) the : class:`assessment ` for each regression , and 3 ) the * df * columns for the best fit ."
? ? ?
update the emtf index file at * repository_path * named * pkl_fname * based on the .xml files found at * repository_path * . return name of the pickle file storing the index .
initialize the emtf index file at * repository_path * named * pkl_fname * if it does not exist .
return the index information for the emtf repository located at * repository_path * .
initialize the emtf repository index based on the .xml files found at * repository_path * .
return the : class:`emtfindex ` corresponding to those emtfs with a quality index of at least * min_quality * .
return the : class:`emtfindex ` corresponding to those emtfs within * d_km * ( in km ) of geodetic * lat * and * lon * .
"generate two figures , each a 2x2 grid plot ( zxx , zxy , zyx , and zyy ) showing the magnitude ( figure 1 ) and phase ( figure 2 ) for the 3 - d emtf given in * xml_fname * . plot the frequency response for $ n$ uniformly spaced frequencies over the interval from * fmin * to * fmax * ( in hz ) . use * figsize * sized plots and pass * kwds * as keyword arguments to all calls to : func:`pl.plot ` and : func:`pl.scatter ` . return a tuple with the handles to the two generated figures ."
? ? ?
update the glonass status table stored at * glo_status_fname * . the remote file is accessed via ftp at * glo_status_server_fname * .
parse * glo_status_fname * and store glonass status information .
return the : class:`statusinfo ` associated with glonass satellite with id * slot * at : class:`datetime ` * dt * .
"given a boteler resitivity specification * model * ( list of depth [ m ] / resistivity [ ohm / m ] tuples ) , return a conductivity map suitable for func:`conductivity.surface_impedance_1d ` ."
return linear phase impulse response for a length * n * filter that approximates the differential operator . the sampling frequency is * hz * .
construct gradient operator for signal of dimension * n * for dimension * axis * . use a filter kernel of length * order * ( must be even ) . use convolution type * mode * .
construct a second - order gradient operator for signal of dimension * n * for dimension * axis * . use a filter kernel of length * order * ( must be odd ) . use convolution type * mode * .
"convert fortran format string , e.g. , ` 2i4,4i3,3i4,2i7,f6.2,i7 , 8f8.2,4f8.1,f7.2,f9.0,f6.2,2f7.2,f6.1,6f8.2,7i6,f7.2,f5.1 ` , to the list of fixed columns tuples expected by : func:`pandas.read_fwf ` ."
set up the whatlastgenre object .
since _ _ del__s do n't get called we need to do some stuff manually .
wlg as command
wlg during import
return the current genres of an album if they exist and the force option is not set or get genres from whatlastgenre .
"write content to filepath+pack+filename , create filepath if it does not allready exists ."
return compiled template from given path with given context
"return compiled template with given context where only ' form ' is required . if crispy helper is given , it must be given as ' helper ' named argument ."
"compute the sum of a blcoked rdd , either the sum of all values , or the sum along the specified dimension ( must be 0 )"
done this way to avoid overflow from summing everything before dividing . though not sure if that 's an issue ?
"calculated the covariance matrix for the given blocked rdd . unlike numpy.cov , expects each row to represent an observation ."
"calculate the svd of a blocked rdd directly , returning only the leading k singular vectors . assumes n rows and d columns , efficient when n > > d must be able to fit d^2 within the memory of a single machine ."
"calculate the svd of a blocked rdd using an expectation maximization algorithm ( from roweis , nips , 1997 ) that avoids explicitly computing the covariance matrix , returning only the leading k singular vectors . assumes n rows and d columns , does not require d^2 to fit into memory on a single machine ."
super complicated will figure out
overrideable method in this function . returns whether or not the item should be considered fully mounted
overrideable method in this function . returns whether or not the item should be considered fully unmounted
returns a list of objects that have been unmounted that are no longer being updated by the episode . call to this function empties the list keeping track of removed items .
"takes a surface , x and y. the surface is used for rendering . x and y are used to define the position where the surface will be drawn . all anime surfaces will be drawn anchored to center to allow smooth rotation ."
sets a renderer to the given attribute name .
returns the renderer of the attribute name .
given a surface . anime will draw its wrapped surface onto the given surface at its current x and y coordinates . all renderers will be called to generate the proper image .
returns a pygame rect describing the bounding rectangle where surface is drawn . if this object has not yet been drawn than none is returned .
check to see if given point x and y is inside bounding rectangle of the drawn object
check to see if given point x and y is inside bounding rectangle of the drawn object as well as the given point 's alpha is above the given threshold .
returns the current width of the object .
sets the current width of the object
returns the current height of the object .
sets the current height of the object
returns the current position of the object .
sets the current position of the object
takes the exact same arguments as animebase
"given the operators s^z and s^+ on two sites in different hilbert spaces ( e.g. two blocks ) , returns a kronecker product representing the corresponding two - site term in the hamiltonian that joins the two sites ."
"this function enlarges the provided block by a single site , returning an enlargedblock ."
transforms the operator to the new ( possibly truncated ) basis given by ` transformation_matrix ` .
"performs a single dmrg step using ` sys ` as the system and ` env ` as the environment , keeping a maximum of ` m ` states in the new basis ."
build a file path from * paths * and return the contents .
project audios to the joint space using model .
pass audios through the model and for each audio return the state of each timestep and each layer .
project imgs to the joint space using model .
"test < , > , ="
"test = = , ! = against other types"
"if hideattributes parametr is set to true in constructor of serverproxy all serverproxy attrs should be taken as frpc call attempt ( proxy.url ( ) , proxy.path ( ) ... )"
"setup the example publisher object , passing in the url we will use to connect to rabbitmq ."
"this method connects to rabbitmq , returning the connection handle . when the connection is established , the on_connection_open method will be invoked by pika . if you want the reconnection to work , make sure you set stop_ioloop_on_close to false , which is not the default behavior of this adapter ."
"this method is called by pika once the connection to rabbitmq has been established . it passes the handle to the connection object in case we need it , but in this case , we 'll just mark it unused ."
this method adds an on close callback that will be invoked by pika when rabbitmq closes the connection to the publisher unexpectedly .
"this method is invoked by pika when the connection to rabbitmq is closed unexpectedly . since it is unexpected , we will reconnect to rabbitmq if it disconnects ."
will be invoked by the ioloop timer if the connection is closed . see the on_connection_closed method .
"this method will open a new channel with rabbitmq by issuing the channel . open rpc command . when rabbitmq confirms the channel is open by sending the channel . openok rpc reply , the on_channel_open method will be invoked ."
this method is invoked by pika when the channel has been opened . the channel object is passed in so we can make use of it .
this method tells pika to call the on_channel_closed method if rabbitmq unexpectedly closes the channel .
"invoked by pika when rabbitmq unexpectedly closes the channel . channels are usually closed if you attempt to do something that violates the protocol , such as re - declare an exchange or queue with different parameters . in this case , we 'll close the connection to shutdown the object ."
"setup the exchange on rabbitmq by invoking the exchange . declare rpc command . when it is complete , the on_exchange_declareok method will be invoked by pika ."
invoked by pika when rabbitmq has finished the exchange . declare rpc command .
"setup the queue on rabbitmq by invoking the queue . declare rpc command . when it is complete , the on_queue_declareok method will be invoked by pika ."
"method invoked by pika when the queue . declare rpc call made in setup_queue has completed . in this method we will bind the queue and exchange together with the routing key by issuing the queue . bind rpc command . when this command is complete , the on_bindok method will be invoked by pika ."
"this method is invoked by pika when it receives the queue . bindok response from rabbitmq . since we know we 're now setup and bound , it 's time to start publishing ."
this method will enable delivery confirmations and schedule the first message to be sent to rabbitmq
send the confirm . select rpc method to rabbitmq to enable delivery confirmations on the channel . the only way to turn this off is to close the channel and create a new one .
"invoked by pika when rabbitmq responds to a basic . publish rpc command , passing in either a basic . ack or basic . nack frame with the delivery tag of the message that was published . the delivery tag is an integer counter indicating the message number that was sent on the channel via basic . publish . here we 're just doing house keeping to keep track of stats and remove message numbers that we expect a delivery confirmation of from the list used to keep track of messages that are pending confirmation ."
"if the class is not stopping , publish a message to rabbitmq , appending a list of deliveries with the message number that was sent . this list will be used to check for delivery confirmations in the on_delivery_confirmations method ."
invoke this command to close the channel with rabbitmq by sending the channel . close rpc command .
run the example code by connecting and then starting the ioloop .
stop the example by closing the channel and connection . we set a flag here so that we stop scheduling new messages to be published . the ioloop is started because this method is invoked by the try / catch below when keyboardinterrupt is caught . starting the ioloop again will allow the publisher to cleanly disconnect from rabbitmq .
this method closes the connection to rabbitmq .
import a module .
sessions based login works
/ is avaliable to unauthenticated users and resturns a meaningful response
/users/ route is not avaliable to unauthenticated users
/link/ route should not be available to unauthenticated users
"/users/ should not be accessable to normal , authenticated users"
/links/ should be accesable to authenticated users
/users / me should return relevent data about the currently authenticated user and also check that unauthenticated users can not access the endpoint
/users/ should return all of the users if a user is a superuser
"/users/1/ if authed , should return a 404 if it is n't the current user 's link if the user is unauthenticated it should give a auth error"
updates status of the pet from ' for adoption ' to ' adopted '
only the ownser should be able to change the pet 's status
view should only accept http post method
slug should contains both the pet name and city
should auto append a number if the slug is not unique
should return only pets that are staled and are still lost or for adoption
should return active pets with request_sent date older than expected
should call send_request_action_email method from request_action
deactivate should call the send_deactivate_email method
should set the request_sent date in the pet and keep modified date
should set the request_key if the send_request_action_email succeed
should n't set the request_key if the send_request_action_email fail
should set the registration as inactive and keep modified date
should set the registration to active and clear fields
should return only active pets
"returns initial rnn context rnn_1 ( lower , actor ) context is reset at every call . rnn_2 ( upper , critic ) context is reset if : - episode initial ` state ` ` trial_num ` metadata has been changed form last call ( new trial started ) ; - no context arg is provided ( initial episode of training ) ; ... else carries critic context on to new episode ;"
"norm . v - shaped realtive position of x in [ a , b ] , a<=x<=b ."
"current value log - normalized in [ -1,1 ] wrt p / l limits ."
"current value normalized in [ -1,1 ] wrt upper and lower bounds ."
"current value , piece - wise linear normalized in [ -1,1 ] and zero - centered at ` start_value `"
"normalized in [ -1,1 ] trade result , lineary decayed wrt current_value ."
"returns exp . scaled value in [ epsilon , 1 ] for x in [ 0 , 1 ] ; gamma controls steepness ."
returns gamma_power weighted average of 2d input array along 0 - axis .
meta - learning loop runtime logic of the thread runner .
create hdl integer value ( for example integer value in vhdl )
create hdl bool value ( for example bool value in vhdl )
create hdl string value ( for example string value in vhdl )
create hdl bit value ( for example std_logic value in vhdl )
create hdl vector value
find files by pattern in directory
check if is register or wire
reverse byteorder ( littleendian / bigendian ) of signal or value
process for injecting of this callback loop into simulator
"get "" ready "" signal"
"get value of "" ready "" signal"
"get "" valid "" signal"
"get value of "" valid "" signal , override f.e . when you need to use signal with reversed polarity"
collect data from interface
extract data from interface
write data to interface
push data to interface
called beforee preparing of simulation
log change of value for signal
log value propagation over netlist
log simulator value quantum applied
gets value of bits between selected range from memory
cast harray signal or value to signal or value of type bits
": param template : list of tuples ( type , name ) or hstructfield objects name can be none (= padding ) : param name : optional name used for debugging purposes"
"override of addition , merge struct into one"
: param indent : number of indentation : param withaddr : if is not none is used as a additional information about on which address this type is stored ( used only by hstruct ) : param expandstructs : expand hstructtypes ( used by hstruct and harray )
: return : list of extra discovered processes
: param filename : relative filename with .vhdl or .v
set hwt unit as template for component
"an equality assertion for ordered sequences ( like lists and tuples ) . for the purposes of this function , a valid ordered sequence type is one which can be indexed , has a length , and has an equality operator ."
randomly disable and enable interface for testing purposes
create simulation model and connect it with interfaces of original unit and decorate it with agents and collect all simulation processes
": param val : value of python type int or none : param typeobj : instance of integer : param vldmask : none vldmask is resolved from val , if is 0 value is invalidated if is 1 value has to be valid"
create simulation model and connect it with interfaces of original unit and decorate it with agents
create a simulation model for unit
reconnect model signals to unit to run simulation with simulation model but use original unit interfaces for communication
syntax sugar if outputfile is string try to open it as file
": param unit : interface level unit to simulate : param stimulfunctions : iterable of function(env ) ( simpy environment ) which are driving the simulation : param outputfile : file where vcd will be dumped : param time : endtime of simulation , time units are defined in hdlsimulator : return : hdl simulator object"
oscillative simulation driver for your signal ( usually used as clk generator )
: param sig : signal on which write callback should be used : attention : if condfn is none callback function is always executed
process for injecting of this callback loop into simulator
: param lowerindex : if this is none only upper index will be used like sig[upperindex ] else range select like sig[upperindex : lowerindex ]
method called by simulator to update new value for this object we are only delegating update on parent signal
": param ctx : context - rtlnetlist which is this signal part of : param name : name hint for this signal , if is none name is chosen automatically : param defval : value which is used for reset and as default value in hdl : param usenopval : use nopval or ignore it : param nopval : value which is used to fill up statements when no other value is assigned"
get next instance i d
returns a first driver if signal has only one driver .
place any commands to setup nipapwww here
"> > > client = client(['http://host-1:4001 ' , ' http://host-2:4001 ' ] ) : param urls : list of addresses of ida containers including the published port"
"send a command to an ida container via http : param command : the command to send , should start with idal or idal64 : param timeout : a timeout given for the command ( optional ) : returns true if the command ran successfully , else false"
"send a batch of commands asynchronously to an ida container via http : param commands : an iterable of commands to send to the container : param timeout : a timeout given for the command ( optional ) : returns a dictionary where the key is the command and the value is true if succeeded , else false"
load reduced dimensionality map points from hdf5 into numpy array .
return a sqlalchemy database connection .
masked colormap for quantitative metadata .
masked markersize for quantitative metadata .
update plot data in response to bokeh widget form data .
update marker color metadata .
update marker size metadata .
: param state : { ' input_size ' : ' output_size ' : ' activation_func ' : ' layer_name ' : } : return :
"predict one batch data : param batch_samples : list of samples : return : loss , pred_vals , gth_vals"
"predict one sample data with loss : param sample : one data sample : return : loss , pred_val , gth_val"
get recall @ ks : param ranks : the ranks of correct index : param ks : values of k : return : print the result
": param state : = { ' selection_type ' : , ' activation_func ' : , ' input_size : ' , ' output_size ' , } : param rng : : return :"
return a tuple with the command line to execute .
get profile name from i d @param i d as str @return str
remove www from an urllib parse netloc @param netloc as str @return str
return window type based on current index
return true if desktop is gnome
resize surface to match favicon size @param favicon as cairo.surface @return cairo.surface
draw a char with a random color @param char as str @return cairo surface
set snapshot on main image @param webview as webkit2.webview @param result as gio . asyncresult @return cairo . surface
get a rand string at size @param size as int return str
return monitor model as string @param window as gtk . window @return str
return string without accents @param string as str @return str
try to guess best ftp app @return app cmd as str
print debug @param debug as str
init row @param uri as str @param domain as str
toggle check box @param row as scriptrow @param event as gdk . buttonevent @param check as gtk . checkbutton
save state @param check as gtk . checkbutton
init widget @param netloc as str
populate scripts @param listbox as gtk . listbox
save js blocker state @param listbox as gtk . listbox @param state as bool
populate listbox with scripts @param source as gobject . object @param result as gio . asyncresult @param listbox as gtk . listbox
call function @param call as str @param page_id as int @param dbus_args as glib . variant()/none @param callback as function
connect callback to object signals @param signal as str @param callback as function @param page_id as int
disconnect signal @param page_id as int
launch call and connect it to callback @param source as gobject . object @param result as gio . asyncresult @param call as str @param dbus_args as glib . variant()/none @param callback as function
init widget @param uri as str @param window as gtk . window
update entry @param selection as gtk . treeselection
save user agent @param dialog as gtk . dialog @param response_id as int
select matching element @param user_agent as str
update matching @param entry as gtk . entry
init widget @param parent as gtk . window
check item and update parent / child @param renderer as gtk . cellrenderertoggle @param path as gtk . treepath
update model @param combobox as gtk . combobox
filter model @param entry as gtk . searchentry
clear data @param dialog as gtk . dialog @param response_id as int
remove data from data_manager @param data_manager as webkit2.websitedatamanager @param items as [ { } ]
get name for type @param data_type as int @return str
extract types from flags @param data_types as int @return [ int ]
add items to model @param items as [ str ]
check parent state @param iterator as gtk . treeiter
@param data_manager as webkit2.websitedatamanager @param result as gio . asyncresult @param items as [ { } ]
@param model as gtk . treemodel @param iterator as gtk . treeiter @param data as object
get fetch result @param data_manager as webkit2.websitedatamanager @param result as gio . asyncresult
add header @param name as str @param value as str
"run command with params and return to callback @param command as function @param * args as command arguments @param * * kwd as { "" callback "" : ( function , * args ) }"
"load uri with libsoup ( better performance than gio ) @param uri as str @param cancellable as gio . cancellable @param callback as a function @callback ( uri as str , status as bool , content as bytes , args )"
"load uri @param uri as str @param cancellable as gio . cancellable @return ( loaded as bool , content as bytes )"
"pass command result to callback @param command as function @param * args as command arguments @param kwd as { "" callback "" : ( function , * args ) }"
"read data from stream , when finished , pass to callback @param stream as gio . inputstream @param result as gio . asyncresult @param cancellable as gio . cancellable @param content as bytes @param callback as function @param uri as str"
get stream and start reading from it @param source as soup . session @param result as gio . asyncresult @param cancellable as gio . cancellable @param callback as a function @param uri as str
initialise the baseclass class
configure logging for the class that has inherited this method
get the conditional dependencies for source distributions .
get the conditional dependencies for wheel distributions .
get requirements from pip requirement files .
check whether setuptools has support for pep-426 environment markers .
create a new entity to be used for this merge
load a set of results to be used for this merge
set the goal for a given entity
build a span of source code from its bounds
x.__str _ _ ( ) < = = > str(x )
x.__str _ _ ( ) < = = > str(x )
called when a captcha must be solved writes the image to a temporary file and asks the user to enter the code .
called when steamguard requires authentication via e - mail . asks the user to enter the code .
called when steamguard requires two - factor authentication .. asks the user to enter the code .
stops idlechild does not emit any signals or trigger further action
called whenever new steam data arrives
"called when idle is forcefully stopped ( on stopaction , nextaction or app quit for example ) emits finish signal that should be connected to thread.quit"
called whenever new steam data arrives
init groups with base smartsheet object .
add one or more members to a group .
create a new group
delete the specified group .
get the specified group .
get all groups in an organization .
removes a member from the specified group .
updates the specified group .
initialize the result model .
simplify difference between result and indexresult
initialize the fontfamily model .
initialize the automationaction model .
initialize the error model .
initialize the discussion model .
initialize the booleanobjectvalue model .
initialize the searchresultitem model .
init images with base smartsheet object .
get urls that can be used to retrieve specified cell images .
initialize the cell model .
run migrations in ' offline ' mode .
run migrations in ' online ' mode .
return a field from within a json
finds concrete profile by the rule in profile generator .
test creation of flame graph format out of the profile of memory type
test creation of heap map out of the profile of memory type
test generation of the heat map information from the profile
test creation of allocations table
test creation of flow table
test correct conversion from models coefficients to points that can be used for plotting .
test conversion from models coefficients to points on a profile with invalid model .
tests malformed indexes
test correct working with index
summary plot for all reports
creates a series of images and stores them in the target directory
helping function that extracts the dates and data from the reports
routine that adds labels to the plot in order to add a legend
generic function for plotting stacks
removes all nones from a list and replaces them by zero
add zeros at the beginning and end to prevent interpolation in join_data from stacking to much up
creates a stacked plot with cumulated sums for a given semantic
creates a stacked plot with cumulated sums for a given semantic
creates a stacked plot with cumulated sums for a given semantic
this functions makes heterogenous time series data align with one time series axis dates : list of date - lists data : list of data - lists_lock
introduces calculation with months
calculates the differences in months between two dates
"returns true , if the current day is the end of month"
introduces calculation with months
calculates the differences in months between two dates
edge case : unknown formats should be ignored
setup method .
teardown method .
invoke list_pop ( ) pop string with correct parameters
invoke list_append ( ) append list with correct policy
invoke list_pop ( ) without any mandatory parameters .
invoke list_pop ( ) with incorrect policy
invoke list_pop ( ) with non - existent key
invoke list_pop ( ) with non - existent bin
invoke list_pop ( ) with extra parameter .
invoke list_pop ( ) with policy is string
invoke list_pop ( ) with key is none
invoke list_pop ( ) with bin is none
invoke list_pop ( ) with negative index
invoke list_pop ( ) with metadata input is of type integer
invoke list_pop ( ) with index is of type string
setup method .
teardoen method .
invoke self ( ) without any mandatory parameters .
invoke exists ( ) with a key and not policy 's dict .
invoke exists ( ) with a key and policy .
invoke exists ( ) with a key and policy as string .
invoke exists ( ) with a key and timeout as string .
invoke exists ( ) for list typed record .
invoke exists ( ) for map type record .
invoke exists ( ) for list and map combined record .
invoke exists ( ) for list of objects .
invoke exists ( ) for bytarray record .
invoke exists ( ) with a string key and not policy 's dict .
invoke exists ( ) with none set in key tuple .
invoke exists ( ) with none namespace in key tuple .
invoke exists ( ) with none as primary_key part of key tuple .
invoke exists ( ) with none as a key .
"invoke exists ( ) with key specified as a list of ns , set and key / digest ."
invoke exists ( ) for non - existent namespace .
invoke exists ( ) for non - existent set .
invoke exists ( ) for non - existent key .
invoke exists ( ) with a key and not policy 's dict and no connection
"test to see whether a namespace , set , and bin exist after a key is added"
test that sending none as the request raises an error
test info positive for sets without connection
test that sending a non dict / none as policy raises an error
invoke remove ( ) when records are present
invoke remove ( ) with policy
invoke remove ( ) with policy
invoke remove ( ) with policy_key_digest
invoke remove ( ) with policy gen ignore
invoke remove ( ) with policy gen positive
invoke remove ( ) with policy gen gt positive
invoke remove ( ) with policy gen not equal
invoke remove ( ) with policy gen gt lesser
invoke remove ( ) with policy as string
invoke remove ( ) with extra parameter
invoke remove ( ) with namespace as none
invoke remove ( ) with set as none
invoke remove ( ) with correct arguments without connection
invoke remove ( ) without any mandatory parameters .
setup method .
teardown method .
invoke list_remove ( ) pop string with correct parameters
invoke list_remove ( ) remove list with correct policy
invoke list_remove ( ) without any mandatory parameters .
invoke list_remove ( ) with incorrect policy
invoke list_remove ( ) with non - existent key
invoke list_remove ( ) with non - existent bin
invoke list_remove ( ) with extra parameter .
invoke list_remove ( ) with policy is string
invoke list_remove ( ) with key is none
invoke list_remove ( ) with bin is none
invoke list_remove ( ) with negative index
invoke list_remove ( ) with metadata input is of type integer
invoke list_remove ( ) with index is of type string
invoke list_clear ( ) with correct parameters
invoke list_clear ( ) removes all list elements with correct policy
invoke list_clear ( ) with incorrect policy
invoke list_clear ( ) with non - existent key
invoke list_clear ( ) with non - existent bin
invoke list_clear ( ) with extra parameter .
invoke list_clear ( ) with policy is string
invoke list_clear ( ) with key is none
invoke list_clear ( ) with bin is none
invoke list_clear ( ) with metadata input is of type integer
invoke list_clear ( ) without any mandatory parameters .
setup method .
invoke job_info ( ) without any mandatory parameters .
invoke job_info ( ) with correct parameters
invoke job_info ( ) with correct policy
invoke job_info ( ) with incorrect policy
"invoke job_info ( ) with scan i d incorrect , this should not raise an error"
invoke job_info ( ) with scan i d incorrect
invoke job_info ( ) with correct parameters without connection
invoke job_info ( ) with the scan module out of the expected range
invoke job_info ( ) with the scan module argument of the wrong type
"simple tests demonstrating the functionality . if the database is set up with a small enough write block - size , several subrecords will be created ."
"args : client ( aerospike.client ): a connected client to be used to talk with the database base_key ( string ): the base key around which all record keys will be constructed if base_key is ' person1 ' , the top record will have the key ( ns , set , ' person1 ' ) and subrecords will be of the form ( ns , set , ' person1 - 1 ' ) , ( ns , set , ' person1 - 2 ' ) ... ns ( string ): the namespace into which the records will be stored . setname ( string ): the set into which the records will be stored . subrecord_count_name ( string ): the name of the bin in the metadata record which will store the count of subrecords . subrecord_list_bin ( string ): the name of the list bin in each of the subrecords ."
fetches the top level record containing metadata about this list . returns none if the record does not exist
"add a given item to this conceptual group of lists . if a top level record has not yet been created , this operation will create it ."
get all of the entries from all subrecords flattened and buffered into a list
returns a formatted string to be used as the userkey portion of a key .
create the top level information about the key .
create a new subrecord for the item . 1 . create or append an item to the given specified subrecord 2 . update the top level metadata record to mark this subrecord 's existence
increment the metadata record 's count of subrecords . this is only safe to do if the generation of the metadata matches the expected value . ignore if this fails .
"extract only the items from a list of subrecord tuples given records = [ ( key , meta , { ' items ' : [ 1 , 2 , , 3 ] } ) , ( key , meta , { ' items ' : [ 4 , 5 , 6 ] } ) , ( key , meta , { ' items ' : 7 , 8 , 9 } ) ) ] returns [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ]"
setup method .
teardoen method .
invoke touch ( ) without any mandatory parameters .
invoke touch ( ) with correct parameters
invoke touch ( ) with correct policy
invoke touch ( ) with policy key send
invoke touch ( ) with policy key digest
invoke touch ( ) with gen eq positive ignore
invoke touch ( ) with gen eq positive
invoke touch ( ) with policy key eq not equal
invoke touch ( ) with gen gt lesser
invoke touch ( ) with gen gt positive
invoke touch ( ) with incorrect policy
invoke touch ( ) with non - existent key
invoke touch ( ) not a string
invoke touch ( ) with extra parameter .
invoke touch ( ) with policy is string
invoke touch ( ) with correct parameters without connection
invoke touch ( ) with ttl value greater than ( 2 ^ 63 - 1 )
returns a string representing the full type of the component .
key generator .
key generator .
test case with lag within the length of the input array
test case with lag is higher than the trial length
create the toolbar handler .
"provides a way to get repeatable random numbers from the given seed . unlike random.seed ( ) , this approach provides consistent results across platforms . see also http://stackoverflow.com/a/18992474"
provided as a helper to generate new keys from ` bw debug ` .
decrypts a given encrypted password .
decrypts the file at source_path ( relative to data/ ) and returns the plaintext as unicode .
decrypts the file at source_path ( relative to data/ ) and returns the plaintext as base64 .
"like _ generate_password ( ) , but creates a password which can be typed more easily by human beings ."
derives a password from the given identifier and the shared key in the repository .
encrypts a given plaintext password and returns a string that can be fed into decrypt ( ) to get the password back .
"encrypts the file at source_path and places the result at target_path . the source_path is relative to cwd or absolute , while target_path is relative to data/."
download a file .
runs a command on the local system .
runs a command on a remote system .
upload a file .
wraps func in lambda which prevents aggregate_numpy from recognising and optimising it . instead it groups and loops .
return the formatted tab menu .
install / upgrade the override menu .
uninstall the override menu .
install / upgrade the standard tab menu .
install menu if nothing can be found .
display upgrade message .
prep data for sort .
: param configuration_file_path : path to the config file : param run_mode : default is ' impact ' - this runs the full mc simulation if option is ' analysis ' then new output folders are not created
the main program function .
tests the _ debugprintmemberheader function .
tests the _ readmemberheader function .
tests the readfileobject .
the main program function .
the main program function .
initializes a timezone information file .
prints file header debug information .
prints transition time index debug information .
prints transition times debug information .
reads a file header .
reads the lead second records .
reads the local time types table .
reads the standard time indicators .
reads transition time index .
reads timezone abbreviation strings .
reads 32 - bit timezone information .
reads 64 - bit timezone information .
reads 32 - bit transition times .
reads 64 - bit transition times .
reads the utc time indicators .
reads a timezone information file - like object .
tests the _ debugprintfixedlengthdatasection function .
tests the _ debugprinttrigger function .
tests the _ readfixedlengthdatasection function .
tests the _ readvariablelengthdatasection function .
tests the readfileobject .
the main program function .
tests the _ debugprintfileheader function .
tests the readfileobject .
"instantiate the densenet architecture , # arguments nb_dense_block : number of dense blocks to add to end growth_rate : number of filters to add per dense block nb_filter : initial number of filters reduction : reduction factor of transition blocks . dropout_rate : dropout rate weight_decay : weight decay factor classes : optional number of classes to classify images weights_path : path to pre - trained weights # returns a keras model instance ."
"apply batchnorm , relu , bottleneck 1x1 conv2d , 3x3 conv2d , and option dropout # arguments x : input tensor stage : index for dense block branch : layer index within each dense block nb_filter : number of filters dropout_rate : dropout rate weight_decay : weight decay factor"
"apply batchnorm , 1x1 convolution , averagepooling , optional compression , dropout # arguments x : input tensor stage : index for dense block nb_filter : number of filters compression : calculated as 1 - reduction . reduces the number of feature maps in the transition block . dropout_rate : dropout rate weight_decay : weight decay factor"
build a dense_block where the output of each conv_block is fed to subsequent ones # arguments x : input tensor stage : index for dense block nb_layers : the number of layers of conv_block to append to the model . nb_filter : number of filters growth_rate : growth rate dropout_rate : dropout rate weight_decay : weight decay factor grow_nb_filters : flag to decide to allow number of filters to grow
"instantiate the densenet 161 architecture , # arguments nb_dense_block : number of dense blocks to add to end growth_rate : number of filters to add per dense block nb_filter : initial number of filters reduction : reduction factor of transition blocks . dropout_rate : dropout rate weight_decay : weight decay factor classes : optional number of classes to classify images weights_path : path to pre - trained weights # returns a keras model instance ."
sample initial states by taking random number of no - ops on reset . no - op is assumed to be action 0 .
"do no - op action for a number of steps in [ 1 , noop_max ] ."
take action on reset for environments that are fixed until firing .
"make end - of - life = = end - of - episode , but only reset on true game over . done by deepmind for the dqn and co. since it helps value estimation ."
"reset only when lives are exhausted . this way all states are still reachable even though lives are episodic , and the learner need not know about any of this behind - the - scenes ."
return only every ` skip`-th frame
clear past frame buffer and init . to first obs . from inner env .
從 self.responses 中挑選出可靠度前 k 高的回應回傳
"將 json 格式中目前用不上的 user , vote 去除，只留下 content"
對 self.responses 中所有的回應斷詞並去除中文停用詞，儲存於 self.segresponses
統計 self.segresponses 中每個詞出現的次數
為 self.segresponses 中的詞配置一個 i d
inizializza e avvia il server tcp .
this function generates sample data and populates the databases
tests that the whisper database get created if does not exist .
ads a new resource to the collection .
returns json representation of all resources in the collection .
returns json representation of a resource with a given uuid .
deletes a resource with a given uuid .
attributes representing a resource to which a request is related .
creates a resource that enables open access to a given location .
check if a resource that enables open access to a location exists .
deletes a resource .
creates a resource .
checks if a resource that grants access exists .
deletes a resource .
add data to the shared plugin results plist .
sanitize collection data into a string format for db storage .
decodes a string that is optionally bz2 compressed and always base64 encoded .
class decorator for view subclasses to restrict to logged in .
class decorator for view subclasses to restrict to ga .
class decorator for view subclasses to restrict to staff .
decorator for view subclasses to restrict by business unit .
decorator for view functions to restrict by business unit .
view decorator to redirect non ga users .
view decorator to redirect users without acceptable userprofile ..
view decorator to redirect non staff users .
"returns a cache key unique to the current table , and ( if available ) the request user ."
"returns the cached object list under the appropriate key , or none if not set ."
stores the object list in the cache under the appropriate key .
"given a filename , parse the flagstat values and return as a hash . relying on flagstat contents being in usual order ."
make a random data iteration plan
get the attribute dict given the attribute set by the symbol .
returns a cpu context .
returns a gpu context .
returns the current context .
returns the device type of current context .
compute hash value of context for dictionary lookup
compares two contexts . two contexts are equal if they have the same device type and device i d.
import names from module into the globs dict .
callback to show speed .
"greedily select boxes with high confidence and overlap with current maximum < = thresh rule out overlap > = thresh : param dets : [ [ x1 , y1 , x2 , y2 score ] ] : param thresh : retain overlap < thresh : return : indexes to keep"
lstm cell symbol
sample from independent categorical distributions
sample from independent normal distributions
sample from independent mixture of gaussian ( mog ) distributions
get a numpy - array list from a ndarray list parameters ---------- ndarray_list : list of ndarray
"return a dict of testbatch : param roidb : [ ' image ' , ' flipped ' ] + [ ' boxes ' ] : return : data , label , im_info"
"return a dict of multiple images : param roidb : a list of dict , whose length controls batch size [ ' images ' , ' flipped ' ] + [ ' gt_boxes ' , ' boxes ' , ' gt_overlap ' ] = > [ ' bbox_targets ' ] : return : data , label"
"generate random sample of rois comprising foreground and background examples : param rois : all_rois [ n , 4 ] ; e2e : [ n , 5 ] with batch_index : param fg_rois_per_image : foreground roi number : param rois_per_image : total roi number : param num_classes : number of classes : param labels : maybe precomputed : param overlaps : maybe precomputed ( max_overlaps ) : param bbox_targets : maybe precomputed : param gt_boxes : optional for e2e [ n , 5 ] ( x1 , y1 , x2 , y2 , cls ) : return : ( labels , rois , bbox_targets , bbox_weights )"
check function consistency with uniform random numbers
callback to log training speed and metrics in tensorboard .
"runs "" adb shell "" with the given arguments ."
uses adb to attempt to determine the sdk version of a running device .
get resource attribute dictionary for a model object .
selects the list of annotations to use
extract all lines with annotations
"finds all occurences of "" string "" in "" text "" and notes their positions as a sublime region"
modify is not supported for ifiles
update is not supported for config
normal save and load only need the command .
peer bigip fixture
poll with a given callable for a specified number of times .
test updating of the remote server list
modify is not supported for vulnerabilities resource
modify is not supported for vulnerabilities resource
delete is not supported for vulnerabilities resource
test that we remove the other exclusive args if we set one .
test that we remove the other exclusive args if we set one .
test that we get an exception because we have both exclusives set .
test that we get an exception because we have both exclusives set .
this tests for issue # 148 .
modify is not supported for sensitive parameters resource
create is not supported for signature system resource
modify is not supported for signature system resource
delete is not supported for signature system resource
an alternative to test above that works regardless of version .
test licensing a managed device
create the resource on the big - ip ® .
create is not supported for signature resources
delete is not supported for signature resources
fixture for session tracking status
performance collections are not proper big - ip ® collection objects .
update is not supported for statistics .
wraps the poll to get attempts and interval applicable for cluster .
get device information about a specific bigip device .
map a list of devices to their hostnames .
initialize the imgur export api .
attempt to log into the imgur api .
upload one or multiple images to imgur . can not support videos .
will delete an export if given the image deletehash
send an email notifying the recipient of l about their love .
get all love from a particular sender or to a particular recipient .
send love and do associated bookkeeping .
deletes love links that are more than a month ( 30 days ) old .
creates a markercluster plugin to append into a map with map.add_children .
process travis ci buildlog .
run flake8 with the given ` ` config ` ` against the passed file .
create a temporary environment within which to run flake8 .
helper function to that raises userwarning if user 's request defines an invalid combination of job states
determine whether a specific job is in one or more specific state(s )
"given a function definition , determine which of the args and kwargs are relevant and then execute the function"
"decorator to add setup and/or teardown methods to a test function works like nose.tools.with_setup , but adds ` params ` option ."
the less unexpected way for plugins to fail .
does check_state support multiple job_ids ?
logs - out the session .
check if the module is a vim object instance .
calls a method within the module specified with args provided .
gets the vim object reference .
return a l2 agent on the host .
get the differenc of chars in two strings .
check if decimal equal to its integer ( 8.0 = = 8)
check if string expression is a number .
find suggestions in safeeval_dict if function name is misstyped .
error handling and quickhelp decorator for functions .
"reformat input expression for better representation in history , i.e. ' 2*(2**8 - 186)/sin(32 ) ' -- > ' 2 * ( 2**8 - 186 ) / sin(32 ) . '"
"if there is a base2 incorrect transforms like 1.000000000000001 or trigonometry calculaion like 0.4999999999999994 , rounds eval ( ) 's result to 12th symbol after floating point . if result is decimal but equal to integer , turn to integer truncating [ .0 ] ."
add ' /1 ' to element in input expression if it has a ' power ' operator to add limitations to power operation and avoid overflows .
remove trailing ' .0 's and ' ( ... /1 ) 's added by turnfloat ( ) if exist to restore original indexing for error handling .
"check if there are bin - oct - hex elements or functions in expression . raise an exception if there is more than one type , otherwise remove existing function name from expression and enclose by function of he same name ."
@param database : source . database
"before_commit happens before before_flush , and we need to make sure the history gets built during the final one of these two events , so we need to use the gross is_committing_key flag to control this behavior"
setup the session to track changes via temporal
mock post request .
mock get request .
add metapreprocessor to markdown instance .
parse meta - data and store in markdown . meta .
this function returns normalized adjacency matrix .
"this function implements network propagation , as detailed in : vanunu , oron , et al . ' associating genes and protein complexes with disease via network propagation . ' inputs : - g : networkx graph on which to run simulation - wprime : normalized adjacency matrix ( from normalized_adj_matrix ) - seed_genes : genes on which to initialize the simulation . - alpha : heat dissipation coefficient . default = 0.5 - num_its : number of iterations ( default = 20 . convergence usually happens within 10 ) outputs : - fnew : heat vector after propagation"
"calculate the dot - product of heat propagated on n disease gene sets ( disease_seeds : dict with keys disease names and values lists of disease genes ) , on an edge - shuffled , degree - preserving random matrix , with number of repetitions = num_reps , alpha = alpha , num_its = num_its ."
"calculate co - localization between three gene sets , using network propagation"
helper function to return label positions offset by dx
boilerplate headers for http post .
enrolls the test 's user in the course under test .
this is a baseline for all settings - related tests . it clears any settings - related state that have been setup by prior tests .
normal successful circumstances : load a valid settings file with a mix of optional / required / public / secret settings .
missing required setting in main document should raise an exception
missing required setting in secrets document should raise an exception
"load a valid settings file without a "" secrets "" yaml document ."
"load a valid settings file with an empty "" secrets "" yaml document ."
settings class smoke tests .
"settings.update ( ) test to make sure overrides are working properly , keys do n't get dropped , etc ."
"return true if task_set is a root taskset instance , which means that it has been called directly from the locust class and so it has no parent ."
"decorator for a locust task which causes it to be the last task to be scheduled in the current taskset , unless the current taskset is the root taskset --- in the latter case this decorator is a no - op ."
return true if the logger should skip this entry .
"set 6s to use a predefined aerosol type , one of the constants defined in this class ."
set 6s to use a user - defined aerosol profile based on proportions of standard aerosol components .
set 6s to use a multimodal log - normal distribution .
set 6s to use a modified gamma distribution .
set 6s to use a junge power law distribution .
set 6s to use an aerosol parameterisation from sun photometer measurements .
parse * line * and insert into either * files * or * subdirs * depending on whether the line is for a directory or not .
initialize with a ftplib . ftp instance ( or an instance of a subclass ) . use the classmethod connect to create an actual ftplib connection and get an ftphost instance .
"connect to host , using port . if user is given , login with given user , password and account . the two latter can be none , in which case ftplib will set the password to ' anonymous@ ' . you can choose which class to instance by means of ftp_client ."
creates a file proxy object for filename . see ftpfileproxy .
make directory .
remove directory .
"emulates os.walk very well , even the caveats ."
"returns a list of files and directories at ` directory ` , relative to the current working directory . the return value is a two - tuple of ( dirs , files ) ."
download remote directory found by source to destination .
upload local directory ` source ` to remote destination ` destination ` .
try to create directories out of each part of ` dpath ` .
send quit command and close connection .
close connection ungracefully .
"attempt a quit , always close ."
"initialize file an ftplib . ftpconnection , and filename ."
uploadad file from file - like object fp .
upload file from contents in string v.
upload file from file identified by name filename .
download file into file - like object fp .
download file and return its contents .
download file into file identified by name filename .
delete file .
"rename file to new_name , and return an instance of that file ."
does the stubification on an xml string .
extract selection to current directory
compress selection to current directory
complete with current folder name
simplify a query by converting ctes into table metadata objects
extract constant table expresseions from a query
yields tuples of tablereference namedtuples
extract the table names from an sql statment .
: param hw_session : : param label : : return : 0 : protocol i d 1 : hw type i d 1 : hw passphrase encoding 2 : hw bip32 path usad to encodind
used to uniquefy ranks after sorting operations have been applied to position duplicate ranks .
returns a new queryresult object containing only filenames that exactly match the provided query .
a wrapper for old mechanisms of implicitly constructing queries .
searches the index given the provided query .
returns the default port on which quickopend runs .
creates a logger with the given name ( the name prefixes each log line ) .
registers a handler .
unregisters the logging handler .
retrieves the python native logger
convenience function to log a message at the debug level .
convenience function to log a message at the info level .
convenience function to log a message at the warning level .
convenience function to log a message at the error level .
convenience function to log a message at the critical level .
convenience function to log a message at the error level with additonal exception information .
closes and unregisters all logging handlers .
return a list value translating from other types if necessary .
return a os path value translating from other types if necessary .
a convenience method which coerces the option in the specified section to a list of strings .
a convenience method which coerces the option in the specified section to a file .
a convenience method which coerces the option in the specified section to a directory .
a convenience method which coerces the option in the specified section to a list of directories .
extends : meth:`~configparser . configparser.set ` by auto formatting byte strings into unicode strings .
extends : meth:`~configparser . configparser.set ` by auto formatting byte strings into unicode strings .
returns true if the hawk nonce has been seen already .
"translate string , converting it to a utf-8 encoded bytestring"
returns the jvm view associated with sparkcontext . must be called after sparkcontext is initialized .
returns or creates a java object .
transforms the embedded params and additional params to the input java object . : param params : additional params ( overwriting embedded values ) : param java_obj : java object to receive the params
returns an empty java parammap reference .
creates a model from the input java model reference .
"fits a java model to the input dataset . : param dataset : input dataset , which is an instance of : py : class:`pyspark.sql . schemardd ` : param params : additional params ( overwriting embedded values ) : return : fitted java model"
"get the cluster centers , represented as a list of numpy arrays ."
find the cluster to which x belongs in this model .
train a k - means clustering model .
find the cluster to which the points in ' x ' has maximum membership in this model .
find the membership of each point in ' x ' to all mixture components .
train a gaussian mixture clustering model .
computes column - wise summary statistics for the input rdd[vector ] .
"compute the correlation ( matrix ) for the input rdd(s ) using the specified method . methods currently supported : i{pearson ( default ) , spearman } ."
.. note : : experimental
displays jobs in a horizontal table
run the management command .
whether flake8 should consider a file as a core file or a package .
get list of changed files in the spack repository .
add a flake8 exemption to a line .
filter a single file through all the patterns in pattern_exemptions .
test when user inputs just frontend that both the frontend target and frontend operating system match
test when user inputs backend that both the backend target and backend operating system match
puts the next token in the input stream into self.next .
adds all tokens in some iterable to the token stream .
"put the next symbol in self.token if accepted , then call gettok ( )"
raise an error about the next token in the stream .
raise an error about the previous token in the stream .
"like accept ( ) , but fails if we do n't like the next token ."
return the path to the library
load the module into the environment for dependents
build an absolute path from * parts * and and return the contents of the resulting file . assume utf-8 encoding .
extract _ _ * meta * _ _ from meta_file .
create a function that always returns the next integer beginning at 0 .
ensures prometheus_client 's collectorregistry is empty before each test .
calls rhino post article list api with parameters
calls rhino patch article list api with parameters
runs a delete sql statements to remove any created lists from articlelistjointable : param name : list_name .
runs a delete sql statements to remove any created lists from articlelist : param name : list_name .
create a test case for an article .
return the article 's actual doi .
return a local file path from this script to the article 's data .
return a local file path from this script to the asset file .
return the asset 's doi .
return an abbreviated name for this asset .
list full xml path under given directory
"give a list of author and its affiliation keys in this following format [ first_name , last_name , [ key1 , key2 ] ] return [ [ first_name , last_name , key1 ] , [ first_name , last_name , key2 ] ] instead"
apply zip_author to author_list and flatten it
"parse pmid , pmc and doi from given article tree"
"given single xml path , extract information from xml file and return parsed xml file in dictionary format ."
"given path to xml file , parse references articles to list of dictionary"
"give tree and reference dictionary return dictionary of referenced paragraph , section that it belongs to , and its cited pmid"
"given single xml path , extract figure caption and reference i d back to that figure"
function to transform plain xml text to list of row values and columns
parse table from given pubmed open - access xml file
return number of waypoints
return a waypoint
add a waypoint
remove a waypoint
clear waypoint list
read a version 100 waypoint
read a version 110 waypoint
load waypoints from a file . returns number of waypoints loaded
save waypoints to a file
return number of points
return a point
add a point
clear point list
load points from a file . returns number of points loaded
save fence points to a file
work out signal loss times for a log file
generate a test value for the ith field of a message
u2fval command line tool
initializes the database by creating the tables .
list the existing clients
create a new client
display information about a client
change the appid and valid facets for a client
deletes a client
runs a u2fval server
re - caclulates fingerprints for all certificates
guess archive format based on filename extension
unarchive a file
"get a single use ticket for the umls rest services . it is supposed that an author client and a ticket granting service have already been set - up in case the apikey = none . if an api - key is given , create the above needed instances and generate a new ticket . input : - apikey : str , umls rest services api - key . default is none and the already establised service is used output : - string of the generated ticket"
"get a single use ticket for the umls rest services . it is supposed that an author client and a ticket granting service have already been set - up in case the apikey = none . if an api - key is given , create the above needed instances and generate a new ticket . input : - apikey : str , umls rest services api - key . default is none and the already establised service is used output : - string of the generated ticket"
"a time_logger function so as to print info with time since elapsed if wanted , alongside with the current logging config ."
"function that maps an entity from another source to umls concepts . input : - source_id : str , string of the unique i d from the source knowledge base - source : str , string code - name of the knowledge base , as used by the umls rest services ( e.g. drugbank - > drugbank , mesh->msh ) - apikey : str , umls rest services api - key . default is none and the already establised service is used . check get_umls_ticket function for details output : - concepts : list , list of dictionaries representing concepts mapped to the source_id entity . each dictionary has keys "" label "" , "" cuid "" , "" sem_types "" check get_concept_from_cui for more details"
"function that fetches a concept 's attributes from the corresponding cui . input : - cui : str , string of cui that will be looked up - apikey : str , umls rest services api - key . default is none and the already establised service is used . check get_umls_ticket function for details output : - res : dictionary , dictionary with the concepts attributes as fetched . specifically , "" label "" , "" cuid""(cui ) and "" sem_types""(comma delimited string of the semantic types us returned )"
"function that fetches a semantic - type 's abbreviation . input : - code_tui : str , string of tui code that will be looked up - apikey : str , umls rest services api - key . default is none and the already establised service is used . check get_umls_ticket function for details output : string , abbreviation of the code ( e.g. "" gngm "" )"
initialize loggers of the program
function to parse the command line arguments
convert single half court movement to shot log dimensional movement
convert full court movement to a single half court
main function entry
load config by cli
add command to self.update_cmd and self.commands
get current evpn global configration
get existing config
get proposed config
get end config
judge whether configuration has existed
set global evpn configration
"rather than modifying the extra data dict , return it as a no - op"
parses annotation.xml files from birdsongrecognition dataset .
"parameters ---------- songfiles : list of str , filenames of .wav files from birdsongrecogntion dataset annotation_file : str path to annotation.xml file"
"given an annotation.xml file from a bird in birdsongrecognition dataset , determine unique set of labels applied to syllables from that bird"
"return resnet unit symbol for building resnet parameters ---------- data : str input data num_filter : int number of output channels bnf : int bottle neck channels factor with regard to num_filter stride : tuple stride used in convolution dim_match : boolean true means channel number between input and output is the same , otherwise means differ name : str base name of the operators workspace : int workspace used in convolution operator"
"return resnet symbol of parameters ---------- units : list number of units in each stage num_stages : int number of stage filter_list : list channel size of each stage num_classes : int ouput size of symbol dataset : str dataset type , only cifar10 and imagenet supports workspace : int workspace used in convolution operator"
adapted from https://github.com/tornadomeet/resnet/blob/master/train_resnet.py original author wei wu
"args : tensor ( tensor ): tensor image of size ( c , h , w ) to be normalized ."
puts each data field into a tensor with outer dimension batch size
returns a list of signature features .
applies features to message body lines .
converts body into a pattern i.e. a point in the features space .
returns all choices in the menu tree rooted at ' node ' . see the kconfig.write_config ( ) implementation in kconfiglib.py for an example of how the tree can be walked iteratively instead .
"generates all valid ( arch , srcarch ) tuples for the kernel , corresponding to different architectures . srcarch holds the arch/ subdirectory ."
generates kconfig instances for all the architectures in the kernel
"returns true if a symbol ( or choice , though that 's unlikely ) with name ' sym_name ' appears in the expression ' expr ' , and false otherwise ."
"returns true if a symbol with name ' sym_name ' appears in any of the properties or property conditions of the symbol or choice ' sc ' , and false otherwise ."
"returns true if a symbol with name ' sym_name ' appears in the prompt condition of the menunode ' node ' or in any of the properties of a symbol / choice stored in the menu node , and false otherwise ."
returns a list of all menu nodes in the menu tree rooted at ' node ' that reference a symbol with name ' sym_name ' in any of their properties . also checks the properties of any symbols or choices contained in the menu nodes .
default clamav configs for various platforms .
initialize clamav configuration .
return socket.getaddrinfo for given host and port .
"scan data for viruses . @return ( infection msgs , errors ) @rtype ( [ ] , [ ] )"
initialize clamav configuration .
check for clamav and extern .
try to ask geoip database for country info .
read configuration file options .
initialize clamd daemon process sockets .
return a connected socket for sending scan data to it .
scan given data for viruses .
get results and close clamd daemon sockets .
parse clamav configuration file .
parse clamav configuration from given file .
connect to clamd for stream scanning .
"create local socket , connect to it and return socket object ."
"create tcp socket , connect to it and return socket object ."
initialize clamav configuration .
"check validity , scheme , extern and url_connection ."
run all ssl certificate checks that have not yet been done . openssl already checked the ssl notbefore and notafter dates .
"check if the certificate is still valid , or if configured check if it 's at least a number of days valid ."
read configuration file options .
"get iterator of entries in directory . only allows regular files and directories , no symlinks ."
urls like ' file://server / path/ ' result in a path named ' /server / path ' . however urllib.url2pathname expects ' ////server / path ' .
return case sensitive filename for nt path .
return filesystem path for given url path .
check if given path is absolute . on windows absolute paths start with a drive letter . on all other systems absolute paths start with a slash .
initialize the scheme .
the url is normed according to the platform : - the base url is made an absolute file:// url - under windows platform the drive specifier is normed
calls super.build_url ( ) and adds a trailing slash to directories .
get size of file content and modification time from filename path .
try to open the local file . under nt systems the case sensitivity is checked .
check if url and windows path name match cases else there might be problems when copying such files on web servers that are case sensitive .
"return file content , or in case of directories a dummy html file with links to the files ."
construct os specific file path out of the file:// url .
get filename for content to parse .
check if file is a directory .
check if content is parseable for recursion .
"return url content type , or an empty string if content type could not be found ."
get pattern for intern url matching .
"if a local webroot directory is configured , replace absolute urls with it . after that queue the url data for checking ."
initialize ftp url data .
"in case of proxy , delegate to httpurl . else check in this order : login , changing directory , list the file ."
log into ftp server and check the welcome message .
check if server can handle utf-8 encoded filenames . see also rfc 2640 .
change to url parent directory . return filename of last path component .
see if filename is in the current ftp directory .
get list of filenames in directory . subdirectories have an ending slash .
see if url target is parseable for recursion .
see if url target is a directory .
"set url content type , or an empty string if content type could not be found ."
"return url target content , or in case of directories a dummy html file with links to the files ."
release the open connection from the connection pool .
only logs that this url is unknown .
return true if this url scheme is ignored .
unknown urls have no content .
initialize the win32com.client cache .
determine if word is available on the current system .
helper to return constants . avoids importing win32com.client in other modules .
"return open word . application handle , or none if word is not available on this system ."
close word application object .
open given word file with application object .
close word file .
get line number for given range object .
get temporary filename for content to parse .
check for pdfminer .
check for word pagetype .
parse word data .
initialize graph node list and internal i d counter .
write start of checking info as xml comment .
write one node and all possible edges .
write one edge .
"finish graph output , and print end of checking info as xml comment ."
"recurse through a pdf object , searching for urls ."
check for pdfminer .
check for pdf pagetype .
parse pdf data .
build an edns option object from wire format
initialize an option . @param rdtype : the rdata type @type rdtype : int
convert an option to wire format .
build an edns option object from wire format
"compare an ends option with another option of the same type . return < 0 if self < other , 0 if self = = other , and > 0 if self > other ."
initialize error counter and optional file output .
colorize file output if possible .
needed to make file descriptor color aware .
write generic start checking info .
log introduction text .
write url checking info .
write unique id of url_data .
write url_data.base_url .
write url_data.name .
write url_data.parent_url .
write url_data.base_ref .
write url_data.url .
write url_data.dltime .
write url_data.size .
write url_data.checktime .
write url_data.info .
write url_data.modified .
write url_data.warning .
write url_data.result .
write end of checking message .
write check statistic info .
"write end of output info , and flush all output buffers ."
helper function calling linkname.image_name ( ) .
helper function calling linkname.href_name ( ) .
test image name parsing .
test href name parsing .
import - time initialization .
"return as an unicode string the css representation of the token , as parsed in the source ."
"return as an unicode string the css representation of the token , as parsed in the source ."
the line number in the css source of the first token .
the column number ( inside a source line ) of the first token .
"return as an unicode string the css representation of the tokens , as parsed in the source ."
parse an @page selector .
"determine the character encoding from the passed metadata and the ` ` @charset ` ` rule in the stylesheet ( if any ) ; and decode accordingly . if no encoding information is available or decoding fails , decoding defaults to utf-8 and then fall back on iso-8859 - 1 ."
returns a database configuration by alias
converts a string to a suitable variable name by removing not allowed characters .
generates the necessary classes .
remove leading $
html解码 : param : url : return : decoded html
wrapper function to decrypt a ciphertext file using the bethencourt2007cae cp - abe scheme .
a method visiting a struct definition and returing the layout .
a method visiting a union definition and returing the layout .
a row generator of collections .
enumerate processes by scanning for _ eprocess .
enumerate processes by scanning for threads .
yields pseudo_data for each context containing all hits .
get the process owner from the physical address .
get some context about this offset .
return the eprocess that owns this thread
we make a sub table for rendering the _ eprocess .
generate merged ranges .
format the sid using sddl notation .
search for event log files in memory .
search for known sids that we can cache .
yields struct members and their containing module .
recursively traverse the proc filesystem yielding proc_dir_entry .
check the proc mount point .
check the file ops for all the open file handles .
check the file ops for all the open file handles .
search backwards from offset for a pool header .
expand the complete path using the client 's config .
create intermediate directories to the ultimate path .
return the names of available socket enumeration methods .
walks the radix tree starting from the header h.
finds the file mapped at this address .
scan the process address space through the vads .
"updates all checksums in a modules "" _ _ versions "" section ."
a function to run length decode an int array . : param in_array : the input array of integers : return the decoded array
a function to delta decode an int array .
a product token for use in user - agent headers .
the datetime .
the low value .
the high value .
true if the line is white ( rising prices ) .
true if the line is black ( falling prices ) .
loads bars for a given instrument from a csv formatted file . the instrument gets registered in the bar feed .
"display list of tags , with delete buttons ."
utility to tranfer a value ( preserving the relative value in the range ) from its current range to a new one .
create the tag cloud link with the poper taglevel class
the standard modelform thinks the translation pks are the initial values . we need to dig deeper to assert whether there are indeed changes .
"if we give an argument of ( addon , 3615 ) ensure we get addon.objects.get(pk=3615 ) ."
"if we are given ( addon , 3615 ) it should log in the addonlog as well ."
"html for review , and collection ."
tests that a user that has something done to them gets into the user log .
this will match rules found in group .
determines if the request user has permission to do a certain action
"similar to action_allowed , but takes user instead of request ."
a convenience function . check if request.user has permissions for the object .
check request.amo_user 's permissions for the addon .
return a key for using with encode .
"when the addonpurchase gets created , see if we need to create a receipt ."
"when the contribution table is updated with the data from paypal , update the addon purchase table . will figure out if we need to add to or delete from the addonpurchase table ."
return the price and currency for the current locale .
return the price as a decimal for the current locale .
return the price as a nicely localised string for the locale .
"have we got a permissions token . if you 've got ' should_ignore_paypal ' enabled , then it will just happily return true ."
"have we got a valid permissions token by ping paypal . if you 've got ' should_ignore_paypal ' , then it will just happily return true ."
"start with one user , two add - ons ."
make sure the dashboard is getting data .
admins should be able to see specific pages .
make sure nobody else can see my precious add - on feed .
check a couple product - details files to make sure they 're available .
update the blog post cache .
"order the queryset by the translated field , honoring the current and fallback locales . returns a new queryset ."
"check if it can be purchased , returns false if not premium . must be called after the addon_view decorator ."
"if the addon is premium , require a purchase . must be called after addon_view decorator ."
check that the addon can become premium .
renders an addon in json for the api .
get a generator of dicts for the stats model given by the filters .
turn a list of dicts like we store in es into one big dict .
combines downloads_series and updates_series into one payload .
generate download counts grouped by ` ` group ` ` in ` ` format ` ` .
generate download source breakdown .
generate adu counts grouped by ` ` group ` ` in ` ` format ` ` .
generate adu breakdown of ` ` field ` ` .
"convert locale codes to pretty names , skip any unknown locales ."
check common series parameters .
check if user is allowed to view stats for ` ` addon ` ` .
parse and validate a pair of yyymmdd date strings .
parse and validate a pair of yyymmdd date strings .
return a contribution queryset common to all contribution views .
generate summarized contributions grouped by ` ` group ` ` in ` ` format ` ` .
generate detailed contributions in ` ` format ` ` .
alter cache headers . do n't cache content where data could be missing .
render a stats series in csv .
render a stats series in json .
"for all non - anonymous collections with no author , populate the author with the first collectionuser . set all other collectionusers to publishers ."
update collections subscribers totals .
update collection 's votes .
give slugs to any slugless collections .
"if we attempt to set the src / dst , we do nothing ."
returns a user object . this user is suitable for assigning to cron jobs or long running tasks .
"given an email find all the possible users , by looking in users and in their history ."
encode+hash an email for a reset code . this is the new email .
extract a user i d and an email from a code and validate against a hash . the hash ensures us the email address has n't changed and that the email address matches the user i d. this will raise ` ` valueerror ` ` if the hash fails or if the code is over 48 hours old .
encode+hash an email for an unsubscribe code .
render this service 's share count with the right term .
test that this removes locale - only cookie .
"given a known remora cookie , can we visit the homepage and appear logged in ?"
bug 566377 .
"no session cookie , no cake csrf token ."
build remora urls .
"listpeer 返回列表 { "" rtn"":0 , "" peerlist "" : [ { "" category "" : "" "" , "" status "" : 0 , "" name "" : "" gunner_home "" , "" vodport "" : 43566 , "" company "" : "" xunlei_mips_be_mips32 "" , "" pid "" : "" 8498352eb4f5208x0001 "" , "" lastlogintime "" : 1412053233 , "" accesscode "" : "" "" , "" localip "" : "" "" , "" location "" : "" 浙江省 联通 "" , "" online "" : 1 , "" path_list "" : "" c:/ "" , "" type "" : 30 , "" deviceversion "" : 22083310 } ] }"
"list 返回列表 { "" recyclenum "" : 0 , "" serverfailnum "" : 0 , "" rtn "" : 0 , "" completenum "" : 34 , "" sync "" : 0 , "" tasks "" : [ { "" failcode "" : 15414 , "" vipchannel "" : { "" available "" : 0 , "" failcode "" : 0 , "" opened "" : 0 , "" type "" : 0 , "" dlbytes "" : 0 , "" speed "" : 0 } , "" name "" : "" blablaba "" , "" url "" : "" magnet:?xt = urn : btih:5df6b321ccbdebe1d52e8e15cbfc6f002 "" , "" speed "" : 0 , "" lixianchannel "" : { "" failcode "" : 0 , "" serverprogress "" : 0 , "" dlbytes "" : 0 , "" state "" : 0 , "" serverspeed "" : 0 , "" speed "" : 0 } , "" downtime "" : 0 , "" sublist "" : [ ] , "" createtime "" : 1412217010 , "" state "" : 8 , "" remaintime "" : 0 , "" progress "" : 0 , "" path "" : "" /tmp / thunder / volumes / c:/tddownload/ "" , "" type "" : 2 , "" i d "" : "" 39 "" , "" completetime "" : 0 , "" size "" : 0 } , ... ] }"
"urlcheck 返回数据 { "" rtn "" : 0 , "" taskinfo "" : { "" failcode "" : 0 , "" name "" : "" .hdtvrip.1024x576.mkv "" , "" url "" : "" ed2k://|file|%e6%b0 % "" , "" type "" : 1 , "" i d "" : "" 0 "" , "" size "" : 505005442 } }"
"post data : { "" path"":""c:/tddownload/ "" , "" tasks "" : [ { "" url"":""ed2k://|file|%e6%b0%b8%e6%81%92.forever ... "" , "" name"":""永恒 . forever . s01e02.中英字幕 . web - hr.mkv "" , "" gcid "" : "" "" , "" cid "" : "" "" , "" filesize"":512807020 } ] }"
render the error document
returns a raw string representation of text
returns basename from raw path string
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes ."
return a tuple of strings to be used in tk plots .
return a tuple of integers to be used in awt / java plots .
return a tuple of strings to be used in html documents .
return a tuple of strings to be used in html documents .
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes ."
return a tuple of integers to be used in awt / java plots .
return a tuple of strings to be used in html documents .
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes . colormap : yellow - > red"
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes . colormap : green - > yellow - > red"
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes . colormap : yellow - > red source : http://awesome.naquadah.org/wiki/gradient"
"return a tuple of floats between 0 and 1 for the red , green and blue amplitudes . colormap : color tuple - > to_color tuple source : http://awesome.naquadah.org/wiki/gradient"
render the error document
implements transparent thread - safe access to a memcached client .
memcached deals with long ( > 30 days ) timeouts in a special way . call this function to obtain a safe value for your timeout .
mysql has the following field length restriction : no character ( varchar ) fields can have a length exceeding 255 characters if they have a unique index on them .
create a complete django test suite for the provided application module .
construct a test case with the specified label . label should be of the form model . testclass or model . testclass.test_method . returns an instantiated test or test suite corresponding to the label provided .
partitions a test suite by test type .
reorders a test suite by test type .
reorder test_databases into an order that honors the dependencies described in test_dependencies .
destroys all the non - mirror databases .
run the unit tests for all the test labels in the provided list . labels must be of the form : - app . testclass.test_method run a single specific test method - app . testclass run all the test methods in a given class - app search for doctests and unittests in the named application .
redirect to a given url while setting the chosen language in the session or cookie . the url and the language code need to be specified in the request parameters .
returns all formats strings required for i18n to work
"returns "" identity "" versions of the javascript i18n functions -- i.e. , versions that do n't actually do anything ."
returns the selected language catalog as a javascript library .
normal module existence can be tested
returns the given session dictionary pickled and encoded as a string .
returns the given session dictionary pickled and encoded as a string .
instantiate a http client instance with some default parameters . these parameters are made accessible as properties to be modified at will by the caller as needed .
perform a request with this client . most parameters here exist to either add to or override the defaults given by the client attributes . the parameters exclude _ ... serve to allow selective removal of defaults .
convenience function : perform a http get operation . arguments are the same as for request .
convenience function : perform a http post operation . arguments are the same as for request .
"perform a http request using the underlying implementation . this is expected to take the arguments given , perform a query , then return the result via a callback ."
return the content type of the body .
return the content type arguments of the body .
attempt to decode the raw body into text based on the encoding given .
"initialisation . this should be overridden by subclasses to accept and validate the inputs presented for the operation , raising an appropriate exception subclass if the inputs are found to be invalid ."
start processing the operation . this is called by the caller ( so after all _ _ init _ _ functions have executed ) in order to begin the asynchronous operation .
wait for an operation to finish . this should * not * be called in the same thread as the thread executing the operation as this will deadlock .
return the current state machine 's state .
return true if the operation is complete .
return true if the result is an exception .
return the result of the operation or raise its exception . raises notreadyerror if not ready .
return a representation of this object 's state .
return the result of the operation to any listeners .
center in a string 60 wide padded with =
( * ) convert positionals -- > tuple ( * * ) convert keyword args -- > dict
a function factory that builds and returns function objects . l is a function that will add whatever letters are passed in to be the ending letters .
take two functions as inputs and return a function that 's their composition
euclid 's method for finding the gcd
"returns the number of numbers between ( 1 , n ) that have no factors in common with n : called the ' totient of n -- called the totient of n."
"three edges from any corner , remaining three edges computed"
output the field as a string
a tractor gains a reference to this very field when added thereto
list all users .
information about a specific email .
creates a user by email with a random api key .
deletes a user by email .
return fractional part of given number .
return integer part of given number .
leap year or not in the gregorian calendar .
gregorian calendar date to julian date .
julian date to gregorian calendar date and time of day .
julian calendar date to julian date .
julian calendar date for the given julian date .
attempts to convert an object to a date .
attempts to convert an object to a time ( of day ) .
attempts to convert an object to a utc datetime .
attempts to convert an object to a time delta .
attempts to convert an object to a time zone .
check if a string is a float
compute the mae between real numbers in two files . it drops all non number . it use 0 for nan
check if the given value is none or empty string .
check if the given value is a legal file or directory path .
check if the given value is a legal directory path .
check if the given value is a legal file path .
check if the given value is of expected type . and also check if the val is none .
logs for entrance into public methods at debug level .
logs for exit from public methods at debug level .
logging exception at error level .
"convert tec to vtp format args : inp : string , the path to the input file output : string . the path to the output file returns : return the status of the conversion"
"convert vtp format to stl , vtk , tecplot , ply , pointdata args : inp : string , the path to the input file output : string . the path to the output file returns : return the status of the conversion"
"args : files : array , a list of files to process . if empty or none the default files are processed this function export the tec files generated by the nemoh module to other format"
gets the proportion of nodes in the graph with each observed degree
ca n't really validate data gather .
"given an "" abstract "" dictionary returned by parse_to_dict , build meta , library , options and misc dictionaries ."
"given an "" abstract "" dictionary returned by parse_to_dict , build library , and misc dictionaries ."
"process a line in the form "" # include foo "" to return a string representing the file"
extract the last exception .
this just tests whether create_wininst runs at all and produces a zip - file .
convert data_files pairs to the common format we use .
prune a list of files relatively to a second list .
obtain meta data information from pkg into a dictionary which may be used directly as an argument for setup function in distutils .
convert packagedescription instance to a dict which may be used as argument to distutils / setuptools setup function .
"given a python package name , check whether it is indeed an existing package ."
"given a python package name , find all its modules relatively to base_node ."
write the pkg - info file into the release tree .
write the pkg - info format data to a file object .
获取用户 : param page : : param page_row : : param kv : : return :
test re - opening partially full shards
"yield document topic vectors from mallet 's "" doc - topics "" format , as sparse gensim vectors ."
"` mallet_path ` is path to the mallet executable , e.g. ` /home / kofola / mallet-2.0.7 / bin / mallet ` . ` corpus ` is a gensim corpus , aka a stream of sparse document vectors . ` id2word ` is a mapping between tokens ids and token . ` workers ` is the number of threads , for parallel training . ` prefix ` is the string prefix under which all data files will be stored ; default : system temp + random filename prefix . ` optimize_interval ` optimize hyperparameters every n iterations ( sometimes leads to java exception ; 0 to switch off hyperparameter optimization ) . ` iterations ` is the number of sampling iterations ."
"serialize documents ( lists of unicode tokens ) to a temporary text file , then convert that text file to mallet format ` outfile ` ."
print the ` num_words ` most probable words for ` num_topics ` number of topics . set ` num_topics=-1 ` to print all topics .
: param message : wechatmessage 对象 : param content : 文字回复内容
: param message : wechatmessage 对象 : param media_id : 图片的 mediaid
: param message : wechatmessage 对象 : param media_id : 语音的 mediaid
: param message : wechatmessage对象 : param media_id : 视频的 mediaid : param title : 视频消息的标题 : param description : 视频消息的描述
initializes the application for web services
initializes the application for web services
connect to a mongodb .
ensures the proper fields are indexed
assert that the mock backend is called exactly once with the provided event
event tracker backend that uses a python logger .
send the event to the standard python logger
serialize datetime and date objects of iso format .
return model pool
return reference i d
write existent record [ 7.0 ]
browse and write existent record
create a new record for test
"raises stored : class:`httperror ` , if one occurred ."
"wraps treq so that actual calls are mostly made , but that certain results can be stubbed out"
"the correct parameters are passed to treq.post , and the json result is returned as a dict"
generating prior with correlated to original psi .
workcontributors - a model defined in swagger
gets the contributor of this workcontributors .
sets the contributor of this workcontributors .
returns true if both objects are equal
item - a model defined in swagger
gets the put_code of this item .
sets the put_code of this item .
gets the item_type of this item .
sets the item_type of this item .
gets the item_name of this item .
sets the item_name of this item .
gets the external_id of this item .
sets the external_id of this item .
returns true if both objects are equal
validate orcid id.
render widget .
render select for a specific part of date .
"process incoming data , calling process_data ."
set up the value list .
iterate through the list of choces .
map selected value representation to the a list to internal domain value .
map submitted value to the domain value .
pre - validate if it 's not bit - map .
adjust the form fields for specific record type .
link the condtion field to the validator .
validate conditionally if the linked field has a value .
creditname - a model defined in swagger
gets the value of this creditname .
sets the value of this creditname .
returns true if both objects are equal
fundingtitle - a model defined in swagger
gets the title of this fundingtitle .
sets the title of this fundingtitle .
gets the translated_title of this fundingtitle .
sets the translated_title of this fundingtitle .
returns true if both objects are equal
funding - a model defined in swagger
gets the created_date of this funding .
sets the created_date of this funding .
gets the last_modified_date of this funding .
sets the last_modified_date of this funding .
gets the source of this funding .
sets the source of this funding .
gets the put_code of this funding .
sets the put_code of this funding .
gets the path of this funding .
sets the path of this funding .
gets the type of this funding .
sets the type of this funding .
gets the organization_defined_type of this funding .
sets the organization_defined_type of this funding .
gets the title of this funding .
sets the title of this funding .
gets the short_description of this funding .
sets the short_description of this funding .
gets the amount of this funding .
sets the amount of this funding .
gets the url of this funding .
sets the url of this funding .
gets the start_date of this funding .
sets the start_date of this funding .
gets the end_date of this funding .
sets the end_date of this funding .
gets the external_ids of this funding .
sets the external_ids of this funding .
gets the contributors of this funding .
sets the contributors of this funding .
gets the organization of this funding .
sets the organization of this funding .
gets the visibility of this funding .
sets the visibility of this funding .
returns true if both objects are equal
educations - a model defined in swagger
gets the last_modified_date of this educations .
sets the last_modified_date of this educations .
gets the education_summary of this educations .
sets the education_summary of this educations .
gets the path of this educations .
sets the path of this educations .
returns true if both objects are equal
source - a model defined in swagger
gets the source_orcid of this source .
sets the source_orcid of this source .
gets the source_client_id of this source .
sets the source_client_id of this source .
gets the source_name of this source .
sets the source_name of this source .
returns true if both objects are equal
personexternalidentifier - a model defined in swagger
gets the created_date of this personexternalidentifier .
sets the created_date of this personexternalidentifier .
gets the last_modified_date of this personexternalidentifier .
sets the last_modified_date of this personexternalidentifier .
gets the source of this personexternalidentifier .
sets the source of this personexternalidentifier .
gets the external_id_type of this personexternalidentifier .
sets the external_id_type of this personexternalidentifier .
gets the external_id_value of this personexternalidentifier .
sets the external_id_value of this personexternalidentifier .
gets the external_id_url of this personexternalidentifier .
sets the external_id_url of this personexternalidentifier .
gets the external_id_relationship of this personexternalidentifier .
sets the external_id_relationship of this personexternalidentifier .
gets the visibility of this personexternalidentifier .
sets the visibility of this personexternalidentifier .
gets the path of this personexternalidentifier .
sets the path of this personexternalidentifier .
gets the put_code of this personexternalidentifier .
sets the put_code of this personexternalidentifier .
gets the display_index of this personexternalidentifier .
sets the display_index of this personexternalidentifier .
returns true if both objects are equal
test task loading and processing with failures .
test task loading and processing with failures .
test expiration data setting and deletion of the exprired tasks .
transientnonemptystring - a model defined in swagger
gets the value of this transientnonemptystring .
sets the value of this transientnonemptystring .
gets the transient of this transientnonemptystring .
sets the transient of this transientnonemptystring .
returns true if both objects are equal
keyword - a model defined in swagger
gets the created_date of this keyword .
sets the created_date of this keyword .
gets the last_modified_date of this keyword .
sets the last_modified_date of this keyword .
gets the source of this keyword .
sets the source of this keyword .
gets the content of this keyword .
sets the content of this keyword .
gets the visibility of this keyword .
sets the visibility of this keyword .
gets the path of this keyword .
sets the path of this keyword .
gets the put_code of this keyword .
sets the put_code of this keyword .
gets the display_index of this keyword .
sets the display_index of this keyword .
returns true if both objects are equal
groupidrecord - a model defined in swagger
gets the name of this groupidrecord .
sets the name of this groupidrecord .
gets the group_id of this groupidrecord .
sets the group_id of this groupidrecord .
gets the description of this groupidrecord .
sets the description of this groupidrecord .
gets the type of this groupidrecord .
sets the type of this groupidrecord .
gets the put_code of this groupidrecord .
sets the put_code of this groupidrecord .
returns true if both objects are equal
handle get request .
handle post request .
log a message .
log an error message .
"create a response object : param content : content of response , might be a file - like object or any jsonable object . : param headers : headers of response . : param status : status code of response ."
"create a response object from a response dict : param result : a result dict or list , a dict may contain special fields : - common . kw_headers : set headers for the response - common . kw_file : set a content - stream to response - common . kw_list : set response body as a list : param status : status code for response : return : a response object"
convert any result into a dict - result . : param result : : return :
verify api documentation .
returns an optional variable . : param str optional_variable : an optional variable : return : the optional variable
set true . : param bool[false ] set_true : set true : return bool : set true ?
set false . : param bool[true ] set_false : set false : return bool : set false ?
return a bool value . : param bool value : value : return bool : the value
ignored method . : return str : ignored - method
returns nothing type . : return none : none
argument with underscores . : param int _ arg _ : argument with underscores : param int _ second_arg _ : second argument with underscores : return dict : parameters
lazy evaluation of parsed url
internal . : return str : nothing
not found . : return str : nothing
initialize the object with a given set of configurations .
adding a host with a given set of attributes and/or templates
delte a host based on the hostname
method to list all hosts or only a select one returns a list of all hosts
method to check if a single host exists
returns host objects that fit the filter and joins
return the count of hosts with problems that are neither acknowledged or have a downtime
lists all hosts and their severity count in a sorted order
calculate the severity
initialize the graphfactorization class
return the git revision as a string . copied from numpy setup.py
"type : : ( int , int ) - > int return modulo of a over b , make sure to return an positive number when b is great than zero"
"type : : ( int , int ) - > int return : : greatest common divisor"
"type : : ( int , int ) - > ( int , int , int ) return : : ( g , x , y ) , g is gcd of a and b and x * a + y * b = g"
"type : : ( int , int ) - > int return : : return module inverse of a * x = 1 ( mod m )"
"type : : int - > [ int ] generate primes number up to m , and return a list"
"the interaction matrix < jkm|v|j'km > divided by e_0 ^ 2 ( the electric field amplitude squared ) . e_0 is just a constant , so the same interaction matrix can be used for all laser pulses by just scaling this one with e_0 ^ 2 = 2*i/(c*epsilon_0 ) times a conversion factor between polarizability volume and polarizability ."
calculate < jkm|cos^2(theta)|j'km > .
test functions of intervalfield without using any specific database backend .
initialize internal state .
initializes all caches .
append an elapsedrecord of an access operation to the elapsed time queue .
returns a list of all queued elapsed time records and clears the queue .
"given time in seconds , converts it to string returns : string of the form hh : mm : ss"
"converts a given time string to seconds . the time string has to be of the form in hh : mm : ss returns : int , the value of time in seconds"
"given two time strings of the form hh : mm : ss , finds the difference in seconds between the two . returns : int , difference in seconds of t2str - t1str"
compute the product of all the elements in a sequence .
compute the sequence of the first n primes .
compute the nth prime .
compute the nth primorial .
compute the sequence of primes less than n.
set up bottle web application
select the 3 - component traces from the same channel
"initialize a session , populating session values ."
closes this session in the database .
input : { }
"see in module "" experiment.tune.compiler.flags """
"see in module "" experiment.tune.compiler.flags """
"see in module "" program.optimization """
"see in module "" program.optimization """
"see in module "" experiment.tune.compiler.flags """
"see in module "" experiment.tune.compiler.flags """
"see in module "" program.optimization """
"see in module "" program.optimization """
"see in module "" experiment.tune.compiler.flags """
"see in module "" experiment.tune.compiler.flags """
"allow get , head and options requests for an unauth user ."
returns a state containing a possible output difference after applying the s - box for the given input difference .
returns a state containing a possible input difference after applying the inverse s - box for the given output difference .
compute the list of all possible values for ( x 0 0 0 0 0 0 0 ) * l = ( y0 y1 y2 y3 y4 y5 y6 y7 )
compute the list of all possible values for ( x 0 0 0 0 0 0 0 ) * linverse = ( y0 y1 y2 y3 y4 y5 y6 y7 )
compute the differential distribution table ( ddt ) for a given s - box
compute the valid pairs for each input / output difference .
"get all possible pairs ( a , b ) such that : s(a ) xor s(b ) = outputdiff"
"get all possible pairs ( a , b ) such that : sinverse(a ) xor sinverse(b ) = inputdiff"
get all possible output differences for a given input difference .
get all possible input differences for a given output difference .
the diff parser reuses modules . so check for that .
checks if the parent / children relationship is correct .
this was a bug in jedi # 878 .
the ` args ` / ` kwargs ` params are the same as in ` api . script ` . : param operation : the refactoring operation to execute . : type operation : str : type source : str : return : list of changed lines / changed files
the ` args ` / ` kwargs ` params are the same as in ` api . script ` . : param operation : the refactoring operation to execute . : type operation : str : type source : str : return : list of changed lines / changed files
"initializes the ycmd server as a webtest application that will be shared by all tests using the sharedycmd decorator in this package . additional configuration that is common to these tests , like starting a semantic subserver , should be done here ."
cleans up the tests using the sharedycmd decorator in this package . it is executed once after running all the tests in the package .
defines a decorator to be attached to tests of this package . this decorator passes the shared ycmd application as a parameter .
"defines a decorator to be attached to tests of this package . this decorator passes a unique ycmd application as a parameter . it should be used on tests that change the server state in a irreversible way ( ex : a semantic subserver is stopped or restarted ) or expect a clean state ( ex : no semantic subserver started , no .ycm_extra_conf.py loaded , etc ) . use the optional parameter |custom_options| to give additional options and/or override the default ones ."
"through inheritance , a call signature is a sub class of definition . check if the attributes match ."
"seems to cause problems , see also # 396 ."
"it 's possible to not use names , but another function result or an array index and then get the call signature of it ."
github issue # 240
"there 's still an implicit param , with a decorator . github issue # 319 ."
function definitions ( and other tokens that can not exist within call signatures ) should break and not be able to return a call signature .
"the self keyword should be visible even for builtins , if not instantiated ."
we 've been having an issue of a mutable list that was changed inside the function execution . test if an execution always returns the same result .
returns the absolute path for which completion suggestions should be returned ( in the standard case ) .
set the default cache directory to a temporary directory during tests .
works only greater equal python 3.3 .
"initializes the ycmd server as a webtest application that will be shared by all tests using the sharedycmd decorator in this package . additional configuration that is common to these tests , like starting a semantic subserver , should be done here ."
cleans up the tests using the sharedycmd decorator in this package . it is executed once after running all the tests in the package .
"defines a decorator to be attached to tests of this package . this decorator passes a unique ycmd application as a parameter . it should be used on tests that change the server state in a irreversible way ( ex : a semantic subserver is stopped or restarted ) or expect a clean state ( ex : no semantic subserver started , no .ycm_extra_conf.py loaded , etc ) . use the optional parameter |custom_options| to give additional options and/or override the default ones ."
for static analysis .
"returns true if only one name is returned : ` ` for x in y ` ` . returns false if the for loop is more complicated : ` ` for x , z in y ` ` ."
returns a cleaned version of the docstring token .
generate call signature of this function .
return a document string including call signature .
move the ` node ` start_pos .
"returns ( as string ) any comment that appears on the same line , after the node , including the #"
returns the underlying scope .
a potentially expensive operation that removes all data already retrieved from the buffer .
see github issue # 390 .
should still work even if there 's a newline .
create a class with a metaclass .
"cast to unicode dammit ! written because python2 repr always implicitly casts to a string , so we have to cast back to a unicode ( and we now that we always deal with valid unicode , because we check that in the beginning ) ."
` ` _ _ repr _ _ ` ` methods in python 2 do n't allow unicode objects to be returned . therefore cast them to utf-8 bytes in this decorator .
returns a copy of the dictionary with the _ sre . sre_pattern instances in each set value replaced with the pattern strings . needed for equality test of two filetype trigger dictionaries .
find the path to the gocode / godef binary .
compute the byte offset in the file given the line and column .
run a command in a subprocess and communicate with it using the contents argument . return the standard output .
start the gocode server .
stop the gocode server .
restart the gocode server .
check if the gocode server is running ( process is up ) .
check if the gocode server is healthy ( up and serving ) .
check if the gocode server is ready . same as the healthy status .
check if given path ends with a python 2.7 or 3.4 + name .
"works like argument clinic ( pep 436 ) , to validate function params ."
todo this function is currently not used . it 's a stab at implementing next in a different way than fake objects . this would be a bit more flexible .
implementation of the namedtuple function .
"splits the header into lines , putting multi - line headers together ."
parses the header_plus block of text ( the headers plus the first line of the request ) .
follow with a link to add to http://telegramusic.ml .
returns true is an instance of a bot is running
claims that the bot is running .
removes claim that bot is running
inserts the interval into the tree .
random shuffle of input array .
pick at random k element from arr .
computes strongly connected components of a acyclic directed graph .
first pass of rao kosaraju 's algorithm .
the second pass through the graph in kosaraju 's algorithm .
"given an array of values , design and code an algorithm that returns whether there are two duplicates within k indices of each other ? and within plus or minus l ( value ) of each other ? do all , even the latter , in o(n ) running time and o(k ) space ."
"finds a neighbouring plot with elevation strictly smaller than ( i , j ) ."
"a group of farmers has some elevation data , and we ’re going to help them understand how rainfall flows over their farmland . we ’ll represent the land as a two - dimensional array of altitudes and use the following model , based on the idea that water flows downhill :"
sort the letters in one word by the order they occur in another in linear time .
search in a sorted rotated array .
merge k sorted singly linked list
"paint a list of n houses and m colors , each combination has cost , minimize the total cost without color in row ."
"given array a of size n , using function random(returns random number between 0 and 1 ) implement function that will return array of size n with randomly shuffled elements of the array a. you should give only algo ."
"given a singly linked list , swap the list items in pairs ( reconnect the pointers , not simply swap the values ) ."
computes shortest path using a dijkstra algorithm and speeding it up using a heap data structure .
computes single source shortest paths to every other vertex in a directed graph starting from the start_vertex .
"computes the edges on the frontier of a graph , given the already explored vertices , ie . the edges where the tail was explored and the head was not yet explored ."
implements dijkstra 's greedy criterion : ie . find the vertex to add to the explored set so that it minimizes the path it creates .
"overrides to support vertices in format ( vertex , cost ) ."
overrides parent method to remove a vertex by it 's vertex not cost .
given the following tree : 9 / 1 10 / \ 0 5 11 / / -1 2 6
"given the following tree : 9 / 1 10 / \ 0 5 11 / / -1 2 6 after deleting 11 ( a leaf ) , we should end up with : 1 / 0 9 / / -1 5 10 / 2 6"
given the following tree : 9 / 1 10 / \ 0 5 11 / / -1 2 6
given the following tree : 9 / 1 10 / \ 0 5 11 / / -1 2 6
returns the pairs of number in input list which sum to the given total .
returns the pairs of number in input list which sum to the given total .
constructs hash table given the number of buckets .
add value to the hash table .
checks whether value is in the hash table or not .
removes value from the hash .
exports a plain list with the enclosed elements .
hashing function used to compute a key for the given value . this is done in two steps : ` hash code ` : key - > really big number ` compression function ` : really big number - > bucket number
attempt to insert the data into the hash table .
attempt to locate the data in the hash table .
removes the value from the data structure .
exports the contents of the hash table into a list .
first hash function for the initial lookup .
second hash function used to offset the indexes produced by the first hash function .
orders the vertices in a directed graph in a topological ordering using depth_first_search .
returns a list of sync vertices .
recursive function which repeatedly removes one of the sync vertices from the given graph and assigns it the given position in the topological ordering .
computes the topological ordering of vertices in a acyclic directed graph .
given the following bipartite graph . ( a)-----(b ) \----(c ) ( d)-----(e ) / ( f)----/ \----(g )
a sligthly larger graph : ( a ) ( c ) | \ /| | x | | / \ | ( b ) ( d ) | \ /| | x | | / \ | ( e ) ( f )
given a graph : ( u)----(v ) | \ / | | \/ | | /\ | | / \ | ( w)---(x )
given the following weighted graph . ( u)-3-(v ) | \ / | | 5\/1 4 2 /\ | | / \ | ( w)-6-(x )
test the connected graphs algorithm for the folowing setup . ( 1)--(3 ) ( 2)--(4 ) ( 6 ) \ / / ( 5 ) ( 8) ( 10 ) / ( 7 ) ( 9 ) this should return the nodes in three subgraphs .
adds two numbers using only bit manipulations .
figures out if an int is a power of two .
interchange two numbers without an extra variable .
checks if the input integer is even .
compute min of a pair of two ints .
compute max of a pair of two ints .
checks whether the offset bit in a is set or not .
set the value of a bit at index < order > to be 1 .
set the value of a bit at index < order > to be 0 .
set the value of a bit at index < order > to be the inverse of original .
returns the number of set bits in the input .
computes all the subsets of input list .
compute the closest pair of a set of given pairs .
"the point space looks like this : | * a(9,1 ) | * e(8,8 ) | * c(7,7 ) | | | | | * d(7,3 ) | * f(8,2 ) | * b(1,1 ) + --------------------------------------------- >"
checks if n is a prime number using probabilitic methods .
decorator which retries a wrapped function a number of times .
locate the key value in the given array .
tests that the following graph is split correctly . ( a)--(c ) | / | ( b)--(d )
test minimum cut for a larger graph . ( a)--(b)--(e)--(f ) | x | | x | ( c)--(d)--(g)--(h )
test minimum cut for a larger graph . ( a)--(b)--(e)--(f ) | x | | x | ( c)--(d)--(g)--(h )
before we can understand this type of decorator we need to consider the partial .
given this graph to explore : /-(a)---(d)---(e ) / | | / ( s)---(b)---(c)-/
given this graph to explore : /-(a)---(d)---(e ) / | | / ( s)---(b)---(c)-/
given this graph to explore : />(a)-->(d)-->(e ) / |v |v /^ ( s)-->(b)-->(c)-/
"given a partition ( dictionary ) , returns the step - function graphon associated with it ."
test home view
test faculties view
test courses view
test speciality view
test specialization view
check saving data
check displaying form
check displaying form
check saving data
build the list of neighbors of a given cell
build the list of cells that are visible from a given one
"get the number of empty cells at the right of the given one , including it"
"get the number of empty cells at the down of the given one , including it"
returns true if server is not the user 's current used in setup of constraints .
saves the solution for this model as json .
serialize a gitmodel object to json .
load a json object string as a gitmodel instance .
"creates a pygit2.signature while making time and offset optional . by default , uses current time , and local offset as determined by ` ` dateutil.tz.tzlocal ( ) ` `"
prepare data for training .
run a linear classifier .
run a dnn classifier .
merge the views from link into self .
the ' get ' method for the link(dict )
equipment : initial equipment instance to model
entrada : parametro opcional de clase corriente que indica la corriente de entrada en el equipo
"cálculo de los coeficientes de reparto entre fases , ref naji - conventional and rapid flash claculations"
equipment : initial equipment instance to model
equipment : initial equipment instance to model
"roots for a cubic polinomy , x^3 + a1*x^2 + a2*x + a3"
cunningham slip correction factor for air l : mean free path kn : knudsen dimensionless number method : reference procedure 0 - jennings ( 1987 ) 1 - allen & raabe ( 1982 ) 2 - fuchs ( 1964 ) 3 - davies ( 1945 )
calculate the collision integral using the neufeld correlation
save chart image to png file
método que dibuja la matriz de datos
load and fmu .
simulate an fmu .
parse simulation key - word arguments and arrange for feeding the simulate method of pyfmi 's model objects .
extract some final values or trajectories from a pyfmi result object .
ensure appropriate number of dimensions for input data . note : only the dimension is affected . the exact shape is not checked .
guess the time vector from input data .
parse one line of a dymola initialization script .
parse a dymola initialization script .
apply an initialization script to a model .
get the list of variable names .
get the causality of the variables .
get the variability of the variables .
"get the values of the variables with ' fixed ' variability , ignoring aliases ."
get the values of the variables with a start value ignoring aliases .
set values from a dictionary with variable names as keys .
"store trajectories in a dictionary , and possibly reinterpolate them ."
"store samples of trajectories in a dictionary , and possibly reinterpolate them ."
returns ` ` repository ` ` object of type linked with given ` ` alias ` ` at the specified ` ` path ` ` . if ` ` alias ` ` is not given it will try to guess it using get_scm method
returns ` ` repository ` ` class identified by the given alias or raises vcserror if alias is not recognized or backend class can not be imported .
returns list of aliases of supported backends .
"returns one of alias from ` ` aliases ` ` ( in order of precedence same as shortcuts given in ` ` aliases ` ` ) and top working dir path for the given argument . if no scm - specific directory is found or more than one scm is found at that directory , ` ` vcserror ` ` is raised ."
returns all scm 's found at the given path . if no scm is recognized - empty list is returned .
returns path 's subdirectories which seems to be a repository .
runs command on the system with given ` ` args ` ` .
if pygments are available on the system then returned output is colored . otherwise unchanged content is returned .
"returns dictionary with * start * , * main * and * end * ids ."
parses given text and returns ` ` datetime.datetime ` ` instance or raises ` ` valueerror ` ` .
returns dictionary for each attribute from given ` ` obj ` ` .
backported for python 2.5 .
"verify the signature in the pkcs7 object against the stored ca certificate , then parse the extracted signed data ( the actual receipt asn.1 data ) . return iapreceipt ."
"extract the pkcs7 container from the der binary . verify the receipt signature against apple 's root ca cert , and against the certificate chain contained in the pkcs7 data . return the raw receipt blob in asn.1 format ."
"parse receipt in asn.1 format , returning iapreceipt object ."
"return last receipt parsed , or none"
"return last receipt der parsed , or none"
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
experimental function . not part of the official api
"prepare dataset for amo , make amo call and return a policy object with the associated model ."
filter the provided parameters dict and return a list of parameter names which are marked as secret .
introspect the parameters dict and return a new dict with masked secret parameters .
introspect an inquiry 's response dict and return a new dict with masked secret values .
retrieve all the available roles .
retrieve all the available system roles .
retrieve all the roles assigned to the provided user .
retrieve all the userroleassignmentdb objects .
retrieve all the userroleassignmentdb objects for a particular user .
retrieve role by name .
create a new role .
""" delete role with the provided name ."
assign role to a user .
revoke role from a user .
retrieve all the permission grants for a particular user optionally filtering on :
create a new permission grant for a resource and add it to the provided role .
create a new permission grant and add it to the provided role .
remove a permission grant from a role .
verify that the roles with the provided names exists in the system .
validate that the permissions can be manipulated for the provided resource type .
validate that the permission_types list only contains valid values for the provided resource .
: param create_handler : function which is called on triggerdb create event . : type create_handler : ` ` callable ` `
"utility function which retrieves pack "" ref "" attribute from the pack metadata file ."
return parsed metadata for a particular pack directory .
validate provided config dictionary against the provided config schema dictionary .
return the pack 's common lib path . this is the path where common code for sensors and actions are placed .
"normalize old , pre stackstorm v2.1 non valid semver version string ( e.g. 0.2 ) to a valid semver version string ( 0.2.0 ) ."
method for casting string to an object ( dict ) or array .
"cast function which serializes special magic string value which indicate "" none "" to none type ."
determines the callable which will perform the cast given a string representation of the type .
format a value for a simple field .
: param config : action config . : type config : ` ` dict ` `
: param username : username of the user to create the token for . if the account for this user does n't exist yet it will be created . : type username : ` ` str ` `
: param trigger_instance : triggerinstance db object . : type trigger_instance : : class:`triggerinstancedb ` `
return true if the rule is applicable to the provided trigger instance .
: param trigger_instance : triggerinstance db object . : type trigger_instance : : class:`triggerinstancedb ` `
return a list of all the supported format strings .
retrieve datetime object for current time with included utc timezone info .
convert provided datetime object to utc timezone .
parse a date string and return a time - zone aware datetime object .
loads content from file_path if file_path 's extension is one of allowed ones ( see allowed_exts ) . throws unsupportedmetaexception on disallowed filetypes . : param file_path : absolute path to the file to load content from . : type file_path : ` ` str ` ` : rtype : ` ` dict ` `
"loads fixtures specified in fixtures_dict . this method must be used for fixtures that do n't have associated data models . we simply want to load the meta into dict objects . fixtures_dict should be of the form : { ' actionchains ' : [ ' actionchain1.json ' , ' actionchain2.json ' ] , ' workflows ' : [ ' workflow.yaml ' ] } : param fixtures_dict : dictionary specifying the fixtures to load for each type . : type fixtures_dict : ` ` dict ` ` : rtype : ` ` dict ` `"
get a queue name based on base name and suffix . you can also specify if you need a random uuid at the end of the final name generated . format returned is ` ` queue_name_base.queue_.queue_name_suffix - uuid ` ` .
common setup function .
common teardown function .
run all sensors as determined by sensors_partitioner .
action execution escapes escaped chars in result ( i.e. is stored as \n ) . this function unescapes those chars .
yaml.safe_dump converts single newlines to double .
ensure that a minimum supported version of pip is installed .
return a list of requirements and links by parsing the provided requirements file .
"function which detects if the script is being executed inside vagrant and if it is , it deletes "" os.link "" attribute . note : without this workaround , setup.py sdist will fail when running inside a shared directory ( nfs / virtualbox shared folders ) ."
read _ _ version _ _ string for an init file .
discover all the packs in the provided directory and register triggers from all of the discovered packs .
register all the triggers from the provided pack .
return mock logger instance .
retrieve configs for all the packs .
retrieve config for a particular pack .
create a new config for a pack .
: param timeout : action execution timeout in seconds . : type timeout : ` ` int ` `
: param script_path : full path to the script on the remote server . : type script_path : ` ` str ` `
"builds a string of named and positional arguments in powershell format , which are passed to the script ."
upload provided file to the remote server in a temporary directory .
retrieve full absolute path for a share with the provided name .
"parse share information retrieved using "" net share < share name > "" ."
triggerinstance from message is create prior to acknowledging the message . this gets us a way to not acknowledge messages .
codify response of the pre_ack_process method .
break - down response of pre_ack_process into constituents for simpler consumption .
creates a ruleenforcer matching to each rule .
validate whether given string is ipv6 .
validate whether given string is ipv4 .
"split host_str into host and port . can handle ipv4 , ipv6 , hostname inside or outside brackets ."
"converts a sensortypeapi model to db model . also , creates trigger type objects provided in sensortypeapi ."
return the crypto key given a path to key file and the key type .
encrypt the given message using the encrypt_key . returns a utf-8 str ready to be stored in database . note that we convert the hex notation to a ascii notation to produce a utf-8 friendly string .
decrypt the given crypto text into plain text . returns the original string input . note that we first convert the string to hex notation and then decrypt . this is reverse of the encrypt operation .
reread directory trying to keep the current selection
directly jump to given song
check if a server accepts connections on a specific tcp port
"heuristics to improve accuracy of ud tags , return modified ud_tags"
runs a command specified by an argument vector ( including the program name ) and returns lists of lines from stdout and stderr .
derive samples used to create trees in scikit - learn randomforest objects .
"helper function , that performs the core computation"
helper functions that implements bias correction
calculate error bars from scikit - learn randomforest estimators .
return the number of keys in the subtree rooted at this node .
create a new trie .
create a new trie with keys from ` ` iterable ` ` and values set to ` ` value ` ` .
return the longest key in this trie that is a prefix of ` ` key ` ` .
return the value associated with the longest key in this trie that is a prefix of ` ` key ` ` .
"return the item ( ` ` ( key , value ) ` ` tuple ) associated with the longest key in this trie that is a prefix of ` ` key ` ` ."
return an iterator over the keys of this trie that are prefixes of ` ` key ` ` .
return an iterator over the values of this trie that are associated with keys that are prefixes of ` ` key ` ` .
"return an iterator over the items ( ` ` ( key , value ) ` ` tuples ) of this trie that are associated with keys that are prefixes of ` ` key ` ` ."
return a list of this trie 's keys .
return a list of this trie 's values .
"return a list of this trie 's items ( ` ` ( key , value ) ` ` tuples ) ."
return an iterator over this trie 's keys .
return an iterator over this trie 's values .
"return an iterator over this trie 's items ( ` ` ( key , value ) ` ` tuples ) ."
sets up the mpr_6zhmaut platform .
returns the base url for endpoints .
makes the actual request and returns the parsed response .
returns the name of the device .
returns the state of the device .
volume level of the media player ( 0 .. 1 ) .
boolean if volume is currently muted .
current media source .
flags of media commands that are supported .
""" return the current input source of the device ."
list of available input sources .
set input source .
turn the media player on .
turn_off media player .
"set volume level , range 0 .. 1 ."
mute ( true ) or unmute ( false ) media player .
"# spectral decrease class spectraldecrease(essentia . decrease ): def configure(self , samplerate = 44100 , * * kwargs ): essentia . decrease.configure(self , range = samplerate*0.5 )"
test searching by regular expression
clean up before every test .
"open a file through the hadoop filesystem api . supports distributed file systems like hdfs , gs , and s3 ."
"copy a file through the hadoop filesystem api . supports distributed file systems like hdfs , gs , and s3 ."
assumes that : meth:`can_coerce ` is ` ` true ` `
name of reference genome .
contig names .
dict of contig name to contig length .
x contigs .
y contigs .
mitochondrial contigs .
pseudoautosomal regions .
contig length .
load reference genome from a json file .
""" write this reference genome to a file in json format ."
load the reference sequence from a fasta file .
true if the reference sequence has been loaded .
remove the reference sequence .
create reference genome from a fasta file .
` ` true ` ` if a liftover chain file is available from this reference genome to the destination reference .
remove liftover to ` dest_reference_genome ` .
register a chain file for liftover .
parse command arguments
create a directory .
download rico sennrich 's wmt16 model : < src > to < trg > .
decorate functions that modify the internally stored usernotes json .
model function for cnn .
"% feature(""docstring "" ) gr_make_align_on_samplenumbers_ss::align_state "" wraps the c++ : gr_align_on_samplenumbers_ss::align_state "" ;"
": param tol : tolerance of change in error . : param alpha : learning rate . : param epoch : number of passes over data : param criteria : criteria for cost function(to be implemented ) by default sum of squared error . : param batch_size : the size of the batch to be processed . by default the value is 1 . : param verbose : if true print out the error for each epoch . : param decay : decay rate of learning rate by 1 / ( 1 + decay * runs ) : param momentum : value ranges from [ 0,1 ] . use a low learning rate with high momentum and vice versa . : param random_seed : random seed for regeneration of results ."
overrides print function of python . : return : network details .
method adds layer to the network and checks if the input dimension of the current layer matches the output dimension of previous layer .
function to train the neural network . : param x : training examples : param y : training labels : return : none
function to predict the targel label : param x : test examples : return : predicted values
"sigmoid transfer . : param tensor : numpy array : return : numpy array of same shape , where each input element has been modified ."
"hyperbolic tangent . : param tensor : numpy array . : return : numpy array of same shape , where each input element has been modified ."
"rectified linear unit : param tensor : numpy array : return : numpy array of same shape , where each input element has been rectified with noise ."
"nosiy rectified linear unit . the noise is chosen from a gaussian distribution of zero mean and unit variance . : param tensor : numpy array : return : numpy array of same shape , where each input element has been rectified ."
leaky rectified linear unit . : param tensor : numpy array : return : numpy array of same shape .
"softmax function(normalized exponential ): changes array of arbitrary real values into array of real values in the range ( 0,1 ) that add upto 1 . softmax usually fails for large numbers so we will shift the numbers and then calculate . : param tensor : 1d numpy array . : return : softmax transferred numpy array of same dimension ."
test that trainingclassset data can be saved without exception .
test that the data loaded is the same as was saved .
tests that classification of spectrum is same as from image .
tests that gaussianclassifier classifies a spyfile object .
tests that gaussianclassifier classifies a transformedimage object .
gaussian classification of an ndarray and transformedimage are equal
test that a class 's mean spectrum is classified as that class . note this assumes that class priors are equal .
mahalanobis classifier works with a spyfile object .
mahalanobis classifier works with a transformedimage object .
mahalanobis classification of ndarray and transformedimage are equal
test that 2x1 network can learn the logical and function .
test that 2x2x1 network can learn the logical xor function .
test that 2x2x2 network can learn the logical xor function .
test that perceptron can learn image class means .
tests that classification of spectrum is same as from image .
returns a spyfile object for an aviris image file .
returns a bandinfo object for an aviris spectral calibration file .
"create an x11 tunnel from node:6000 to the root host display : display on root host ( optional ) returns : node $ display , popen object for tunnel"
"create an x11 tunnel to the node and start up a terminal . node : node object title : base title term : ' xterm ' or ' gterm ' returns : two popen objects , tunnel and terminal"
run an x11 client on a node
remove moldy socat x11 tunnels .
create terminals . nodes : list of node objects title : base title for each returns : list of created tunnel / terminal processes
create an empty network and add nodes to it .
add node to graph
add edge to graph
return list of graph nodes
iterator : return graph edges
return link dict for the given node
topo object : hinfo : default host options sopts : default switch options lopts : default link options eopts : default ee options
add node to graph . name : name opts : node options returns : node name
convenience method : add host to graph . name : host name opts : host options returns : host name
convenience method : add switch to graph . name : switch name opts : switch options returns : switch name
"node1 , node2 : nodes to link together port1 , port2 : ports ( optional ) opts : link options ( optional ) returns : link info key"
generate port mapping for new edge . @param src source switch name @param dst destination switch name
convenience method : add an ee to graph . name : exection environment name opts : ee options returns : ee name
return nodes in graph
returns true if node is a host .
returns true if node is a switch .
returns true if node is an ee .
return switches . sort : sort switches alphabetically @return dpids list of dpids
return hosts . sort : sort hosts alphabetically @return dpids list of dpids
return ees . sort : sort ees alphabetically @return dpids list of dpids
return links . sort : sort links alphabetically @return links list of name pairs
get port number .
return link metadata
set link metadata
return metadata ( dict ) for node
set metadata ( dict ) for node
items sorted in natural ( i.e. alphabetical ) order
init . k : number of switches n : number of hosts per switch hconf : host configuration options lconf : link configuration options
"expire probes and "" memorized "" flows"
send an arp to a server to see if it 's still up
time to wait between probes
pick a server for a ( hopefully ) new connection
"we may have "" lost "" buffers -- packets we got but did n't know where to send at the time . we may know now . try and see ."
"verify that each target is pinged at least once , and that pings to ' real ' targets are successful and unknown targets fail"
returns a list of unpack methods .
ping test on minimal topology
ping test on 5 - host single - switch topology
ping test on a 5 - switch topology
send an arp reply .
send an arp request
get the version number of the raspberry pi board .
get the i2c bus number /dev / i2c .
reads the humidity and temperature from the as2315 .
read humidity data from the sensor .
read temperature data from the sensor . ( celsius is default )
returns the 16 - bit crc of sensor data
convert celsius to fahrenheit .
"read configuration files , initialize glin and run main loop"
decorator for parsing element attributes .
decorator for parsing a element .
returns the tag name string without namespace of the passed element .
extract color histogram data from object images
save histogram data to data / histogram_data/{object_nm}.pkl.gz
: param point : point that is going to be transformed : type point : pointstamped : param transform : camera_frame - > bbox_frame : type transform : transform
": param points : list of geometry_msgs.msg . pointstamped : type list of stamped points : : param projected_points : list of camera_coordinates : type projected_points : ( u , v )"
old user of an item should not be taken into account for that filter
load session .
factory for removing duplicate webob code from tests .
compare xml atom links .
compare xml media types .
compare parts of lxml.etree objects to dicts .
regression test for bug # 1552888 .
execute optional pre and post methods around the decorated function . this is useful for customization around callables .
clear loaded hooks .
invoke_on_load creates an instance of the hook class
execute optional pre methods of loaded hooks .
execute optional post methods of loaded hooks .
return true if host has sufficient cpu cores .
filters all model attributes except for keys item is a dict
"if the transport_url is present in the cell , derive username , rpc_host , and rpc_port from it ."
return all cells .
return all cells in brief .
return all cells in detail .
return name and capabilities for this cell .
return capacities for a given cell or all cells .
return data about the given cell name . ' i d ' is a cell name .
delete a child or parent cell entry . ' i d ' is a cell name .
normalize input cell data . normalizations include :
create a child cell entry .
update a child cell entry . ' i d ' is the cell name to update .
tell all cells to sync instance info .
tests the case that send_service_user_token is true but there is some misconfiguration with the [ service_user ] section which makes ksa return none for the service user auth .
checks a host in an aggregate that metadata key / value match with image properties .
tests getting all of the hostmappings for a given cellmapping i d.
returns a full log for all instance usage audit tasks on all computes .
stores password as system_metadata items .
return a list of hosts that can create instance_type
load up doc_files and see if any routes are missing .
update dict d recursively with data from dict update
override the weight multiplier .
higher weights win . we want spreading to be the default .
builds a mock client network adapter for unit tests .
test the top - level plug method .
httperror is converted to virtualinterfaceplugexception .
test the top - level unplug method .
httperror is converted to virtualinterfaceplugexception .
tests that a vif can be created . mocks neutron net
tests that a vif need not be created .
tests that a delete of the vif can be done .
create a volume snapshots .
the access url with token parameter .
authorise the console token and store in the database .
validate the token .
remove all console authorizations for the instance .
remove all expired console authorizations for the host .
ensure invalid auth schemes are not supported .
returns a dict in the format
return booleanized version of body dict .
"start / stop host maintenance window . on start , it triggers guest vms evacuation ."
sets the specified host 's ability to accept new instances . : param enabled : a boolean - if false no new vms will be able to start on the host .
"reboots , shuts down or powers up the host ."
shows the physical / usage resource given by hosts .
check if the pci_dev meet spec requirement
"returns ( domain , bus , slot , function ) from pci address that is stored in pcidevice db table ."
parse a fully - specified pci device address .
assembles pci address components into a fully - specified pci address .
"given the device name , returns the pci address of a device and returns true if the address is in a physical function ."
get the sysfs path based on the pci address of the device .
get the interface name based on a vf 's pci address .
get the mac address of the nic based on its pci address .
get the vf number based on a vf 's pci address
"given the vf pci address , returns the net device name ."
"use the ' ram_free ' for a particular instance_type advertised from a child cell 's capacity to compute a weight . we want to direct the build to a cell with a higher capacity . since higher weights win , we just return the number of units available for the instance_type ."
compute operation requiring claimed resources has failed or been aborted .
test if this claim can be satisfied given available resources and optional oversubscription limits
test if the given type of resource needed for a claim can be safely allocated .
compute operation requiring claimed resources has failed or been aborted .
appends process_id of instance to cache .
removes pid of process from cache .
kills the running processes for given instance .
create a new abstract image
create a new local image object
create a new local file object
create a new local file object
create a new rbd image object
convert suds object into serializable format .
gets the properties of the managed object specified .
gets the list of objects of the type specified .
gets the list of inner objects of the type specified .
builds the property spec object .
builds the object spec object .
builds the property filter spec object .
gets the list of properties for the collection of objects of the type specified .
get the about info from the service content .
stubs out the vmwareapisession 's get_vim_object method .
stubs out the vmwareapisession 's vim property access method .
stubs out the vmwareapisession 's is_vim_object method .
set the stubs .
test response 200 .
test response 404 .
test response 403 .
test some other return from keystone .
test if we get a keystoneauth exception .
test endpoint not found .
"return the cell type , ' api ' , ' compute ' , or none ( if cells is disabled ) ."
manager calls this so drivers can perform periodic tasks .
return the list of hosts that have a running service for topic .
"returns a list of lists of selection objects that have been chosen by the scheduler driver , one for each requested instance ."
returns the desired output of the api from an object .
return all migrations using the query parameters as filters .
return all migrations using the query parameters as filters .
return all migrations using the query parameters as filters .
query a full first page and ensure an empty second one .
provide a testsuite to the discovery process .
"implements cmp(rec1 , rec2 ) for the first key that is different ."
return the name of the property used as the marker identifier .
get an instance of the marker record by i d.
get the identifier of the marker record by value .
"list records by filters , sorted and paginated ."
get a cross - cell list of records matching filters .
returns xml for libvirt .
detach the volume from instance_name .
tests the case that versioned notifications are disabled which makes _ send_versioned_instance_update_notification a noop .
tests the case that versioned notifications are disabled and assert that this does not prevent sending the unversioned instance.update notification .
"tests the case that we fail to generate the image ref url because conf.glance.api_servers is n't set and we have a context without an auth token , like in the case of a periodic task using an admin context . in this case , we expect the payload field ' image_ref_url ' to just be the instance.image_ref ( image id for a non - volume - backed server ) ."
tests the case that we fail to generate the image ref url because an endpointnotfound error is raised up from the image api but the context does have a token so we pass the error through .
"returns a tuple of ( session , image_id ) . if the supplied ` id_or_uri ` is an image id , then the default client session will be returned for the context 's user , along with the image id . if the supplied ` id_or_uri ` parameter is a uri , then a client session connecting to the uri 's image service endpoint will be returned along with a parsed image id from that uri ."
returns a client session that can be used to query for image information .
generate an image url from an image_ref .
"retrieves all information records about all disk images available to show to the requesting user . if the requesting user is an admin , all images in an active status are returned . if the requesting user is not an admin , the all public images and all private images that are owned by the requesting user in the active status are returned ."
"retrieves the information record for a single disk image . if the supplied identifier parameter is a uuid , the default driver will be used to return information about the image . if the supplied identifier is a uri , then the driver that matches that uri endpoint will be used to query for image information ."
"creates a new image record , optionally passing the image bits to backend storage ."
"update the information about an image , optionally along with a file handle or bytestream iterator for image bits . if the optional file handle for updated image bits is supplied , the image may not have already uploaded bits for the image ."
delete the information about an image and mark the image bits for deletion .
transfer image bits from glance or a known source location to the supplied destination filepath .
wraps execute calls for mounting a quobyte volume
wraps execute calls for unmouting a quobyte volume
runs a number of tests to be sure this is a ( working ) quobyte mount
connect the volume .
disconnect the volume .
deletes a requestspec by the instance_uuid .
create a flavor .
create a new hashring .
returns a ketama compatible hash from the given key .
calculate the weight factor of the given node and yield its hash key for every configured replica .
python 2 compatible int iterator from str .
generate a ketama compatible continuum / ring .
remove the given node from the continuum / ring .
"given three pairs of ( x , y ) points return the vertex of the parabola passing through the points . vectorized and common expression reduced ."
transform [ batch ] matrix x with left multiplication : x -- > ax .
transform [ batch ] matrix x with left multiplication : x -- > ax .
gradient of s is g^t . cdct^-1.(g - dobs ) + cm^-1.(m - mprior )
info : 获得请求参数，包括get和post，其他类型的访问不管
short time fourier transform of audio signal : param sig : array of amplitude values from audio file : param nfft : number of ffts : param overlapfac : percentage of window overlap : return : transpose of values that make up spectrogram
scale frequency axis logarithmically : param spec : initial values that make up spectrogram : param sr : samples / sec : param factor : exponential growth rate factor : return :
function to allow code reuse : param ax : : param p : : return :
optimize and save spectrogram : param conf : configuration settings for the spectrogram : param samples : samples to create spectrogram from : param plotpath : path to the file to save the output to : return :
smooth and normalize the spectrogram array . creates an image and writes to a file : param q : the spectrogram array : param conf : configuration settings : param factor : factor to multiply to standard deviation for normalization : param maxm : max index in the array to keep : param minm : min index in the array to keep : param mval : mean value for normalization : param plotpath : path to file to save the results to ( png file ) : param sval : standard deviation for normalization : return :
optimize and save spectrogram : param conf : configuration settings for the spectrogram : param samples : samples to create spectrogram from : param plotpath : path to the file to save the output to : return :
optimize spectrogram ans and optionally save spectrogram : param samples : array of db values from audio file : param sample_rate : samples / sec of audio : param binsize : bins / sec of audio : param plotpath : location of produced spectrogram : return : enhanced spectrogram
cancel the next selection update coming from qt .
retrieves model amount data and converts it to a displayamount .
converts displayamount into a tuple of currency and value widths .
sizehint returns a qsize of the required size to draw the amount .
paints the amount within the bounding box provided in the option parameter .
toggle the reconcile flag of selected entries
return outputted filename with # # # # for padding
"if a log file passes midnight , increment the current_day . pass it current_timestamp and a new timestamp ( this_timestamp ) and it will checks whether this_timestamp is earlier in the 24 hour day than current_timestamp ; if so , we 've gone past midnight ( e.g. 23:59:59 > 00:00:00 ) and need to set current_timestamp to this_timestamp + 1 day ."
"parameters ---------- target : ocgis field the target distribution the different candidates are compared to . candidate : tuple sequence of variable names identifying climate indices on which the comparison will be performed . dist : { ' seuclidean ' , ' nearest_neighbor ' , ' zech_aslan ' , ' kolmogorov_smirnov ' , ' friedman_rafsky ' , ' kldiv ' } name of the distance measure , or dissimilarity metric ."
reshape the input arrays to conform to the conventions used in the dissimilarity metrics .
standardize x and y by the square root of the product of their standard deviation .
compute the euclidean distance between the mean of a multivariate candidate sample with respect to the mean of a reference sample .
compute a dissimilarity metric based on the number of points in the pooled sample whose nearest neighbor belongs to the same distribution .
compute the zech - aslan energy distance dissimimilarity metric based on an analogy with the energy of a cloud of electrical charges .
compute the skezely - rizzo energy distance dissimimilarity metric based on an analogy with the energy of a cloud of electrical charges .
compute a dissimilarity metric based on the friedman - rafsky runs statistics .
compute the kolmogorov - smirnov statistic applied to two multivariate samples as described by fasano and franceschini .
compute the kullback - leibler divergence between two multivariate samples .
"> > > lzwdecode(b' ` p ""  ' ) ' -----a --- b '"
"returns a tuple ( r , i , j ) such that r = gcd(a , b ) = ia + jb"
runs hdparm against device and displays its output
return to filesystemview
presents the user with a question
checks that the system this tool is being run on contains a recovery partition
"finished answering wizard questions , and can continue process"
calls an external application for burning this iso
overridden method to make us generate os media
asks the user before closing the dialog
hides the progress bar
stops any running spinners and updates gui items
updates the progressbar to show what we are working on
prepares our gtk assistant
"alias for "" invoke test --style """
"run tests ( unit , style )"
calculate the log likelihood of the observed topic proportions . a negative likelihood is more likely than a negative likelihood .
the tracking class keeps a most recently used cache of values
add an item with a particular to the cache .
get the statistics for items with a particular key
"run an xml edit script , and return the new html produced ."
remove any indentation and newlines from the html .
construct a new pileup .
"append a pileupelement to this pileup . if an identical pileupelement is already part of this pileup , do nothing ."
add all pileup elements from other into self .
"apply filters to the pileup elements , and return a new pileup with the filtered elements removed ."
outputs the given dict as json
renders a jinja2 template
outputs a file with the given mimetype
parses an spk file
builds an spk file containing the apk data specified
parses an spk file
builds an spk file from the encrypted key and data specified
decrypts an rsa - encrypted key
decrypts the apk data using the specified aes key
encrypts the apk data using the specified aes key
lists all detected mtp devices
send a ptp / mtp command without data phase
send a ptp / mtp command with write data phase
send a ptp / mtp command with read data phase
initialize new line manager dict .
return sphinx config object .
expand to a new release line with given ` ` major_number ` ` .
returns true if ' unstable prehistory ' behavior should be applied .
returns release family numbers which are n't 0 ( i.e. prehistory ) .
returns whether stable ( post-0.x ) releases seem to exist .
"takes a view , calculates its dominator tree , and highlights its loops ."
baseline exponential density profile
baseline power - law density profile
modified power - law density profile tuned to match mpa models
constructs a gp interpolator based on a simple grid of values
adds a usb pid to the list of pids to look for when searching for apt controllers
return a function that will call both the ipython kernel execepthook and ida 's
perform an iteration on ipython kernel runloop
write on both the previously saved ida std output and zmq 's stream
produce an item type .
register effect instance customizer for all item types .
get types of messages which this modifier cares about .
decide if modification value may change .
add item to the container against key .
remove item from the container via its key .
remove everything from the container .
create new instance of container based on passed containers .
access point to skill level .
add item to the container .
remove item from the container .
remove everything from the container .
generate decoding graphs for each token for our cleanup module .
returns a magicmock ( ) with some methods of dbhandler to fit these tests here .
returns a magicmock ( ) with some methods of qchandler to fit these tests here .
@status : done
"when a dictfield has an value - field , to_internal_value should return a dict of elements resulting from the application of the value - field 's to_internal_value method to each value of the input data dict ."
"when a dictfield has an value - field , to_representation should return a dict of elements resulting from the application of the value - field 's to_representation method to each value of the input object dict ."
"when a dictfield is given a non - dict value , then validate should raise a validationerror ."
"when a dictfield is given a dict whose values are valid for the value - field , then validate should not raise a validationerror ."
"when a dictfield is given a dict containing values that are invalid for the value - field , then validate should raise a validationerror ."
get test image from sat - testdata
return a integration instance specified by ` integration ` name
amount : the amount of money to authorize . options : required : callerreference sendertokenid transactionamount
has to be overridden by the subclasses
check a credit card number for validity using the mod10 algorithm .
returns a creditcard from the submitted ( cleaned ) data .
"test _ _ init _ _ , customize_agent_state , and parse_bridge_mappings ."
test the port_update override .
test heal_and_optimize and _ refresh_bridge_mappings_to_neutron .
download and extract twitter - korean - text jar file
encode a string value as short string and append it to pieces list returning the size of the encoded value .
encode a dict as an amqp table appending the encded table to the pieces list passed in .
encode the value passed in and append it to the pieces list returning the the size of the encoded value .
decode the amqp table passed in from the encoded value returning the decoded result and the number of bytes read plus the offset .
decode the value passed in returning the decoded value and the number of bytes read in addition to the starting offset .
ensure that the readme is in sync with the docstring .
"takes a qs , size ` request ` and returns paginated data"
receives a post request and creates a response for a specific question
handles upvoting responses
sends a message back to the channel the original msg came from .
"receives a message and tries to figure out the tilte . the official format is that the title is the alphanumeric string before the first new line character ` ` . if this does nt return a valid title we take the string before and including the first question mark . if nothing matches , we will return ` none ` ."
"receives a message from slack and creates a question based on the content . this endpoint get triggered , only if the slack message contains a trigger word , usually ' @devolio ' or ' devolio ' ."
returns distance unit used by a given region .
returns true if the app is running in development .
copies the properties of the given db . model into a struct .
returns a generator that yields struct objects .
"calls set_func , then waits until test_func passes before returning ."
returns the given html with tags stripped ( minus those in tag_whitelist ) .
converts a utc datetime object to a scalar posix timestamp .
converts a scalar posix timestamp to a utc datetime object .
generates a random identifier made of 12 url - safe characters .
returns a short string describing a relative time in the past .
gets the contents of a file from either the app or static directory .
populates a new struct from an ndb . model ( does n't take a db . model ) .
creates a maproot dictionary for a sharks map with kml layer .
this endpoint is only for setting up data for system tests .
stores a test map from a given file into the datastore .
stores a test map from a given maproot in the datastore .
tests getdestination with old - style id= and crisis= parameters .
tests getdestination with no label parameter .
selects a handler for the request according to app.app and executes it .
sets up a webapp2.request object for testing .
context manager : signs in a non - google - apps user .
context manager : signs in a google apps user .
"context manager : signs in as user ' root ' , which always has admin access ."
ensures that the user for a login context exists in the datastore .
sets up a requesthandler object for testing .
makes a replacement for datetime.datetime with a fixed value for now ( ) .
a replacement for makerandomid ( ) that gives predictable ids in tests .
makes a context manager that sets up a cookie jar for doget / dopost .
dispatches a get request according to the routes in app.py .
dispatches a post request according to the routes in app.py .
"removes all the tasks from a given queue , returning a list of dicts ."
gets the content of the post data for a task as a string .
"gets the post parameters for a task as a list of ( key , value ) pairs ."
"executes a task from poptasks , using a given handler ."
"sets an attribute of an object , just for the duration of the test ."
"sets a fake value for the current time , for the duration of the test ."
stubs time.sleep ( .. ) with an update of time returned by time.time ( ) .
checks that a value is within a desired range .
"checks for an expected url , ignoring the order of query params ."
"uses scikit - learn 's perceptron , a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector ."
"uses scikit - learn 's lineardiscriminantanalysis , a classifier with a quadratic decision boundary , generated by fitting class conditional densities to the data and using bayes ’ rule ."
"uses scikit - learn 's selectfrommodel , a meta - transformer for selecting features based on importance weights ."
retunrn a scikit - learn 's methods already configured to make the pipeline .
"uses scikit - learn 's adaboostclassifier , an adaboostclassifier is a meta - estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases ."
execute when someone is calling .
take no action .
handle rssi level change .
update connection report .
update connection mode .
new message action .
create a group .
"update a group 's name , description and/or permission ."
retrieve a group based on its id .
retrieve all groups in the domain .
retrieve one page of groups in the domain .
retrieve all groups that belong to the given member_id .
delete a group based on its id .
add a member to a group .
check whether the given member already exists in the given group .
retrieve the given member in the given group .
retrieve all members in the given group .
retrieve one page of members of a given group .
remove the given member from the given group .
add an owner to a group .
check whether the given member an owner of the given group .
retrieve the given owner in the given group .
retrieve all owners of the given group .
retrieve one page of owners of the given group .
remove the given owner from the given group .
"parse a string containing a < privatekey > or < publickey > , or pem - encoded key ."
merge multiple orderings so that within - ordering order is preserved
add an i / o handler to the loop .
register an io - handler at the polling object .
call the ` interfaces.iohandler.prepare ` method and remove the handler from unprepared handler list when done .
remove an i / o - handler .
a loop iteration - check any scheduled events and i / o available and run the handlers .
convenience function to dig out weather values .
fetches weather report from google
initialize a ` message ` object .
decode the stanza subelements .
return the xml stanza representation .
create a deep copy of the stanza .
message subject .
message body .
thread i d.
create error response for any non - error message stanza .
method decorator generator for decorating event handlers .
method decorator generator for decorating event handlers .
return file descriptor to poll or select .
: return : ` true ` when the i / o channel can be read
stop current thread until the channel is readable .
: return : ` true ` when the i / o channel can be written to
prepare the i / o handler for the event loop or an event loop iteration .
stop current thread until the channel is writable .
handle the ' channel writable ' state . e.g. send buffered data via a socket .
handle the ' channel readable ' state . e.g. read from a socket .
handle the ' channel hungup ' state . the handler should not be writtable after this .
handle an error reported .
handle an ' invalid file descriptor ' event .
"close the channell immediately , so it wo n't expect more events ."
add a new handler to the main loop .
add a new handler to the main loop .
schedule function to be called from the main loop after ` delay ` seconds .
make the loop stop after the current iteration .
` true ` then the loop has been started .
` true ` then the loop has been finished or is about to finish ( the final iteration in progress ) .
run the loop .
single loop iteration .
create a new on - disk database .
open a pre - existing on - disk database .
check if the database contains the specified username .
return a list of usernames in the database .
sets up a mock client which will reuse a saved session .
loads or begins a cached session to record http traffic .
saves the recoded responses to a temp file if the config file allows .
sets up a mock gdataservice v1 client to reuse recorded sessions .
loads or starts a session recording for a v1 service object .
creates a testsuite for all unit test classes in the list .
"create and save a user with the given email , date of birth and password ."
create and save a superuser with the given email .
return the user full name .
return the user first name .
unicode representation of the class .
string representation of the class .
do the user have a specific permission ? checking it .
do the user have permissions to view the app ` accounts ` ? checking it .
checking if the user is a member of staff .
post method for creating new user .
validate that the username is alphanumeric and is not already in use .
verifiy that the values entered into the two password fields match . note that an error here will end up in ` ` non_field_errors ( ) ` ` because it does n't apply to a single field .
validate that the supplied email address is unique for the site .
check the supplied email address against a list of known free webmail domains .
"creates a question with the given ` question_text ` published the given number of ` days ` offset to now ( negative for questions published in the past , positive for questions that have yet to be published ) ."
was_published_recently ( ) should return false for questions whose pub_date is in the future
was_published_recently ( ) should return false for questions whose pub_date is older than 1 day
was_published_recently ( ) should return true for questions whose pub_date is within the last day
"if no questions exist , an appropriate message should be displayed ."
questions with a create_date in the past should be displayed on the index page
questions with a create_date in the future should not be displayed on the index page .
"even if both past and future questions exist , only past questions should be displayed ."
the questions index page may display multiple questions .
the detail view of a question with a create_date in the future should return a 404 not found .
the detail view of a question with a create_date in the past should display the question 's text .
tile class initializer .
"return an ( x , y , w , h ) srcrect for the current graphic frame of the tile ."
"return a copy of our ( x , y , w , h ) dstrect so that external operations do n't change our local variable ."
return the tile at this offset .
helper function to change the tile graphic or animation .
cleanup before deletion .
close review requests as submitted automatically after a push .
return a mapping of review request id to a list of commits .
returns instructions for setting up incoming webhooks .
returns the diffrenderer class used for rendering diffs .
sets the diffrenderer class used for rendering diffs .
returns a diffrenderer instance used for rendering diffs .
renders the diff to an httpresponse .
returns the diff as a string .
renders a diff to a string without caching .
creates and returns a cache key representing the diff to render .
creates and returns context for a diff render .
connect e - mail callbacks to signals .
initialize the signal processor .
register the signal handlers for this processor .
unregister all signal handlers for this processor .
conditionally update the search index when an object is updated .
conditionally update the search index when an object is deleted .
handle a group.users relation changing .
serialize the application field .
serialize the expires field .
serialize the scope field .
return the queryset for the request .
return whether or not the user has access permissions .
return whether or not the user has modification permissions .
return whether or not the user has deletion permissions .
retrieves information on a particular oauth2 token .
retrieve a list of information about an oauth2 token .
"delete the oauth2 token , invalidating all clients using it ."
update the scope of an oauth2 token .
validate the given set of scopes against known valid scopes .
testing changeset defaults
testing commit initialization with diff as byte string
testing commit initialization with diff as unicode string
testing the get / api
testing the get / api with local sites
testing the get / api without access to local site
testing the get / api with multiple local sites
testing the get users/<username>/api - tokens/ api denies access when using token - based authentication
testing the post users/<username>/api - tokens/ api with token generation failed error
testing the post users/<username>/api - tokens/ api denies access when using token - based authentication
testing the delete users/<username>/api - tokens/<id>/ api denies access when using token - based authentication
testing the get users/<username>/api - tokens/<id>/ api with not modified response
testing the get users/<username>/api - tokens/<id>/ api denies access when using token - based authentication
testing the put users/<username>/api - tokens/<id>/ api denies access when using token - based authentication
cache the siteconfiguration settings object .
restore the siteconfiguration settings object .
return the review board version as a human - readable string .
return the review board version as a python package version string .
return whether this is a released version of review board .
return the url to the review board manual for this version .
begin initialization of review board .
initialize the error .
return a string representation of the error .
test the request contains the http basic auth header .
testing http basic auth requests
testing hostingserviceclient.http_request with basic auth
returns links for using this resource .
validate a diff .
builds a django url name from the provided name .
testing bzrtool.check_repository with repository not found
testing bzrtool with a ssh - backed repository
testing bzrtool with a ssh - backed repository with a localsite
testing bzrtool with a sftp - backed repository
testing bzrtool.get_file with timezone offset
testing bzrtool.get_file with settings . time_zone ! = utc
testing bzrtool.get_file with revision id
testing bzrtool.get_file with unknown file
testing bzrtool.get_file with unknown revision
testing bzrtool.get_file with invalid revision
testing bzrtool.files_exists with timezone offset
testing bzrtool.files_exists with settings . time_zone ! = utc
testing bzrtool.files_exists with revision id
testing bzrtool.files_exists with invalid revision
initialize the widget .
render the widget .
testing reviewrequestpageentryregistry.register with already registered entry
testing reviewrequestpageentryregistry.register with already registered entry_type_id
testing reviewrequestpageentryregistry.get_entry with invalid entry id
check whether the user needs to log in .
check whether the profile object exists .
display a list of all review requests .
display the dashboard .
display a list of review requests belonging to a particular group .
display a list of all review groups .
display a list of users registered for a particular group .
"display a user 's profile , showing their review requests and reviews ."
display a list of all users .
creates a new reply to a diff comment on the parent review .
updates a reply to a diff comment .
deletes a comment from a draft reply .
returns information on a reply to a comment .
returns the list of replies to comments made on a review reply .
returns the list of draft per - file diffs on the review request .
updates a per - file diff .
yield each of the items within this section .
yield each of the items within this section .
return extra data to include in the template render context .
yield each of the items within this section .
get the bug info from the server .
create a cipher for use in symmetric encryption / decryption .
return the default aes encryption key for the install .
encrypt data using aes encryption .
decrypt aes - encrypted data .
encrypt a password and encode as base64 .
decrypt an encrypted password encoded in base64 .
decrypt aes - encrypted data .
encrypt data using aes encryption .
set up the review request child tests .
tests json encoding numpy and pandas .
tests msgpack encoding numpy and pandas .
"binary matrices or matrix - vector product in z/2z. works with scipy.sparse.csr_matrix matrices x , y too ."
"computes binary product of h and x. if product is null , x is in the code . returns appartenance boolean ."
"decoding function using belief propagation algorithm ( logarithmic version ) important : if h is large ( n>1000 ) , h should be scipy.sparse.csr_matrix object to speed up calculations ( highly recommanded . ) ----------------------------------- parameters :"
"omp directive may introduce new variables , do the minimal required processing here"
gather required information .
return matched keyword .
"add itertools import for imap , izip or ifilter iterator ."
replace function call by its correct iterator if it is possible .
check correct error is returned for incorrect module import .
check correct error is returned for incorrect module manipulation .
"145 is a curious number , as 1 ! + 4 ! + 5 ! = 1 + 24 + 120 = 145 ."
solve a linear toeplitz system using levinson recursion .
check long to float conversion .
placehorder are identified using an identifier .
initialiser to keep track of arguments .
initialize attributs .
check if list of node are equal .
save matching node or compare it with the existing one .
every node match with it .
match if any of the or content match with the other node .
set have unordered values .
dict can match with unordered values .
check if two fields match .
check if the pattern match with the checked node .
basic initialiser saving pattern and initialising result set .
visitor looking for matching between current node and pattern .
facility to get values of the matcher for a given node .
"simulation d'un pont brownien sur [ ti , tf ] , avec les valeurs extremes bi et bf et n points par unite de temps sortie : - t : positions temporelles des echantillons - b : valeurs des echantillons"
"the number 3797 has an interesting property . being prime itself , it is possible to continuously remove digits from left to right , and remain prime at each stage : 3797 , 797 , 97 , and 7 . similarly we can work from right to left : 3797 , 379 , 37 , and 3 ."
creates a gensim.corpora . dictionary object from given document iterator and serializes it to given dict_file ( filename ) in a memory efficient way . @params : as_text - flag : dictionary saved as text ( default : binary )
"attempts to get image from url , stores it in file . throws exceptions directly from urllib functions ( urlretrieve )"
"takes a cursor ( or any iterable ) of tweets , returns a sorted list of ( url , num_occurrences ) pairs ( sorted by num_occurrences , greatest first ) of all images in the tweets given"
compose functions left to right - allows generators to compose with same order as clojure style transducers in first argument to transduce .
"right compose for stack , left compose to traverse stack afterwards for clojure style transducers . this is an _ intended _ pun on ' reducer compose ' , i.e. , you should use it to compose against the reducer argument to transduce if you want to use a clojure style transducer ."
returns n entites from collection .
"cats items from nested colls into the coll , traverses one level ."
"filter , for composition with generators that take coll as an argument ."
remove any item from collection on traversal if that item meets condition specified in pred .
keep taking until pred is false .
drop n items from collection ( first in dropped ) .
drop so long as pred is true -- then yield values even if pred becomes true again ( triggered once ) .
"take each nth item from a collection , always start on first ( 0 idx ) ."
"with dictionary argument , subsitute each instance of key with value ."
"keep only items that do not return none when pred is called . this is for functions that only return values in certain cases , or which return none for their false value ."
"for each enumerated collection , we can use a function that takes its index and the item to determine whether to keep the result and if so what form to keep it in ."
remove consecutive duplicates .
"if pred changes from true to false or vice versa , we break up the results from that boundary into their own sub - collections ( lists ) ."
partition a collection into sub - collections ( lists ) of size n.
transducer that has a prob ( 0.0 - 1.0 ) of returning item per item in collection .
map a function to sub - collections then cat the subcollections into a collection at the next level up ( traverses one level ) .
"function that can be used to transduce over a collection . that is , it transforms the collection as the collection traverses the reduction process per step through the process ."
"given constructing function or instance of a target collection , transforms input collection through generator and outputs a new collection of type target_collection ."
apply generator to coll to produce an iterable transforming collection . this is basically just to allow semantic equivalence to clojure 's eduction .
tries to find the parent maprenderingjob of a given file from its filename . both the job id found in the first part of the prefix and the entire files_prefix is used to match a job .
"returns a structured dictionary of the output files for this job . the result contains two lists , ' maps ' and ' indeces ' , listing the output files . each file is reported by a tuple ( format , path , title , size ) ."
this function tells whether this job still has its output files available on the rendering storage .
"removes all the output files from this job , and returns the space saved in bytes ( note : the thumbnail is not removed ) ."
initialise entrance switch counter .
return false because this device can not know if it is jammed .
return false because this device can not know if it is jammed .
handle entrance event .
add a ball to the device since the entrance switch has been hit .
return the number of balls entered .
wait for a ball to leave .
return true if entrance switch is inactive .
wait until the entrance switch is inactive .
initialise ejector .
post event .
reorder balls when jammed .
run ball search .
initialise rgb dmd .
initialise platform .
stop platform .
return string representation .
configure rgb dmd .
evaluate result of task .
initialise smart matrix device .
feed hardware in separate thread .
connect to smartmatrix device .
set brightness .
stop platform .
update dmd data .
post queue events .
validate one entry of this player .
no express config .
parse args .
return name .
initialise output .
pulse output .
enable output .
set up pwm .
disable output .
initialise servo .
move servo to position .
todo emulate speed parameter .
todo emulate acceleration parameter .
initialise i2c device on rpi .
open i2c port .
split and return bus + address .
get or open handle for i2c device via pigpio .
write to i2c via pigpio .
read from i2c via pigpio .
read block via i2c.
initialise raspberry pi platform .
initialise platform .
add a command to the command queue .
handle the command queue .
stop platform .
evaluate result of task .
configure a servo .
return current switch states .
configure a switch with pull up .
process switch change .
raise exception .
raise exception .
raise exception .
raise exception .
raise exception .
configure an output on the raspberry pi .
configure i2c device .
move servo to a certain position .
initialise mode .
start the attract mode .
handle start button press .
handle start button release .
handle the result of the start request .
initialise ball save .
return true if this device can exist outside of a game .
make sure timer_start_events are not in enable_events .
enable ball save .
disable ball save .
start the timer .
perform early ball save if enabled .
trigger eject of all scheduled balls .
disable ball save when mode ends .
initialize device manager .
return all devices which are registered as monitorable .
register a monitorable device .
notify subscribers about changes in a registered device .
stop all devices in the machine .
create devices for a collection .
load all devices .
initialise devices .
scan a config dictionary for control_events .
create machine wide control events .
annotate dummy for type annotations .
annotate dummy for type annotations .
annotate dummy for type annotations .
annotate dummy for type annotations .
initialise device collection .
return device by key .
iterate collection .
return of list of device objects which have a certain tag .
return a device object based on its number .
play sound on external card .
parse express config .
parse string config .
this method is called to action a reaction
perform heroku actions
this function establishes a connection to the rethinkdb before each connection
this function closes the database connection when done
dashboard : generate the welcome / status page for the dashboard
dashboard modify subscription : this will allow a user to modify their subscription and account plan
"dashbaord user preferences : this will allow a user to change user preferences , i.e. password"
this will close connections cleanly
this method is called to action a reaction
this method performs the heavy lifting
general response validation
grab analytics from cloudflares api for desired zone
get the zoneid for the specified domain
get the dns records for a domain by domain name
get the zoneid for the specified domain
return a dictionary of records that match searchstring or zoneid
add a new dns record using the rec dictionary as json data
delete the specified dns entry
update dns record
returns data using joins . up to one query . : return : models . queryset
returns data using prefetch . as many queries as different data types . : return :
retrieves the key for a specific path .
retrieves the key for a specific path .
creates a virtual windows registry key .
creates a virtual windows registry key with a mapped registry .
tests the last_written_time property .
tests the number_of_subkeys property .
tests the number_of_values property .
tests the offset property .
tests the properties with a mapped registry .
tests the _ getkeyfromregistry function .
tests the _ joinkeypath function .
tests the addsubkey function .
tests the getsubkeybyindex function .
tests the getsubkeybyindex function with a mapped registry .
tests the getsubkeybyname function .
tests the getsubkeybyname function with a mapped registry .
tests the getsubkeybypath function .
tests the getsubkeybypath function with a mapped registry .
tests the getsubkeys function .
tests the getsubkeys function with a mapped registry .
tests the getvaluebyname function .
tests the getvaluebyname function with a mapped registry .
tests the getvalues function .
tests the getvalues function with a mapped registry .
authenticate with the bitmex api & request account information .
init with key & secret .
called when forming a request - generates api key headers . this call uses ` expires ` instead of nonce .
generate a request signature compatible with bitmex .
downloads ( and compiles ) osmfilter tool from web and calls that osmfilter to only filter out only the road elements .
generate n days until now
start crawler back to numdays
it should not contain ` user_default ` in avail actions
it should still contain other valid keys
print a file
note we use self here as some older ppd use tray rather than inputslot so we may need to query printer in override
print a file
": parameters : variables : dict template parameters , passed through . templates_path : str root directory for transclusions . main_template : str contents of the main template ."
"reads the bing api key from a file called ' bing.key ' returns : a string which is either none , i.e. no key found , or with a key remember to put bing.key in your .gitignore file to avoid committing it to the repo ."
return options as dict from env vars
add a new schema to an existing db
execute transition and persist to storage on success
open db transaction
test that an event - machine schema exists
test that a stream exists
create a new stream if it does n't exist
get event by eventid
get event by eventid
config is requested and this method is called as this module is included ( see bottom of file )
bind event handler
trigger event handler
"subscribe(schema , oid ): lisent for events over websocket"
"unsubscribe(schema , oid ): stop listening for events"
"_ rpc(method , params= [ ] , callback = none , errback = none ): make jsonrpc post to backend"
"_ get(resource , callback = none , errback = none ): make http get to backend"
echo(req ): append return value to terminal as an assignment to a var : ' _ '
schemata(callback = none ): retrieve list of available state machine definitions
"state(schema , oid , callback = none ): get current state"
"machine(schema , callback = none ): get machine definition"
"dispatch(schema , oid , action , payload= { } , callback = none ): dispatch new event to endpoint"
"stream(schema , oid , callback = none ): get all events"
"event(schema , eventid , callback = none ): get a single event"
"exists(schema = none , oid = none , callback = none , errback = none ): test for existance of schema and/or stream"
"load(machine_name , new_schema ): load machine definition as db schema"
"create(schema , oid ): create a new stream"
destroy(schema ): drop from db / destroys a schema and all events
create a segmenter .
segment a sentence .
segment a sentence .
"encode the object as a bytes object : - if it 's already a bytes object , do n't do nothing - else , take its string representation and encode it as a bytes"
convert a ngram to a leveldb key ( a bytes object ) .
": param db : the leveldb object ( used to retrieve / save the nodes ) : param key ( bytes ): the key of the node in the database : param data : should be generally kept as a none . if you have the data , you can pass them as a bytes object . if you pass false , we wo n't try to retrieve them and assume the node does n't exists ."
: returns : the childs of the node as other node objects .
save the node in the database .
update the entropy of the node ( and save it if it changed ) .
create or opent a trie using leveldb as backend .
returns root node
delete the trie that 's in the database .
initialize the model .
adds content versioning to static files by appending a last modification timestamp to the url
redirect to login page if user not logged in
return a list of normalized tags from a string with comma separated tags
convert the argument from markup to html
create an atom feed from the posts
show the latest x blog posts
show a specific blog post alone
shows all posts with a specific tag
shows all posts in a category
shows all posts which are n't in any category
show all posts from a specific year and month
"show the archive . that is recent posts , posts by category etc ."
"webtest 's testapp . patch and unpatch settings before and after each test . webtestmixin , when used in a unittest . testcase , automatically calls _ patch_settings ( ) and _ unpatchsettings ."
test weather the action column is rendered .
if ` inline_actions = none ` no actions should be visible
test is all required methods are called .
test wether all action buttons are rendered .
test dynamically added actions using ` get_actions ( ) `
test view action .
delete action should not be visible without permission .
test delete action .
the customer 's email address . : return :
indicates whether or not the customer would like to receive email updates from the shop .
the date and time when the customer record was created . : return :
the date and time when the customer record was last updated . : return :
the customer 's first name . : return :
the customer 's last name . : return :
the number of orders placed by this customer to a shop .
no documentation available .
no documentation available . : return :
no documentation available . : return :
extra information about the customer . : return :
no documentation available . : return :
no documentation available . : return :
no documentation available . : return :
"tags are additional short descriptors , commonly used for filtering and searching . : return :"
no documentation available . : return :
no documentation available . : return :
the two - letter code ( iso 3166 - 1 alpha-2 two - letter country code ) for the country of the address . : return :
the two - letter abbreviation of the state or province of the address . : return :
the full name of the person associated with the address . : return :
street address . : return :
optional field for the street address . : return :
the city of the address . : return :
the zip / postal - code of the address . : return :
the first name of the person associated with the address . : return :
the phone number of the address . : return :
the name of the state or province of the address . : return :
the name of the country of the address . : return :
the last name of the person associated with the address . : return :
the company of the person associated with the address . : return :
the longitude of the address . : return :
the latitude of the address . : return :
boolean value whether or not the address is to be used as the default address . : return :
attach an image file instead of using a url . : param f : path to image file . : return :
evaluate the binary classification error .
returns the binary classification error balanced across the size of classes .
returns regression error .
implementation of the fast iterative shrinkage - thresholding algorithm to solve a least squares problem with ` l1l2 ` penalty .
estimation of an useful maximum bound for the ` l1 ` penalty term .
implementation of the regularized least squares solver .
efficient solution of different ` l1l2 ` regularization problems on increasing values of the ` l1 - norm ` parameter .
implementation of the fast iterative shrinkage - thresholding algorithm to solve a least squares problem with ` l1l2 ` penalty .
"get the next available rgb frame from the kinect , as a numpy array ."
"get the next available depth frame from the kinect , as a numpy array . low bits in this depth are stripped so it fits in an 8 - bit image channel"
"get the next available depth frame from the kinect , as a numpy array ."
coordinates rect center
return if two rect overlap
return if two rect overlap
check whatever two rect are similar with a tolerance of 10px in center distance and 0.1 in area ratio
return if r1 and r2 satisfy overlapping criterion
return similarity measure between two bounding box
draw all bounding box inside image as red rectangle
iperf -s -d --mss mss
iperf -d -c host -t 60
prepare the data to feed to create the kubeconfig file .
request a service restart in case credential updates were detected .
process shell command line and return output
"get ports for all services related to an infra server - docker : the docker name ( ' prod2 ' , ' dev3 ' , ... )"
build clrmagic.dll using csc or mcs
"register magics function , can be called from a notebook"
defines command ` ` % % cs ` ` .
"this creates a tsr for stamping a box . it is assumed that when called , the robot is grasping a stamp"
"read the given analyze , nifti , compressed nifti or par / rec file , remove singleton image dimensions and convert image orientation to ras+ canonical coordinate system . analyze header does not support affine transformation matrix , though can not be converted automatically to canonical orientation ."
it transforms a numpy array into a vtkimagedata .
function to plot the circle
return the cursor 's pixels .
function to plot the retangle
creates a new mask object . this method do not append this new mask into the project .
creates and return a copy from the mask instance .
basic setup .
returns true if the model is built for training mode .
decodes and processes an image string .
"input prefetching , preprocessing and batching ."
builds the image model subgraph and generates image embeddings .
builds the input sequence embeddings .
builds the model .
sets up the function to restore inception variables from checkpoint .
sets up the global step tensor .
creates all ops for training and evaluation .
the returned path is bytes .
set the proper mapping between csidl _ consts .
override shgetfolderpath functionality .
make sure we can import the platform module .
check thet get_data_dirs uses pathsep correctly .
check thet get_data_dirs uses pathsep correctly .
unset ( and restore ) a fake environ variable .
test that get_env_path transforms an env var .
test that get_env_path returns the default when env var not set .
set up fake modules .
"not frozen , return path to bin dir ."
"not frozen , raise oserror when the path does n't exist ."
setup to mimic frozen darwin .
"teardown , remove frozen attr"
return sub - app path on darwin when frozen .
raises typeerror when no app_names dict is in the kwargs .
"frozen , raise oserror when the path does n't exist ."
setup to mimic frozen windows .
"teardown , remove frozen attr"
return sub - app path on windows when frozen .
"frozen , raise oserror when the path does n't exist ."
setup to mimic linux2 .
"linux , return source relative path if it exists ."
raise if no src rel path .
try to obtain info from the remote object . if remote object does n't support disco fall back to browse ( if fb2b is true ) and if it does nt support browse ( or fb2b is not true ) fall back to agents protocol ( if gb2a is true ) . returns obtained info . used internally .
query remote object about any items that it contains . return items list .
query remote object about info that it publishes . returns identities and features lists .
"gets registration form from remote host . you can pre - fill the info dictionary . f.e . if you are requesting info on registering user joey than specify info as { "" username "" : "" joey "" } . see jep-0077 for details . "" disp "" must be connected dispatcher instance ."
"perform registration on remote server with provided info . disp must be connected dispatcher instance . returns true or false depending on registration result . if registration fails you can get additional info from the dispatcher 's owner attributes lasterrnode , lasterr and lasterrcode ."
unregisters with host ( permanently removes account ) . disp must be connected and authorized dispatcher instance . returns true on success .
changes password on specified or current ( if not specified ) server . disp must be connected and authorized dispatcher instance . returns true on success .
requests privacy lists from connected server . returns dictionary of existing lists on success .
requests specific privacy list listname . returns list of xml nodes ( rules ) taken from the server responce .
"switches privacy list "" listname "" to specified type . by default the type is "" active "" . returns true on success ."
"sets the default privacy list as "" listname "" . returns true on success ."
"set the ruleset . "" list "" should be the simplexml node formatted according to rfc 3921 ( xmpp - im ) ( i.e. node(""list "" , { "" name "" : listname } , payload= [ ... ] ) ) returns true on success ."
"deletes privacy list "" listname "" . returns true on success ."
"checks if the client supports xep-0144 : roster item exchange if it does n't , or it did n't answer us , then transport will use the old method"
unescapes escaped html characters
e.g. base info of yiibai : return :
returns graph title
to get dynamic criteria & return into select box to display on dashboard
returns active graphs
returns an array with new users count per interval .
prepares data for template ( passed as module attributes )
"returns 3 basic chart modules ( today , last 7 days & last 3 months )"
load a raw data file
load a raw data biologic mpr file
initiates the biologicloader class
include the settings for how to decide what kind of step you are examining here .
include the settings for the units used by the instrument .
loads data from biologic . ? files .
load a raw data - file
inspect the file .
try to repair a broken / corrupted file
path prefix to be used when archiving any items from the given folder .
sax parse xml text .
@param tag : the content tag . @type tag : str @param value : the content 's value . @type value : i{any }
"raised exception in case of detected non - ascii url characters may be either unicodeencodeerror or unicodedecodeerror , depending on the used python version 's str type and the exact value passed as url input data ."
url is stored as a str internally and must not contain ascii chars .
@param code : the http code returned . @type code : int @param headers : the http headers included in the received reply . @type headers : dict @param message : the ( optional ) message received as a reply . @type message : bytes
open the url in the specified request .
send soap message . implementations are expected to handle : - proxies - i{http } headers - cookies - sending message - brokering exceptions into l{transporterror }
test utility asserting an expected captured stderr context output and no captured stdout output .
test that the encoding listed in the xml declaration is honored .
: return : : rtype : float
"message receipt this function accepts message receipt from peer , checks if the message hash already been received or not . in case its a already received message , it is ignored . otherwise the request is made to get the full message . : return :"
send full message this function serves the request made for the full message . : return :
transaction executed whenever a new tx type message is received . : return :
message transaction this function processes whenever a transaction having subtype message is received . : return :
token transaction this function processes whenever a transaction having subtype token is received . : return :
transfer token transaction this function processes whenever a transaction having subtype transfertoken is received . : return :
receives ephemeral message : param source : : param message : : return :
receives lattice public key transaction : param source : : param message : : return :
receives lattice public key transaction : param source : : param message : : return :
log converserequest fields without audio data .
log converseresponse fields without audio data .
put object to s3 bucket ( output : dict )
"convert specific string values to boolean ( input : dict , output : dict ) ' true ' to true and ' false ' to false"
"convert json to dict ( input : json , output : dict )"
make request and return binary content
image modifier caller function
make the dictionary for the clustergram.js visualization
pull iin the readme file for the long description
answers with picture with custom text on .
answers with users in conference . does n't show users offline if ` show_offline ` is false .
answers with a news from news . yandex .
"adds self to messages and event 's ` data ` field . through this instance you can access tinydb instance ( data[""tinydbproxy""].tinydb ) . this plugin should be included first !"
run rbldnsd with an ip4trie dataset
performs operation on two operands
add builders and construction variables for acc & cc to an environment .
"this method is called from multiple threads in a parallel build , so only do thread safe stuff here . do thread unsafe stuff in built ( ) ."
calling a memoized dict method
calling a memoized value method
test the platform ( ) function
add default tools .
"converts strings to true / false depending on the ' truth ' expressed by the string . if the string ca n't be converted , the original value will be returned ."
validates the given value to be either ' 0 ' or ' 1 ' .
"the input parameters describe a boolen option , thus they are returned with the correct converter and validator appended . the ' help ' text will by appended by ' ( yes|no ) to show the valid valued . the result is usable for input to opts . add ( ) ."
return a prototype scanner instance for scanning rc source files
add builders and construction variables for gnulink to an environment .
add builders and construction variables for lib to an environment .
add builders and construction variables for gnulink to an environment .
verify that a message constructed without explicitly setting any fields can be encoded .
create a message with a small byte array and encode it . decode it and verify that the decoded message matches the original .
"run a function on the handle that results from opening the file identified by the given path with the given mode . when the function completes , the file handle is automatically closed . resource cleanup is ensured in the case of exceptions ."
find both the lower and upper bounds for a given mean value and dispersion parameter in a poisson distribution .
any zeroes ( values smaller than the cutoff ) found in the given sequence of numbers are offset by the given offset .
"from a ' _ pred ' file as created by tracts , generate a list of theory objects ."
"load a fancyplot from a set of files , specifically the output from tracts ."
"based on the data to be shown by this fancyplot , choose some nice colors . a tuple ( population colors , theory colors ) is returned such that its components can be supplied directly to fancyplot.draw 's second and third arguments ."
draw this fancyplot onto an existing set of axes with the given colors .
create a figure from this fancyplot .
return the absolute path to the global git configuration file .
get a value from the global git configuration file .
initialize pgqadm .
do an http get to control the arduino board .
setup the correct sys.path .
handle error 404
main functionality of webserver
"generate image by hash , usese tempfile :-/"
take 1d float array of rewards and compute discounted reward
backward pass . ( eph is array of intermediate hidden states )
creates a new l{exponentiallydecayingsample } .
clears the values in the sample and resets the clock .
"returns the size of the exponentially decaying sample . the size does not increase if the i{count } exceeds the i{reservoir_size } . instead , we wait until it is time for the sample rescale ."
adds an old value with a fixed timestamp to the sample .
checks the current time and rescales the sample if it time to do so .
creates a statistical snapshot from the current set of values .
"assigns a weight based on a specific timer interval , used to calculate priority for each value ."
"rescales the i{values } , assigning new priorities for each value ."
test wrong arguments to gather
test process_directory ( ) function
test get_cnc ( ) function
test get_cnc ( ) parsing of pocket information
test gather_features ( ) function
test for _ compare_getter_list .
args : x ( pd . dataframe ): a pd . dataframe .
returns the number of splitting iterations in the cross - validator
binarize x based on the fitted cut points .
uploads a notebook : param force : true / false : returns { }
parameters ---------- sequences : list list of variable length feature sequences
compute the local or global relative entropy between two time series treating each as observations from a distribution .
compute the average or local entropy rate of a time series with history length * k * .
compute the ( local ) conditional entropy between two time series .
compute the ( local ) mutual information between two time series .
run the process using pexpect .
make sure prompt is displayed .
edit file with external editor .
refresher object should contain a few handlers : param refresher : : return :
: param refresher : : return :
"if refresh is called a second time , it should be restarted : param refresher : : return :"
callbacks must be called : param refresher :
decorator to populate the dictionary of refreshers with the current function .
creates a pgcompleter object and populates it with the relevant completion suggestions in a background thread .
create test database .
open connection to database . : param hostname : : param password : : param username : : param dbname : string : return : psycopg2.connection
drop database . : param hostname : string : param username : string : param password : string : param dbname : string
close connection . : param connection : psycopg2.connection
test if position is added if last_position is none .
add this method because django does n't validate correctly because required fields are excluded .
hook for specifying the form field instance for a given database field instance .
default user to the current version owner .
simplest possible application object
read full listening history of echo nest data
calculating rates from users ' listening history of echo nest
calculating rates from users ' listening history of echo nest
get full rating matrix with song index at each row
update rating score with average score
get hidden feature matrix by svd method
update residue matrix for each iteration in gradient descent method
stochastic gradient descent method
stochastic gradient descent method with given initail guess
stochastic gradient descent method with flexible learner rate
batch gradient descent method
get hidden feature matrix by stochastic gradient descent method
write hidden features to a json file
get user profile of hidden feature weight by gradient descent method
read all tracks information from million song dataset
"read all tracks information from million song dataset , return dictionaries of msd id with index and song infromation with index"
read user listening logs intercept msd
calculating rates from users ' listening history of msd
get user taste model for prediction
predict user rating score by user model
return a generator that yields watchevents of cls
get from api server if it exists
"if exists , get from api , else create new instance"
"save to api server , either update if existing , or create if new"
write val to addr using only one byte
read one byte from addr
: type n : int : rtype : int
: type area : int : rtype : list[int ]
instantiate a jwtauth while creating the signer inline
test that verify_jwt verifies a valid jwt .
tests that verify_jwt rejects a jwt if the key identifier does not start with the claimed issuer .
tests that verify_jwt rejects a jwt if the claims contains a subject which does not match the issuer .
tests that verify_jwt rejects a jwt if the claims period of validity is greater than the allowed maximum .
tests that verify_jwt rejects a jwt if the jti has already been seen .
tests that verify_jwt accepts a jwt if the jti has already been seen and the verifier has been set to not check the uniqueness of jti .
"trace finds the line , the filename and error message and returns it to the user"
constructor inputs : url - admin url securityhandler - handler that handles site security username - admin username password - admin password
populates server admin information
returns the object as a string
returns the operations
returns the log resources
this operation counts the number of error reports ( crash reports ) that have been generated on each machine . input : machine - name of the machine in the cluster . * means all machines . this is default output : dictionary with report count and machine name
deletes all the log files on all server machines in the site .
returns the current log settings
"the log settings are for the entire site . inputs : loglevel - can be one of [ off , severe , warning , info , fine , verbose , debug ] . logdir - file path to the root of the log directory maxlogfileage - number of days that a server should save a log file . maxerrorreportscount - maximum number of error report files per machine"
"the query operation on the logs resource provides a way to aggregate , filter , and page through logs across the entire site . inputs :"
creates a feature layer object
converts a feature class to json
converts the table to json
converts a json file ( .json ) to a feature class
returns a table as json
gets all the data to pass to a feature service
returns a list of objectids for rows in the attachment table
returns a featureset 's object i d field
merges featureclass into a single feature class
returns the scratch foldre
returns the arcpy scratch file geodatabase
returns a list of fields that are of type date input : fc - feature class or table path output : list of date field names as strings
inserts rows based on a list features object
creates a feature class in a given gdb or folder
converts arcrest api geometry name to python names input : geom_type - string - name of geometry output : name of python geometry type for create feature class function
converts the arcgis rest field types to python types input : field_type - string - type of field as string output : python field type as string
converts a unix time stamp to a datetime object
converts unicode to anscii
constructor inputs : url - admin url securityhandler - handles site security
"the data store configuration properties affect the behavior of the data holdings of the server . the properties include : blockdatacopy - when this property is false , or not set at all , copying data to the site when publishing services from a client application is allowed . this is the default behavior . when this property is true , the client application is not allowed to copy data to the site when publishing . rather , the publisher is required to register data items through which the service being published can reference data . values : true | false"
this operation allows you to update the data store configuration you can use this to allow or block the automatic copying of data to the server at publish time input : datastoreconfig - the json object containing the data configuration output : json message as dictionary
computes the total number of references to a given data item that exist on the server . you can use this operation to determine if a data resource can be safely deleted ( or taken down for maintenance ) . input : path - the complete hierarchical path to the item output : json message as dictionary
you can use this operation to search through the various data items registered in the server 's data store . inputs : parentpath - the path of the parent under which to find items ancestorpath - the path of the ancestor under which to find items . type - a filter for the type of the items i d - a filter to search by the id of the item output : dictionary
registers a new data item with the server 's data store . input item - the json representing the data item . see http://resources.arcgis.com/en/help/arcgis-rest-api/index.html#//02r3000001s9000000 output : dictionary
this resource lists data items that are the root of all other data items in the data store .
validates all the items in the datastore
"in order for a data item to be registered and used successfully within the server 's data store , you need to make sure that the path ( for file shares ) or connection string ( for databases ) is accessible to every server node in the site . this can be done by invoking the validate data item operation on the json object representing the data store . validating a data item does not automatically register it for you . you need to explicitly register your data item by invoking the register data item operation . input : item - the json representing the data item . output : dictionary"
promotes a standby machine to the primary data store machine . the existing primary machine is downgraded to a standby machine .
removes a standby machine from the data store . this operation is not supported on the primary data store machine .
starts the database instance running on the data store machine .
stop the database instance running on the data store machine .
unregisters a data item that has been previously registered with the server 's data store .
checks the status of arcgis data store and provides a health check response .
fake set of mws credentials
get power status of a z / vm instance .
reachable through iucv communication channel .
""" power on z / vm instance ."
reboot a guest vm .
reset z / vm instance .
create z / vm userid into user directory for a z / vm instance .
return true if the instance is powered off .
delete z / vm userid for the instance .
execute commands on the guest vm .
"send back results to client in the json format of : { ' overallrc ' : x , ' modid ' : x , ' rc ' : x , ' rs ' : x , ' errmsg ' : ' msg ' , ' output ' : ' out ' }"
read client request and call target sdk api
"if decorated with bind_call_state , the function receives the call state dictionary as its first argument ."
i 'm allowing the node decorator to be applied without calling because this is how both celery and function_pipes work .
return a handler which connects to a pre - existing i2p process on the default sam port .
return a handler which connects to a pre - existing i2p process on the given sam port . - sam_endpoint : a clientendpoint which points at the sam api
"there 's a bug in python3.4 + , see http://bugs.python.org/issue23773 , remove this and use sys._getframe(3 ) when bug is fixed"
".. note : : we are just checking in ` authhandler ` that the given user is a valid krb5 principal ! we do n't check if the krb5 principal is allowed to log in on the server , because there is no way to do that in python . so if you develop your own ssh server with paramiko for a certain platform like linux , you should call ` ` krb5_kuserok ( ) ` ` in your local kerberos library to make sure that the krb5_principal has an account on the server and is allowed to log in as a user ."
( most ) kwargs get passed directly into sshclient.connect ( ) .
verify that paramiko can handle sshv2 gss - api / sspi authentication ( gssapi - with - mic ) in client and server mode .
failed gssapi - with - mic auth does n't prevent subsequent key auth from succeeding
"check to see if there is a "" pageant "" agent we can talk to ."
communication with the pageant process is done through a shared memory - mapped file .
shuffle the batches in the dataset .
iterate over batches in the dataset .
"the perfstat mode 's main routine . calls all functions to read perfstat data , write csvs and finally create an html . : param perfstat_console_file : path to a console.log file which contains - if available - meta data for perfstats : param perfstat_output_files : list of paths to perfstat files like output.data or data.out . : param result_dir : path to an existing directory . function stores its results in here . : param csv_dir : path to an existing directory inside result_dir . function stores its csv tables in here . : param sort_columns_by_name : boolean , which says whether user wants to sort chart legends by name or by value . : return : none"
"this function reads a performance file in hdf5 format . it holds a hdf5container object to store all collected information . : param asup_hdf5_files : path to an .h5 file which contains performance data . : return : all chart data in tablelist format ; ready to be written into csv tables . additionally an identifier dict , which contains all required meta data about charts , labels or file names ."
"gets meta data from header file . : param header_file : path to a header file as string . may be none . : return : node name , cluster name , and time zone as strings . values might be none ."
reads a xml info file and collects unit and base information from it . buffers xml ' row ' elements and sends them one after another to the container for managing them . : param container : a xmlcontainer object which holds all collected xml data : param asup_xml_info_file : the path to a ' cm - stats - hourly - info.xml ' file : return : none
"reads a xml data file and collects all useful information from it . buffers xml ' row ' elements and sends them one after another to the container for managing them . in the end , calls the xmlcontainer.process_base_heap ( ) method to perform remaining base conversions . : param container : a xmlcontainer object which holds all collected xml data : param data_file : the path to a ' cm - stats - hourly - data.xml ' file : return : none"
"this function analyzes both , the ' cm - stats - hourly - data.xml ' and the ' cm - stats - hourly - info.xml ' file . it holds a xmlcontainer object to store collected information . : param asup_xml_data_files : list of paths to ' cm - stats - hourly - data.xml ' files ( with unique name extensions ) : param asup_xml_info_file : the path to a ' cm - stats - hourly - info.xml ' file : return : all chart data in tablelist format ; ready to be written into csv tables . additionally an identifier dict , which contains all required meta data about charts , labels or file names ."
recursively extract the transformed data from a given dictionary .
initialize with the given configuration and start the server .
return the context to include in the log statement .
return a list of all stored stat names .
fetch the properties of a stat .
insert a data point
handle the data url .
return the components of the match .
"i 'm not entirely sure about the mocking , so test that ."
test that safe_translation does n't mess with good translations .
test that safe_translation insulates from bad translations .
"logging translation errors is really important , so test it ."
test that uselocale does what it says on the tin .
test that styles tags are converted to inline styles
upload all images in request . files .
delete an image given its object i d.
upload a group avatar .
delete a group avatar .
converts a list of tag objects into a comma - separated slug list .
returns the tag vocabulary as a json object .
get objects that have group perm permission on
delete permissions related to an object instance
remove granular permission perm from user on an object instance
"render a readouts , possibly with overview page ."
"get a list of ( locale , visits ) tuples sorted descending by visits ."
adding / deleting the last post in a thread should update the last_post field
deleting the only post in a thread should delete the thread
assert that two datetime objects are within ` range ` ( a timedelta ) .
saving a new thread should behave as if auto_add_now was set .
saving a new thread that already has a created date should respect that created date .
saving an old thread should not change its created date .
saving a new post should behave as if auto_add_now was set on created and auto_now set on updated .
saving an existing post should update the updated date .
saving a new post should not allow you to override auto_add_now- and auto_now - like functionality .
the content_parsed field is populated .
"if there are no creds , do n't hit the api and return an empty list ."
ensure the token and secret are passed correctly .
"if there are no creds , do n't hit the api and return an empty list ."
ensure the token and secret are passed correctly .
"if there are no creds , do n't hit the api and return an empty list ."
ensure the token and secret are passed correctly .
build a query that matches objects with a content type that matches an action .
hit a simple push endpoint to send a notification to a user .
call every notification handler for a notification .
send simple push notifications to users that have opted in to them .
saving a new post in a thread should update the last_post key in that thread to point to the new post .
updating / saving an old post in a thread should _ not _ update the last_post key in that thread .
the thread.replies value should remain one less than the number of posts in the thread .
sticky threads should come before non - sticky threads .
"after the sticky threads , threads should be sorted by the created date of the last post ."
posts should be sorted chronologically .
sorting threads by creator .
sorting threads by replies .
sorting threads by last_post descendingly .
thread 's last_page property is accurate .
trying to reply to a locked thread should raise an exception .
delete a thread while logged out redirects .
assert ` doc ` contains ` contents ` within the ` slug ` readout .
assert main dash and all the readouts render and do n't crash .
"login , or other setup , then call this ."
"login , or other setup , then call this ."
ensure that a .yaml file has been specified
create or update a sumo web deployment
create or update a sumo celery deployment
create or update a sumo cron deployment
create or update a sumo nodeport
delete an existing sumo nodeport
the product picker page .
the product landing page .
the document listing page for a product + topic .
build and send the announcement emails to a group .
redirect in - product urls to the right place .
deleting a post also removes the flags on that post .
assert forums are inaccessible to the public when restricted .
delete the creator of the last post and verify forum survives .
deleting the only post in a thread should delete the thread
assert that two datetime objects are within ` range ` ( a timedelta ) .
saving a new thread should behave as if auto_add_now was set .
saving an old thread should not change its created date .
saving an existing post should update the updated date .
the content_parsed field is populated .
"verify that after 50 messages , no more are sent ."
preview the wiki syntax content .
send a new private message .
apply action to selected messages .
ajax preview of posts .
approve granular permission request setting a permission entry as approved = true for a specific action from an user on an object instance .
make a user who watches for revision readiness .
have a user watch for revision approval . log in .
"make a revision , and approve or reject it through the view ."
show that a ready(-and - approved ) rev mails ready watchers a ready notification and approved watchers an approved one .
verify product - specific ready for review notifications .
show that an approved rev mails ready watchers nothing and approved watchers an approved notification .
show that neither an approved nor a ready mail is sent if a rev is rejected .
"if a single person is watching ready and approved revisions and a revision becomes ready , send only the readiness email , not the approval one ."
test that newlines in a review message are properly displayed .
the 1st approved revision of a document has major_significance .
have a user watch for revision approval . log in .
"make a revision , and approve or reject it through the view ."
show that a ready(-and - approved ) rev mails ready watchers a ready notification and approved watchers an approved one .
verify product - specific ready for l10n notifications .
verify the escalate cronjob escalates the right questions .
accept - language is case insensitive .
requests for /fr - fr / search should end up on /fr / search
ensure that /en/ gets directed t /en - us/.
/en - us should redirect to /en - us .
' en - us ' and ' en - us ' are both ok in accept - language .
stick with english if you can .
try not to fall back to ' es ' here .
"en - us is a better match for en - gb , es;q=0.2 than es ."
remove model and data dirs for a clean run
extract compressed archives tar.gz
removes all files not ending in extension
makes data science file system for ml modelling
flattens directory tree to single level
compares the json data from file with the new data from trellis plot
executes the trellis plotting - for mean
tests the distanceimt trellis data generation
executes the trellis plotting - for standard deviation
executes the trellis plotting - for mean
tests the magnitudeimt trellis data generation
executes the trellis plotting - for standard deviation
compares the magnitudedistancespectra jsons
executes the trellis plotting - for mean
tests the magnitudedistancespectra trellis data generation
executes the trellis plotting - for standard deviation
instantiate with dictionary of parameters
in the simple case the parameters are valid
applies the smoothing to a given spectrum
retrieving data from hdf5 leads to precision differences use relative error ( i.e. < x % difference )
"when data is stored in a dictionary of arrays , compare by keys"
connect to hdf5 data store
close hdf5 connection
compares two json files by parsing them into strings
get the translation for a string using qt translation api .
add a toolbar icon to the toolbar .
create the menu entries and toolbar icons inside the qgis gui .
cleanup necessary items here when plugin dockwidget is closed
removes the plugin menu item and icon from qgis gui .
run method that loads and starts the plugin
set value from argument
add a value
return sum + y
"if the path is none , there should n't be any import problem"
named import - jedi - vim issue # 8
resolve a named object in a module .
command line runner .
builds a dictionary mapping ycm vim user options to values . option names do n't have the ' ycm _ ' prefix .
this function adjusts the candidate insertion text to take into account the text that 's currently in front of the cursor .
"changes ` /usr / lib / python3.4 / email / utils.py ` to ` email.utils ` . i.e. compares the path with sys.path and then returns the dotted_path . if the path is not in the sys.path , just returns none ."
if not name : name = os.path.basename(path ) name = name.rpartition(' . ')[0 ] # cut file type ( normally .so )
takes a function and returns the params and return value as a tuple . this is nothing more than a docstring parser .
used to have an object to return for generators .
a very weird interface class to this module . the more options provided the more acurate loading compiled objects is .
returns only the faked scopes - the other ones are not important for internal analysis .
check if the object has a ` ` _ _ call _ _ ` ` method .
decorator for makin
"looks at the stack , to see if a debug message should be printed ."
the default debug function
bug : goto assignments on ` ` in ` ` used to raise attributeerror : :
github jedi - vim issue # 44
"speed checks should typically be very tolerant . some machines are faster than others , but the tests should still pass . these tests are here to assure that certain effects that kill jedi performance are not reintroduced to jedi ."
precedence calculation can slow down things significantly in edge cases . having strange recursion structures increases the problem .
all attributes containing a deprecated note should n't be documented anymore . this makes it even clearer that they are not supported anymore .
regression test for httpchannel.maintenance method
"check if there 's any setattr method inside an instance . if so , return true ."
checks if a jedi object ( e.g. ` statement ` ) sits inside a try / catch and does n't count as an error ( if equal to ` exception ` ) . also checks ` hasattr ` for attributeerrors and uses the ` payload ` to compare it . returns true if the exception was catched .
returns the statements used in a module . all these statements should be evaluated to check for potential exceptions .
"splits the header into lines , putting multi - line headers together ."
adj is an adjustments object .
receives the http stream for one request . returns the number of bytes consumed . sets the completed flag once both the header and the body have been received .
parses the header_plus block of text ( the headers plus the first line of the request ) .
"return the boolean value ` ` true ` ` if the case - lowered value of string input ` ` s ` ` is any of ` ` t ` ` , ` ` true ` ` , ` ` y ` ` , ` ` on ` ` , or ` ` 1 ` ` , otherwise return the boolean value ` ` false ` ` . if ` ` s ` ` is the value ` ` none ` ` , return ` ` false ` ` . if ` ` s ` ` is already one of the boolean values ` ` true ` ` or ` ` false ` ` , return it ."
convert the given octal string to an actual number .
"pre - parse command line arguments for input into _ _ init _ _ . note that this does not cast values into adjustment types , it just creates a dictionary suitable for passing into _ _ init _ _ , where _ _ init _ _ does the casting ."
"get a : class:`connectionpool ` based on the host , port , and scheme ."
same as : meth:`urllib3.connectionpool . httpconnectionpool.urlopen ` with custom cross - host redirect logic and only sends the request - uri portion of the ` ` url ` ` .
"same as http(s)connectionpool.urlopen , ` ` url ` ` must be absolute ."
return details of request as html page
return checklist evaluation as rdf / turtle
return checklist evaluation as rdf / xml
return json data for trafficlight display of checklist evaluation
return html page for trafficlight display of checklist evaluation
applies appropriate escaping to the supplied value to allow it to be included in a json string result .
applies appropriate escaping to the supplied value to allow it to be included in html element text .
applies no escaping to the supplied value .
generates a report defined to the supplied output stream .
processes a report template item to the supplied output stream .
process a single query+template structure
decorator to use associated function to render the indicated content types
decorator to use associated function when supplied with the indicated content types
"utility function returns uri of current request ( useful when building new uris with post , etc . )"
default error method using errorvalues
return the list of file extensions that are compatible with this styler .
return the string type of this styler .
upgrade zazu using pip .
get the name of the issue .
get the status string of the issue .
return true if the issue is closed .
get the description of the issue .
get the string type of the issue .
get the string assignee of the issue .
get the url to open to display the issue .
get the string i d of the issue .
return the i d as the string representation .
return the i d as the string representation .
read the settings.yml file in from yaml
"turn a project - location path into a triple of ( protocol , hostname , path )"
"wrangle the list of paths the user gave us . expand if they specify a directory , etc"
iterate through the settings file and do any data coercion necessary
normalise links . * strips wikipedia article prefixes . * replaces spaces with underscores .
test that readall on any type of transport throws an eoferror
teest the ability of tbinaryprotocol to deal with the removal of every byte in the file
test that tbinaryprotocol throws an eoferror when it reaches the end of the stream
test that tbinaryprotocolaccelerated throws an eoferror when it reaches the end of the stream
a cstringio buffer that contains the current chunk we are reading .
refills cstringio_buf .
value -- a value to read from for stringio
analyzes the given callgraph . finds all references to all input variables .
docstring for _ _ init _ _
docstring for _ _ init _ _
docstring for _ _ init _ _
this function name was changed in django 1.10 and removed in 2.0 .
we convert an error code into certain action over start_response and return a wsgi - compliant payload .
inputs : static_content_path ( mandatory ) string containing a file - system level path behaving as served root .
initialize a newly instantiated tag
find all tags in the repository
parse out tag information into an array of tag objects
create a new tag instance from the given string .
create an unbaked blob containing just the specified attributes
the size of this blob in bytes
the binary contents of this blob .
the mime type of this file ( based on the filename )
returns the basename of the blobs file name
the blame information for the given file at the given commit
the tag can be initialized with an optional list of values which expected type depends on the iptc type of the tag .
the key of the tag in the dotted form ` ` familyname.groupname.tagname ` ` where ` ` familyname ` ` = ` ` iptc ` ` .
"the iptc type of the tag ( one of short , string , date , time , undefined ) ."
the name of the tag ( this is also the third part of the key ) .
the title ( label ) of the tag .
the description of the tag .
the photoshop name of the tag .
whether the tag is repeatable ( accepts several values ) .
the name of the tag 's record .
the description of the tag 's record .
convert one raw value to its corresponding python type .
"convert one value to its corresponding string representation , suitable to pass to libexiv2 ."
: return : a string representation of the iptc tag for debugging purposes : rtype : string
converts day count str to quantlib object
log into lockbox .
add a new entry .
test deleting an entry .
test that scattering scales as 1 / wl^4 .
test of scattering calculations .
find the smallest bounding rectangle for a set of points . returns a set of points representing the corners of the bounding box . parameters ---------- points : list an nx2 iterable of points
creates a pipeline that writes entities to cloud datastore .
creates a cloud datastore ancestor query .
creates a pipeline that reads entities from cloud datastore .
main entry point ; defines and runs the wordcount pipeline .
"returns an iterator over words in contents of cloud datastore entity . the element is a line of text . if the line is blank , note that , too . args : element : the input element to be processed returns : the processed element ."
main entry point ; defines and runs the user_score pipeline .
"replaces the top of the stack , tos , with getattr(tos , co_names[arg ] )"
creates a function with the arguments at the top of the stack .
"createsnapshot(name , seqname='s',target = none , targets= [ ] ) returns an animation node for one target or a list of targets target : single object , targets : list of objects"
"createviewsequence(name , sequencename ) returns an animation node for a sequence list"
registers the given ` tqdm ` instance with ` pandas.core.groupby . dataframegroupby.progress_apply ` . it will even close ( ) the ` tqdm ` instance upon completion .
return the elements with the starting date within the given period of time . this can be called like checkstatus.objects.in_period(days=7 ) # checkstatus in last 7 days
returns the checklogs created within the last 24 hours .
returns the checklogs created the previous week ( not including the present day ) .
returns the checklogs created within the last 24 hours with some details averaged .
returns the checklogs created the previous week ( not including the present day ) with some details averaged .
"computes and returns the average , min and max response time within the received checklog queryset ."
sets the option in target only if the given option was explicitly set
"returns a list of scenarios , each scenario being described by two parameters ( yaml and xml filenames by default ) . - content of the fixture output file ( aka expected )"
"user passes no args , should fail with systemexit"
determine the url corresponding to python object
args : firefly : package : kwargs :
args : firefly : package : kwargs :
parent_set_light takes all the set_light params and if there are colors converts the colors into other formats
args : mode : the mode to check . no_motion : check for modes with no motion active . motion : check for modes with motion active .
"gets the zwave package and device alias based off of the type of device , malefactor , and workaround ."
adds a command to the list of supported ff_id commands .
adds a request to the list of supported ff_id requests .
function that is called to send a command to a ff_id . args : command ( command ): the command to be sent in a command object
"function to request data from the ff_id . the returned data can be in any format . common formats should be : str , int , dict"
save config to file
reloads the config from the file .
"gets the config value from the config file . if the value is not in the file and a default is okay , return the default value ."
generates a config object from all the values . raises errors if values are missing .
tries to install all services that are enabled .
gets list of installed services .
return a lambdified function for the cram approximation to exp(-x )
creates a key policy for use of a kms key .
we use repr instead of pickle.dumps(key ) because in pickle dumping the object is not always guaranteed to be the same exact string
"first test , caching some data ."
"second test , using cached data of the first one ."
"third test , two groups , the latter being the parent of the former . then we remove it right after ( with ( 2 , x ) tuple ) to test the creation of a ' write ' log with a deleted resource ( so with no text representation ) ."
text gets correctly extracted .
empty html handled correctly .
` ` false ` ` html handled correctly .
it provides mocked core assets
it patches filtered record and provides a mock
it should create proper sftp uri
it should not allow recursive backups
it should raise connection succeeded warning
it should raise connection fail warning
it should backup local database
backup local database and cleanup old databases
it should create remote dirs
it should guard from connectionexception on remote.mkdirs
it should open remote file w/ proper args
it should search all records
it should return result of backup operation
it should initiate sftp connection w/ proper args and pass
it should initiate sftp connection w/ proper args and key
it should return new sftp connection
it should not error and should return a .dump.zip file str
call a prefixed function based on ' namespace ' .
ensure that the next_state value is in the state values of destination model
"this method must be used in a constraint that must be created in the object that inherits for base.exception . for sale : @api.constrains('ignore_exception ' , ) def sale_check_exception(self ): ... ... self._check_exception"
condition method for the workflow from draft to confirm
returns the list of exception_ids for all the considered base.exceptions
splits : param:`string ` and strips : param:`strip_chars ` from values .
load config settings for this extension from config file .
change the ckan ( pylons ) environment configuration .
add new routes that this extension 's controllers handle .
add new routes that this extension 's controllers handle .
return the ckan 2.0 template helper functions this plugin provides .
render the googleanalytics_header snippet for ckan 2.0 templates .
modifies resource_download method in related controller to attach ga tracking code .
initialize the exampledevice object .
@return : a list of partition device names on the block device . @rtype : str
create a partition table on the block device .
"wipe a device ( partition or otherwise ) of meta - data , be it file system , lvm , etc ."
"wipe the block device of meta - data , be it file system , lvm , etc ."
copy blocks between two infinite levels by looping through the destination 's chunks . make a sub - box of the source level for each chunk and copy block and entities in the sub box to the dest chunk .
calculate the total viewing matrix from given data
determine whether this sphere is visible in frustum
extract and calculate frustum clipping planes from opengl
normalize clipping plane equations
"builds the raw nbt data from the ' mcedit_waypoints.dat ' file to a readable dictionary , with the key being ' < name > ( < x>,<y>,<z > ) ' and the values being a list of [ < x>,<y>,<z>,<yaw>,<pitch>,<dimension > ]"
"loads the ' mcedit_waypoints.dat ' file from the world directory if it exists . if it does n't exist , it sets the ' empty ' waypoint"
saves all waypoint information to the ' mcedit_waypoints.dat ' file in the world directory
adds a waypoint to the current dictionary of waypoints
deletes the specified waypoint name from the dictionary of waypoints
saves the final position of the camera viewport when the world is closed or mcedit is exited
bresenham line algorithm adapted for 3d . slooooow .
test whether or not expfit can model a simple one variable exponential relationship .
test whether expfit correctly handles not a number in input array .
test whether or not expfit2 can model a simple two variable exponential relationship .
test whether or not expfit2 can model a simple two variable exponential relationship in the presence of nans .
generate rollout by iteratively evaluating the current policy on the environment .
"choose an action , given a state , with the current policy network ."
"compute the cumulative discounted rewards , a.k.a . returns ."
computes the average reward per episode .
computes the average reward per most recent episodes / games
computes the average number of steps per episode .
int : the current episode number .
int : the number of steps in the current episode .
int : the total number of steps globally .
float : the score in the current episode .
float : the total score over all episodes .
float : the maximum reward per episode .
creates a new game .
creates a new game where we initially perform some random actions to get a different start to the game .
takes a step in the environment by giving an action and updating all related attributes .
actions to perform after an environment action .
perform an action in an environment with both a step and whatever extra is defined in after_act ( ) .
render the environment .
": obj : ' list ' of : obj : ' ndarray ' of : obj : float , : obj : float , : obj : bool :"
int : the number of actions available in the selected game .
int : available legal actions .
str : the meanings of actions .
"initialize minesweeper rows , cols : int - number of rows and cols on the board sizeofsq : pixels - determines the size of the window , reduce to get smaller window mines : integer - number of mines generated on the board display : bool - chooses weather to display the game with pygame"
initializes the board
computes the neighbor matrix for quick lookups
"takes col , row and grid as input and returns as list of neighbors"
finds amount of mines adjacent to a field .
prints the current state
prints the board
"finds out which values to show in the state when a square is pressed checked : np.array((row , col ) ) to check which squares has already been checked if the field is not a bomb we want to reveal it , if the field is empty we want to find it 's neighbors and reveal them too if they are not a bomb ."
"external action , taken by human or agent row , col : integer - where the agent want to press"
computes the reward for a given action
converts 2d state to one - hot encoded 3d state input : state ( rows x cols ) output : state3d ( row x cols x 10 ) ( if full ) ( row x cols x 2 ) ( if condensed ) ( row x cols x 1 ) ( if image )
return the current value of the potential energy
compute and return the total energy on the current state of pset
return a tuple containing the shape of the measures dataset
return the dimension of the measure : 1 for the energy
"return the string : "" total energy """
update the scatter plot .
return the current value of the potential energy
compute and return the elestic potential energy on the current state of the pset
return the dimension of the measure : 1 for the potential energy
"return the string : "" potential energy """
electrimagnetic field demo
compute and return the elestic potential energy on the current state of the pset
return the current value of the total momentum
compute and return the total momentum of the system
return a tuple containing the shape of the measures dataset
return the dimension of the measure : dim for the momentum
"return the string : "" momentum """
return the current value of the momentum
compute and return the total momentum of the specified particles
return a tuple containing the shape of the measures dataset
return the dimension of the measure : dim : ( 2d or 3d ) for the momentum
return the euclideian distance between * x * and * y *
return country name on country listing ( changeview_list )
figure out the git tag and version - release we 're building .
yield the number of actions for each minute of the game for ` player ` .
"return the minimum , average and maximum number of actions per minutes for ` player ` ."
return a dictionary containing the unit types and the number produced during the game for ` player ` .
return a dictionary containing the building types and the number produced during the game for ` player ` .
return a dictionary containing the action types and the number of time they were executed during the game for ` player ` .
"a new random vector , evenly distributed within a cube of ` size ` sides ."
"a new random vector , evenly distributed within a sphere of ` radius ` ."
"a new random vector , evenly distributed on surface a sphere of ` radius ` ."
length squared . cheaper to calculate .
"return a new vector in the same direction , but given length ( default 1 )"
"return a new vector , the cross product . a x b = ( a2b3 - a3b2 , a3b1 - a1b3 , a1b2 - a2b1 ) this will be at right angles to both self and other , with a length : :"
return the scalar dot product
return the angle between this vector and the given one
"return a new vector , rotated ` angle ` radians about the x axis"
"return a new vector , rotated ` angle ` radians about the y axis"
"return a new vector , rotated ` angle ` radians about the z axis"
"return a new vector , rotated about the given axis"
return any unit vector at right angles to the given vector
update the availability status of the service object .
do a remote call to the service .
args : kwargs :
args : kwargs :
args : cooldown :
testing gh category
keychain will dump all the generic password and generic internet passwords known to the process ( ios only ) .
dispatch to the appropriate class .
returns the /info
"performs a query . either specify * args or * * kwargs , not both . respects query_timeout ."
returns a dict representing where endpoint data should be uploaded .
returns endpoints from the management api .
returns an endpoints from the management api given its name .
adds an endpoint through the management api .
updates an endpoint through the management api .
deletes an endpoint through the management api .
returns the status of the server .
delete one or more objects from the query_objects map
flush objects from the query_objects map
count the number of loaded queryobjects stored in memory
"list the objects as ( uri , version ) pairs"
execute a queryobject query
create a new customqueryobject .
query the custom defined query method using the given input .
get doc string from customized query
helper function to create a test package
round trip the install / uninstall functionality
check for differences in the updatable values .
arguments : consulate_session : consulate session object
filter a list of consulhealthstruct by the blacklists in the kv .
"add tags to each object in a list of consulhealthstruct , acquires catalog for each ' node ' to associate service tags for notificationengine to determine who to alert . consul checks not associated to application or services do not have tags , used list of check_tags or the consul kv check tags to determine who to notify ."
"return alerts that have changed in status , if never put in consul kv return object list if there any warning / critical statuses ."
performs the internal operations to create an alert_list if there is one at all . will not run if another consulalerting instance has acquired a lock on the same catalog
creates a list of consulhealthstruct
used to compare prior node state to current
"filter a list of consulhealtnodestruct by state states : passing , warning , critical , unknown"
no post due to missing api token
no post due to missing site url
"successfully get components , identifies intersecting tag , and posts incident to cachet"
"successfully get response but no component data , does not find tag intersection , does not post incident"
"successfully get components however , because the retrieved components do not match any of the provided tags a valueerror is encountered and we do not post incident"
"unsuccessful get request , skips incident post as a result"
"successfully get components , identifies intersecting tag , but post fails"
replace latextitle layout with title .
update from tabular format 3 to 4 if necessary .
iterate over all layout entity spaces .
get layout entity space by * key * .
iterate over all handles in all entity spaces .
get entity space by * key * or create new entity space .
store * tags * in associated layout entity space .
write all entity spaces to * stream * .
delete * entity * from associated layout entity space . type of * entity * has to be dxfentity ( ) or inherited .
delete layout entity space * key * .
delete all entities from all layout entity spaces .
generator for the dictionary 's keys .
"generator for the dictionary 's items ( ` ` ( key , value ) ` ` pairs ) ."
"return the value for * key * if * key * is in the dictionary , else raises a : class:`keyerror ( ) ` ."
"add item * ( key , value ) * to dictionary ."
remove element * key * from the dictionary . * keyerror * if * key * is not contained in the dictionary .
"return * true * if the dictionary has a key * key * , else * false * ."
return the number of items in the dictionary .
return the number of items in the dictionary .
"return the value for * key * if * key * is in the dictionary , else * default * . if * default * is not given , it defaults to : class:`keyerror ( ) ` , so that this method raises a * keyerror * ."
"add item ` ` ( key , value ) ` ` to dictionary . the key parameter * code * specifies the group code of the * value * data and defaults to ` ` 350 ` ` ( soft - owner handle ) ."
remove element * key * from the dictionary . raises * keyerror * if * key * is not contained in the dictionary .
remove * key * from the dictionary if it is present .
create a new sub dictionary .
"return the value for * key * if * key * is in the dictionary , else the predefined dictionary wide * default * value . parameter * default * is always ignored !"
returns dxf tag at position * index * .
replace dxf tag at position * index * with * dxftag * .
"iterate over data , yielding dxf tags as named tuple * ( code , value ) * ."
append * dxftag * at the end of the tag list .
create a new dxf drawing .
"read dxf drawing from a text * stream * , which only needs a readline ( ) method ."
read dxf drawing from file * filename * .
reads the dxf file * filename * from * zipfile * or the first dxf file in * zipfile * if * filename * is * none * .
attention : private attributes will not be checked in testdrawingproxy !
parse the recently added page and grab all the detail page links as the first step to the cover art .
parse the cover art detail page grabbing : - artist name - album title - album art image
runs array conversion when a file is being saved .
runs the command .
decorator to note which object methods require authorization
request app token from github to operate gists
shorten a long url with git.io service
build up uploaded or updated files ' structure
find a gist by _ i d
convert _ id(id or url ) to id
"a callback func , when type ` -h ` , show help"
a python command - line wrapper with github3.py library to access github gists
list all gists or public only ones
"create public , private or anonymous gists"
update a gist
delete a gist by _ i d
fork a gist by id or url
"if gpustats ( or any other pycuda work ) is used inside a multiprocessing . process , this function must be used inside the thread to clean up invalid contexts and create a new one on the given device . assumes one gpu per thread ."
will set the order of garray in place
pad data to be a multiple of 16 for discrete sampler .
pad data to avoid bank conflicts on the gpu-- dimension should not be a multiple of the half - warp size ( 16 )
for multivariate distributions-- what 's the optimal block size given the gpu ?
creates an sciondserviceinforequest .
initialize ` additional_lines ` of payload . all extensions have to have constant size .
check whether payload length is equal to the allocated space for the extension .
return length of extenion header in bytes .
updates the state of the object .
resets the state of an interfacestate object .
sets the state of the interface to revoked .
returns properly formatted tcintf config parameters
parse a raw : any:`infoopaquefield ` .
parse raw : any:`hopopaquefields`\s .
set an of label to the given value .
get current infoopaquefield and hopopaquefield indexes .
set current infoopaquefield and hopopaquefield indexes .
reverse the direction of the path .
return the : any:`hopopaquefield ` needed to verify the current hof .
get current : any:`infoopaquefield ` .
get current : any:`hopopaquefield ` .
increment the hof idx to next routing hof .
return the interface to forward the current packet to .
"return the current interface , depending on the direction of the segment ."
return the path length in bytes .
"convert a sibra bandwidth class to bps ( bits per second ) . class 0 is a special case , and is mapped to 0bps ."
"convert bps ( bits per second ) to a sibra bandwidth class . bps 0 is a special case , and is mapped to class 0 ."
converts from sibra tick to unix timestamp
converts from unix timestamp to sibra tick
returns the current sibra tick
""" strictly less than equal "" . only returns true if this object 's forward and reverse bandwidth are < = other.fwd and other.rev"
""" less than equal "" . only returns true if this object 's forward or reverse bandwidth are < = other.fwd and other.rev"
convert to a bandwidth class
"apply a list of bandwidth updates to the reservation predictions . the updates are in the form [ ( tick , val ) ] where the former specifies which tick the change happens in , and val is a relative bandwidth change ."
"return the max available bandwidth . as all reservations can not start in the future , the current snapshot is also the maximum bandwidth used ."
test that the manager will open the package .
test that the manager can read the file listing .
test that the manager will generate a new package listing when broken files have been detecetd .
test that the manager can retrieve the correct file name .
test that a file can be read from the package .
test that a file can be written in utf-8 to the package .
tests that the xpi manager correctly reports a missing xpi file .
test for a weird bug in the way we detected properties .
test for a weird bug in the way we detected properties .
tests that createelement and createelementns throw errors .
test that function declarations happen in the right time .
test that function expressions happen in the right time .
test that nested functions are considered in the right order .
whether the path is to a git sub - directory
parse out command line arguments
run the script
if conf is not none : conf = conf ; else : conf = config . conf log = config . log self . log = log # log = conf.log # self.conf = conf # self.conf = conf # conf = conf . conf
cli entrypoint for testing .
return a dict as a list of lists .
return list of params as params .
urlencode a multidimensional dict .
collapse the rst labels to the 18 described by the carlson et al . paper that comes with the rst discourse treebank .
"compute the probability of being in the interval ( a , b ) for a variable with a t distribution ( not truncated )"
compute the density for the non truncated t distribution
compute the quantile for the non truncated distribution
loads the data in numpy array for further processing in tab delimiter format
saves objects returned from load_data
returns the binary test data set .
returns the multiclass test data set .
test rocauc with a binary classifier
test rocauc with a multiclass classifier
test the rocauc quick method
test rocauc without a micro average
test rocauc without a macro average
test rocauc without a macro or micro average
test rocauc without per - class curves
test rocauc with no curves specified at all
test rocauc with label encoding before scoring
test rocauc without label encoding before scoring
test rocauc with classifiers that have a decision function
test rocauc with classifiers that utilize predict_proba
test rocauc with classifiers that have no scoring method
creates a binary classification dataset for use in rankd tests
test rank1d on a random binary classification dataset
test rank1d on occupancy dataset with pandas dataframe and series
test rank2d on a random binary classification dataset
test rank2d on occupancy dataset with pandas dataframe and series
prints the version .
assume utf-8 encoding and return the contents of the file located at the absolute path from the repository joined with * parts .
"reads the _ _ init__.py defined in the version_path to find the get_version function , and executes it to ensure that it is loaded correctly ."
yields a generator of requirements as defined by the require_path which should point to a requirements.txt output by ` pip freeze ` .
quick method :
draws a confusion matrix based on the test data supplied by comparing predictions on instances x with the true values specified by the target vector y.
renders the classification report ; must be called after score .
return a list of potential include directories
return the directory potentially containing compilation_commands.json
return compile flags for src file with same base in the same directory
"return the compile flags for the corresponding src file in ros return the compile flags for the source file corresponding to the header file in the ros where the header file is . todo : does not work , when the workspace is not sourced"
returns dumper for literals with ' | ' style .
returns dumper for baseproduct object as dict .
represents ordereddict for yaml dumper .
dumps ' data ' object to yaml string and saves to specified path .
dumps ' data ' object to yaml string
constructs ordereddict for yaml map . : param node : : return :
helper to create ordereddict for yaml node .
": type feed : feed : param product_names : string list of product names : param feed : core.storage.feed for installed products ( uninstall process ) , core.feed for all products"
"реализация интерфейса , чтобы быть коллекцией"
"реализация интерфейса , чтобы быть коллекцией"
"реализация интерфейса , чтобы быть коллекцией"
"добавить продукт в коллекцию , проверить что валидный , что еще нету в этой коллекции : param product : : return : : raise exception :"
"найти продукт по имени в фиде , добавить в коллекцию : param product_name : : raise exception :"
для апгрейда используется список продуктов с точной версией
make json serilizeable list : return :
для сериализации в json
"получить список имен продуктов , без версий"
"получить список имен продуктов , с версиями"
отсортировать коллекцию в обратном порядке
проверить есть ли уже такой продукт в этой коллекции : param product : : return :
распечатать в удобочитаемом виде
helper callback .
do core sync
заменяет переменные окружения в пути на значения .
специальный метод для синтаксиса envs['key ' ] = ' value '
специальный метод для синтаксиса val = envs['key ' ]
специальный метод для синтаксиса del envs['key ' ]
create command line arguments parser
returns string representaion of platform .
returns runtime os python platform api .
returns runtime bitness .
matches platform with other . used for filtering product by current core platform . : type other : platform
creates platform instance from product yaml representaion . : param data : : return :
loads zoo app config from ' physical_path ' and returns ready - to - use dict object with config .
computer guess a random number you choosed in range 0~100
pop the smallest number from the list
return a sorted list
player guess a random number in range 0~100
"find the location of a dataset on disk , downloading if needed ."
load the mnist digits dataset .
load the cifar10 image dataset .
plot an array of images .
"create a plot of weights , visualized as "" bottom - level "" pixel arrays ."
"create a plot of conv filters , visualized as pixel arrays ."
create a matrix of randomly - initialized weights .
create a vector of randomly - initialized values .
get the outputs from a network that match a pattern .
get the parameters from a network that match a pattern .
rows : a list of items ( all items will be stringified ) fmt : string of chars ' lrc ' for text justification ( default : right ) header : first row will be a table header if true
return first matched filename for rmn_libfile wildcard return none if no match
import librmnshared using ctypes
smooth data using scipy 's uniform_filter
"read , smooth and write field in file"
"url , filename , or string -- > stream"
"fetch data and metadata from a url , file , stream , or string"
install a source file or directory into a destination by symlinking
get best setting of parameters from grid search
distributes work of non - nested cross - validation across slave nodes
wait for new data until node receives a message with mpi_msg_terminate or mpi_msg_test
delete all employees without user relation .
change employee password . change password for current employee if we have no passed employee value .
change employee data for current user .
create a message in the current session .
get and delete all messages for current session .
returns version of coffin package as a three integer value tuple
returns three - tuple for the version of django
returns path of a directory levels_up relative to the start_path
"turns relative urls in < img > and < a > tags to absolute , starting with the ` ` askbot_settings . app_url ` `"
"any absolute links will be replaced with the url in plain text , same with any img tags"
sanitizes an html fragment .
"returns html for the link to the given url todo : may be improved to process url parameters , keyword and other arguments"
"source : http://effbot.org/zone/re-sub.htm#unescape-html removes html or xml character references and entities from a text string . @param text the html ( or xml ) source text . @return the plain text , as a unicode string , if necessary ."
"creates an instance of django 's file storage object based on the file - like object , returns the storage object , file name , file url"
"create an askbot user account , given email address , user name , ( optionally ) password and ( also optionally ) - the default email delivery schedule"
todo : add real file attachment
"for a list or a tuple ( ' one ' , ' two ' , ) return a list formatted as [ ' 1 ) one ' , ' 2 ) two ' , ]"
"inserts one space between words , including one space before the first word and after the last word . string without words is collapsed to ''"
"takes text , representing a loosely formatted list ( comma , semicolon , empty space separated words ) and returns a list ( ) of words ."
"returns text with redundant spaces replaced with just one , and stripped leading and the trailing spaces"
custom paginator tag inspired from http://blog.localkinegrinds.com/2007/09/06/digg-style-pagination-in-django/
"returns an admin users , usefull for raising flags"
"return random string , length is number of characters"
sets up the test harness .
exits the program if the binary from the given flag does n't run .
rotates and re - centers the arm segment .
start up method for logfile fixture .
logfile : test len ( ) and iteration over logfile method .
logfile : test .start and .end property work correctly .
logfile : test datetime_format and year_rollover properties .
logfile : test if the correct storage engine is detected .
process line .
set up the datastore by connecting to the mongodb instance .
"stores a set of log entries to the datastore . this function may be called multiple times per session , so it must append the log entries in the storage mechanism ."
"called to indicate to the datastore that the session is over . this sets the "" ended "" flag to true on the session ."
retrieves logs for the given session .
retrieves a list of devices associated with the given api key .
retrieves apps for the given device .
"retrieves a list of sessions for a given api key , device , and app ."
adds a device / app combination to the device / app collection .
updates the alias for a device .
updates the alias for an app .
this function returns the raw device name based on an alias .
this function returns raw app name based on an alias .
this function clears datastore of records .
tests that retrieving data from the config file works as expected .
"verify that the login ui does n't exist , and that a blank html page is returned ."
verify that the no authorization user management interface does n't care about user logins and always returns true .
verify that the no authorization use management interface always lets the user through .
verify that there are no api - keys being passed around in no authorization mode .
"the only sort of non - trivial test , verifies that find_associated_websockets says to broadcast to all websocket connections ."
"parses a log message from the mobile api . note , this is a generator function ."
returns the elements that the web interface shows of a log .
parse a raw log line .
takes a parsed_line and converts it to html .
takes a parsed block and converts it to html .
gets a group from a parsed log .
parses a datetime string into a datetime python object .
tracks the messages sent by send message .
grabs a value from form data .
builds a request object .
appends a form to a request object .
gets a cookie from the dictionary of cookies .
sets a cookie in the dictionary of cookies .
restarts the current program . note : this function does not return . any cleanup action ( like saving data ) must be done before calling this function .
return columns not containing and containing the noexpand prefix .
"read a root file , or list of root files , into a pandas dataframe . further * args and * kwargs are passed to root_numpy 's root2array . if the root file contains a branch matching _ _ index _ _ * , it will become the dataframe 's index ."
write dataframe to a root file .
make all the opcodes globals in this module to make it possible to use constructs like opcodes . op_pubkey
the kwargs required depend upon the script type . hash160_lookup : dict - like structure that returns a secret exponent for a hash160 signature_for_hash_type_f : function to return the sign value for a given signature hash signature_type : usually sighash_all ( 1 )
secret_exponent : a long representing the secret exponent public_pair : a tuple of long integers on the ecdsa curve hash160 : a hash160 value corresponding to a bitcoin address
"this function will accept a bip0032 wallet string , a wif , or a bitcoin address ."
create a key from an sec bytestream ( which is an encoding of a public pair ) .
return an integer representing the secret exponent ( or none ) .
"return the wif representation of this key , if available . if use_uncompressed is not set , the preferred representation is returned ."
return a pair of integers representing the public key ( or none ) .
return the netcode
"return the sec representation of this key , if available . if use_uncompressed is not set , the preferred representation is returned ."
"return the sec representation of this key as hex text . if use_uncompressed is not set , the preferred representation is returned ."
"return the hash160 representation of this key , if available . if use_uncompressed is not set , the preferred representation is returned ."
"return the public address representation of this key , if available . if use_uncompressed is not set , the preferred representation is returned ."
return a textual representation of this key .
return the key corresponding to the hierarchical wallet 's subkey
return an iterator yielding keys corresponding to the hierarchical wallet 's subkey path ( or just this key ) .
return a der - encoded signature for a hash h. will throw a runtimeerror if this key is not a private key
return whether a signature is valid for hash h using this key .
yield info for a child node for this node .
yield info for a child node for this node .
p2sh_lookup : dict - like structure that returns the underlying script for the given hash256
"this function creates a set of * patternautomata * patterns , each one responsible for obtaining the i - th relevant deflection in a given scope . it allows to overcome the limitation of having a single hypothesis for a pattern with the same base evidence ( in the case of this pattern , this base evidence is none , since the only transition of the pattern automata does not include any observable , only general constraints ) ."
temporal constraints for the energy interval abstraction pattern
obtains the general constraints function for a specific level .
converts a beat code from the mit - bih to the aami scale
converts a beat code from the aami scale to a corresponding mit - bih
"obtains the character corresponding to a specific code , by performing an inverse search on the charmap dict ."
initializes a new wrapper with an existing iterator
returns the iterator object
obtains the next element in the sequence
checks if the iterator has more elements to return .
return a list of arguments for setting a filesystem uuid .
whether this task can label the filesystem .
whether this task can set the uuid of a filesystem .
any labeling options that a particular filesystem may use .
any uuid options that a particular filesystem may use .
get a list of format options to be used when creating the filesystem .
return the command to make the filesystem .
create the format on the device and label if possible and desired .
create the filesystem with an invalid uuid .
create the filesystem with a valid uuid .
create the filesystem with random uuid and reassign later .
create the filesystem and try to reassign an invalid uuid later .
create the filesystem with random uuid and reset it later .
reasons if this task or the tasks it depends on are unavailable .
"true if the task is available , otherwise false ."
do the task for this class .
: param device : the device name ( generally a device node 's basename ) : type device : str : keyword parents : a list of parent devices : type parents : list of : class:`storagedevice ` : keyword fmt : this device 's formatting : type fmt : : class:`~.formats . deviceformat ` or a subclass of it
device node representing this device .
"open , or set up , a device ."
"close , or tear down , a device ."
create the device .
destroy the device .
build lists of known device and format helper classes .
return the device helper class appropriate for the specified data .
return the device helper class appropriate for the specified data .
construct an external resource that is an application .
construct an external resource that is an application .
construct an external resource that is a libblockdev plugin .
construct an external resource that is always unavailable .
construct an external resource that is always available .
initializes an instance of an external resource .
whether the resource has any availability errors .
whether the resource is available .
returns [ ] if the resource is available .
returns [ ] if the name of the application is in the path .
returns [ ] if the plugin is loaded .
test that a bootloader such as prepboot / biosboot shows up in the kickstart data
return a boolean indicating whether or not the device contains media .
eject the drawer .
": return : the ppc machine type , or none if not ppc . : rtype : string"
": return : the powermac machine type , or none if not ppc or a powermac . : rtype : string"
": return : the ppc generation , or none if not ppc or a powermac . : rtype : string"
": return : true if the hardware is an i_book or powerbook , false otherwise . : rtype : string"
": return : true if the hardware supports aarch64 , false otherwise . : rtype : boolean"
": return : the arm processor variety type , or none if not arm . : rtype : string"
": return : true if the hardware is the cell platform , false otherwise . : rtype : boolean"
": return : true if the hardware is an intel - based apple mac , false otherwise . : rtype : boolean"
": return : true if the hardware supports efi , false otherwise . : rtype : boolean"
": return : true if the hardware supports x86 , false otherwise . : rtype : boolean : param bits : the number of bits used to define a memory address . : type bits : int"
": return : true if the hardware supports ppc , false otherwise . : rtype : boolean : param bits : the number of bits used to define a memory address . : type bits : int"
": return : true if the hardware supports ppc , false otherwise . : rtype : boolean"
": return : true if the hardware supports ia64 , false otherwise . : rtype : boolean"
": return : true if the hardware supports alpha , false otherwise . : rtype : boolean"
": return : true if the hardware supports arm , false otherwise . : rtype : boolean"
: return : the hardware architecture : rtype : string
"return an integer representing the length of the "" word "" used by the current architecture - > it is usually either 32 or 64"
parse a string into a message object model .
read a file and parse its contents into a message object model .
does a little test to see if threading is worth it . sets up a global worker queue if it 's worth it .
cleans up everything .
"does a little test to see if workers are at all faster . returns the number of workers which works best . takes a little bit of time to run , so you should only really call it once . you can pass in benchmark data , and functions if you want . a_bench_func - f(data ) the_data - data to work on ."
"like map , but uses a thread pool to execute . num_workers - the number of worker threads that will be used . if pool is passed in , then the num_workers arg is ignored . worker_queue - you can optionally pass in an existing workerqueue . wait - true means that the results are returned when everything is finished . false means that we return the [ worker_queue , results ] right away instead . results , is returned as a list of funcresult instances . stop_on_error -"
sets up the worker threads note : undefined behaviour if you call this again .
puts a function on a queue for running later .
"stops the workerqueue , waits for all of the threads to finish up ."
loops until all of the tasks are finished .
waits until all tasks are complete .
f - is the function we that we call callback(result ) - this is called when the function(f ) returns errback(exception ) - this is called when the function(f ) raises an exception .
"device : videocapture enumerates the available video capture devices on your system . if you have more than one device , specify the desired one here . the device number starts from 0 ."
displays a dialog containing the property page of the capture filter .
displays a dialog containing the property page of the capture pin .
sets the capture resolution . ( without dialog )
returns a string containing the raw pixel data .
returns a pygame surface .
create a temporary directory that will be cleaned up .
writes a file in the given path .
will generate a test environment .
test an empty maildir mailbox
transmitted when the latest chunk of data is available .
generates zero - mean gaussian data .
start the keyboard input device .
read which keys have just been pressed .
stop the keyboard input device .
reset the input device .
start sampling mouse movements .
read the last - updated mouse position .
stop sampling mouse movements .
clear the input device .
make sure an array has at least 2 dimensions .
create a rolling window from an array .
generate a rectangular window with de - emphasized onset and offset .
generate a symmetric trapezoidal window .
x coordinate of the item in the canvas .
y coordinate of the item in the canvas .
x and y coordinates of the item in the canvas .
visibility of the item .
opacity of the item ( between 0 and 1 ) .
set the item to visible .
set the item to invisible .
set any properties of the underlying qgraphicsitem .
get any property of the underlying qgraphicsitem .
determine if the item intersects with another item .
"instead of minimizing log(1 - d ) , maximize log(d ) ."
"maximizes y_pred , regardless of y_true ."
"minimizes y_pred , regardless of y_true ."
generative moment matching loss with rbf kernel .
"parses tag input , with multiple word input being activated and delineated by commas and double quotes . quotes take precedence , so they may contain commas ."
"given list of ` ` tag ` ` instances , creates a string representation of the list suitable for editing by the user , such that submitting the given string representation back without changing it will give the same list of tags ."
creates a new humiditysensor wrapper .
returns relative humidity level .
processes all available properties and returns results as dictionary .
recursively walks through all available parsers .
in case of usage of yaml.load ` test ` value will be equal to 0 .
runs before each test .
runs after each test .
test we can click ok .
constructor : param canvas :
handle layers being added to the registry so they show up in canvas .
handle a layer being added to the registry so it shows up in canvas .
remove layers from the canvas before they get deleted .
create new project .
zoom to the logic full extent .
zoom to previous view extent .
zoom to next view extent .
zoom to extent of active layer .
add a vector layer .
add a raster layer given a raster layer file name
get pointer to the active layer ( layer selected in the legend ) .
add an icon to the plugins toolbar .
remove an action ( icon ) from the plugin toolbar .
add toolbar with specified name .
return a pointer to the logic canvas .
return a pointer to the main window .
add a dock widget to the main window .
get the legend .
constructor . nothing special here
does this os have topojson installed ?
output the geojson file as topojson
topojson check in windows is a complicated mess
output the geojson file as topojson
attempt to get the install location of nodejs
attempt to get the topojson package installation location
a simple script that returns ( to stdout ) the paths to _ parameter files given a list of directories to search ( as arguments on the commandline ) . this is used in various makefiles to get the input for write_probin.py
this is run before each test
this is run after each test
search twitter for the given query and result results : param query : : type query : : return : : rtype :
takes a fasta file input_file and returns a fasta iterator
takes a fastq file infile and returns a fastq object iterator
shutdown all logging when turning off this cog .
format the specified record as text .
push to the program 's stack .
pop from the program 's stack .
read what is comparable to c 's size_t .
create a router for the given routes . mapper .
dispatch the request to the appropriate controller .
parse dictionary created by routes library .
mozrepl firefox add - on과 연결합니다 .
mozrepl firefox add - on과 연결합니다 .
mozrepl firefox add - on과의 연결을 일시적으로 끊습니다 .
명령을 실행합니다 .
명령을 실행합니다 .
install the server
"return an owserver proxy object bound at ( host , port ) ; default is ( localhost , 4304 ) ."
parse commandline arguments and print result
set up the about dialog
should generate correct oauth signature .
should generate a correct signature with url query parameters .
should generate a correct signature with a non - standard port .
should include uri query parameters .
should not allow overwriting other parameters from the uri query string .
should not overwrite an lti version passed in params
set the roles for the current launch .
"populates the launch data from a dictionary . only cares about keys in the launch_data_parameters list , or that start with ' custom _ ' or ' ext _ ' ."
"createa a new dictionary with all launch data . custom / extension keys will be included . roles are set as a ' , ' separated string ."
invokes report depending on exporter_type set in constructor
stores report to specified file
generate simple unique tool - tip name which can be used . for example as html < div > section i d attribute .
generates separate < div > sections which contains test results output .
if test was run in a loop ( we got few results from the same test ) we will show it in a column to see all results . this function produces html table with corresponding results .
gets all unique test ids from all ran tests . we need this to create complete list of all test ran .
export test results in proprietary html format .
export test results in junit xml compliant format
generates the project files
converts the folder structue to iar project format .
inserts a source file into the folder tree
returns the directory of the file
set up the threshold sensor .
initialize the threshold sensor .
return the name of the sensor .
return true if sensor is on .
no polling needed .
return the sensor class of the sensor .
return the state attributes of the sensor .
get the latest data and updates the states .
set up the bitcoin sensors .
initialize the sensor .
return the state of the sensor .
return the unit the value is expressed in .
"return the icon to use in the frontend , if any ."
return the state attributes of the sensor .
get the latest data and updates the states .
initialize the data object .
get the latest data from blockchain.info .
common setup for envisalink devices .
initialize the device .
return the name of the device .
set up the insteon local switch platform .
request configuration steps from the user .
set up the switch .
small configuration file management function .
initialize the device .
return the the name of the node .
return the id of this insteon node .
get the updated status of the switch .
return the boolean response if the node is on .
turn device on .
turn device off .
setup tellstick switches .
return true if switch is on .
turn the switch on .
turn the switch off .
return the icon .
double - decode required .
convert pid from hex string to integer .
setup torque platform .
initialize a torque view .
handle torque data request .
initialize the sensor .
return the unit of measurement .
return the default icon of the sensor .
receive an update .
helper method to generate urls .
initialize a home assistant server .
stop everything that was started .
stop everything that was started .
test if we can get the frontend .
test for http 404 error .
test that post is not allow to root .
all served by index .
test an install attempt on an existing package .
test an install attempt on a package that does n't exist .
test an upgrade attempt on a package .
test an install with a target .
test an install with a target .
test for a globally - installed package .
test for a locally - installed package .
test for an installed zip package .
setup the connection to the knx ip interface .
close the nkx tunnel connection on shutdown .
initialize the configuration .
the name given to the entity .
the address of the device as an integer value .
the group address the device sends its current state to .
initialize the device .
the entity 's display name .
the entity 's configuration .
"return the state of the polling , if needed ."
"return true if the value is not 0 is on , else false ."
return the knx group address .
return the knx group address .
the name given to the entity .
write to the group address .
get the state from knx bus or cache .
initialize the device .
check if the attribute with the given name is defined .
return the value to a given named attribute .
set the value of a given named attribute .
create zwave entity device .
return the brightness and state .
convert color temperature ( mireds ) to rgb .
initialize the light .
update internal properties based on zwave values .
called when a value for this entity 's node has changed .
return the brightness of this light between 0 .. 255 .
return true if device is on .
flag supported features .
turn the device on .
turn the device off .
initialize the light .
search for color values available on this node .
called when a value has been added to the network .
update internal properties based on zwave values .
return the rgb color .
return the color temperature .
turn the device on .
flag supported features .
setup tellstick lights .
initialize the light .
flag supported features .
turn the value from ha into something useful .
turn the value recieved from tellcore into something useful .
update the device entity state to match the arguments .
let tellcore update the actual device to the requested state .
set up things to be run when tests are started .
stop everything that was started .
test the moon sensor .
test the moon sensor .
setup hikvision binary sensor devices .
initialize the data oject .
shutdown hikvision subscriptions and subscription thread on exit .
return list of available sensors and their states .
return camera i d.
return camera name .
initialize the binary_sensor .
extract sensor state .
extract sensor last update time .
return the name of the hikvision sensor .
return an unique id .
return true if sensor is on .
"return the class of this sensor , from device_classes ."
return the state attributes .
"update the sensor 's state , if needed ."
setup the bose soundtouch platform .
create a zone ( multi - room ) and play on all devices .
create a zone ( multi - room ) on a master and play on specified slaves .
add slave(s ) to and existing zone ( multi - room ) .
remove slave(s ) from and existing zone ( multi - room ) .
create soundtouch entity .
return specific soundtouch configuration .
return soundtouch device .
retrieve the latest data .
volume level of the media player ( 0 .. 1 ) .
return the state of the device .
boolean if volume is currently muted .
flag media player features that are supported .
turn off media player .
turn the media player on .
volume up the media player .
volume down media player .
"set volume level , range 0 .. 1 ."
send mute command .
simulate play pause media player .
send play command .
send media pause command to media player .
send next track command .
send the previous track command .
image url of current playing media .
title of current playing media .
duration of current playing media in seconds .
artist of current playing media .
artist of current playing media .
album name of current playing media .
play a piece of media .
setup the mysensors climate .
return true if unable to access real state of entity .
return the unit of measurement .
return the current temperature .
return the temperature we try to reach .
return the highbound target temperature we try to reach .
return the lowbound target temperature we try to reach .
"return current operation ie . heat , cool , idle ."
list of available operation modes .
return the fan setting .
list of available fan modes .
set new target temperature .
set new target temperature .
set new target temperature .
update the controller with the latest value from a sensor .
set new target humidity .
set new target swing operation .
turn away mode on .
turn away mode off .
turn auxillary heater on .
turn auxillary heater off .
set up the hp ilo sensor .
initialize the sensor .
return the state attributes .
get the latest data from hp ilo and updates the states .
initialize the data object .
get the latest data from hp ilo .
setup things to be run when tests are started .
stop everything that was started .
test track sunrise decorator .
test track sunset decorator .
test tracking time change .
test track_state_change .
send a time changed event .
set up the web scrape sensor .
initialize a web scrape sensor .
return the state of the device .
get the latest data from the source and updates the state .
setup the demo lock platform .
initialize the lock .
no polling needed for a demo lock .
return the name of the lock if any .
return true if lock is locked .
lock the device .
unlock the device .
setup the introduction component .
setup an endpoint for the gpslogger application .
initialize gpslogger url endpoints .
a gpslogger message received as get .
handle gpslogger request .
setup things to be run when tests are started .
stop everything that was started .
test configuration .
test configuration .
test configuration .
test configuration .
test configuration .
test with 0 cover .
test with 1 cover .
test with 3 covers .
test with discovery of covers .
test with discovery of cover when auto add is false .
load up the module to call the is_on method .
turn specified entity on if possible .
turn specified entity off .
toggle specified entity .
stop home assistant .
stop home assistant .
check the config files .
reload the core config .
setup general services related to home assistant .
get the html5 push notification service .
load configuration .
save configuration .
"decode object if it 's a bytes object , else defer to baseclass ."
init html5pushregistrationview .
accept the post request for push registrations from a browser .
delete a registration .
init html5pushcallbackview .
find the registration that signed this jwt and return it .
check the authorization header .
accept the post request for push registrations event callback .
initialize the service .
return a dictionary of registered targets .
send a message to a user .
setup things to be run when tests are started .
test template .
test icon template .
test templating syntax error .
test missing attribute template .
test invalid name .
test invalid sensor .
test no sensors .
test missing template .
set up the haveibeenpwnedsensor sensor .
initialize the haveibeenpwnedsensor sensor .
return the name of the sensor .
return the atrributes of the sensor .
update sensor without throttle .
update data and see if it contains data for our email .
initialize the data object .
set the next email to be looked up .
get the data for a specific email .
get the latest data for current email from rest service .
setup things to be run when tests are started .
stop down everything that was started .
test if methods call the services as expected .
test the provided services .
test simple function ( executor ) .
test simple function ( executor ) and unsub .
test simple callback ( async ) .
test simple coro ( async ) .
test simple function ( executor ) .
test configuration .
test configuration .
test invalid configuration .
test invalid configuration .
test invalid configuration .
test configuration .
test with 0 switches .
test with 1 switch .
test with 1 switch .
test with 3 switches .
test with discovery of switches .
test with discovery of switch when auto add is false .
setup the pocketcasts platform for sensors .
initialize the sensor .
update sensor values .
return the name of the sensor .
return the sensor state .
return the icon for the sensor .
validate the configuration and returns a tomato scanner .
initialize the scanner .
scan for new devices and return a list with found device ids .
return the name of the given device or none if we do n't know .
ensure the information from the tomato router is up to date .
"create mock rflink asyncio protocol , test component setup ."
test sending unknown commands does n't cause issues .
test command sending without ack .
an unexpected disconnect should cause a reconnect .
a failure to reconnect should be retried .
sending command should error when not connected .
setup s20 switches .
initialize the s20 device .
polling is needed .
return the name of the switch .
return true if device is on .
update device state .
turn the device on .
turn the device off .
set up the system monitor sensors .
initialize the sensor .
return the name of the sensor .
"icon to use in the frontend , if any ."
"return the unit of measurement of this entity , if any ."
get the latest system information .
setup things to be run when tests are started .
stop everything that was started .
test request config with least amount of data .
test request config with all possible info .
test if our callback gets called when configure service called .
test state change on notify errors .
test if notify errors fails silently with a bad request i d.
test if calling request done works .
test that request_done fails silently with a bad request i d.
sanitize a filename by removing .. / and \\.
sanitize a path by removing ~ and ..
slugify a given text .
help creating a more readable string representation of objects .
"convert value to to_type , returns default if fails ."
return a string that is not present in current_strings .
try to determine the local ip address of the machine .
return a random string with letters and digits .
return the greater than element .
return the greater element .
return the lower than element .
return the lower element .
initialize the set .
return the length of the set .
check if key is in set .
add an element to the end of the set .
"promote element to beginning of the set , add if not there ."
discard an element from the set .
iteration of the set .
reverse the ordering .
pop element of the end of the set .
add elements from args to the set .
return the representation .
return the comparision .
initialize the throttle .
caller for the throttle .
send a notification message .
setup the notify services .
send a message .
send a message .
ensure exactly 2 of conf_period_keys are provided .
set up the history stats sensor .
initialize the historystats sensor .
return the state of the sensor .
polling required .
return the state attributes of the sensor .
get the latest data and updates the states .
parse the templates and store a datetime tuple in _ period .
"format a duration in days , hours , minutes , seconds ."
format the ratio of value / period duration .
log an error nicely if the template can not be interpreted .
set up the aurora sensor .
initialize the sensor .
return the name of the sensor .
return true if aurora is visible .
return the class of this device .
return the state attributes .
get the latest data from aurora api and updates the states .
initialize the data object .
get the latest data from the aurora service .
get forecast data and parse for given long / lat .
setup the verisure component .
initialize the neato hub .
login to my neato .
update the robot states .
register the process service .
get the aws sns notification service .
initialize the service .
send notification to specified sns arn .
test the default setup .
test a custom setup .
setup the enocean light platform .
initialize the enocean light source .
return the name of the device if any .
brightness of the light .
if light is on .
flag supported features .
turn the light source on or sets a specific dimmer value .
turn the light source off .
update the internal state of this device .
setup hikvision camera .
initialize the switch .
poll for status regularly .
return the name of the device if any .
return the state of the device if any .
turn the device on .
turn the device off .
update motion detection state .
set up the zoneminder component .
login to the zoneminder api .
perform a zoneminder request .
get a state from the zoneminder api service .
update a state using the zoneminder api .
setup things to be run when tests are started .
test the controlling state via topic .
test the controlling state via topic .
test changing state optimistically .
test the sending of open_cover .
test the sending of close_cover .
test the sending of stop_cover .
test the current cover position .
process a timestamp into datetime object .
create an event database object from a native event .
convert to a natve ha event .
create object from a state_changed event .
convert to an ha state object .
return the entity ids that existed in this run .
"return self , native format is this model ."
setup the scsgate cover .
initialize the cover .
return the scsgate id .
return the name of the cover .
return if the cover is closed .
move the cover .
move the cover down .
stop the cover .
handle a scsgate message related with this cover .
initalize the platform with devices .
return mock devices .
create zwave entity device .
initialize the zwave rollershutter .
callback on data changes for node values .
return if the cover is closed .
return the current position of zwave roller shutter .
move the roller shutter up .
move the roller shutter down .
move the roller shutter to a specific position .
stop the roller shutter .
initialize the zwave garage door .
callback on data changes for node values .
return the current position of zwave garage door .
close the garage door .
open the garage door .
"return the class of this device , from component device_classes ."
flag supported features .
setup the hassbian config .
validate config and return results .
set up the beaglebone black gpio component .
setup a gpio as output .
setup a gpio as input .
write a value to a gpio .
read a value from a gpio .
add detection for rising and falling events .
setup the sabnzbd sensors .
initialize the sensor .
return the name of the sensor .
call the throttled sabnzbd refresh method .
get the latest data and updates the states .
stop everything that was started .
test if methods call the services as expected .
test the provided services .
test light profiles .
test light profiles .
create a new request for configuration .
add errors to a config request .
mark a configuration request as done .
setup the configurator component .
get an instance per hass object .
initialize the configurator .
setup a request for configuration .
update the state with errors .
remove the configuration request .
handle a configure service call .
generate a unique configurator id .
validate that the request belongs to this instance .
get the facebook notification service .
initialize the service .
send some message .
setup bloomsky component .
initialize the booksky .
use the api to retrieve a list of devices .
test the usage of yaml aliases and anchors .
test active scene .
enhance staticresourcehandler middleware .
initialize the hass file sender .
shut down test instance .
test the input source service .
test clear playlist .
test the volume service .
test turn_on and turn_off .
test media_pause .
test media_next_track and media_previous_track .
test play_media .
setup things to be run when tests are started .
test the media server image proxy server .
setup demo fan platform .
initialize the entity .
get entity name .
no polling needed for a demo fan .
return the current speed .
get the list of available speeds .
turn on the entity .
turn off the entity .
set the speed of the fan .
set the direction of the fan .
set oscillation .
fan direction .
flag supported features .
test up trend .
test down trend .
test up trend with custom message .
test down trend with custom message .
test attribute up trend .
test attribute down trend .
test up trend .
test attribute down trend .
test invalid name .
test invalid sensor .
test no sensors .
setup the fake email reader .
stay always connected .
get the next email .
test emails from allowed sender .
test multi part emails .
test multi part emails with only html .
test multi part emails with only other text .
test multiple emails .
test not whitelisted emails .
test value template .
return if the fans are on based on the statemachine .
turn all or specified fan on .
turn all or specified fan off .
toggle all or specified fans .
set oscillation on all or specified fan .
set speed for all or specified fan .
set direction for all or specified fan .
expose fan control via statemachine and services .
set the speed of the fan .
set the speed of the fan .
set the direction of the fan .
set the direction of the fan .
turn on the fan .
turn on the fan .
oscillate the fan .
oscillate the fan .
return true if the entity is on .
return the current speed .
get the list of available speeds .
return the current direction of the fan .
return optional state attributes .
flag supported features .
test config adheres to the type .
test config adheres to the type .
test we warn when non - default port is used for google home .
setup the heatmiser thermostat .
initialize the thermostat .
"return the name of the thermostat , if any ."
return the unit of measurement which this thermostat uses .
return the current temperature .
return the temperature we try to reach .
set new target temperature .
get the latest data .
deep update a dictionary .
get the group notification service .
initialize the service .
send message to all entities in the group .
set up the thinkingcleaner platform .
initialize the thinkingcleaner .
return the name of the sensor .
update the sensor .
set up the speedtest sensor .
initialize the sensor .
return the name of the sensor .
return icon .
get the latest data and update the states .
called when entity is about to be added to hass .
initialize the data object .
get the latest data from speedtest.net .
initialization of mqtt discovery .
setup zoneminder cameras .
set up the restful switch .
initialize the rest switch .
the name of the switch .
turn the device on .
turn the device off .
get the latest data from rest api and update the state .
stop everything that was started .
test configuration .
test configuration .
test configuration .
test fire event .
test fire event .
return the notify service .
initialize the service .
send a message to kodi .
"read in all of our configuration , and initialize the loopback switch ."
simple constructor for reading in our configuration .
send a command to the pa server using a socket .
helper method to get the full response back from pulseaudio .
refresh state in case an alternate process modified this data .
send a command to pulseaudio to turn on the loopback .
send a command to pulseaudio to turn off the loopback .
"for a sink / source , return it 's module i d in our cache , if found ."
initialize the pulseaudio switch .
tell the core logic if device is on .
turn the device on .
turn the device off .
refresh state in case an alternate process modified this data .
setup the one wire sensors .
initialize the sensor .
read the temperature as it is returned by the sensor .
return the unit the value is expressed in .
get the latest data from the device .
setup the mqtt cover .
initialize the cover .
subscribe mqtt events .
return if the cover is closed .
return current position of cover .
move the cover up .
move the cover down .
stop the device .
setup things to be run when tests are started .
test weather attributes .
test temperature conversion .
convert a fahrenheit temperature to celsius .
convert a celsius temperature to fahrenheit .
convert a temperature from one unit to another .
setup the proliphix thermostats .
initialize the thermostat .
polling needed for thermostat .
update the data from the thermostat .
return the name of the thermostat .
return the precision of the system .
return the device specific state attributes .
return the unit of measurement .
return the current temperature .
return the temperature we try to reach .
return the current state of the thermostat .
set new target temperature .
set up a wake on lan switch .
initialize the wol switch .
return true if switch is on .
turn the device on .
turn the device off if an off action is present .
check if device is on and update the state .
setup the neurio sensor .
initialize the sensor .
"icon to use in the frontend , if any ."
get the neurio monitor data from the web service .
setup things to be run when tests are started .
setup the discovery component with mocked netdisco .
simulate that netdisco discovered a new service .
test that netdisco is started .
test that unknown service is ignored .
test load a supported platform .
test discover a supported platform .
test that ignored platforms are not setup .
connect with serial port and return acer projector .
init of the acer projector .
write to the projector and read the return .
"write msg , obtain awnser and format output ."
return if projector is available .
return name of the projector .
return if the projector is turned on .
return state attributes .
get the latest state from the projector .
turn the projector on .
turn the projector off .
test values with exact match .
test values with domain match .
test values with glob match .
test domain overrules glob match .
test exact overrules domain match .
"test merging glob , domain and exact configs ."
"test merging glob , domain and exact configs ."
validate the configuration and return a bbox scanner .
initialize the scanner .
scan for new devices and return a list with found device ids .
return the name of the given device or none if we do n't know .
check the bbox for devices .
return an auth_ok message .
return an auth_required message .
return an auth_invalid message .
return an event message .
return an error result message .
return a pong message .
return a success result message .
initialize the websocket api .
handle an incoming websocket connection .
initialize an active connection .
print a debug message .
print an error message .
helper method to send messages .
handle the websocket connection .
handle subscribe events command .
handle unsubscribe events command .
handle call service command .
handle get states command .
handle get services command .
handle get config command .
handle get panels command .
handle ping command .
help migrate properties to new names .
allow an old config name to be deprecated with a replacement .
setup the demo covers .
initialize the cover .
try to remove token .
no polling needed for a demo cover .
return true if entity is available .
return the device state attributes .
return if the cover is closed .
get new token for usage during this session .
remove authorization token from api .
start watcher .
check the state of the service during an operation .
close the cover .
open the cover .
stop the door where it is .
get updated status from api .
get latest status .
send commands to api .
"receives a rrule parameter value , returns a upper case version of the value if its a weekday or an integer if its a number"
"> > > rule = rule(params = "" count:1;bysecond:1;byminute:1,2,4,5 "" ) > > > rule.get_params ( ) { ' count ' : 1 , ' byminute ' : [ 1 , 2 , 4 , 5 ] , ' bysecond ' : 1 }"
human readable string for rule
"retrieve a function from a library , and set the data types ."
run the main windows message loop .
create a connection to a service / topic .
cleanup any active connections .
request updates when dde data changes .
execute a dde command .
request data from dde service .
calback function for advice .
make netcdf file grids.nc
make netcdf file areas.nc
error page . it only shows an error message
"this controller is not really part of the oauth 2.0 server but it acts like a oauth client callback . it receives a "" code "" parameter given by the "" auth "" controller and it tries to exchange the < code , i d , secret , redirect_uri > for an access token ."
"find the system program with name @program . similar to the "" which "" command in bash . returns the runnable app with correct path . returns none is program does n't exist ."
save the provided bisect document .
combine the boot document values with their own defconfing .
search for a previous saved bisect saved .
update the bisect document based on the provided fields .
iterate through the docs until one that passed is found .
save the results of a delta calculation .
search for a previously saved delta document .
a build document .
when this object was created .
set the creation date of this object .
the id of this object as returned by mongodb .
set the id of this object with the objectid from mongodb .
the schema version of this object .
set the schema version of this object .
a dictionary with metadata about this build .
set the metadata about this build .
the status of this build .
set the status .
details about the platform used to build .
set details about the build platform .
perform a distinct query on the collection for the specified field .
perform a distinct query on the collection for the specified field .
get the valid distinct keys for the specified resource and method .
make sure the requested distinct field is valid .
handle the keyword arguments passed via url definition .
execute post pre - operations .
execute put pre - operations .
execute delete pre - operations .
handle get pre - operations .
make sure the requested distinct field is valid .
get the distinct values for the specified field and query .
get the distinct values for the specified field .
"url : websocket url . header : custom header for websocket handshake . on_open : callable object which is called at opening websocket . this function has one argument . the arugment is this class object . on_message : callbale object which is called when recieved data . on_message has 2 arguments . the 1st arugment is this class object . the passing 2nd arugment is utf-8 string which we get from the server . on_error : callable object which is called when we get error . on_error has 2 arguments . the 1st arugment is this class object . the passing 2nd arugment is exception object . on_close : callable object which is called when closed the connection . this function has one argument . the arugment is this class object . on_cont_message : callback object which is called when recieve continued frame data . on_message has 3 arguments . the 1st arugment is this class object . the passing 2nd arugment is utf-8 string which we get from the server . the 3rd arugment is continue flag . if 0 , the data continue to next frame data keep_running : a boolean flag indicating whether the app 's main loop should keep running , defaults to true get_mask_key : a callable to produce new mask keys , see the websocket.set_mask_key 's docstring for more information"
"send message . data : message to send . if you set opcode to opcode_text , data must be utf-8 string or unicode . opcode : operation code of data . default is opcode_text ."
close websocket connection .
"run event loop for websocket framework . this loop is infinite loop and is alive during websocket is available . sockopt : values for socket.setsockopt . sockopt must be tuple and each element is argument of sock.setscokopt . sslopt : ssl socket optional dict . ping_interval : automatically send "" ping "" command every specified period(second ) if set to 0 , not send automatically . ping_timeout : timeout(second ) if the pong message is not recieved . http_proxy_host : http proxy host name . http_proxy_port : http proxy port . if not set , set to 80 ."
chemical dictionary commands .
fix issues with jochem names .
filter words when adding to dictionary . return true if name should be added .
return variants of chemical name .
process and filter jochem file to produce list of names for dictionary .
process and filter include file to produce list of names for dictionary .
build chemical name dictionary .
tag chemical entities and write chemdner annotations predictions file .
return true if text is an allowed abbreviation .
"discard if long shorter than abbr , or if abbr token(s ) are in the long token(s ) ."
"return a ( abbr , long ) pair for each abbreviation definition ."
"return ( abbr_span , long_span ) pair for each abbreviation definition ."
test that footnote links are removed from the end of titles .
convert table element to python dictionary .
chemical records that have been parsed from the table .
empty list . abbreviation detection is disabled within table cells .
"empty list . individual cells do n't provide records , this is handled by the parent table ."
test normalize function .
test extract_urls function .
test solvent regex .
test inchi regex .
return the encoding of a byte string . uses bs4 unicodedammit .
return the levenshtein distance between two strings .
return 0 if string contains balanced brackets or no brackets .
support selecting text nodes using : : text pseudo - element
we set qty delivered 1 for every sale order line that : * is a delivery * do nt has qty delivered * is a service * ordered qty is 1 this way we guarantee we are changing delivery lines added with so button or automatically by the picking and that the user has not change for any reason
sobreescribimos directamente el invoice status y no el qty_to_invoice ya que no nos importa tipo de producto y lo hace mas facil . ademas no molesta dependencias con otros modulos que ya sobreescribian _ get_to_invoice_qty
modificamos la funcion original para sobre escribir con la policy del sale type si es que viene definida distinta de by product
check wpa_supplicant.conf has at least one network configured .
check wlan0 has an ip address .
check the api server is reachable on port 443 .
run all checks and print status .
warning : this method would change the construct of xml tree
"notice : this method must be a reentrant function , which means it should not change status or modify any member of ` self ` object . because other methods may change the construct of the xml tree ."
keep char unchanged if char is number or letter or unicode
encode object ` o ` with utf-8 recursively
"seems ` click.echo ` has fixed the problem of unicodedecodeerror when redirecting ( see https://stackoverflow.com/questions/4545661/unicodedecodeerror-when-redirecting-to-file for detail ) . as a result , the below code used to solve the problem is conflict with ` click.echo ` . to avoid the problem , you should always use ` print ` with below code or ` click.echo ` in ` _ _ main__.py `"
"gets the "" point in time "" or end of the bucket that a point shows ."
extracts the actual numeric value of a point .
gets a collection of lines for a given project and metric .
a labeled series of x and y points .
transforms an identifier to be more swift idiomatic .
converts the default value for an attr to a swift value .
returns the tensor type for the provided input / output argument .
generates some swift code for a given op .
test that no exceptions are triggered .
: param tx : a ` tx ` . : param block : a ` block ` . : param index : the index of the tx in the block .
no manual entry for busybox
no manual entry for wget
uname(1 ) user commands uname(1 )
"mass of the segment , in units of kg ."
"center of mass of the segment , a np.ndarray , in units of m , expressed in the global frame , from the bottom center of the pelvis ( ls0 ) ."
"inertia matrix of the segment , a np.matrix , in units of kg - m^2 , about the center of mass of the human , expressed in the global frame ."
"center of mass of the segment , a np.ndarray , in units of m , expressed in the frame of the segment , from the origin of the segment ."
"inertia matrix / dyadic of the segment , a np.matrix , in units of kg - m^2 , about the center of mass of the segment , expressed in the frame of the segment ."
"position of the origin of the segment , a np.ndarray , in units of m , expressed in the global frame , from the bottom center of the pelvis ( ls0 ) ."
"position of the center of the last ( farthest from pelvis ) stadium in this segment , a np.ndarray , in units of m , expressed in the global frame , from the bottom center of the pelvis ( ls0 ) ."
"rotation matrix specifying the orientation of this segment relative to the orientation of the global frame , a np.matrix , unitless . multiplying a vector expressed in this segment 's frame with this rotation matrix on the left gives that same vector , but expressed in the global frame ."
"initializes a segment object . stores inputs as instance variables , calculates the orientation of the segment 's child solids , and calculates the "" relative "" inertia parameters ( mass , center of mass and inertia ) of the segment ."
"sets the position ( self.pos ) and rotation matrix ( self.rot_mat ) for all solids in the segment by calling each constituent solid 's set_orientation method . the position of the i - th solid , expressed in the global frame , is given by the sum of the segment 's base position and the directed height of all the solids of the segment up to the i - th solid ."
"calculates the mass , relative / local center of mass , and relative / local inertia tensor ( about the segment 's center of mass ) . also computes the center of mass of each constituent solid with respect to the segment 's base in the segment 's reference frame ."
calculates the segment 's center of mass with respect to the bottm center of the pelvis ( ls0 ) and the segment 's inertia in the global frame but about the segment 's center of mass .
"prints mass , center of mass ( in segment and global frames ) , and inertia ( in solid and global frames ) ."
"prints mass , center of mass ( in segment and global frames ) , and inertia ( in solid and global frames ) ."
calls the print_properties ( ) member method of each of this segment 's solids . see the solid class 's definition of print_properties(self ) for more detail .
draws in a mayavi window all the solids within this segment .
updates all of the solids in this segment for mayavi .
initialize the simulation object
is the simulation finished based on time or the number of steps
is it time to output ?
the method - specific timestep code
a generic wrapper for computing the timestep that respects the driver parameters on timestepping
do any necessary evolution before the main evolve loop . this is not needed for advection
do any final clean - ups for the simulation and call the problem 's finalize ( ) method .
output the state of the simulation to an hdf5 file for plotting
write out any extra simulation - specific stuff
read in any simulation - specific data from an h5py file object f
initialize the quadrant problem
print out any information to the user at the end of the run
initialize the collection of timers
"create a timer with the given name . if one with that name already exists , then we return that timer ."
generate a timing summary report
initialize a timer with the given name .
"stop timing . this does not destroy the timer , it simply stops it from counting time ."
construct the fluxes through the interfaces for the linear advection equation :
this is run once for each class before any tests
this is run once for each class after all tests
this is run before each test
this is run after each test
unsplitfluxes returns the fluxes through the x and y interfaces by doing an unsplit reconstruction of the interface values and then solving the riemann problem through all the interfaces at once
perform flux - vector - split ( lf ) finite differencing using weno in 1d .
construct the fluxes through the interfaces for the linear advection equation :
initialise the manager
delete a plate from the database
"create a new plate , and commit it to the database"
add a plate using the plate definition : param plate_definition : the plate definition : return : none : type plate_definition : platedefinitionmodel
gets the plate values from the global meta data according to the given plate definition : param plate_definition : the plate definition : return : the plate values : type plate_definition : platedefinitionmodel
recurse up the tree getting parent plate values : param tree : the tree : param node : the current node : param value : the initial plate value : return : the plate value as a list of tuples
recurse up the tree getting parent data : param tree : the tree : param node : the current node : param current : the current list : return : the hierarchical dictionary
"calculate the n - th discrete difference along given axis . the first difference is given by ` ` out[n ] = a[n+1 ] - a[n ] ` ` along the given axis , higher differences are calculated by using ` diff ` recursively ."
cumulative sum generator
compute the histogram of a set of data .
initialise the engine .
execute the engine - currently simple executes all workflows .
initialise the channel : param channel_id : the channel i d
"must be overridden by deriving classes , must create the stream according to the tool and return its unique identifier stream_id"
clears all streams in the channel - use with caution !
clears all the data in a given stream and the calculated intervals
calculates / receives the documents in the stream interval determined by the stream : param stream : the stream reference : param time_interval : the time interval : return : the sorted data items
deriving classes must override this function
"call this function to ensure that the channel is up to date at the time of timestamp . i.e. , all the streams that have been created before or at that timestamp are calculated exactly until up_to_timestamp ."
tool implementations should override this function to actually perform computations
"execute the tool over the given time interval . if an alignment stream is given , the output instances will be aligned to this stream"
"performs a search on the mpd server for tracks matching the specified criteria ( as arguments in the url i.e. http gets ) . must contain at least one of ` ` artist ` ` , ` ` title ` ` , or ` ` album ` ` ."
takes a result set in results and returns an organized result set sorted by the following criteria :
the ' default ' route when you hit the index of the app . just sweeps the user off to the player page ( which redirects to login if there is no user authenticated ) .
performs all of the actions needed to get the web server up and running .
starts the webapp .
"overrides the @app.route decorator provided by flask . takes the opportunity to replace instances of : route : or : methods : in the wrapped function 's docstring with information from the app.route ( ) decorator . if : route : or : methods : are not present in the docstring at the time of wrapping , then append route and methods to bottom of the docstring for nicer documentation ."
creates a singleuseradminadminform that can be used in concert with other singleuseradminadminforms .
"shows the admin console . admin.html expects a list of forms for the admin_admin functions , a dict of user ids and names , a configuration form , the current user , and the privileges a user has ."
updates the configuration values provided by the configuration form presented by : func:`admin_console ` .
updates the administrative privileges of other users given the input from the form presented by : func:`admin_console ` .
"attempts to tell mopidy to play , regardless of mopidy 's current play state ."
"attempts to tell mopidy to pause , regardless of mopidy 's current play state ."
skips the current track .
clears the global play queue .
"returns a list of singleuseradminadminforms - one for each user . this is useful for the admin admin section of the admin page , where one form per user is needed ( due to the way wtforms does things ) ."
returns information about the user for use with an adminadminform .
initializes the manager for the ` ` desired_player_state ` ` information .
updates the state that we want the player to be in for the next call to the consistency function .
tells us what state we want the player to be in .
"initializes the manager for the ` ` last_updated_times ` ` dict which tracks the times that certain events happen , such as playlist updates ."
updates ` ` last_updated_times ` ` with a key and the value for that key .
gets the value for ` ` key ` ` in ` ` last_updated_times ` ` .
initializes the lock that is used to prevent badness in accessing mpd .
acquires the lock needed to access mpd .
releases the mpd lock .
confirm consistency in peak finding
confirm consistency in peak finding
calculate the phase time series of a neural oscillation
calculate the amplitude time series
estimate the instantaneous frequency at each sample
compute the hilbert transform of x. ignoring the boundaries of x that are filled with nan
quantify the rhythmicity of an oscillator using the lagged coherence measure .
calculate lagged coherence of x at frequency f using the hanning - taper fft method
split x into nonoverlapping chunks of length n
initialize the endpoint
"get feedback based on a campaign ’s statistics . advice feedback is based on campaign stats like opens , clicks , unsubscribes , bounces , and more ."
initialize the endpoint
create a new list in your mailchimp account .
batch subscribe or unsubscribe list members .
get information about all lists in the account .
get information about a specific list in your mailchimp account . results include list members who have signed up but have n’t confirmed their subscription yet and unsubscribed or cleaned .
update the settings for a specific list .
"delete a list from your mailchimp account . if you delete a list , you ’ll lose the list history — including subscriber activity , unsubscribes , complaints , and bounces . you ’ll also lose subscribers ’ email addresses , unless you exported and backed up your list ."
initialize the endpoint
create a new template for the account . only classic templates are supported .
get a list of an account ’s available templates .
get information about a specific template .
"update the name , html , or folder_id of an existing template ."
delete a specific template .
initialize the endpoint
get links to all other resources available in the api .
initialize the class with your api_key and user_id and attach all of the endpoints
initialize the endpoint
pause an automated email .
start an automated email .
"initialize the instance , optionally configuring turbomail itself ."
emit a record .
initialize the immediate delivery manager .
perform startup actions .
concurrent feature data reader .
the function for running a training replica on a worker .
the function for running model evaluation on the master .
number of training examples to use
choose features overlapping with provided ranges during training
window max duration in seconds . a value of zero indicates that we would instead like to choose a fixed - length window .
build net suitable for training model
build net suitable for running inference on model
returns a queryset of workflow - logs filtered by given parameters
"returns a worker queryset or a list of ids ( flat = true ) , which a workflow recently was performed on by request.user ."
"import dynamically generated code as a module . code is the object containing the code ( a string , a file handle or an actual compiled code object , same types as accepted by an exec statement ) . the name is the name to give to the module , and the final argument says wheter to add it to sys.modules or not . if it is added , a subsequent import statement using name will return this module . if it is not added to sys.modules import will try to load it in the normal fashion ."
notify user in case of failure .
create an instance of * anyfilesearcher * bound to specific directory .
creates an instance of * borrower * class .
connect to a host on a given ( ssl ) port .
"for i in start .. end { writeln(""this is "" , i ) ; } return 0.0 ;"
"printf(""printing stuff ... \n "" ) ; pych_pprint_array(x ) ; pych_pprint_array(y ) ; printf(""create pointers ... \n "" ) ; double * x_cast = x->ptr_d ; double * y_cast = y->ptr_d ; printf(""loop through ... \n "" ) ; printf(""where is void : x=%p , y=%p\n "" , x->ptr_d , y->ptr_d ) ; for(int i=0 ; i < x->shape[0 ] ; i++ ) { printf(""i=%d , "" , i ) ; printf(""x=%f , y=%f "" , * x_cast , * y_cast ) ; printf(""\n "" ) ; * x_cast = * x_cast + * y_cast ; y_cast++ ; x_cast++ ; } printf(""done.\n "" ) ;"
measure execution time .
"plot bid price , asking price and "" voodoo "" values ."
load stock - prices .
var future = 200 ; voodoo = ask - bid ; for i in 1 .. future { voodoo + = ( ask - bid + ask - bid + ask - bid + ask - bid + ask - bid + ask - bid + ask - bid + ask - bid ) / 8 ; } voodoo = voodoo / future ;
mnist tutorial for carlini and wagner 's attack : param train_start : index of first training set example : param train_end : index of last training set example : param test_start : index of first test set example : param test_end : index of last test set example : param viz_enabled : ( boolean ) activate plots of adversarial examples : param nb_epochs : number of epochs to train model : param batch_size : size of training batches : param nb_classes : number of output classes : param source_samples : number of test inputs to attack : param learning_rate : learning rate for training : param model_path : path to the model file : param targeted : should we run a targeted attack ? or untargeted ? : return : an accuracyreport object
mnist tutorial for the jacobian - based saliency map approach ( jsma ) : param train_start : index of first training set example : param train_end : index of last training set example : param test_start : index of first test set example : param test_end : index of last test set example : param viz_enabled : ( boolean ) activate plots of adversarial examples : param nb_epochs : number of epochs to train model : param batch_size : size of training batches : param nb_classes : number of output classes : param source_samples : number of test inputs to attack : param learning_rate : learning rate for training : return : an accuracyreport object
"device instance implementing the following methods : getsize ( ) - > int size of the underlying storage . write(offset , data ) write < data > starting at < offset > . read(offset , length ) - > string read < length > bytes starting at < offset > ."
"to be called upon socket connection establishment . sends nbd server greeting sequence , device size , and whether it is read - only ."
"to be called upon incomming data on socket . blocks until an entire command has been received , and response had been sent back ."
decorator for returning paginated json data .
generic ' smart ' get function . does different things based on number of arguments . some would call this a ' not smart ' idea but we are not asking them .
"potentially check if dbsession is "" clean "" and then commit only if it is , or if commit flag specified"
custom create logic to be overridden by inheriting classes
creates a new entry in cls . tbl with given data . calls create_hook which is implemented / overridden by extending classes to handling custom validation
custom create logic to be overridden by inheriting classes
save / update an existing entity . saving should fail if the primary_key has no value set ( requires create api to enforce validation rules for creation )
"mechanism for raw , unchecked atomic saves"
sorts an array of items by multiple properties ;
converts json to html table format .
converts json to html table format .
wraps the generated html in table cell ` < td></td > ` tags .
creates a row of table header items .
"converts a dictionary to a string of ` ` key=""value "" ` ` pairs . if ` ` none ` ` is provided as the dictionary an empty string is returned , i.e. no html attributes are generated ."
detects if all entries in an list of ` ` dict ` ` 's have identical keys . returns the keys if all keys are the same and ` ` none ` ` otherwise .
recursively generates html for the current entry .
"if all keys in a list of dicts are identical , values from each ` ` dict ` ` are clubbed , i.e. inserted under a common column heading . if the keys are not identical ` ` none ` ` is returned , and the list should be converted to html per the normal ` ` convert ` ` function ."
判断是否符合爬取的时间 : param item : end_day : 指定结束天数 : return : item or none
"reduces a series of points to a simplified version that loses detail , but maintains the general shape of the series ."
called when some datagram is received .
produces factory for protocol implementation .
return full path to specified data file or none if not found . if a valid absolute path is provided it will be returned .
setup the newly created client connection ready for handler .
no - op implementation of mode handling . really just here to avoid sending lots of ' unknown command ' responses back to client as most clients will set nick and channel modes automatically .
returns the docker registry host associated with a given image name .
"reads the local docker client config for the current user and returns all registries to which the user may be logged in . this is intended to be run client - side , not by the daemon ."
test if firenado root matches the upper directory relative to the current one .
test if firenado root matches the upper directory relative to the current one .
"test if the default firenado config file value will be "" firenado "" ."
test if firenado config file value will be changed setting firenado_config_file env variable .
tests is only the framework config stack was loaded . no app config is provided .
application config is provided . test if the app config file was loaded .
checks if the app port is set correctly .
checks if the pythonpath is set on the application config file .
on an application with a yml and yaml config files the yml should be loaded .
if static path is defined on the app configuration .
test if the root path was set on the app configuration .
test if the root path with a slash in the front will be returned without it was set on the app configuration .
test if the root path with a slash in the front will be returned without it was set on the app configuration .
if static url prefix is defined on the app configuration .
checks if the session is enabled and the type is file
"checks if the session name is default , firenadosessid"
checks if the session is enabled and the type is redis
checks if the session name will be defined as in the config file
checks if the application is multi app
checks if the application is n't multi app
application configuration file will be read and components will be loaded .
checks default session parameters on the configuration session section
checks if the session handler loaded is the same the session handler defined .
checks if test component was loaded correctly by the application _ _ init _ _ method .
application configuration file will be read and components will be loaded .
checks if test component was loaded correctly by the application _ _ init _ _ method .
checks default session parameters on the configuration session section
checks if the pickle session encoder will keep a dict structure and values intact after encoding and decoding it .
checks if challenge username and password matches username and password defined on the service constructor ..
test hex_array ( ) with str type .
test hex_array ( ) with bytearray type .
test hex_array ( ) with bytes type . ( python3 only )
test binary_str ( ) with str type .
test binary_str ( ) with bytearray type .
test binary_str ( ) with bytes type . ( python3 only )
a convenient wrapper for ipv4 arp for ethernet .
"parse an ovs - ofctl style action string and return a list of jsondict representations of ofpinstructionactions , which can then be passed to ofproto_parser.ofp_instruction_from_jsondict ."
tokenize an argument portion of ovs - ofctl style action string .
convert an ovs - ofctl field name to ryu equivalent .
convert an ovs - ofctl style nxm_/oxm _ field name to a ryu match field name .
: type packet : ryu.lib.packet.packet . packet : param packet : : type vlan_id : int ( 0 < = vlan_id < = 4095 ) or none (= no vlan ) : param vlan_id :
: type dpid : datapath i d : param dpid : : rtype : ryu.controller.controller . datapath : returns : datapath corresponding to dpid
calculate checksum of ip pseudo header
fletcher checksum -- refer to rfc1008
converts binary representation label to integer .
converts integer label to binary representation .
"this returns the landing url ( e.g. , where the user will be forwarded ) ."
"in this code , you can do something to setup the experiment . it is called for every user , before they start using it ."
"in this code , you can do something to clean up the experiment . it is guaranteed to be run ."
"this is your code . if you provide @requires_active to any other url , it is secured ."
exports the named shapes array to igs
gets the wing from the cpacs config
args : type : word or lemma
old insecure authentication of participant . just expire link and send new authentication url .
"return baggage associated with this spancontext . if no baggage has been added to the span , returns an empty dict ."
provides access to the spancontext associated with this span .
provides access to the tracer that created this span .
changes the operation name .
indicates that the work represented by this span has completed or terminated .
attaches a key / value pair to the span .
adds a log record to the span .
stores a baggage item in the span as a key / value pair .
retrieves value of the baggage item with the given key .
invoked when span is used as a context manager .
ends context manager and calls finish ( ) on the span .
"gerald b. folland , how to integrate a polynomial over a sphere , the american mathematical monthly , vol . 108 , no . 5 ( may , 2001 ) , pp . 446 - 448 , < https://doi.org/10.2307/2695802 > ."
shows the quadrature points on a given triangle . the size of the circles around the points coincides with their weights .
"given $ r$ ( as appearing in the article ) , it returns the barycentric coordinates of the three points ."
"like sympy.atan2 , but return 0 for x = y=0 . mathematically , the value is undefined , so sympy returns nan , but for the sake of the coordinate conversion , its value does n't matter . nans , however , produce nans down the line ."
: param headers : : return :
: param config : the client configuration . the constructor makes a copy of this parameter so that it is safe to change the configuration after then . : type config : bceclientconfiguration
var : primary variable looking in variables . it takes short_var from varsdict . 26.08.2013
var : primary variable looking in variables . it takes short_var from varsdict . 26.08.2013
dtype : anl | fcst hour : fcst hour . by default none
"earth science data consists of a strong seasonality component as indicated by the cycles of repeated patterns in climate variables such as air pressure , temperature and precipitation . the seasonality forms the strongest signals in this data and in order to find other patterns , the seasonality is removed by subtracting the monthly mean values of the raw data for each month . however since the raw data like air temperature , pressure , etc . are constantly being generated with the help of satell- ite observations , the climate scientists usually use a moving reference base interval of some years of raw data to calculate the mean in order to generate the anomaly time series and study the changes with respect to that ."
uses device_specific_media as a basis to pass extra context when the wurfl - detected device is a child of a given device i d.
pulls talkscam feeds
"parse date as tue , 21 feb 2012 23:49:34 +0000"
"show a list of favourited things , and allow removal of these"
"add and remove favourites . favourites are stored as urls ( the part of them django is interested in anyway ) in the database , if the user is logged in - otherwise , it is stored in the session , and then migrated to the database when the user logs in . this has the downside of breaking favourites if urls change ."
find the distance and angle of the margin on a particular side .
adds ` ` value ` ` to the variable ` ` name ` ` .
restore the default values .
"when an invalid form is submited , no action is taken , no changes are made , so no log are recorded ."
handles the dependency injection to get an userrequestcontextfinder instance .
"imports the staticfiles finder class described by import_path , where import_path is the full python path to the class ."
returns a queryset of all collections the current user is part .
returns the active collection of the current user .
"this interaction is performed by ajax requests , while querying for the list of issues waiting to be marked - up ."
"this interaction is performed by ajax requests , while querying for the list of issues of a given journal ."
"the recommended values to be used as boolean params are 0 and 1 . but we are already prepared to handle : true , true , yes , yes , on , on , y , y. anything else is handled as false ."
"the recommended values to be used as boolean params are 0 and 1 . but we are already prepared to handle : true , true , yes , yes , on , on , y , y. anything else is handled as false ."
"the recommended values to be used as boolean params are 0 and 1 . but we are already prepared to handle : true , true , yes , yes , on , on , y , y. anything else is handled as false ."
access to the ajax that returns a list of issues for a given journal .
decorator to be used in migrations . this decorator monkeypatch a given model to avoid the datetimefield to override the current dates priviously registered in the database .
the elapsed time since the last refresh .
generates a hash from a file . args : path : ( string ) the path to the file to generate the hash from . returns : returns a hash digest ( string ) of the file .
return the endpoint absolute address .
return the endpoint direction .
return the transfer type of the endpoint .
return the direction of a control request .
build a bmrequesttype field for control requests .
create a buffer to be passed to a read function .
find an inner descriptor .
explicitly claim an interface .
explicitly release an interface .
release internal resources allocated by the object .
retrieve the list of supported language ids from the device .
retrieve a string descriptor from the device .
returns an instance of a transformation by name
returns whether the provided name is a valid variable name in python
"returns the coordinates of a new point that is a given angular distance s away from a starting point ( lon0 , lat0 ) at bearing ( angle from north ) a1 ) , to within a given precision"
change / report the solar abundance table in use . see xspec manual for help :
define the cosmology in use within the xspec models . see xspec manual for help :
change / report the photoionization cross sections in use for xspec models . see xspec manual for help :
create an empty ( zeroed ) vertexlist with the specified number of features for each vertex and number of vertices .
returns the number of vertices contained in this object .
returns the number of features of the vertices of this object .
set the vertices to the given numpy array .
"replace all the vertices within this class with a new set . must have the same number vertices , but can alter the number of features ."
returns a set of vertices specified by vertexindices . if vertexindices is none then all vertices are returned .
set a vertex to the corresponding value .
sets a vertex to the all - zeros array .
returns the value of a vertex .
"returns a tuple ( frequencies , items ) about a particular feature given by findex . this method is depricated ."
returns the string representation of this object .
returns a copy of this object .
"returns a subset of this object , indicated by the given indices ."
save this object to filename.nvl .
load this object from filename.nvl .
"this is called when using numpy square bracket notation and returns the value of the specified vertex , e.g. vlist[i , :] returns the ith vertex ."
"this is called when using square bracket notation and sets the value of the specified vertex , e.g. vlist[i , :] = v."
adds n vertices to this object .
create a random graph generator according to the barabasi - albert model
: param ell : the initial number of vertices . : type ell : : class:`int `
: param m : the number of edges to be added at each step : type m : : class:`int `
create a random graph using the input graph according to the barabasi - albert model . note that the input graph is modified .
we want to try creating a huge graph and adding lots of edges .
"create an array of pairs of vertex labels for each edge in the graph . returns a tuple of this array and a vector of corresponding edge weights , for the indices of the full edge index array as given by getalledges ."
"return a set of examples with pairs of vertex labels connected by an edge . for undircted graphs there exists an example ( v_i , v_j ) for every ( v_j , v_i ) . also , there is a set of negative examples where the edge does not exist ."
find the root of the given tree
find the depth of the given tree .
"give a symmetric weight matrix w and a clustering array "" clustering "" , compute the modularity of newman and girvan . the input matrix w can be either an ndarray or a scipy.sparse matrix ."
do k - way normalised cut . each cluster should have at least 1 edge . the input matrix w can be either an ndarray or a scipy.sparse matrix .
"give a scipy sparse csr matrix w , compute the shifted laplacian matrix , which is defined as i + d^-0.5 w d^-0.5 where d is a diagonal matrix of degrees . for vertices of degree zero , the corresponding row / col of the laplacian is zero with a 0 at the diagonal . the eigenvalues of the shift laplacian are between 0 and 2 ."
"give a scipy sparse csr matrix w , compute the normalised laplacian matrix , which is defined as i - d^-0.5 w d^-0.5 where d is a diagonal matrix of degrees . for vertices of degree zero , the corresponding row / col of the laplacian is zero with a 0 at the diagonal . the eigenvalues of the laplacian are between 0 and 2 ."
compute the random walk laplacian matrix given by d^-1 l where l is the unnormalised laplacian .
compute the modularity matrix from a weight matrix w.
compute the rand index for 2 clusterings given in arrays v1 and v2 .
read a multigraph from at least 2 files : one is the information about vertices and the other(s ) are lists of edges . for the list of vertices the first column must be the id of the vertex .
each edge file contains a list of edges with possible weights .
ideally we should n't lose the first second of events
test merging user to another user .
test default behaviour of user.delete - merge to nobody
test purging user using ` purge_user ` function
test purging user using ` user.delete(purge = true ) `
test verifying user using ` verify_user ` function
test verifying user using ` verify_user ` function that has an allauth . emailaddress object but is not yet verified
test verifying user using ` verify_user ` function that has an allauth . emailaddress object but is not yet verified
test user ` has_manager_permissions ` method .
helper to get / create a new project .
require ` tutorial ` test project .
require ` tutorial - disabled ` test project in a disabled state .
require ` foo ` test project .
require ` bar ` test project .
` project0 ` fixture but with on - disk directories and tps .
returns a projectresource object for a directory
returns a projectresource object for a store
override this method if you need to render a template with the context object but wish to include the rendered output within a json response
overriden to call ` get_response_data ` with output from ` get_context_data `
returns es ` hits ` filtered according to their levenshtein distance to the ` source_text ` .
"setup test environment by trying to load a data dump file . if this is missing , populate the db and generate the dump for use in future test runs ."
test directories are not created with ( back)slashes on their name .
test directory can not be created with name and no parent or without name but no parent .
tests that the in - db directory are marked as obsolete after the on - disk file ceased to exist and that the on - disk file and directory are recovered after syncing .
tests that the in - db directories are marked as obsolete if the on - disk directories are empty .
returns a string which leaves the value readily available for js consumption ; breaks closing html tags into concatenated strings to avoid ' < /script > inside js string ' problem
returns a string which leaves the value readily available for js consumption ; escapes closing tags to avoid ' < /script > inside js string ' problem ; breaks html tags into concatenated strings to avoid jquery ` html ( ) ` rendering problem ( see https://github.com/evernote/zing/issues/105 ) .
returns the absolute url to ` path_name ` in the rtd docs .
factory that builds an agreement form .
convenience function to create and setup fake post requests .
convenience function to create unit forms .
tests that the source string can not be modified .
tests that non - admin users ca n't set the fuzzy flag .
tests that similarities are within a particular range .
tests how checkbox states ( as strings ) map to booleans .
tests unit 's ` multistringwidget ` decompresses none values .
tests unit 's ` multistringwidget ` decompresses a list of values .
tests unit 's ` multistringwidget ` decompresses string values .
tests unit 's ` multistringwidget ` decompresses string values .
tests ` multistringformfield ` 's value compression in a form .
tests that target hash changes when suggestion is modified
submissions with same creation_time should order by pk
tests that the maximum similarity is properly returned .
tests if the submission needs to be logged or not .
tests suggestion can be accepted with a comment .
argument parser for python 2.7 and above
argument parser for python 2.6
test combining multiple strings in a single species identifiers
test that a single string remains unchanged as a species identifier
test that a single column data frame / series returns the same
test that multiple series return the right combined series
test that multiple lists return the right combined list
test that multiple arrays return the right combined array
"test richness_in_group with a single species identifier column , one group"
"test richness_in_group with a multiple species i d columns , one group"
test richness_in_group with a multiple groups
test abundance_in_group with no abundance column provided
test abundance_in_group with a single group and an abundance column
test abundance_in_group w / multiple group columns and no abundance column
test abundance_in_group w / multiple group columns and an abundance column
called per engine 's reset .
called only once on initialization .
create player defined ai
load source code from file
save source code from ai to a file
"create scenario with defaults values , check default.txt for more information"
load scenario from file it does n't save current scenario
save scenario as scx format
create whole new blank scenario
clear all scenario data
migra um hash de senha do zope para uso com o zopesha1passwordhasher
upload a torrent to andoex anime category returns torrent url
copy torrent data files from torrent into dest_dir
return true if anodex has a copy of this torrent
return true if xd has this torrent already
return true if we should process this torrent
add torrent to xd by url
given a torrent generate anodex tags
iterates over tri - state tuples for the provided value .
converts incoming form data to a nullable boolean value .
a view for performing various acts of data maintenance .
determines if a given record already exists in the database .
"gets or creates an record based on if it already exists . if it does not already exist , it will be created ."
attempts to add the list of provided categories to the resource .
attempts to add the list of provided populations to the resource .
checks to see if a resource already exists in the database and adds it if it does not exist ( or is forced to by use of the lazy argument ) .
"renders an option as the appropriate element , but wraps options into an ` ` optgroup ` ` tag if the ` ` label ` ` parameter is ` ` list ` ` or ` ` tuple ` ` ."
overrides choice iteration to ensure that optgroups are included .
recurses on validation of choices that are contained within embedded iterables .
return a snapshot of the icecast listener status .
"return a list of icecast metrics , or the empty list if it fails ."
"get the current upload , in bytes , since last boot ."
get the percentage usage of every cpu .
"get the disk usage , in bytes ."
"get the ram and swap usage , in bytes ."
gather metrics to send to influxdb .
implements the needleman - wunsch pairwise sequence alignment algorithm .
"function for parsing a file containing fastq sequences . the input is the absolute filepath including the filename ( as a string ) . the parsed data is returned as i d , dna , qual_val tuples in a generator ."
class to be loaded at every file change . it then evaluates the restrictionsites and saves every info . this enables fast access from every part of the software to restriction sites
should be called if you want to reload the enzymes
"load the restrictionenzymes from the emboss file , once ."
initialize priorityq .
insert a val into the queue with an argument for the priority .
remove the most important item from the queue .
return the most important item without removing it .
dll fixtures .
test node class has data .
test list of none head and tail is none .
"test list of one , head is tail ."
test list of five .
test prev pointer .
test next pointer .
test push increases length .
test push updates head .
test old head points to new with prev after a push .
test pop reduces lists .
test pop removes head .
test pop changes prev pointer .
test pop decreases length .
test pop returns data .
test pop on an empty list raises error .
test append increases length .
test append updates tail .
test old tail points to new with prev after a append .
test append updates tail .
test append next pointer is none .
test that entire sequence is returned by successive pops .
push data and pop it off .
test shift reduces lists .
test shift removes tail .
test shift changes prev pointer .
test shift decreases length .
test shift on an empty list raises error .
test that entire sequence is returned by successive shifts .
append data and shift it off .
test remove from middle of list .
test remove from head of list .
test remove from tail of list .
test remove from middle of list decreases length .
test remove from head of list decreases length .
test remove from tail of list decreases length .
test remove from middle of list updates pointers .
test remove from head of list changes pointers .
test remove from tail of list changes pointers .
test remove on list of one .
test remove on list of one .
test remove on list of none .
test remove from middle of list .
initialize deque .
add value to the end of the deque .
add a value to the front of the deque .
remove a value from the end of the deque and returns it .
remove a value from the front of the deque and returns it .
return the next value that would be returned by pop .
return the next value from the front of the deque .
return the count of items in the queue .
input is unicode string .
writes text .
writes text in a cdata section .
"writes a bytes ( ) sequence into the xml , escaping non - ascii bytes . when this is read in xmlreader , the original bytes can be recovered by encoding to ' latin-1 ' ."
writes text without indentation .
"writes bytes , possibly indented ."
loads font and initializes closuretaker
takes closure of character ' c ' expected result is array : [ 3 ]
takes closure of cleared input lists expected result is array : [ ]
build glyphname to glyphid and vice versa dictionaries dicts[0 ] is name to i d dicts[1 ] is i d to name
build reverse cmap table for unicode returns dict from name to unicode points
generates pink noise using the voss - mccartney algorithm .
just test that this runs without crashing
user.get_profile ( ) returns what you 'd expect .
changing to same email shows validation error .
changing to same email shows validation error .
entering wrong password shows validation error .
generate sha-256 hash .
set sha-256 password .
"write a given url to disk , maintaining extension ."
generate the svox output for the given text
combine the two files .
parses a xml string / fileobject into a record tree
"given the name of a .scm file , compile it with the bob compiler to produce a corresponding .bobc file ."
"given the name of a compiled bob file ( .bobc ) , run it with the bob vm with output redirected to stdout ."
"given the name of a compiled bob file ( .bobc ) , print it in human - readable format ."
a basic view decorator .
"the echo service should echo received parameters correctly , regardless of their type ."
the string service should concatenate strings correctly .
the number service should add integers correctly .
the number service should add floats correctly .
the number service should raise an assertion error if one tries to add just one number .
the number service should raise an assertion error if one tries to add a string to a number .
create a new testsuite run .
"closes a testsuite run . after a testsuite run is closed , the test result data can not be changed or new data added ."
saves a test result in the database .
: param observers : an iterable of itestrunobserver instances . : type observers : iterable
generate a test report index and write to file like object or to an automatically chosen report file ( under the default output directory
generate a test report and write to file like object or to an automatically chosen report file ( under the default output directory
returns the next test case for this run or none when the test run is finished .
number of remaining test cases in this test run .
the length of this test run ( note that fetching test cases does not change the length ) .
run the test case . returns a deferred that provides an instance of testresult when successful .
set up testing parameters .
print system to the standard output .
test state space to transfer function conversion .
test state space to transfer function conversion .
regression : tf2ss for siso static gain
regression : tf2ss for mimo static gain
regression : ss2tf for siso static gain
regression : ss2tf for mimo static gain
"siso_almost_equal(g , h ) - > none raises assertionerror if g and h , two siso lti objects , are not almost equal"
siso plant with s weighting
siso plant with ks weighting
siso plant with t weighting
siso plant with all weights
mimo plant with s weighting
mimo plant with ks weighting
mimo plant with t weighting
mimo plant with all weights
error cases handled
mixsyn with siso system
define some test parameters .
"directly tests the functions tb04ad and td04ad through direct comparison of transfer function coefficients . similar to convert_test , but tests at a lower level ."
compare the bode reponses of the ss systems and tf systems to the original ss they generally are different realizations but have same freq resp . currently this test may only be applied to siso systems .
nichols plot for a system
nichols chart grid
"contours of the function gcl = gol/(1+gol ) , where gol is an open - loop transfer function , and gcl is a corresponding closed - loop transfer function ."
"constant - magnitude contours of the function gcl = gol/(1+gol ) , where gol is an open - loop transfer function , and gcl is a corresponding closed - loop transfer function ."
"constant - phase contours of the function gcl = gol/(1+gol ) , where gol is an open - loop transfer function , and gcl is a corresponding closed - loop transfer function ."
try to find and use gcc on osx for openmp support
"boilerplate to compile the extension the only thing that we need to worry about is the modules part , where we define the extension that needs to be compiled"
check and returns actual and valid ratio
find the classes statistics to perform sampling .
resample the dataset
extend default endpoint description with serializer description .
respond on get requests using ` ` self.retrieve ( ) ` ` handler .
respond on put requests using ` ` self.update ( ) ` ` handler .
extend default endpoint description with serializer description .
respond on get requests using ` ` self.list ( ) ` ` handler .
create items in bulk by reusing existing ` ` .create ( ) ` ` handler .
respond on post requests using ` ` self.create ( ) ` ` handler .
respond on patch requests using ` ` self.create_bulk ( ) ` ` handler .
create a new articleset based on name . if articleset exists add postfix number to make articleset name unique .
returns properties used in given articlesets . may contain duplicates .
return the number of articles according to elastic search
add the given articles to this articleset . implementation is exists of three parts :
add properties to property cache
completely discard property cache
"resets all property caches from all articlesets for current database . use this function with care , it runs o(n ) with n being the number of keys in redis ."
discard property cache and recalculate properties
add(*a ) is an alias for add_articles(a )
remove article from this articleset . also removes codedarticles ( from codingjobs ) and updates index if ` remove_from_index ` is true .
return the sequence of ids of articles in this set . this is an optimized form of ' return [ a.id for a in self.articles.all ( ) ] '
"return the sequence of ids of articles in this set . as opposed to get_article_ids , this method uses elastic to fetch its data ."
make sure that the index for this set is up to date
return a ' name [ ( n ) ] ' that is unique in this project
delete the articleset and all articles from index and db
test whether posting and retrieving an article works correctly
test whether deduplication works
retrieve / create a memoized codebooksereialiser for the given field.codebook
convert the given serialised value to a domain object
convert the given domain object to a serialised value
get the possible values
get a label for the given ( deserialised ) value
"return a sequence of ( i d , django form fields ) pairs with export options for this field the i d and field label need only be locally unique , they will be prepended with the field name"
"return ( label , function ) pair for each column that a codingjob export should include . the function will be called with the serialised coded value as the only argument . the label need only be locally unique , it will be prepended with the field name . @param * * options : the form values of the fields specified by get_export_fields"
can we create objects and assign labels ?
are label lookups cached ?
unit : a pdf document
test whether we can create a user
@param filename : filename relative to tools / sql folder
can viewsets also be used ?
format of mostly 2013
new format as of 2014 and a few days before
"some ugly ms word format , as of 2014 - 03 - 03"
test the str serialiser
test the int serialiser
does memoisation work ?
test the boolean serialiser
test the boolean serialiser
test the codebook serialiser
return current amcat version based on mercurial repository
join l by sep if it is a list
redirect a successful login
"try to log a user in . if method is get , show empty login - form"
let the user fill in a registration form or process such a form .
reset password based on email address or username .
overview of api resources
test whether codingschema objects can be created
"validate the given form , raising an invalidformexception if invalid"
"create an exception signalling a validation problem with the form @param message_or_form : the invalid form object , or a message string @param errors : the errors , will be extracted from first argument if it is a form"
"returns the fields containing errors as dict , with the fieldname as key and the errors as value ( in a list , there can be more than one )"
500 error handler which includes a normal request context and some extra info .
400 error handler which includes a normal request context .
404 error handler which includes a normal request context .
503 error handler which includes a normal request context .
403 forbidden handler which includes a normal request context .
"test if a set of keys matches this language . @param items : the keys to test @return : true if it 's a match , otherwise false ."
provides an interactive debugging session on unhandled exceptions see http://aspn.activestate.com/aspn/cookbook/python/recipe/65287
start the apt backend
implement the { backend}-get - distro - upgrades functionality
follow a different execution path based on variable values .
"reference : "" the ciede2000 color - difference formula : implementation notes , supplementary test data , and mathematical observations , "" , g. sharma , w. wu , e. n. dalal , submitted to color research and application , january 2004 . http://www.ece.rochester.edu/~gsharma/ciede2000/"
tests against a case where a negative square root in the delta_h calculation could happen .
tests against a case where a negative square root in the delta_h calculation could happen .
write a prompt to stdout and ask for answer in stdin .
write msg to standard out and flush .
run echo [ lines from diff ] | cmd -p0
run tests with command line interface input / output .
"this function will read through the rdf defined info and proccess the json to return the correct values for the instance , security and details"
return an api field
takes an object that fails with json.dumps and converts it to a json.dumps dumpable object . this is useful for debuging code when you want to dump an object for easy reading
returns all windows on all desktops @rtype : list of accessible
@type x : int @type y : int @type parent : accessible
@param window : parent window @type x : int @type y : int @type window : accessible
@type actioninfo : actioninfo @rtype : string
"add bid to bidlist . if opps_bid is true , surround it with parantheses ."
stringrep should be < denomination><kind >
appends a new child node to the node
"list with all the parent , and the current , bids"
used when copying from another node
"wait for network service to appear @param timeout : in seconds , if none or 0 wait forever @return : true of false , if timeout is none may return only true or throw unhandled network exception"
download latest chrome driver and add it to system path ( only for this session ) . if system already contains proper version do nothing . based on information from http://chromedriver.storage.googleapis.com/latest_release
download latest firefox geckodriver driver and add it to system path ( only for this session ) . if system already contains proper version do nothing . based on information from https://api.github.com/repos/mozilla/geckodriver/releases/latest
currently hard coded as arg future change to download from https://selenium-release.storage.googleapis.com
: return :
convert windows paths in dos format ( e.g. exampl~1.txt ) to long format .
feature engineering and computation of the grid .
classification inside one grid cell .
"iterates over all grid cells , aggregates the results and makes the submission ."
"renders form , and link to display it ."
"split key and value . return tuple ( key , value ) ."
"checks , if there are more args / kwargs available"
extract either positional or keyword argument .
returns remaining keyword arguments
you must only import bge modules here
resolve the dependency list such that the result contains all functions .
convert all the parameters in the given parameter list to actual parameter objects .
creates classes with as base class libraryfunctionsbase
creates classes with as base class simplecascademodel
finalize the preparation of the model in this callback .
parse the given model expression into a suitable model tree .
"mocked decorator , needed in the case we need to mock a decorator"
mock all modules starting with one of the mock_modules names .
this is an interface for some base methods we expect in an mri model .
check if the input data has enough information for this model to work .
get all the problems with the protocol .
get a list with the constant data names that are needed for this model to work .
update the active post - processing semaphores .
the base class for indicating problems with the input data .
this extends the given model protocol problem to also include the name of the model .
evaluate the model for every problem and every observation and return the estimates .
creates the crystal structure using ase . : param alat : lattice parameter in angstrom : return : structure object converted from ase
"make an input template and select potential and structure , and the path where to run"
verify that distributed packages survive setuptools installation .
"using regex invokes this function , which significantly impacts performance of adapt . it is an n ! operation ."
"tag known entities within the utterance . args : utterance(str ): a string of natural language text context_trie(trie ): optional , a trie containing only entities from context for this request"
example : play season 1 of the big bang theory play season one of the big bang theory series should contain two instances of the big bang theory : return :
write bibliography in a bibtex format
write bibliography in a text format
create and start an app . : param app_id : ( str ) - application id : param attr : marathon.models.app . marathonapp application to create . : return : the created app
get slave statistics via mesos api @args : ip : ip of the slave port : port that slave is listening to for requests
initialize parameters with small random values
"structured svm loss function , naive implementation ( with loops ) ."
"structured svm loss function , vectorized implementation ."
unit of theta is rad
this method is only used to interpolate large box
this method is only used to interpolate small box defined by its arguments
this method is only used to interpolate small box defined by its arguments
for both small and large depending on the previous
only for large box
only for small box
saveimage can save small box image or large box image depending on what interpolate and project methods are used previously
for both small and large depending on the previous
"core dynamic programming calculation of best path . m[r , c ] is the array of local costs . create d[r , c ] as the array of costs - of - best - paths to r , c , and phi[r , c ] as the indicator of the point preceding [ r , c ] to allow traceback ; 0 = ( r-1,c-1 ) , 1 = ( r , c-1 ) , 2 = ( r-1 , c )"
use dynamic programming to find a min - cost path through a matrix of local costs .
mean of word vectors
create a new context manager decorating a function within its scope .
parses a docstring looking for indented blocks that start with $ . it returns the first lines as call and the rest of the blocks as outputs .
engine configuration .
raise keyerror if a given config key violates any requirements .
create a slackobserver from a given configuration file .
evaluate this configscope .
"a catter plot ( scatter plot with cats ) . most arguments are interpreted the same as the matplotlib ` scatter ` function , except that ` ` s ` ` is the * data * size of the symbol ( not pixel ) . additional kwargs include :"
returns the url for a resourcefile
returns the redirect url for a resourceurl
creates a user bookmark for a resource
returns only resources that were sourced from peer instances
sanity check on defaults
should be equal to default approved count
should include resources created by user
should include resources updated by user
staff should include all resources regardless of status
reviewer should include all resources regardless of status
should include resources created by user
only one resource url should be returned for anon user
all resourceurls should be returned for staff user
check ca n't do a get request
check anon user ca n't post
check both resource and rating are required
check invalid resource
check invalid rating score
check rating gets updated rather than as new
sends an email to staff recipients that the peer was synced and a summary of updated resource counts .
a function that returns a request object configured with a user ( either a provided user or an anonymous user ) as well as a session attribute . useful anywhere testing against user state of any kind is required in a view .
returns a mock that can be used like a related object
args : instance : a model instance field_name : the name of the image field
return a synset for an ambiguous word in a context .
decorates a class to register it 's json tag .
access the relevant time offset .
returns ` false ` if the client should stop fetching tweets .
: param int limit : the number of data items to process in the current round of processing .
deal appropriately with data returned by the twitter api
actions when the tweet limit has been reached
validate date limits .
non - interactive demonstration of the clusterers with simple 2 - d data .
"creates an em clusterer with the given starting parameters , convergence threshold and vector mangling parameters ."
decode the result of model_found ( )
try some proofs and exhibit the results .
try to build a ` ` nltk.sem . valuation ` ` .
transform the model into various mace4 ` ` interpformat ` ` formats .
: param goal : input expression to prove : type goal : sem . expression : param assumptions : input expressions to use as assumptions in the proof . : type assumptions : list(sem . expression ) : param max_models : the maximum number of models that mace will try before simply returning false . ( use 0 for no maximum . ) : type max_models : int
transform the output file into an nltk - style valuation .
convert a mace4 - style relation table into a dictionary .
pick an alphabetic character as identifier for an entity in the model .
print out a mace4 model using any mace4 ` ` interpformat ` ` format . see http://www.cs.unm.edu/~mccune/mace4/manual/ for details .
transform the output file into any mace4 ` ` interpformat ` ` format .
call the ` ` interpformat ` ` binary with the given input .
use mace4 to build a first order model .
call the ` ` mace4 ` ` binary with the given input .
construct a new tagged corpus reader for a set of documents located at the given root directory . example usage :
: return : the given file(s ) as a single string . : rtype : str
: return : the given file(s ) as a list of words and punctuation symbols . : rtype : list(str )
": return : the given file(s ) as a list of sentences or utterances , each encoded as a list of word strings . : rtype : list(list(str ) )"
": return : the given file(s ) as a list of paragraphs , each encoded as a list of sentences , which are in turn encoded as lists of word strings . : rtype : list(list(list(str ) ) )"
": return : the given file(s ) as a list of tagged words and punctuation symbols , encoded as tuples ` ` ( word , tag ) ` ` . : rtype : list(tuple(str , str ) )"
": return : the given file(s ) as a list of sentences , each encoded as a list of ` ` ( word , tag ) ` ` tuples ."
": return : the given file(s ) as a list of paragraphs , each encoded as a list of sentences , which are in turn encoded as lists of ` ` ( word , tag ) ` ` tuples . : rtype : list(list(list(tuple(str , str ) ) ) )"
"initialize the corpus reader . categorization arguments ( ` ` cat_pattern ` ` , ` ` cat_map ` ` , and ` ` cat_file ` ` ) are passed to the ` ` categorizedcorpusreader ` ` constructor . the remaining arguments are passed to the ` ` taggedcorpusreader ` ` ."
reads one paragraph at a time .
traverse the alignment cost from the tracebacks and retrieves appropriate sentence pairs .
"returns the log probability of the two sentences c{source_sents[i ] } , c{target_sents[j ] } being aligned with a specific c{alignment } ."
return the sentence alignment of two text blocks ( usually paragraphs ) .
creates the sentence alignment of two texts .
splits an iterator c{it } at values of c{split_value } .
parses a stream of tokens and splits it into sentences ( using c{soft_delimiter } tokens ) and blocks ( using c{hard_delimiter } tokens ) for use with the l{align_texts } function .
wraps function arguments : if fileids not specified then function set nkjpcorpusreader paths .
"corpus reader designed to work with national corpus of polish . see http://nkjp.pl/ for more details about nkjp . use example : import nltk import nkjp from nkjp import nkjpcorpusreader x = nkjpcorpusreader(root='/home / user / nltk_data / corpora / nkjp/ ' , fileids= '' ) # obtain the whole corpus x.header ( ) x.raw ( ) x.words ( ) x.tagged_words(tags=['subst ' , ' comp ' ] ) # link to find more tags : nkjp.pl/poliqarp/help/ense2.html x.sents ( ) x = nkjpcorpusreader(root='/home / user / nltk_data / corpora / nkjp/ ' , fileids='wilk * ' ) # obtain particular file(s ) x.header(fileids=['wilkdom ' , ' /home / user / nltk_data / corpora / nkjp / wilkwilczy ' ] ) x.tagged_words(fileids=['wilkdom ' , ' /home / user / nltk_data / corpora / nkjp / wilkwilczy ' ] , tags=['subst ' , ' comp ' ] )"
returns a list of file identifiers for the fileids that make up this corpus .
returns a view specialised for use with particular corpus file .
add root if necessary to specified fileid .
returns header(s ) of specified fileids .
returns sentences in specified fileids .
returns words in specified fileids .
"call with specified tags as a list , e.g. tags=['subst ' , ' comp ' ] . returns tagged words in specified fileids ."
returns words in specified fileids .
header_mode a stream backed corpus view specialized for use with header.xml files in nkjp corpus .
returns text as a list of sentences .
replaces the old suffix of the original string by a new suffix
"if precision is the default value , to_dict should return a string"
"if precision is the default value , to_dict should return a string"
initialises a new ' steamsupply ' instance .
steam turbines may have steam supplied by a steam supply
initialises a new ' breaker ' instance .
initialises a new ' bay ' instance .
the association is used in the naming hierarchy .
the association is used in the naming hierarchy .
initialises a new ' work ' instance .
all the customers for which this work is performed .
initialises a new ' transformerwinding ' instance .
the ratio tap changer associated with the transformer winding .
the phase tap changer associated with the transformer winding .
a transformer has windings
initialises a new ' energyconsumer ' instance .
the load response characteristic of this load .
initialises a new ' govhydror ' instance .
initialises a new ' valuealiasset ' instance .
the measurements using the set for translation
the valuealiasset used for translation of a control value to a name .
the valuetoalias mappings included in the set
initialises a new ' direction ' instance .
initialises a new ' currentlimitset ' instance .
initialises a new ' dclinesegment ' instance .
initialises a new ' jumper ' instance .
initialises a new ' outageclearancetag ' instance .
initialises a new ' duct ' instance .
initialises a new ' tapchangercontrol ' instance .
copy from reg conduting eq
initialises a new ' opencircuittest ' instance .
all other windings measured during this test .
initialises a new ' ratiotapchangertabularpoint ' instance .
initialises a new ' regulatingcondeq ' instance .
"the controller outputs used to actually govern a regulating device , e.g. the magnetization of a synchronous machine or capacitor bank breaker actuator ."
the regulating control scheme in which this equipment participates .
initialises a new ' cashier ' instance .
all shifts operated by this cashier .
initialises a new ' coreterminal ' instance .
initialises a new ' connectionframe ' instance .
initialises a new ' remoteunit ' instance .
remote points this remote unit contains .
rtus may be attached to communication links .
initialises a new ' voltagecontrolzone ' instance .
a voltagecontrolzone may have a voltage regulation schedule .
a voltagecontrolzone is controlled by a designated busbarsection .
initialises a new ' cheque ' instance .
payment tender the cheque is being used for .
initialises a new ' steamsendoutschedule ' instance .
a cogeneration plant has a steam sendout schedule
initialises a new ' energyconsumer ' instance .
an energy consumer is assigned to a power cut zone
initialises a new ' outagerecord ' instance .
multiple outage codes may apply to an outage record .
initialises a new ' shuntcompensator ' instance .
the state for the number of shunt compensator sections in service .
initialises a new ' dynamicsmetablockconnectivity ' instance .
initialises a new ' govgasm ' instance .
initialises a new ' faultindicator ' instance .
initialises a new ' breaker ' instance .
initialises a new ' svtapstep ' instance .
the tap changer associated with the tap step state .
initialises a new ' loadarea ' instance .
the subloadareas in the loadarea .
initialises a new ' pssieee2b ' instance .
initialises a new ' switchschedule ' instance .
a switchschedule is associated with a switch .
initialises a new ' apparentpowerlimitset ' instance .
initialises a new ' season ' instance .
schedules that use this season .
initialises a new ' overheadconductorinfo ' instance .
initialises a new ' equipmentcontainer ' instance .
the association is used in the naming hierarchy .
initialises a new ' dynamicdemand ' instance .
initialises a new ' vendor ' instance .
all points of sale this vendor controls .
merchant account against which this vendor sells tokens or recept payments .
all cachiers managed by this vendor .
all vendor shifts opened and owned by this vendor .
initialises a new ' shuntcompensator ' instance .
initialises a new ' breaker ' instance .
initialises a new ' psrlist ' instance .
initialises a new ' excitationsystemsexcac5a ' instance .
initialises a new ' dimensionsinfo ' instance .
initialises a new ' register ' instance .
reading type for values displayed by this register .
device function metering quantities displayed by this register .
initialises a new ' currentlimit ' instance .
initialises a new ' basepower ' instance .
initialises a new ' startrampcurve ' instance .
the unit 's startup model may have a startup ramp curve
initialises a new ' cuallowableaction ' instance .
initialises a new ' infcoremodelingauthorityset ' instance .
initialises a new ' govwt1p ' instance .
initialises a new ' assetmodelcatalogueitem ' instance .
initialises a new ' topologicalisland ' instance .
"the angle reference for the island . normally there is one topologicalnode that is selected as the angle reference for each island . other reference schemes exist , so the association is optional ."
a topological node belongs to a topological island
initialises a new ' hydrogeneratingunit ' instance .
a hydro generating unit has a penstock loss curve
the hydro generating unit belongs to a hydro power plant
a hydro generating unit has a tailbay loss curve
a hydro generating unit has an efficiency curve
initialises a new ' voltagelimit ' instance .
initialises a new ' geolocation ' instance .
all power system resources at this geographical location .
initialises a new ' stationsupply ' instance .
initialises a new ' transformercoreadmittance ' instance .
all transformer ends having this core admittance .
initialises a new ' busbarsection ' instance .
test cim rdf / xml serialisation .
initialises a new ' outageschedule ' instance .
an outageschedule may operate many switches .
a power system resource may have an outage schedule
initialises a new ' activepowerlimit ' instance .
initialises a new ' transformerwinding ' instance .
initialises a new ' merchantagreement ' instance .
all merchant accounts instantiated as a result of this merchant agreement .
initialises a new ' excac1a ' instance .
initialises a new ' reservoir ' instance .
a reservoir may have a level versus volume relationship .
a reservoir may have a water level target schedule .
generators discharge water to or pumps are supplied water from a downstream reservoir
generators are supplied water from or pumps discharge water to an upstream reservoir
a reservoir may have a ' natural ' inflow forecast .
a reservoir may spill into a downstream reservoir
a reservoir may spill into a downstream reservoir
initialises a new ' wiretype ' instance .
all wire arrangements using this wire type .
all concentric neutral cables using this wire type .
initialises a new ' conformloadschedule ' instance .
the conformloadgroup where the conformloadschedule belongs .
initialises a new ' conductingequipment ' instance .
initialises a new ' heatinputcurve ' instance .
a thermal generating unit may have a heat input curve
initialises a new ' staticvarcompensator ' instance .
initialises a new ' discretevalue ' instance .
measurement to which this value is connected .
initialises a new ' erpinvoice ' instance .
initialises a new ' dynamicsmetablockinput ' instance .
initialises a new ' transformerinfo ' instance .
data for all the windings described by this transformer data .
all transformers that can be described with this transformer data .
initialises a new ' windgeneratingunit ' instance .
initialises a new ' fossilsteamsupply ' instance .
initialises a new ' modelingauthorityset ' instance .
a modeling authority set supplies and maintains the data for the objects in a modeling authority set .
an identifiedobject belongs to a modeling authority set for purposes of defining a group of data maintained by the same modeling authority .
initialises a new ' auxiliaryaccount ' instance .
all charges levied on this account .
auxiliary agreement regulating this account .
all payments against this account .
initialises a new ' specification ' instance .
"userattributes used to specify further properties of the asset covered with this specification . use ' name ' to specify what kind of property it is , and ' value.value ' attribute for the actual value ."
"userattributes used to specify ratings of the asset covered by this specification . ratings also can be used to set the initial value of operational measurement limits . use ' name ' to specify what kind of rating it is ( e.g. , voltage , current ) , and ' value ' attribute for the actual value and unit information of the rating ."
initialises a new ' gmlfeaturetype ' instance .
initialises a new ' coreidentifiedobject ' instance .
initialises a new ' distributiontransformerwinding ' instance .
data for this winding .
transformer this winding belongs to .
ratio tap changer associated with this winding .
initialises a new ' subgeographicalregion ' instance .
the association is used in the naming hierarchy .
a line can be contained by a subgeographical region .
the association is used in the naming hierarchy .
initialises a new ' route ' instance .
initialises a new ' emissioncurve ' instance .
a thermal generating unit may have one or more emission curves
initialises a new ' orgpropertyrole ' instance .
initialises a new ' incrementalheatratecurve ' instance .
a thermal generating unit may have an incremental heat rate curve
initialises a new ' fuse ' instance .
initialises a new ' pricingstructure ' instance .
service category to which this pricing structure applies .
all customer agreements with this pricing structure .
"all service delivery points ( with prepayment meter running as a stand - alone device , with no customeragreement or customer ) to which this pricing structure applies ."
all tariffs used by this pricing structure .
all transactions applying this pricing structure .
initialises a new ' aclinesegment ' instance .
initialises a new ' medium ' instance .
initialises a new ' accumulatorlimitset ' instance .
the measurements using the limitset .
the limit values used for supervision of measurements .
initialises a new ' perlengthphaseimpedance ' instance .
all conductor segments described by this phase impedance .
all data that belong to this conductor phase impedance .
initialises a new ' hazard ' instance .
the point or polygon location of a given hazard .
initialises a new ' serviceguarantee ' instance .
initialises a new ' loadbreakswitch ' instance .
initialises a new ' erppayable ' instance .
initialises a new ' fuse ' instance .
initialises a new ' transformerend ' instance .
"core admittance of this transformer end , representing magnetising current and core losses . the full values of the transformer should be supplied for one transformer end only ."
data for this transformer end .
"( accurate for 2- or 3 - winding transformers only ) pi - model impedances of this transformer end . by convention , for a two winding transformer , the full values of the transformer should be entered on the high voltage end ( endnumber=1 ) ."
initialises a new ' noloadtest ' instance .
transformer end that current is applied to in this no - load test .
initialises a new ' statevariable ' instance .
initialises a new ' branchgroupterminal ' instance .
the branch group to which the directed branch group terminals belong .
the terminal to be summed .
initialises a new ' rectifierinverter ' instance .
initialises a new ' resistor ' instance .
initialises a new ' excac8b ' instance .
initialises a new ' distributiontransformer ' instance .
transformer data .
all windings of this transformer .
bank this transformer belongs to .
initialises a new ' enddeviceevent ' instance .
set of measured values to which this event applies .
device function that reported this end device event .
initialises a new ' tapschedule ' instance .
a tapschedule is associated with a tapchanger .
initialises a new ' accumulator ' instance .
a measurement may have zero or more limit ranges defined for it .
the values connected to this measurement .
initialises a new ' genunitopcostcurve ' instance .
"a generating unit may have one or more cost curves , depending upon fuel mixture and fuel cost ."
initialises a new ' intervalreading ' instance .
all blocks containing this interval reading .
used only if quality of this interval reading value is different than ' good ' .
initialises a new ' phasetapchangerlinear ' instance .
initialises a new ' shuntcompensator ' instance .
initialises a new ' timetariffinterval ' instance .
"all consumption tariff intervals that introduce variation in this time of use tariff interval ; allows to express e.g. , peak hour prices that are different with different consumption blocks ."
all tariff profiles defined by this time tariff interval .
all charges used to define this time tariff interval .
initialises a new ' apparentpowerlimit ' instance .
initialises a new ' regulatingcondeq ' instance .
initialises a new ' gmldiagramobject ' instance .
initialises a new ' fuelallocationschedule ' instance .
a fuel allocation schedule must have a fossil fuel
a thermal generating unit may have one or more fuel allocation schedules
initialises a new ' voltagelevel ' instance .
the base voltage used for all equipment within the voltagelevel .
initialises a new ' financialinfo ' instance .
initialises a new ' switchinfo ' instance .
initialises a new ' commonlocation ' instance .
initialises a new ' distributionlinesegment ' instance .
conductor data of this conductor segment .
sequence impedance of this conductor segment ; used for balanced model .
phase impedance of this conductor segment ; used for unbalanced model .
initialises a new ' motorasync ' instance .
initialises a new ' govdum ' instance .
initialises a new ' excac3a ' instance .
initialises a new ' substation ' instance .
the association is used in the naming hierarchy .
the association is used in the naming hierarchy .
initialises a new ' textdiagramobject ' instance .
initialises a new ' pendingcalculation ' instance .
all blocks of interval reading values to which this pending conversion applies .
reading type resulting from this pending conversion .
initialises a new ' safetydocument ' instance .
initialises a new ' request ' instance .
initialises a new ' remotesource ' instance .
link to the physical telemetered point associated with this measurement .
initialises a new ' erpchartofaccounts ' instance .
initialises a new ' loadresponsecharacteristic ' instance .
the set of loads that have the response characteristics .
initialises a new ' topologicalnode ' instance .
the short circuit state associated with the topological node .
the connectivity node container to which the toplogical node belongs .
the injection state associated with the topological node .
"several connectivitynode(s ) may combine together to form a single topologicalnode , depending on the current state of the network ."
the state voltage associated with the topological node .
the base voltage of the topologocial node .
a topological node belongs to a topological island
the reporting group to which the topological node belongs .
"the terminals associated with the topological node . this can be used as an alternative to the connectivity node path to terminal , thus making it unneccesary to model connedtivity nodes in some cases . note that the if connectivity nodes are in the model , this association would proably not be used ."
the island for which the node is an angle reference . normally there is one angle reference node for each island .
initialises a new ' protectionequipment ' instance .
the unit for the protection equipment .
protection equipment may be used to protect specific conducting equipment . multiple equipment may be protected or monitored by multiple protection equipment .
initialises a new ' reservoir ' instance .
initialises a new ' analoglimit ' instance .
the set of limits .
initialises a new ' motorsmechload1 ' instance .
initialises a new ' govhydro0 ' instance .
initialises a new ' clearancetagtype ' instance .
the clearancetags currently being defined for this type .
initialises a new ' name ' instance .
type of this name .
identified object that this name designates .
initialises a new ' basevoltage ' instance .
use association to conductingequipment only when there is no voltagelevel container used .
the voltagelevels having this basevoltage .
initialises a new ' energyconsumer ' instance .
initialises a new ' transaction ' instance .
pricing structure applicable for this transaction .
all snapshots of meter parameters recorded at the time of this transaction . use ' name ' and ' value.value ' attributes to specify name and value of a parameter from meter .
customer account for this payment transaction .
cashier shift during which this transaction was recorded .
vendor shift during which this transaction was recorded .
meter asset for this vending transaction .
auxiliary account for this payment transaction .
the receipted payment for which this transaction has been recorded .
initialises a new ' operatingshare ' instance .
the powersystemresource to which the attribues apply . the percentage ownership of all owners of a powersystemresource should add to 100 % .
"the linkage to a owners and its linkage attributes like percentage ownership . the ownership percentage should add to 100 % for all owners of a powersystemresource , but a psrowner may own any percentage of any number of powersystemresource objects ."
initialises a new ' topologicalnode ' instance .
initialises a new ' substation ' instance .
initialises a new ' loadmgmtfunction ' instance .
initialises a new ' enddevicemodel ' instance .
all end device assets being of this model .
initialises a new ' vehicle ' instance .
initialises a new ' terminal ' instance .
the power flow state associated with the terminal .
initialises a new ' transformercoreadmittance ' instance .
transformer end info having this core admittance .
initialises a new ' govsteam1 ' instance .
initialises a new ' tariffprofile ' instance .
all tariffs defined by this tariff profile .
all consumption tariff intervals used to define this tariff profile .
all time tariff intervals used to define this tariff profile .
initialises a new ' switch ' instance .
a switch can be associated with switchschedules .
initialises a new ' rectifierinverter ' instance .
initialises a new ' iec61970cimversion ' instance .
initialises a new ' svshortcircuit ' instance .
the topological node associated with the short circuit state .
initialises a new ' energyconsumer ' instance .
initialises a new ' materialitem ' instance .
initialises a new ' svshortcircuit ' instance .
initialises a new ' turbinegovernorsgovct1 ' instance .
initialises a new ' synchronousmachine ' instance .
make all the directories the specified relative path consists of .
perform soft - reset of the esp8266 board .
list relative file paths inside the given path .
wait for some esp8266 devices to become ready for repl commands .
show progress while iterating over a sequence .
open a dash scope .
open the preview of an application .
click an item from the scope .
return the list of applications on a category .
we 'll need empty stacks for undo / redo and some state keeping
do n't record the next actions
record next actions
undo inserts or deletions
redo inserts or deletions
"short version , only used for eval_offset"
will update the motor rpm supposes u is constant for the interval dt
return the motor speed ( rpm )
returns the motor position
sets the motor cmd in volts
function to renice a process
returns true only if all processes status are s
will renice all the blocks processes according to block.niceness value
"starts all the blocks processes ( block.prepare ) , but not the main loop"
stops all the blocks ( crappy.stop )
"if main is not overriden , this method will be called first , before entering the main loop"
"if main is not overriden , this method will be called upon exit or after a crash ."
for block with a given number of loops / s ( use freq attr to set it )
"to start the main method , will call start if needed"
"returns the status of the block , from the process itself or the parent"
"this will be run when creating the process , but before the actual start"
to send the data to all blocks downstream
to get the latest value of each labels from all inputs
to get the data from all links of the block
will clear the inputs of the blocks
init the buzzer : param pin : pin number : param real_true : gpio.high or gpio.low : return : void
return the status of buzzer : return : void
set buzzer on : return : void
set buzzer off : return : void
beep one time : param seconds : beep time : return : void
"beep in a rhythm e.g. beepaction(0.02,0.02,30 ) : param secs : beep time : param sleepsecs : break time : param times : repeat times : return : void"
init the digital display : param pin : pin numbers in array : param real_true : gpio.high or gpio.low : return : void
get the current numbers array showing : return : numbers array
set the numbers array to show : return : void
set display on : return : void
set display off : return : void
set the numbers array to show and enable the display : return : void
init the digital display : param pin : pin numbers in array : param real_true : gpio.high or gpio.low : return : void
get the current status of the digital display
set the numbers array to show : return : void
return the instance of ic : return : ic
set display on : return : void
set display off : return : void
set the numbers array to show and enable the display : return : void
init the ds18b20 : param pin : pin number : return : void
return true if the ds18b20 is exist : param index : from 0 to n : return : return true if the ds18b20 is exist
"get the temperature from ds18b20 : param index : from 0 to n : return : return the temperature from ds18b20 , return -128 means get a error ."
trace log debug info
"do_debug ( ) wrapper from rfx . base object , pivoting off server global"
"do_debug ( ) wrapper from rfx . base object , pivoting off server global"
debug wrapper for logging
log key = value pairs for easier splunk processing
"pull the jti from the payload of the jwt without verifying signature . dangerous , not good unless secondary verification matches ."
constructor . any message fields that are implicitly / explicitly set to none will be assigned a default value . the recommend use is keyword arguments as this is more robust to future message changes . you can not mix in - order arguments and keyword arguments .
"serialize message into buffer : param buff : buffer , ` ` stringio ` `"
"unpack serialized message in str into this message instance : param str : byte array of serialized message , ` ` str ` `"
"serialize message with numpy array types into buffer : param buff : buffer , ` ` stringio ` ` : param numpy : numpy python module"
"unpack serialized message in str into this message instance using numpy for array types : param str : byte array of serialized message , ` ` str ` ` : param numpy : numpy python module"
create a planning scene interface ; it uses both c++ wrapped methods and scene manipulation topics .
add a sphere to the planning scene
"create an empty collision object , used when the object already exists"
add a mesh to the planning scene
add a box to the planning scene
add a plane to the planning scene
"remove an object from planning scene , or all if no name is provided"
"remove an attached object from planning scene , or all objects attached to this link if no name is provided"
"get the names of all known objects in the world . if with_type is set to true , only return objects that have a known type ."
"get the names of known objects in the world that are located within a bounding region ( specified in the frame reported by get_planning_frame ( ) ) . if with_type is set to true , only return objects that have a known type ."
get the poses from the objects identified by the given object ids list .
"get the objects identified by the given object ids list . if no ids are provided , return all the known objects ."
"get the attached objects identified by the given object ids list . if no ids are provided , return all the attached objects ."
initialize ' components ' & add them to the suite .
return test name as used in django db .
run the tests under the suite and update its data object .
get the number of ancestors .
update the data that the test started .
encode a message .
decode a message .
encode a message .
decode a message .
save a copy of the resource to the db and link it to the case .
assign the tests ' datas with the saved run data and save them .
save all the test datas and the run data .
update the test data to ' in progress ' state and set the start time .
check if the test passed in the last run .
save a copy of the test 's resources and point to them in the db .
finalize the test 's data and save a copy of its resources .
update the test data to ' in progress ' state and set the start time .
save the composite test 's data .
save the test data result as success .
save the test data result as skip .
save the test data result as failure .
save the test data result as error .
save the test data result as expected failure .
save the test data result as unexpected success .
initialize the handler and check that the artifacts dir was set .
add the case dir to the artifact .
add the files of the main work directory to the artifact .
add the sub test data as a child .
called when a connection is made .
called when the connection is shut down .
handle data received .
recursively create the test 's datas and add them to ' all_tests ' .
initialize the tests run data .
initialize the tests run data .
update the test data to ' in progress ' state and set the start time .
check if the test passed in the last run according to results db .
finalize the test 's data .
update the resources list for a test data .
add a result to the test .
update the test data to ' in progress ' state and set the start time .
save the composite test 's data .
respond to the client 's request .
create and return the relevant test runner .
initialize the test runner .
validate the state of the test and its sub - tests is finished .
validate the result of a simple case of success .
validate that a testcase can run on its own .
validate the result of a simple case of failure .
validate the result of a simple case of stored failure .
validate the result of a simple case of error .
validate the result of success and skip .
validate the result of a simple case of skip .
validate the result of a simple case of unexpected success .
validate the result of a simple case of expected failure .
validate that the tests under a testsuite are not linked .
create and return the relevant test runner .
validate runner result in case of a timeout .
validate runner result in case of a timeout in flow 's setup .
validate runner result in case of worker process crash .
validate runner result in case of flow process crash .
validate runner result in case of a mid - test timeout .
validate runner result of a mid - test of crash .
create and return the relevant test runner .
write the given message with the given color .
write the colored message with a new line postfix .
initialize the handler .
write the test details to the stream .
print a summary of the given error list to the stream .
print a summary of all the given error lists to the stream .
initialize the result handler and connect to the result server .
save all the test datas and the run data in the remote db .
disconnect from the result server .
update the remote test data to ' in progress ' and set the start time .
check if the test passed in the last run according to the remote db .
update the resources of the test in the remote db .
finalize the remote test 's data .
update the remote test data to ' in progress ' and set the start time .
save the remote composite test 's data .
save the remote test data result as success .
save the remote test data result as skip .
save the remote test data result as failure .
save the remote test data result as error .
save the remote test data result as expected failure .
save the remote test data result as unexpected success .
validate an expression contains only boolean values and operators .
return the tags of a test item .
check whether a tags list answers a condition expressed in tags_filter .
initialize the displaywidget .
this method replaces the previous simulator with ` simulator ` .
initialize the displaywidget .
turn a name of a subcell into x / y coords
add code to c and python
adds the randseed attribute to the target .
": param probab : the probability of a cell to be computed . : param random_generator : if supplied , use this random object for random values ."
adds c code for handling the skipping .
create the image surface to use .
instantiate a display ( thas is : a window with a display widget and simulation controls ) from a simulator .
sets the scale of the display component .
adds the activity mask and position list to the target attributes .
calculate how big the mask and list have to be .
returns a dictionary mapping categories to known classes .
"from the given parameters , assemble a stepfunc with the given computation and visitors objects . additionally , a target is created ."
": param size : the size of the config to generate if no config is supplied . must be a tuple . : param nondet : if this is not 1 , use this value as the probability for each cell to get executed . : param histogram : generate and update a histogram as well ? : param rule : the rule number for the elementary cellular automaton . : param config : optionally the configuration to use . supply a configuration generator here to make the reset method of the simulator work . : param beta : if the probability is not 1 , use this as the probability for each cell to succeed in exposing its result to the neighbouring cells . this is incompatible with the nondet parameter . : param copy_borders : copy over data from the other side ? : param neighbourhood : the neighbourhood to use . : param base : the base of possible values for the configuration . : param sparse_loop : should a sparse loop be used ?"
": param size : the size of the config to generate if no config is supplied via the * config * parameter . : param nondet : if this is not 1 , use this value as the probability for each cell to get executed . : param histogram : generate and update a histogram as well ? : param config : optionally the configuration to use . supply a configuration generator here to make the reset method of the simulator work . : param beta : if the probability is not 1 , use this as the probability for each cell to succeed in exposing its result to the neighbouring cells . this is incompatible with the nondet parameter . : param copy_borders : copy over data from the other side ? : param life_params : those parameters are passed on to the constructor of ` lifecellularautomatonbase ` . : param sparse_loop : should a sparse loop be generated ?"
computes a babel.core : locale ( ) object for this request .
"create the service , given the context and request for which it is being created for ."
sends an email with the given subject and body to the given recipient .
test if all html templates have defined the title block . see https://github.com/pypa/warehouse/issues/784
calculate the hamming distance ( number of bits different ) between the two integers given .
"initialize a bktree instance with given distance function ( which takes two items as parameters and returns a non - negative distance integer ) . "" items "" is an optional list of items to add on initialization ."
add given item to this tree .
"find items in this tree whose distance is less than or equal to n from given item , and return list of ( distance , item ) tuples ordered by distance ."
return iterator over all items in this tree ; items are yielded in arbitrary order .
return a string representation of this bk - tree with a little bit of info .
request release information from jetbrains xhr endpoint
request lightroom updates lua script which contains the download url and localised update string currently unused
get the .dmg url
returns the file name for input restart file .
returns the file name for output restart file .
calculates cr value used in superbee advection scheme
2th order advective tracer flux
from mitgcm calculates advection of a tracer using second - order interpolation with a flux limiter : egin{equation * } f^x_{adv } = u \overline { heta } ^i - rac{1}{2 } \left ( [ 1 - \psi(c_r ) ] |u| + u rac{u \delta t}{\delta x_c } \psi(c_r ) ight ) \delta_i heta \end{equation * } where the $ \psi(c_r)$ is the limiter function and $ c_r$ is the slope ratio .
calculates advection velocity for tracer on w grid
calculates advection of a tracer defined on wgrid
calculates advection of a tracer defined on wgrid
define standard grid in netcdf file
"if using io threads , start a new thread to write the netcdf data to disk ."
"if there is no lock for file_id , create one"
wait for the lock of file_id to be released
"sync netcdf data to disk , close file handle , and release lock . may run in a separate thread ."
island and island perimeter boundary mapping routines
"this function uses a "" flood fill "" algorithm to expand one previously unmarked land point to its entire connected land mass and its perimeter ocean points . diagonally adjacent land points are considered connected . perimeter "" collisions "" ( i.e. , ocean points that are adjacent to two unconnected land masses ) are detected and error messages generated ."
prompt for and return a username and password .
set response with given parameters
create a pdf from cadastre data
get pdf files previously exported
returns a user which is connected with wunderlist and habitica .
"it appears one asian character takes two spots , but _ _ len _ _ counts it as three , so this function counts the dispalyed length of the string ."
create elasticsearch fixture pairs .
simple test for starting elasticsearch_proc .
test if elasticsearch fixtures connects to process .
verfiy if we can properly extract elasticsearch version .
test if elasticsearch fixture can be started on random port .
test default configuration .
test if ini and option configuration works in proper way .
test if arg comes first than opt and ini .
takes in a private key / secret exponent .
create keypair from a passphrase input ( a brain wallet keypair ) .
the secret exponent is the private key in int or hex format .
"the "" wif pk "" is the private key in wallet import format ."
the address is the hash160 in b58check format .
queries the twilio rest api to get phone numbers available for puchase
purchases a new phone number from the twilio api
_ _ init _ _ create connection to redis database . open a file for api output .
_ _ del _ _ strictredis does n't implement close or quit methods . we do n't need to close redis connection here .
"test if jad command exists . run ` jad ` command as a test . if the status is 32512 , it means that system can not find the ` jad ` command . if the response is 256 , ` jad ` can be run but ` jad ` can not runs stably without arguments . if the status is neither 32512 nor 256 , i do n't know what happened ."
read apis from java file .
convert data to xml .
build xml recursively .
"sets the log_level for weld : 0 = no logs , 1 = error , 2 = warn , 3 = info , 4 = debug , 5 = trace ."
: return : number of iocs in self.iocs
parses files to load them into memory and insert them into the class .
parses an ioc to populate self.iocs and self.ioc_name
register a callback function that is called after self.iocs and self.ioc_name is populated .
initializes the exception instance .
initializes the exception instance . arguments are : * ( str ) message . describes the error . * ( int ) code . the code error ( defined in the error class ) .
builds the metadata of the sp
signs the metadata with the key / cert provided
adds the x509 descriptors ( sign / encryption ) to the metadata the same cert will be used for sign / encrypt
deep - merge dictionary ` b ` into dictionary ` a ` .
gets the metadata xml from the provided url : param url : url where the xml of the identity provider metadata is published . : type url : string
"gets the metadata xml from the provided url and parse it , returning a dict with extracted data : param url : url where the xml of the identity provider metadata is published . : type url : string"
parses the identity provider metadata and return a dict with extracted data .
will update the settings with the provided new settings data extracted from the idp metadata : param settings : current settings dict data : type settings : string : param new_metadata_settings : settings to be merged ( extracted from idp metadata after parsing ) : type new_metadata_settings : string : returns : merged settings : rtype : dict
filters the discovered test cases
determine whether ` ` value ` ` is iterable .
create one and only one pool using the configured settings .
obtain a database connection from the connection pool .
store ` ` old_connect ` ` to be used whenever we connect .
delegate to the old ` ` connect ` ` .
calculate the hash of this ` ` dict ` ` .
get timezone from a string .
posix is stupid so these are reversed .
format when something will happen
a countdown tag .
"set the osu ! api key . this simplifies every api function as they can exclude the "" k "" parameter ."
add a section using a template to simplify adding api functions .
"parse the beatmap url and return either a beatmapurlinfo . for v1 , only one parameter of either beatmap_id or beatmapset_id will be set . for v2 , only beatmapset_id will be set , or all arguments are set ."
finds and returns the first beatmap with the lookup specified .
return the rank of the first score of given beatmap_id from a list of events gathered via get_user ( ) .
return the mode with the specified string .
convert the given value to 2^num .
return a list of mod enums from the given bitwise ( enabled_mods in the osu ! api )
"return a string with the mods in a sorted format , such as dthd ."
return the ip address ( can be v4 or v6 ) of the client requesting this view .
put the ip address ( can be v4 or v6 ) of the client requesting this view into the client 's session .
construct a 401 response requesting http basic auth .
get username and password from http basic auth string .
check username and password against our database .
check our database whether the hostname is owned by the user .
shortcut for plaintext response
dyndns2 compatible /nic / update api .
"similar to nicupdateview , but the client is not a router or other dyndns client , but the admin browser who is currently logged into the nsupdate.info site ."
get the record type ' a ' or ' aaaa ' for this ipaddr .
intelligent dns adder - first does a lookup on the master server to find the current ip and only sends an ' add ' if there is no such entry . otherwise send an ' upd ' if the if we have a different ip .
intelligent dns updater - first does a lookup on the master server to find the current ip and only sends a dynamic update if we have a different ip .
query a dns name from our master server
parse a fully qualified domain name into a relative name and a origin zone . please note that the origin return value will have a trailing dot .
"get the master nameserver for the < origin > zone , the key needed to update the zone and the key algorithm used ."
update our master server
: ivar int index : the index of this item in the list used to initialize the : class:`cursesmenu . selectionmenu `
: return : the index of this item in the list of strings : rtype : int
set the -setnumber inputs to be passed to gmsh .
get the number associated with the variable name found in the mesh_name as specified in the parameters.geo file .
get the number associated with the single variable name as specified in the parameters.geo file .
write meshvariables file .
"returns a list of all the [ docname , similarity_score ] pairs relative to a list of words ."
parse a string containing a boolean value .
parse a dash - separated number range .
parse a comma - separated list of dash - separated number ranges .
utility method for converting docstrings into help - text
utility routine used by path completion methods
wraps a paragraph of text to the terminal
prompts and reads input from the user
pretty - prints text to the terminal
pretty - prints a table of data
displays the available commands or help on a specified command .
exits from the application .
"@type uifile : str @param uifile : absolute path of .ui file @type baseinstance : qwidget @param baseinstance : the optional instance of the qt base class . if specified then the user interface is created in it . otherwise a new instance of the base class is automatically created . @type custom_widgets : dict of { str : qwidget } @param custom_widgets : class name and type of the custom classes used in uifile if any . this can be none if no custom class is in use . ( note : this is only necessary for pyside , see http://answers.ros.org/question/56382/what-does-python_qt_bindingloaduis-3rd-arg-do-in-pyqt-binding/ for more information )"
converts all variables in a graph and checkpoint into constants .
: type nums : list[int ] : type k : int : rtype : bool
use bfs to set o to y
: type p : treenode : type q : treenode : rtype : bool
: type nums : list[int ] : rtype : int
: type nums : list[int ] : type target : int : rtype : int
: type root : treelinknode : rtype : nothing
: type nums : list[int ] : type target : int : rtype : list[list[int ] ]
: type s : str : rtype : bool
constructor . any message fields that are implicitly / explicitly set to none will be assigned a default value . the recommend use is keyword arguments as this is more robust to future message changes . you can not mix in - order arguments and keyword arguments .
serialize message into buffer @param buff : buffer @type buff : stringio
unpack serialized message in str into this message instance @param str : byte array of serialized message @type str : str
serialize message with numpy array types into buffer @param buff : buffer @type buff : stringio @param numpy : numpy python module @type numpy module
unpack serialized message in str into this message instance using numpy for array types @param str : byte array of serialized message @type str : str @param numpy : numpy python module @type numpy : module
constructor . any message fields that are implicitly / explicitly set to none will be assigned a default value . the recommend use is keyword arguments as this is more robust to future message changes . you can not mix in - order arguments and keyword arguments .
serialize message into buffer @param buff : buffer @type buff : stringio
unpack serialized message in str into this message instance @param str : byte array of serialized message @type str : str
serialize message with numpy array types into buffer @param buff : buffer @type buff : stringio @param numpy : numpy python module @type numpy module
unpack serialized message in str into this message instance using numpy for array types @param str : byte array of serialized message @type str : str @param numpy : numpy python module @type numpy : module
constructor . any message fields that are implicitly / explicitly set to none will be assigned a default value . the recommend use is keyword arguments as this is more robust to future message changes . you can not mix in - order arguments and keyword arguments .
serialize message into buffer @param buff : buffer @type buff : stringio
unpack serialized message in str into this message instance @param str : byte array of serialized message @type str : str
serialize message with numpy array types into buffer @param buff : buffer @type buff : stringio @param numpy : numpy python module @type numpy module
unpack serialized message in str into this message instance using numpy for array types @param str : byte array of serialized message @type str : str @param numpy : numpy python module @type numpy : module
constructor . any message fields that are implicitly / explicitly set to none will be assigned a default value . the recommend use is keyword arguments as this is more robust to future message changes . you can not mix in - order arguments and keyword arguments .
success test with minimal complexity
"this form takes a lecturer_id or none as the first argument . if a lecturer i d is provided , it will be set as initial value for the dropdown ."
is templating used ?
"does all context binding and pathing to get content , templated out"
read file content if it is static and return content handler with no i / o
"self explanatory , input is inline content or file path ."
parse content from input node and returns contenthandler object it 'll look like :
test content and templating of it
a couple combination of templating using unicode data
test file read and templating of read files in this directory
test method that creates a copy with file read already performed
test parsing of simple content
test parsing of file content
test parsing of templated content
unicode parsing tests
test parsing of templated file path
test parsing of templated file content
test parsing of file with path and content templated
test for handling parsing of some bad input cases
just encode the object you have as value
run through all fields of the object and parse the values
"if a metronome client object exists in our context , delete any apps in marathon and wait until they die ."
